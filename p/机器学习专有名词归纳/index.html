<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="归纳了一些在机器学习中经常遇到的专有名词 特征： 模型的输入 样本： 用于训练流程的输入/输出对 标签： 模型的输出 层级： 神经网络中相互连接的节点集合。 模型： 神经网络的表示法 密集全连接层 (FC)： 一个层级中的每个节点都与上个层级中的每个节点相连。 权重和偏差： 模型的内部变量 损失： 期望输出和真实输出之间的差值 MSE： 均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕 梯度下降法： 每次小幅调整内部变量，从而逐渐降低损失函数的算法 优化器： 梯度下降法的一种具体实现方法（“Adam”优化器是 ADAptive with Momentum 的简称，并且被视为最佳优化器） 学习速率： 梯度下降过程中的损失改进“步长” 批次： 在训练神经网络的过程中使用的一组样本。 周期： 完全经过整个训练数据集一轮 前向传播： 根据输入计算输出值 反向传播： 根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层 训练集： 用于训练神经网络的数据。 测试集： 用于测试神经网络最终效果的数据 回归： 输出一个值的模型。例如，估算房屋价值。 分类： 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。 CNN： 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层 卷积： 向图像应用核（滤波器）的过程 核/滤波器： 小于输入的矩阵，用于将输入变成多个小区域 填充： 在输入图像周围添加像素，像素值通常为 0 池化： 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。 最大池化： 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。 步长： 在图像上滑动核（滤波器）的间隔像素数量。 下采样： 降低图像大小的操作 "><title>机器学习专有名词归纳</title>
<link rel=canonical href=https://wlynxg.github.io/blog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E5%BD%92%E7%BA%B3/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="机器学习专有名词归纳"><meta property='og:description' content="归纳了一些在机器学习中经常遇到的专有名词 特征： 模型的输入 样本： 用于训练流程的输入/输出对 标签： 模型的输出 层级： 神经网络中相互连接的节点集合。 模型： 神经网络的表示法 密集全连接层 (FC)： 一个层级中的每个节点都与上个层级中的每个节点相连。 权重和偏差： 模型的内部变量 损失： 期望输出和真实输出之间的差值 MSE： 均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕 梯度下降法： 每次小幅调整内部变量，从而逐渐降低损失函数的算法 优化器： 梯度下降法的一种具体实现方法（“Adam”优化器是 ADAptive with Momentum 的简称，并且被视为最佳优化器） 学习速率： 梯度下降过程中的损失改进“步长” 批次： 在训练神经网络的过程中使用的一组样本。 周期： 完全经过整个训练数据集一轮 前向传播： 根据输入计算输出值 反向传播： 根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层 训练集： 用于训练神经网络的数据。 测试集： 用于测试神经网络最终效果的数据 回归： 输出一个值的模型。例如，估算房屋价值。 分类： 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。 CNN： 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层 卷积： 向图像应用核（滤波器）的过程 核/滤波器： 小于输入的矩阵，用于将输入变成多个小区域 填充： 在输入图像周围添加像素，像素值通常为 0 池化： 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。 最大池化： 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。 步长： 在图像上滑动核（滤波器）的间隔像素数量。 下采样： 降低图像大小的操作 "><meta property='og:url' content='https://wlynxg.github.io/blog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E5%BD%92%E7%BA%B3/'><meta property='og:site_name' content="Wlynxg's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2025-08-22T17:34:52+08:00'><meta property='article:modified_time' content='2025-08-22T17:34:52+08:00'><meta name=twitter:title content="机器学习专有名词归纳"><meta name=twitter:description content="归纳了一些在机器学习中经常遇到的专有名词 特征： 模型的输入 样本： 用于训练流程的输入/输出对 标签： 模型的输出 层级： 神经网络中相互连接的节点集合。 模型： 神经网络的表示法 密集全连接层 (FC)： 一个层级中的每个节点都与上个层级中的每个节点相连。 权重和偏差： 模型的内部变量 损失： 期望输出和真实输出之间的差值 MSE： 均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕 梯度下降法： 每次小幅调整内部变量，从而逐渐降低损失函数的算法 优化器： 梯度下降法的一种具体实现方法（“Adam”优化器是 ADAptive with Momentum 的简称，并且被视为最佳优化器） 学习速率： 梯度下降过程中的损失改进“步长” 批次： 在训练神经网络的过程中使用的一组样本。 周期： 完全经过整个训练数据集一轮 前向传播： 根据输入计算输出值 反向传播： 根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层 训练集： 用于训练神经网络的数据。 测试集： 用于测试神经网络最终效果的数据 回归： 输出一个值的模型。例如，估算房屋价值。 分类： 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。 CNN： 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层 卷积： 向图像应用核（滤波器）的过程 核/滤波器： 小于输入的矩阵，用于将输入变成多个小区域 填充： 在输入图像周围添加像素，像素值通常为 0 池化： 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。 最大池化： 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。 步长： 在图像上滑动核（滤波器）的间隔像素数量。 下采样： 降低图像大小的操作 "><link rel="shortcut icon" href=/blog/favicon.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/file_hu6889846174828548036.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🐂</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Wlynxg's Blog</a></h1><h2 class=site-description>The harder, ther luckier!</h2></div></header><ol class=menu-social><li><a href=https://github.com/wlynxg target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:liuauthor@foxmail.com target=_blank title=Mail rel=me><svg t="1730733819354" class="icon" viewBox="0 0 1024 1024" p-id="3570" width="24" height="24"><path d="M942.08 200.704s-1.024.0.0.0c-1.024-2.048-1.024-4.096-2.048-6.144-1.024-1.024-2.048-3.072-3.072-4.096l-1.024-1.024-1.024-1.024c-1.024-1.024-2.048-2.048-4.096-2.048h-1.024c-2.048-1.024-3.072-1.024-5.12-1.024h-1.024C788.48 163.84 649.216 153.6 512 153.6s-276.48 10.24-412.672 30.72h-1.024c-2.048.0-3.072 1.024-5.12 1.024H92.16c-1.024 1.024-3.072 1.024-4.096 2.048l-1.024 1.024-1.024 1.024c-1.024 1.024-2.048 2.048-3.072 4.096v1.024c-1.024 2.048-1.024 3.072-2.048 5.12C61.44 304.128 51.2 408.576 51.2 512s10.24 207.872 30.72 311.296c2.048 8.192 8.192 15.36 17.408 16.384C235.52 860.16 374.784 870.4 512 870.4s276.48-10.24 412.672-30.72c8.192-1.024 15.36-8.192 17.408-16.384C962.56 719.872 972.8 615.424 972.8 512s-10.24-207.872-30.72-311.296zm-60.416 19.456c-44.032 50.176-96.256 97.28-156.672 142.336C654.336 415.744 582.656 457.728 512 489.472c-77.824-36.864-148.48-78.848-212.992-126.976-56.32-41.984-108.544-90.112-156.672-142.336 122.88-17.408 246.784-25.6 369.664-25.6s246.784 8.192 369.664 25.6zm22.528 580.608C774.144 820.224 642.048 829.44 512 829.44s-262.144-9.216-392.192-28.672C101.376 705.536 92.16 608.256 92.16 512c0-87.04 8.192-175.104 22.528-262.144 48.128 53.248 102.4 102.4 159.744 145.408 69.632 52.224 144.384 96.256 229.376 135.168 3.072 1.024 6.144 2.048 8.192 2.048 3.072.0 5.12-1.024 8.192-2.048 76.8-32.768 153.6-78.848 229.376-135.168 60.416-46.08 114.688-94.208 159.744-144.384C924.672 337.92 931.84 424.96 931.84 512c0 96.256-9.216 193.536-27.648 288.768z" p-id="3571" fill="#707070"/></svg></a></li><li><a href=/blog/index.xml target=_blank title=RSS rel=me><svg t="1730718821658" class="icon" viewBox="0 0 1024 1024" p-id="21619" width="24" height="24"><path d="M554.666667 896C529.066667 896 512 878.933333 512 853.333333 512 665.6 358.4 512 170.666667 512 145.066667 512 128 494.933333 128 469.333333s17.066667-42.666667 42.666667-42.666666c234.666667.0 426.666667 192 426.666666 426.666666.0 25.6-17.066667 42.666667-42.666666 42.666667z" p-id="21620" fill="#707070"/><path d="M853.333333 896c-25.6.0-42.666667-17.066667-42.666666-42.666667.0-354.133333-285.866667-640-640-640-25.6.0-42.666667-17.066667-42.666667-42.666666S145.066667 128 170.666667 128C571.733334 128 896 452.266667 896 853.333333 896 878.933333 878.933333 896 853.333333 896z" p-id="21621" fill="#707070"/><path d="M213.333333 810.666667m-85.333333.0a85.333333 85.333333.0 10170.666667.0 85.333333 85.333333.0 10-170.666667.0z" p-id="21622" fill="#707070"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li><a href=/blog/plan/><svg t="1730733517435" class="icon" viewBox="0 0 1024 1024" p-id="1581" width="24" height="24"><path d="M874.24 1013.76H143.36a94.72 94.72.0 01-94.72-94.72V188.16a94.72 94.72.0 0194.72-94.72h730.88a95.36 95.36.0 0194.72 94.72v730.88a94.72 94.72.0 01-94.72 94.72zM143.36 156.8a31.36 31.36.0 00-32 31.36v730.88a32 32 0 0032 32h730.88a32 32 0 0031.36-32V188.16a31.36 31.36.0 00-31.36-31.36z" fill="#707070" p-id="1582"/><path d="M926.08 399.36h-832a32 32 0 010-64h832a32 32 0 110 64zM339.84 273.28a31.36 31.36.0 01-31.36-32V39.04a31.36 31.36.0 0131.36-32 32 32 0 0132 32v202.24a32 32 0 01-32 32zm337.28.0a31.36 31.36.0 01-31.36-32V39.04a31.36 31.36.0 1164 0v202.24a31.36 31.36.0 01-32.64 32zM444.16 841.6a33.92 33.92.0 01-23.04-9.6l-128-138.24a32 32 0 1146.08-43.52L448 768l280.32-279.68a30.72 30.72.0 0144.8.0 31.36 31.36.0 010 44.16L466.56 832a32 32 0 01-22.4 9.6z" fill="#707070" p-id="1583"/></svg>
<span>Plan</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#归纳了一些在机器学习中经常遇到的专有名词>归纳了一些在机器学习中经常遇到的专有名词</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ style=background-color:#7fc7d9;color:#fff>数据分析</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E5%BD%92%E7%BA%B3/>机器学习专有名词归纳</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Aug 22, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 1 分钟</time></div></footer></div></header><section class=article-content><h3 id=归纳了一些在机器学习中经常遇到的专有名词>归纳了一些在机器学习中经常遇到的专有名词</h3><ul><li><strong>特征：</strong> 模型的输入</li><li><strong>样本：</strong> 用于训练流程的输入/输出对</li><li><strong>标签：</strong> 模型的输出</li><li><strong>层级：</strong> 神经网络中相互连接的节点集合。</li><li><strong>模型：</strong> 神经网络的表示法</li><li><strong>密集全连接层 (FC)：</strong> 一个层级中的每个节点都与上个层级中的每个节点相连。</li><li><strong>权重和偏差：</strong> 模型的内部变量</li><li><strong>损失：</strong> 期望输出和真实输出之间的差值</li><li><strong>MSE：</strong> 均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕</li><li><strong>梯度下降法：</strong> 每次小幅调整内部变量，从而逐渐降低损失函数的算法</li><li><strong>优化器：</strong> 梯度下降法的一种具体实现方法（“Adam”优化器是 ADAptive with Momentum 的简称，并且被视为最佳优化器）</li><li><strong>学习速率：</strong> 梯度下降过程中的损失改进“步长”</li><li><strong>批次：</strong> 在训练神经网络的过程中使用的一组样本。</li><li><strong>周期：</strong> 完全经过整个训练数据集一轮</li><li><strong>前向传播：</strong> 根据输入计算输出值</li><li><strong>反向传播：</strong> 根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层</li><li><strong>训练集：</strong> 用于训练神经网络的数据。</li><li><strong>测试集：</strong> 用于测试神经网络最终效果的数据</li><li><strong>回归：</strong> 输出一个值的模型。例如，估算房屋价值。</li><li><strong>分类：</strong> 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。</li><li><strong>CNN：</strong> 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层</li><li><strong>卷积：</strong> 向图像应用核（滤波器）的过程</li><li><strong>核/滤波器：</strong> 小于输入的矩阵，用于将输入变成多个小区域</li><li><strong>填充：</strong> 在输入图像周围添加像素，像素值通常为 0</li><li><strong>池化：</strong> 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。</li><li><strong>最大池化：</strong> 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。</li><li><strong>步长：</strong> 在图像上滑动核（滤波器）的间隔像素数量。</li><li><strong>下采样：</strong> 降低图像大小的操作</li></ul></section><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:!0}),document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll("pre code.language-mermaid");e.forEach(function(e){var n,t=document.createElement("div");t.className="mermaid",t.innerHTML=e.textContent,n=e.parentElement,n.parentNode.replaceChild(t,n)})})</script><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/keras-%E4%B8%AD-model.evaluate-%E5%92%8C-model.predict-%E7%9A%84%E5%8C%BA%E5%88%AB/><div class=article-details><h2 class=article-title>Keras 中 model.evaluate 和 model.predict 的区别</h2></div></a></article><article><a href=/blog/p/numpy-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E6%96%B9%E6%B3%95/><div class=article-details><h2 class=article-title>numpy 常用函数与方法</h2></div></a></article><article><a href=/blog/p/pandas-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E6%96%B9%E6%B3%95/><div class=article-details><h2 class=article-title>pandas 常用函数与方法</h2></div></a></article><article><a href=/blog/p/%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/><div class=article-details><h2 class=article-title>新闻分类：多分类问题</h2></div></a></article><article><a href=/blog/p/%E7%94%B5%E5%BD%B1%E8%AF%84%E8%AE%BA%E5%88%86%E7%B1%BB%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/><div class=article-details><h2 class=article-title>电影评论分类：二分类问题</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Wlynxg's Blog</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.29.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>