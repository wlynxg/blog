### 归纳了一些在机器学习中经常遇到的专有名词
- **特征：** 模型的输入
- **样本：** 用于训练流程的输入/输出对
- **标签：** 模型的输出
- **层级：** 神经网络中相互连接的节点集合。
- **模型：** 神经网络的表示法
- **密集全连接层 (FC)：** 一个层级中的每个节点都与上个层级中的每个节点相连。
- **权重和偏差：** 模型的内部变量
- **损失：** 期望输出和真实输出之间的差值
- **MSE：** 均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕
- **梯度下降法：** 每次小幅调整内部变量，从而逐渐降低损失函数的算法
- **优化器：** 梯度下降法的一种具体实现方法（“Adam”优化器是 ADAptive with Momentum 的简称，并且被视为最佳优化器）
- **学习速率：** 梯度下降过程中的损失改进“步长”
- **批次：** 在训练神经网络的过程中使用的一组样本。
- **周期：** 完全经过整个训练数据集一轮
- **前向传播：** 根据输入计算输出值
- **反向传播：** 根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层
- **训练集：** 用于训练神经网络的数据。
- **测试集：** 用于测试神经网络最终效果的数据
- **回归：** 输出一个值的模型。例如，估算房屋价值。
- **分类：** 一种模型，能够输出多个类别的概率分布。例如在 Fashion MNIST 模型中，输出是 10 个概率，每种服饰对应一个概率。我们在最后的密集层中使用 Softmax 激活函数创建了这个概率分布。
- **CNN：** 卷积神经网络。即至少有一个卷积层的网络。典型的 CNN 还包括其他类型的层级，例如池化层和密集层
- **卷积：** 向图像应用核（滤波器）的过程
- **核/滤波器：** 小于输入的矩阵，用于将输入变成多个小区域
- **填充：** 在输入图像周围添加像素，像素值通常为 0
- **池化：** 通过下采样降低图像大小的过程。池化层有多种类型。例如，平均池化通过求平均值将多个值变成一个值。但是最大池化是最常见的池化类型。
- **最大池化：** 一种池化过程，通过获取多个值中的最大值，将多个值变成一个值。
- **步长：** 在图像上滑动核（滤波器）的间隔像素数量。
- **下采样：** 降低图像大小的操作